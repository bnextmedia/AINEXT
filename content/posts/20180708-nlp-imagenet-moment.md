---
title: "當 NLP 終於等到它的 ImageNet 時刻"
date: 2018-07-08T00:00:00+08:00
description: "2018 年 7 月，NLP 研究者 Sebastian Ruder 在部落格上宣告：自然語言處理終於迎來了屬於自己的 ImageNet 時刻。三個預訓練模型同時爆發，從此改變了整個領域的遊戲規則。八年後回頭看，他的預言不只被驗證，而且被超額實現——語言模型不只統一了 NLP，還反過來吞掉了所有模態。"
tags: ["Sebastian Ruder", "NLP", "AI 經典文獻", "遷移學習", "預訓練模型"]
categories: ["AI 技術前沿"]
image: "/images/posts/20180708-nlp-imagenet-moment.webp"
source_url: "https://thegradient.pub/nlp-imagenet/"
source_name: "The Gradient"
draft: false
---

> 本文為「AI 經典文獻回顧」系列第八篇，介紹 Sebastian Ruder 於 2018 年 7 月發表在 The Gradient 的部落格文〈NLP's ImageNet Moment Has Arrived〉。這篇文章宣告自然語言處理正在經歷一場如同電腦視覺領域 ImageNet 革命般的範式轉移——從淺層的詞向量，走向整個模型的預訓練。

![封面圖](/images/posts/20180708-nlp-imagenet-moment.webp)

---

## NLP 研究者的隔壁家小孩焦慮

2018 年夏天，自然語言處理（NLP）的研究者有一種很深的焦慮，而這種焦慮的來源不是自己的領域出了什麼問題，是隔壁的電腦視覺過得太好了。

故事要從 2012 年說起。那一年，Alex Krizhevsky 用一個叫做 AlexNet 的深度神經網路在 ImageNet 圖像辨識比賽中碾壓了所有傳統方法——我們在系列的 AlexNet 篇章中詳細講過這段歷史。但 AlexNet 帶來的改變遠不只是一場比賽的勝負。真正深遠的影響是，它催生了一整套「預訓練加微調」的工作流程：研究者先在 ImageNet 的一千四百萬張圖片上訓練一個大型卷積神經網路，讓它學會辨認從邊緣、紋理到物體輪廓的各層次視覺特徵，然後把這個訓練好的模型拿來當起點，針對新的任務——醫療影像判讀、衛星圖分析、人臉辨識——只需要少量新資料就能微調出高水準的模型。

這套流程徹底改變了電腦視覺的研究方式。一個博士生、一個小型新創團隊，不需要自己蒐集百萬張標註圖片，只要下載一個在 ImageNet 上預訓練好的模型，就能站在巨人的肩膀上做自己的研究。到 2018 年，這已經不是前沿技術，而是電腦視覺領域的日常操作，就像呼吸一樣自然。

但 NLP 研究者回頭看看自己的領域，景況完全不同。他們手上最先進的「預訓練」工具是什麼？是 word2vec 和 GloVe——兩種把單詞映射成固定向量的方法。這些詞向量確實有用，它們捕捉到了詞彙之間的語義關係（經典的例子：「國王」減去「男人」加上「女人」等於「皇后」），讓很多 NLP 模型的表現有了顯著提升。但問題在於，詞向量只初始化了模型的第一層。你拿到的是一組固定的詞彙表示，然後自己從頭搭建模型的其他部分。

更要命的是，word2vec 和 GloVe 給每個詞一個固定的向量，不管上下文是什麼。「我去銀行存錢」和「河岸的銀行長滿了草」裡面的「銀行」（英文的 bank），對應的是同一組數字。這就像電腦視覺只預訓練了邊緣偵測那一層，對於形狀、物體、場景的更高層次理解，你得自己從零開始學。

六年了。從 AlexNet 到 2018 年，電腦視覺靠著 ImageNet 預訓練一路狂飆，而 NLP 還在用淺層的詞向量當起跑點。這不是能力差距的問題，是範式差距。

## 三箭齊發：一個範式的開關被同時按下

然後，在 2018 年的前半年，三個研究團隊幾乎同時發表了三篇論文，一起按下了那個開關。

第一支箭是 ULMFiT。2018 年 1 月，fast.ai 的 Jeremy Howard 和在愛爾蘭攻讀博士的 Sebastian Ruder 把一篇論文放上了 arXiv，標題是〈Universal Language Model Fine-tuning for Text Classification〉。這篇論文的核心想法直接從電腦視覺借來：不要只預訓練第一層，把整個語言模型都預訓練好，然後微調到下游任務。聽起來簡單，但實際操作中有一個棘手的問題——語言模型在微調時很容易「忘記」預訓練階段學到的知識，術語叫「災難性遺忘」。Howard 和 Ruder 提出了三個技巧來解決它：逐層解凍（gradual unfreezing）、分層學習率（discriminative fine-tuning）、以及一種叫做斜三角學習率（slanted triangular learning rates）的訓練策略。結果是：在六個文本分類基準測試上，ULMFiT 把錯誤率降低了 18% 到 24%。

第二支箭是 ELMo。同樣是 2018 年初，艾倫人工智慧研究所（AI2）的 Matthew Peters 和華盛頓大學的團隊發表了〈Deep Contextualized Word Representations〉。ELMo 解決的正是 word2vec 的致命弱點：一詞一義的問題。ELMo 用一個深層的雙向語言模型來生成詞的表示，同一個詞在不同句子裡會得到不同的向量。這不再是查字典式的靜態對應，而是模型真正在「讀」上下文之後才給出的動態理解。ELMo 在六個 NLP 任務上都達到了當時的最佳成績，論文在 NAACL 2018 拿到了最佳論文獎。

第三支箭是 OpenAI 的 GPT。2018 年 6 月，Alec Radford 和同事們發表了一篇用 Transformer 架構（也就是我們在系列第六篇詳細介紹過的那個架構）來做語言模型預訓練的論文。GPT 在 BooksCorpus 這個七千本未出版小說的語料庫上訓練，然後微調到各種下游任務，結果在 12 個任務裡拿了 9 個最佳成績。

三支箭的設計哲學各有不同——ULMFiT 用 LSTM，強調微調技巧；ELMo 用雙向 LSTM，強調上下文表示；GPT 用 Transformer，強調架構的擴展性——但它們指向同一個結論：NLP 的遊戲規則正在改變。過去，你預訓練的是一組詞向量，也就是模型的第一層。現在，你預訓練的是整個模型——從底層的語法結構到高層的語義理解，一次到位。

## 宣告者本身就是革命的參與者

就在這三支箭密集落地的 2018 年 7 月 8 日，Sebastian Ruder 在 The Gradient 發表了一篇部落格文，標題是：〈NLP's ImageNet Moment Has Arrived〉。

這個標題本身就是一個精準的類比。ImageNet 之於電腦視覺，不只是一個資料集，它是一個讓遷移學習成為標準操作的觸發點。Ruder 要說的是：語言模型預訓練之於 NLP，正在扮演同樣的角色。

文章的論證結構很清楚。Ruder 先回顧了電腦視覺如何因為 ImageNet 而建立起預訓練加微調的範式——模型在大規模資料上學會分層次的特徵表示，從低層的邊緣偵測到高層的物體辨識，然後這些學到的表示可以遷移到各種不同的視覺任務。接著他問：NLP 有沒有等價物？他的答案是語言模型。預測下一個詞這個看似簡單的任務，實際上要求模型學會語法結構、語義關係、常識推理、甚至情感理解。更重要的是，訓練資料幾乎無限——任何文本語料庫都可以用，不需要人工標註。

然後 Ruder 做了一個大膽的預測。他寫道：一年之內，NLP 研究者會開始下載預訓練好的語言模型，而不是預訓練好的詞向量，來作為他們專案的起點。

這個預言的有趣之處在於：說這話的人自己就是造成這個改變的人之一。Ruder 不只是一個站在旁邊觀察的評論家——他就是 ULMFiT 的共同作者，三支箭中的第一支就是他射出去的。

這段合作的緣起本身就是一個好故事。Jeremy Howard 在 fast.ai 的課程中展示了語言模型微調的早期實驗結果。Ruder 看到之後主動聯繫 Howard，告訴他這個成果值得寫成正式論文發表，而且自告奮勇說他來寫——因為他希望把這個研究放進自己正在進行的博士論文裡。於是一個在舊金山做線上教育的澳洲創業者，和一個在都柏林讀博士的德國研究生，聯手寫出了一篇改變 NLP 研究方式的論文。

Ruder 當時還是一個博士生，但他在 NLP 社群裡已經有不成比例的影響力。他經營的部落格和電子報——NLP News，是整個領域追蹤最新研究的重要來源之一。他有一種罕見的能力：既能做前沿研究，又能用清晰的文字向更廣泛的社群解釋這些研究為什麼重要。〈NLP's ImageNet Moment〉就是這種能力的完美展現——他同時是研究的參與者和意義的詮釋者。

## 三個月後，預言就被驗證了

Ruder 說一年之內，研究者會開始下載預訓練語言模型而非詞向量。他低估了速度。

2018 年 10 月 11 日——距離〈NLP's ImageNet Moment〉發表只過了三個月——Google 的 Jacob Devlin 和同事在 arXiv 上放出了 BERT 的論文。BERT 做的事情完全符合 Ruder 描繪的圖景：用 Transformer 的編碼器架構，在大量文本上做雙向的語言模型預訓練，然後微調到各種下游任務。結果是毀滅性的——BERT 在十一個 NLP 基準測試上全部刷新了最佳紀錄，其中 GLUE 綜合評分直接提升了 7.7 個百分點。

BERT 之後，洪水來了。Google 在 2019 年就把 BERT 整合進搜尋引擎，到 2020 年幾乎所有英文搜尋查詢都經過 BERT 處理。OpenAI 沿著 GPT 的路線繼續放大規模，2019 年發表了 GPT-2（15 億參數，大到 OpenAI 一度不敢公開釋出完整模型），2020 年發表了 GPT-3（1,750 億參數）。學術界和產業界的每一個 NLP 團隊，都開始把預訓練語言模型當作標準起點。

Ruder 描述的範式轉移——從只初始化第一層到預訓練整個模型——不但發生了，而且發生的速度和規模遠超他在文章中的想像。他原本的類比是 ImageNet：一個讓遷移學習成為標準操作的觸發點。但後來發生的事情遠比 ImageNet 的故事更激進。

ImageNet 預訓練模型讓電腦視覺變得更好更方便，但它沒有改變電腦視覺的基本問題結構——你還是在做圖像分類、物體偵測、語義分割這些明確定義的任務。預訓練語言模型做到的事情完全不同。它們不只是讓 NLP 的各種任務變得更容易，它們最終模糊了「任務」本身的邊界。當一個 GPT-3 或 GPT-4 可以用自然語言指令完成翻譯、摘要、問答、寫作、推理，「NLP 的下游任務」這個概念本身就開始瓦解了。

## 語言模型沒有留在 NLP 裡

Ruder 的文章也有一個他自己大概沒有預見到的後續發展。

他在 2018 年用的類比是：語言模型預訓練之於 NLP，就像 ImageNet 預訓練之於電腦視覺。這個類比假設語言模型會待在 NLP 的領域裡，就像 ImageNet 待在電腦視覺裡一樣。但事實是，語言模型沒有乖乖待在自己的車道上。

到了 2023 年，大型語言模型已經能處理圖像、音訊、影片。GPT-4 可以看圖回答問題，Gemini 可以理解影片內容，各種多模態模型把文字、圖像、聲音全部統一在同一個框架下。語言模型從 NLP 的一個工具，變成了整個 AI 領域的中心架構。

這個發展方向其實在 Ruder 的文章裡有一個微妙的線索。他指出，預測下一個詞這個任務之所以強大，是因為它迫使模型學會語法、語義、常識推理、甚至世界知識。他當時把這當作語言模型適合做 NLP 預訓練任務的理由。但如果你把這個觀察推到極致——如果一個模型為了預測文字而學會了這麼豐富的世界知識——那它為什麼要被侷限在文字任務裡？

站在 2026 年回頭看，NLP 的 ImageNet 時刻不只是 NLP 的 ImageNet 時刻。它是整個深度學習範式的一個轉折點。從那之後，語言模型逐漸成為 AI 的預設架構——如同我們在 Transformer 那篇文章中所說，注意力機制原本是為了翻譯而設計的，結果它吃掉了整個 AI。語言模型預訓練走了一條類似的路：原本是為了解決 NLP 任務的遷移學習問題，結果它定義了一整個時代。

## 正確的直覺，低估的規模

Sebastian Ruder 在寫完〈NLP's ImageNet Moment〉之後，繼續在 NLP 的多語言研究領域深耕。他先後在 Google DeepMind 和 Cohere 工作，帶領多語言團隊。2024 年 11 月，他加入了 Meta 擔任研究科學家，專注於大型語言模型的多語言能力和評估方法。他的電子報 NLP News 至今仍是追蹤自然語言處理研究的重要來源。

有意思的是，Ruder 整個職涯的軌跡就是他那篇文章的延伸。他在 2018 年主張語言模型預訓練會改變 NLP 的遊戲規則，然後他接下來的每一步——在 Google DeepMind 做多語言 NLP、在 Cohere 做企業級語言模型、在 Meta 做 LLM 評估——都是在這個被改變了的新世界裡工作。他宣告了一場革命，然後在革命之後的世界裡建設。

回到這個系列的脈絡。如果說〈數據的不合理有效性〉（2009）是規模思維的起點，AlexNet（2012）是深度學習的大爆炸，Transformer（2017）是架構的基石，Software 2.0（2017）是範式轉移的宣言，那〈NLP's ImageNet Moment〉就是預訓練時代的宣告書。它標記了一個精確的歷史節點：從這裡開始，NLP 不再是 AI 領域的配角，而是即將成為主角。

Ruder 抓對了直覺。語言模型預訓練確實是 NLP 的轉捩點。但跟我們上一篇介紹的 Karpathy 一樣，他低估了規模。他以為語言模型會成為 NLP 的 ImageNet。結果語言模型成為了整個 AI 的 ImageNet——然後它連 ImageNet 本身的領地都接管了。

在這個系列的下一篇，我們將介紹理察．薩頓（Richard Sutton）在 2019 年 3 月寫下的〈The Bitter Lesson〉。那篇只有七百字的短文會提出一個更根本的問題：為什麼規模總是贏？為什麼人類精心設計的巧思，最終總是敗給暴力計算？如果說 Ruder 宣告了預訓練時代的到來，薩頓要解釋的是：這一切背後有一個更深層的、令人不舒服的規律。
