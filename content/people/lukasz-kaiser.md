---
# === 基本資訊 ===
title: "盧卡什・凱撒 Łukasz Kaiser"
slug: "lukasz-kaiser"
name_zh: "盧卡什・凱撒"
name_en: "Łukasz Kaiser"
name_full_en: "Łukasz Kaiser"

# === 照片 ===
photo: "/images/people/lukasz-kaiser.jpg"
photo_alt: "Łukasz Kaiser"
photo_credit: "OpenAI"
photo_source: ""

# === 基本背景 ===
nationality: "波蘭"
birth_year: 1981
birth_place: "波蘭弗羅茨瓦夫"
death_year: null
residence: "美國舊金山"

# === 現職 ===
current_position: "研究員"
current_organization: "OpenAI"
current_org_slug: "openai"

# === 簡介 ===
description_short: "Transformer 論文共同作者，OpenAI 研究員"
description_long: |
  Łukasz Kaiser 是「Attention Is All You Need」論文的共同作者，也是八位作者中唯一選擇留在學術研究而非創業的人。他曾在 Google Brain 工作八年，參與開發 TensorFlow 和 Tensor2Tensor。2021 年加入 OpenAI 後，他參與了 ChatGPT、GPT-4、o1、o3 等重要產品的研發。他的論文被引用超過 34 萬次，是 AI 領域被引用最多的研究者之一。

# === 人物分類 ===
person_type: ["科學家"]
importance_level: "A"
importance_reason: "Transformer 共同作者，OpenAI 核心研究員，參與 GPT-4 和 o1/o3 推理模型開發"

# === AI 領域專長 ===
ai_domains: ["深度學習", "自然語言處理", "Transformer", "推理模型"]
ai_impact_areas: ["LLM", "GPT-4", "ChatGPT", "推理 AI"]

# === 關鍵貢獻（白話解釋）===
key_contributions:
  - title: "Transformer 架構"
    description: "作為 Google Brain 研究員參與開發 Transformer 架構"
    impact_on_llm: "所有現代 LLM 的技術基礎"
    impact_on_other: "改變 AI 領域的發展方向"
    year: 2017
  - title: "Tensor2Tensor"
    description: "共同開發 Google 的深度學習函式庫"
    impact_on_llm: "讓 Transformer 模型更容易訓練和部署"
    impact_on_other: "推動機器學習工具的標準化"
    year: 2017
  - title: "GPT-4 和 o1/o3 推理模型"
    description: "在 OpenAI 參與 GPT-4 和推理模型的核心研發"
    impact_on_llm: "推動 LLM 從「生成」走向「推理」"
    impact_on_other: "開創 AI 推理能力的新方向"
    year: 2023

# === 代表作品 ===
representative_works:
  - title: "Attention Is All You Need"
    type: "論文"
    year: 2017
    description: "提出 Transformer 架構，被引用超過 17 萬次"
    url: "https://arxiv.org/abs/1706.03762"
  - title: "GPT-4"
    type: "產品"
    year: 2023
    description: "OpenAI 最強大的語言模型之一"
    url: "https://openai.com/gpt-4"
  - title: "o1 / o3 推理模型"
    type: "產品"
    year: 2024
    description: "OpenAI 的推理能力 AI 模型"
    url: ""

# === 獲獎紀錄 ===
awards:
  - name: "NEC C&C Prize"
    year: 2024
    issuer: "NEC C&C Foundation"
    category: "computer_science"
    significance: "表彰 Transformer 團隊的開創性貢獻"

# === 學歷 ===
education:
  - institution: "弗羅茨瓦夫大學"
    institution_en: "University of Wrocław"
    degree: "電腦科學碩士"
    field: "電腦科學"
    years: "2004"
  - institution: "弗羅茨瓦夫大學"
    institution_en: "University of Wrocław"
    degree: "數學碩士"
    field: "數學"
    years: "2001"
  - institution: "亞琛工業大學"
    institution_en: "RWTH Aachen University"
    degree: "電腦科學博士"
    field: "電腦科學"
    years: "2008"
    thesis: "Logic and Games on Automatic Structures"
  - institution: "巴黎狄德羅大學"
    institution_en: "Paris Diderot University"
    degree: "特許任教資格"
    field: "電腦科學"
    years: "2013"

# === 職業經歷 ===
career_history:
  - organization: "OpenAI"
    organization_en: "OpenAI"
    position: "研究員"
    years: "2021-現在"
    org_slug: "openai"
    description: "參與 ChatGPT、GPT-4、o1/o3 等核心產品研發"
  - organization: "Google Brain"
    organization_en: "Google Brain"
    position: "研究科學家"
    years: "2013-2021"
    org_slug: "google"
    description: "開發 Transformer、TensorFlow、Tensor2Tensor"
  - organization: "法國國家科學研究中心"
    organization_en: "CNRS"
    position: "終身研究員"
    years: "2008-2013"
    org_slug: ""
    description: "數學邏輯與自動機理論研究"

# === 師承與門生 ===
mentors: []
notable_students: []

# === 重要論文 ===
publications:
  - title: "Attention Is All You Need"
    year: 2017
    venue: "NeurIPS"
    coauthors: ["Ashish Vaswani", "Noam Shazeer", "et al."]
    citations: 173000
    significance: "Transformer 原始論文"

# === 創立或參與的組織 ===
founded_companies:
  - name: "Pathway"
    year: 2020
    role: "共同創辦人"
    outcome: "數據處理公司"
    company_slug: ""

# === 重要言論 ===
notable_quotes:
  - quote: "我選擇留在研究的最前線，而不是創業。這是個人選擇，但我相信基礎研究同樣重要。"
    context: "解釋為什麼選擇加入 OpenAI 而非創業"
    date: ""
    source: ""

# === 對 AI 發展的立場 ===
ai_safety_stance: "neutral"
ai_development_view: |
  Kaiser 是一位專注於技術研究的科學家，較少公開發表對 AI 政策或安全議題的看法。他選擇在 OpenAI 繼續從事前沿研究，而非像其他 Transformer 作者一樣創業。他的工作重心是推動 AI 能力的邊界，特別是在推理和長上下文方面。

# === 相關人物 ===
related_people:
  - slug: "ashish-vaswani"
    relation: "Transformer 論文共同作者"
  - slug: "noam-shazeer"
    relation: "Transformer 論文共同作者"
  - slug: "sam-altman"
    relation: "OpenAI 執行長"

# === 相關公司 ===
related_companies:
  - slug: "openai"
    relation: "研究員"
  - slug: "google"
    relation: "前研究科學家（8 年）"

# === 社群連結 ===
social:
  personal_website: ""
  twitter: ""
  linkedin: "https://www.linkedin.com/in/lukaszkaiser/"
  github: ""
  google_scholar: "https://scholar.google.com/citations?user=JWmiQR0AAAAJ"
  wikipedia: ""

# === 延伸資源 ===
resources:
  - title: "Coursera 課程"
    url: "https://www.coursera.org/instructor/lukaszkaiser"
    type: "course"
  - title: "36Kr 專訪"
    url: "https://eu.36kr.com/en/p/3477639604803976"
    type: "interview"

# === 標籤 ===
tags: ["Transformer", "OpenAI", "GPT-4", "o1", "推理模型", "波蘭", "Google Brain"]

# === 元資料 ===
data_sources: ["LinkedIn", "Google Scholar", "36Kr", "Coursera"]
last_updated: "2026-01-26"
update_notes: "初始建檔"
draft: false
---

## 一句話認識他

**Łukasz Kaiser 是 Transformer 八位作者中唯一沒有創業的人——他選擇留在研究前線，現在在 OpenAI 開發 GPT-4 和 o1/o3 推理模型。**

---

## 為什麼重要？

在「Transformer 八人幫」中，Łukasz Kaiser 是一個獨特的存在。

其他七位作者離開 Google 後，都選擇了創業：Vaswani 創立 Essential AI，Shazeer 創立 Character.AI，Gomez 創立 Cohere，Polosukhin 創立 NEAR Protocol，Jones 創立 Sakana AI，Parmar 先創業後加入 Anthropic，Uszkoreit 創立 Inceptive。

只有 Kaiser 選擇了不同的路。

2021 年，他離開待了八年的 Google Brain，加入 OpenAI。不是為了創業，而是為了繼續做研究。

這個選擇被證明是正確的。在 OpenAI，Kaiser 參與了 ChatGPT、GPT-4、GPT-5 的核心研發，還共同發明了 o1 和 o3 推理模型。這些產品定義了這個時代的 AI 能力邊界。

Kaiser 的論文被引用超過 34 萬次，是 AI 領域被引用最多的研究者之一。他證明了一件事：在 AI 時代，留在研究前線同樣可以產生巨大影響。

---

## 關鍵貢獻

### 1. Transformer 架構（2017）

Kaiser 是「Attention Is All You Need」論文的八位共同作者之一。在 Google Brain，他專注於機器翻譯和自然語言處理研究。

### 2. TensorFlow 和 Tensor2Tensor

Kaiser 參與開發了 TensorFlow（Google 的機器學習框架）和 Tensor2Tensor（專為 Transformer 設計的函式庫）。這些工具讓全世界的研究者都能使用 Transformer。

### 3. GPT-4 和推理模型（2023-2024）

在 OpenAI，Kaiser 參與了多個重要專案：
- **GPT-4**：OpenAI 最強大的語言模型之一
- **長上下文學習**：讓模型能處理更長的文本
- **o1 和 o3**：新一代推理模型，專注於複雜問題解決

---

## 人生軌跡

### 波蘭到法國：學術之路（1981-2013）

Łukasz Kaiser 1981 年出生於波蘭弗羅茨瓦夫。他在弗羅茨瓦夫大學取得電腦科學和數學的雙碩士學位，然後到德國亞琛工業大學攻讀博士，研究數學邏輯和自動機理論。

博士畢業後，他在法國國家科學研究中心（CNRS）擔任終身研究員，專注於理論電腦科學。這段經歷為他後來的 AI 研究奠定了堅實的數學基礎。

### Google Brain（2013-2021）

2013 年，Kaiser 做了一個重大轉變：離開終身職的學術崗位，加入 Google Brain。他的研究方向從純理論轉向機器學習的實際應用。

在 Google Brain，他參與了多項重要工作：
- 機器翻譯的神經網路模型
- TensorFlow 和 Tensor2Tensor 的開發
- **2017 年的 Transformer 論文**

### OpenAI（2021-現在）

當其他 Transformer 作者紛紛離開 Google 創業時，Kaiser 選擇加入 OpenAI。

在 OpenAI，他的工作重心是推動模型能力的邊界：
- 參與 GPT-4 的研發
- 研究長上下文學習
- 共同發明 o1 和 o3 推理模型

Kaiser 是 OpenAI 最資深的研究員之一，他的工作直接影響了數億人使用的產品。

---

## 觀點與立場

### 選擇研究而非創業

Kaiser 是八位 Transformer 作者中唯一沒有創業的人。他曾解釋說，這是個人選擇——他相信基礎研究同樣重要，而且他更享受解決技術問題而非經營公司。

### 專注於技術

相較於一些 AI 領袖經常對政策、安全、社會影響發表意見，Kaiser 相對低調。他的重心始終是技術本身——如何讓 AI 更強大、更可靠、更有用。

---

## 延伸閱讀

### 推薦資源

- **Coursera 課程**：Kaiser 在 Coursera 開設的深度學習課程
- **36Kr 專訪**："From Transformer to GPT-5: Hear First-Principles Thinking About Large Models"

---

## 相關人物

- **[Ashish Vaswani](/people/ashish-vaswani/)**：Transformer 論文第一作者
- **[Noam Shazeer](/people/noam-shazeer/)**：Transformer 共同作者
- **[Sam Altman](/people/sam-altman/)**：OpenAI 執行長
