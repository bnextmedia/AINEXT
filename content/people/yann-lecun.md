---
# ═══════════════════════════════════════════════════════════════
# 基本資訊
# ═══════════════════════════════════════════════════════════════
title: "楊立昆"
slug: "yann-lecun"
name_en: "Yann LeCun"
name_zh: "楊立昆"
nickname: "AI 教父、卷積神經網路之父"
name_variations:
  - "LeCun"
  - "CNN 之父"
  - "深度學習三巨頭"
  - "AI Godfather"

# ═══════════════════════════════════════════════════════════════
# 照片
# ═══════════════════════════════════════════════════════════════
photo: "/images/people/yann-lecun.jpg"
photo_alt: "Yann LeCun 頭像照"
photo_credit: "Wikimedia Commons, CC BY-SA 4.0"
photo_source_url: "https://commons.wikimedia.org/wiki/Category:Yann_LeCun"
photo_year: 2024

# ═══════════════════════════════════════════════════════════════
# 個人背景
# ═══════════════════════════════════════════════════════════════
nationality: "法國/美國"
birth_year: 1960
birthplace: "法國蘇瓦西蘇蒙莫朗西"

# ═══════════════════════════════════════════════════════════════
# 現職
# ═══════════════════════════════════════════════════════════════
current_position: "Chief AI Scientist（離職中）、教授"
current_organization: "Meta AI / NYU"
current_org_slug: "meta"

# ═══════════════════════════════════════════════════════════════
# 人物分類
# ═══════════════════════════════════════════════════════════════
person_type:
  - "科學家"
  - "圖靈獎得主"
  - "創辦人"

ai_domain:
  - "深度學習"
  - "卷積神經網路"
  - "電腦視覺"
  - "世界模型"
  - "自監督學習"

ai_impact_areas:
  - "圖像辨識"
  - "電腦視覺"
  - "自駕車"
  - "醫療影像"
  - "文字辨識"

# ═══════════════════════════════════════════════════════════════
# 重要性標籤
# ═══════════════════════════════════════════════════════════════
importance_level: "A"
importance_summary: "卷積神經網路（CNN）發明人，讓機器能夠「看見」世界。他的 LeNet 架構奠定了現代電腦視覺的基礎，影響從人臉辨識到自駕車的所有視覺 AI 應用"

key_contributions:
  - "卷積神經網路（CNN）發明"
  - "LeNet 架構"
  - "反向傳播演算法的早期實作"
  - "能量基礎模型"
  - "自監督學習推動"
  - "世界模型與 JEPA 架構"

# ═══════════════════════════════════════════════════════════════
# 獎項與榮譽
# ═══════════════════════════════════════════════════════════════
awards:
  - name: "ACM 圖靈獎"
    year: 2018
    category: "計算機科學"
    shared_with: ["Geoffrey Hinton", "Yoshua Bengio"]
    citation: "for conceptual and engineering breakthroughs that have made deep neural networks a critical component of computing"
  - name: "伊麗莎白女王工程獎"
    year: 2025
    category: "工程"
    shared_with: ["Geoffrey Hinton", "Yoshua Bengio", "John Hopfield", "Fei-Fei Li", "Jensen Huang", "Bill Dally"]
    citation: ""
  - name: "IEEE Neural Network Pioneer Award"
    year: 2014
    category: "神經網路"
    shared_with: []
    citation: ""

# ═══════════════════════════════════════════════════════════════
# 學經歷
# ═══════════════════════════════════════════════════════════════
education:
  - institution: "巴黎第六大學（Université Pierre et Marie Curie）"
    degree: "電腦科學博士"
    year: 1987
  - institution: "ESIEE Paris"
    degree: "電機工程學位"
    year: 1983

career_history:
  - organization: "Meta (Facebook)"
    position: "Chief AI Scientist"
    years: "2013-2025"
    org_slug: "meta"
    highlight: "創立 Meta AI Research，推動開源 AI 模型"
  - organization: "NYU"
    position: "Jacob T. Schwartz Professor"
    years: "2003-至今"
    org_slug: ""
    highlight: "創立 NYU 資料科學中心"
  - organization: "AT&T Bell Labs"
    position: "研究員"
    years: "1988-1996"
    highlight: "發明卷積神經網路、LeNet"
  - organization: "多倫多大學"
    position: "博士後研究員"
    years: "1987-1988"
    highlight: "師從 Geoffrey Hinton"

# ═══════════════════════════════════════════════════════════════
# 代表性著作/論文
# ═══════════════════════════════════════════════════════════════
key_publications:
  - title: "Gradient-Based Learning Applied to Document Recognition"
    year: 1998
    venue: "Proceedings of the IEEE"
    coauthors: ["Léon Bottou", "Yoshua Bengio", "Patrick Haffner"]
    citation_count: "50,000+"
    significance: "LeNet-5 論文，卷積神經網路的奠基之作"
  - title: "Backpropagation Applied to Handwritten Zip Code Recognition"
    year: 1989
    venue: "Neural Computation"
    coauthors: ["B. Boser", "J. S. Denker", "等"]
    citation_count: "10,000+"
    significance: "首次將反向傳播成功應用於真實世界問題"
  - title: "A Path Towards Autonomous Machine Intelligence"
    year: 2022
    venue: "預印本"
    coauthors: []
    citation_count: "1,000+"
    significance: "提出 JEPA 架構和世界模型願景"
  - title: "Deep Learning"
    year: 2015
    venue: "Nature"
    coauthors: ["Yoshua Bengio", "Geoffrey Hinton"]
    citation_count: "70,000+"
    significance: "深度學習的里程碑綜述論文"

# ═══════════════════════════════════════════════════════════════
# 創業經歷
# ═══════════════════════════════════════════════════════════════
founded_companies:
  - name: "Meta AI Research"
    year: 2013
    outcome: "全球最大的企業 AI 研究機構之一"
    description: "Facebook/Meta 的 AI 研究部門"
  - name: "NYU 資料科學中心"
    year: 2012
    outcome: "運作中"
    description: "創立並擔任首任主任"
  - name: "Advanced Machine Intelligence (AMI Labs)"
    year: 2025
    outcome: "創業中"
    description: "專注於世界模型的新創公司，估值 35 億美元"

# ═══════════════════════════════════════════════════════════════
# 師承與門生
# ═══════════════════════════════════════════════════════════════
mentors:
  - name: "Geoffrey Hinton"
    relation: "博士後導師（多倫多大學）"

notable_students:
  - name: "Marc'Aurelio Ranzato"
    current_role: "Google DeepMind"
    people_slug: ""
  - name: "Rob Fergus"
    current_role: "DeepMind、NYU 教授"
    people_slug: ""
  - name: "Léon Bottou"
    current_role: "Meta AI"
    people_slug: ""

# ═══════════════════════════════════════════════════════════════
# 重要觀點與言論
# ═══════════════════════════════════════════════════════════════
notable_quotes:
  - quote: "大型語言模型是通往人類級智慧的死路"
    context: "批評當前 LLM 路線"
    date: "2025-11"
    source: "公開演講"
  - quote: "AGI 還要幾十年。那些說一兩年內就會實現的人完全是妄想"
    context: "談 AGI 時間線"
    date: "2024"
    source: "訪談"
  - quote: "我們不需要能背誦百科全書的 AI，我們需要能用眼睛和手理解世界的 AI"
    context: "談世界模型"
    date: "2025"
    source: "LinkedIn"
  - quote: "任何一隻家貓都能規劃複雜的行動，牠們有世界的因果模型"
    context: "批評當前 AI 缺乏真正理解"
    date: "2024"
    source: "訪談"

stance_on_ai_safety: "樂觀派/務實派"
ai_safety_summary: "相對樂觀，認為 AGI 還很遙遠，不贊同 AI 末日論。主張開源 AI 研究，反對過度監管。認為 LLM 路線無法達到真正智慧，需要世界模型"

# ═══════════════════════════════════════════════════════════════
# 關聯
# ═══════════════════════════════════════════════════════════════
related_people:
  - slug: "geoffrey-hinton"
    relation: "博士後導師、圖靈獎共同得主"
  - slug: "yoshua-bengio"
    relation: "圖靈獎共同得主、長期合作者"
  - slug: "mark-zuckerberg"
    relation: "前老闆（Meta）"

related_companies:
  - slug: "meta"
    relation: "前任職（Chief AI Scientist）"

# ═══════════════════════════════════════════════════════════════
# 社群連結
# ═══════════════════════════════════════════════════════════════
social:
  twitter: "https://twitter.com/ylecun"
  linkedin: "https://www.linkedin.com/in/yann-lecun/"
  google_scholar: "https://scholar.google.com/citations?user=WLN3QrAAAAAJ"
  wikipedia_en: "https://en.wikipedia.org/wiki/Yann_LeCun"
  wikipedia_zh: ""
  personal_website: "http://yann.lecun.com/"

# ═══════════════════════════════════════════════════════════════
# 搜尋關鍵字
# ═══════════════════════════════════════════════════════════════
tags:
  - "Yann LeCun"
  - "楊立昆"
  - "卷積神經網路"
  - "CNN"
  - "LeNet"
  - "圖靈獎"
  - "Meta AI"
  - "Facebook AI"
  - "NYU"
  - "電腦視覺"
  - "深度學習"
  - "AI 教父"
  - "世界模型"
  - "JEPA"
  - "AMI Labs"

# ═══════════════════════════════════════════════════════════════
# 元資料
# ═══════════════════════════════════════════════════════════════
description: "楊立昆（Yann LeCun）是「卷積神經網路之父」，2018 年圖靈獎得主。他發明的 CNN 讓機器能夠「看見」，奠定了從人臉辨識到自駕車的所有電腦視覺應用的基礎。他曾任 Meta 首席 AI 科學家，2025 年離開創辦專注於「世界模型」的 AI 新創。"
last_updated: "2026-01-26"
data_sources: ["Wikipedia", "Google Scholar", "ACM", "Meta AI", "NYU"]
draft: false
---

## 一句話認識他

> **楊立昆發明了卷積神經網路（CNN），讓機器能夠「看見」——你手機的人臉解鎖、Google 相簿的圖像搜尋、特斯拉的自動駕駛，全都建立在他的發明之上。**

---

## 為什麼他對 AI 如此重要？

打開手機，讓它辨識你的臉。這個動作背後，是一種叫做「卷積神經網路」（CNN）的技術在運作——而這正是楊立昆在 1980 年代發明的。

當時，讓電腦「看懂」圖像是一個極其困難的問題。傳統方法需要工程師手動設計各種規則來辨識邊緣、形狀、紋理，效果差且難以擴展。

楊立昆的突破性想法是：**讓機器自己學習如何看**。

他設計的卷積神經網路模仿了生物視覺系統的運作方式：

1. 第一層神經元負責辨識簡單的邊緣和線條
2. 第二層把邊緣組合成簡單的形狀
3. 第三層把形狀組合成部件（如眼睛、鼻子）
4. 最後幾層把部件組合成完整的物體（如人臉）

這種「層層抽象」的架構，讓機器能夠從原始像素中自動學習到有意義的視覺特徵。

1990 年代，楊立昆在 AT&T Bell Labs 開發的 LeNet 系統被部署到銀行，用於辨識手寫支票上的數字。巔峰時期，全美 10-20% 的支票都是由他的系統處理的。

但 CNN 的真正爆發要等到 2012 年——當年他的「徒孫」Alex Krizhevsky（Hinton 的學生）用 CNN 架構的 AlexNet 在 ImageNet 競賽中大獲全勝，正式開啟深度學習革命。

今天，CNN 無所不在：

- **手機**：人臉解鎖、相機美顏
- **醫療**：X 光片、CT 掃描的自動診斷
- **自駕車**：識別行人、車輛、交通標誌
- **社群媒體**：自動標記照片中的朋友
- **安防**：監控攝影機的人臉辨識

楊立昆與 Geoffrey Hinton、Yoshua Bengio 並稱「深度學習三巨頭」，三人在 2018 年共同獲得圖靈獎。

---

## 關鍵貢獻

### 卷積神經網路 CNN（1989）

1989 年，楊立昆發表了將反向傳播成功應用於手寫數字辨識的論文，標誌著 CNN 的誕生。

**技術原理（白話版）**：

想像你在辨認一個數字「8」。你不會一個像素一個像素地看，而是會注意到「上面有個圓圈、下面也有個圓圈」這種**局部特徵**。

CNN 做的就是同樣的事：

1. **卷積層**：用一個小的「濾波器」（比如 5×5 像素）在整張圖像上滑動，找出局部特徵（如邊緣、角落）
2. **池化層**：把圖像縮小，保留最重要的特徵，丟掉不重要的細節
3. **重複幾次**：特徵越來越抽象，從「邊緣」→「形狀」→「部件」→「物體」
4. **全連接層**：最後把所有特徵綜合起來，做出判斷

這種架構有兩個巨大的優勢：

- **參數少**：同一個濾波器可以重複使用在圖像的不同位置，不用為每個像素學習獨立的參數
- **平移不變性**：不管數字「8」出現在圖像的左邊還是右邊，都能被正確辨識

### LeNet 架構（1998）

1998 年，楊立昆發表了影響深遠的 LeNet-5 論文〈Gradient-Based Learning Applied to Document Recognition〉。

LeNet-5 是一個 7 層的神經網路，專門設計來辨識手寫數字。雖然以今天的標準來看很簡單（只有幾萬個參數），但它確立了 CNN 的基本架構模式，至今仍被廣泛使用。

這篇論文被引用超過 5 萬次，是電腦視覺領域最重要的論文之一。

### 世界模型與 JEPA（2022-2025）

近年來，楊立昆把注意力轉向「世界模型」（World Models）——他認為這是通往真正人工智慧的正確道路。

2022 年，他發表〈A Path Towards Autonomous Machine Intelligence〉，提出 JEPA（Joint Embedding Predictive Architecture）架構。

**核心觀點**：

當前的大型語言模型（LLM）只會處理文字，缺乏對物理世界的理解。楊立昆認為，真正的智慧需要「世界模型」——能夠：

- 理解物理世界的運作規律
- 預測行動的後果
- 進行長期規劃

他用一個生動的比喻：「任何一隻家貓都能規劃複雜的行動，牠們有世界的因果模型。」——暗示當前最強大的 LLM 連貓都不如。

2025 年，楊立昆離開 Meta，創辦 AMI Labs（Advanced Machine Intelligence Labs），專注於開發世界模型。據報導，這家新創公司估值達 35 億美元。

---

## 人生軌跡

### 早年與求學

1960 年 7 月 8 日，楊立昆出生於法國巴黎近郊。他的父親是工程師，從小就鼓勵他對電子學的興趣。

1983 年，他在 ESIEE Paris 取得電機工程學位，隨後在巴黎第六大學攻讀博士。他的博士論文研究「連接主義學習模型」，提出了反向傳播演算法的早期版本。

### Bell Labs 黃金時代（1988-1996）

1987 年博士畢業後，楊立昆先到多倫多大學跟 Geoffrey Hinton 做了一年博士後研究。這段經歷讓他與深度學習的另外兩位「教父」建立了終身的友誼和合作關係。

1988 年，他加入 AT&T Bell Labs——當時世界上最頂尖的研究機構之一。在這裡，他發明了卷積神經網路，並把它成功應用於手寫數字辨識。

他開發的系統被 NCR 公司部署到銀行，用於自動讀取支票。這是神經網路首次大規模商業應用，證明了深度學習在真實世界中的價值。

### 學術與產業的雙棲（2003-2013）

2003 年，楊立昆加入紐約大學（NYU），擔任電腦科學教授。他在這裡繼續推動深度學習研究，並於 2012 年創立 NYU 資料科學中心，擔任首任主任。

這段時期，他與 Hinton、Bengio 持續合作，共同推動深度學習從邊緣走向主流。

### Meta 首席 AI 科學家（2013-2025）

2013 年 12 月，Facebook（現 Meta）創辦人祖克柏親自邀請楊立昆加入，創立並領導公司的 AI 研究部門。

作為 Meta AI Research 的創始總監和首席 AI 科學家，楊立昆做了幾件重要的事：

1. **建立世界級研究團隊**：招募數百位頂尖 AI 研究者
2. **推動開源**：主導開源 PyTorch 深度學習框架、LLaMA 大型語言模型
3. **平衡學術與產業**：同時保持 NYU 的教職，維持學術獨立性

然而，隨著 Meta 越來越專注於「快速部署 AI 產品」，楊立昆與公司的路線分歧越來越大。他公開批評 LLM 是「死路」，主張需要全新的技術方向。

### 離開 Meta，創辦 AMI Labs（2025）

2025 年 11 月，楊立昆宣布離開工作了 12 年的 Meta，創辦新公司 AMI Labs（Advanced Machine Intelligence Labs）。

他在 LinkedIn 上寫道，新公司將專注於建造「能理解物理世界、有持久記憶、能推理、能規劃複雜行動序列的系統」——這正是他認為當前 LLM 無法做到的事情。

據報導，AMI Labs 已獲得 35 億美元估值的融資，將在巴黎設立總部。

---

## 師承與門生

楊立昆的學術傳承橫跨學術界和產業界。

**師承**：他在多倫多大學的博士後導師是 Geoffrey Hinton。這段經歷讓三位「AI 教父」（Hinton、LeCun、Bengio）建立了終身的友誼——他們在「AI 寒冬」期間互相支持，共同堅持神經網路研究。

**門生**：楊立昆在 NYU 和 Meta 培養了大量人才：

- **Léon Bottou**：隨機梯度下降優化的重要貢獻者
- **Rob Fergus**：電腦視覺專家，現任 DeepMind 研究員兼 NYU 教授
- **Marc'Aurelio Ranzato**：稀疏編碼和深度學習專家，現任 Google DeepMind

---

## 獎項與榮譽

### 2018 年 ACM 圖靈獎

楊立昆與 Geoffrey Hinton、Yoshua Bengio 共同獲得 2018 年圖靈獎，表彰三人對深度學習的開創性貢獻。

頒獎詞指出：「LeCun、Hinton 和 Bengio 發展的概念性和工程性突破，使深度神經網路成為計算的關鍵組成部分。」

### 2025 年伊麗莎白女王工程獎

2025 年，楊立昆再度獲得肯定，與 Geoffrey Hinton、Yoshua Bengio、John Hopfield、李飛飛、黃仁勳、Bill Dally 共同獲得伊麗莎白女王工程獎。

### 學術榮譽

- 美國國家科學院院士
- 美國國家工程院院士
- 法國科學院院士
- 2014 年 IEEE Neural Network Pioneer Award

---

## 觀點與立場

### 對 LLM 的批評

楊立昆是 AI 領域中對當前「大型語言模型熱潮」最直言不諱的批評者之一。

他的核心論點是：**LLM 永遠無法達到人類級別的智慧**。

原因是 LLM 只在文字上訓練，缺乏對物理世界的理解。它們可以生成流暢的文字，但無法真正「理解」文字背後的含義。

他在 2025 年的一次演講中說：「那些說 AGI 一兩年內就會實現的人，完全是妄想。因為真實世界比他們想像的複雜太多了。你不可能靠把世界 tokenize 然後用 LLM 處理來達成目標。」

### 對 AGI 時間線的預測

與許多 AI 研究者不同，楊立昆認為 AGI（通用人工智慧）還需要**幾十年**才能實現，而不是幾年。

他認為，當前的 AI 研究走在錯誤的道路上——需要全新的技術突破，特別是「世界模型」。

### 對 AI 安全的立場

相比 Hinton 和 Bengio 的「警告派」立場，楊立昆是相對的「樂觀派」：

- 他**不認為 AI 會很快超越人類**
- 他**反對過度監管**，擔心會阻礙創新
- 他**支持開源 AI 研究**，認為這樣更安全（因為更多人可以檢視和改進）

### 重要發言摘錄

> 「大型語言模型是通往人類級智慧的死路。」
>
> ——2025 年 11 月

> 「AGI 還要幾十年。那些說一兩年內就會實現的人完全是妄想。」
>
> ——2024 年

> 「我們不需要能背誦百科全書的 AI，我們需要能用眼睛和手理解世界的 AI。」
>
> ——2025 年

> 「任何一隻家貓都能規劃複雜的行動，牠們有世界的因果模型。」
>
> ——2024 年，暗示當前 AI 連貓都不如

---

## 延伸閱讀

### 推薦演講

- [Yann LeCun 圖靈獎演講](https://amturing.acm.org/award_winners/lecun_2027699.cfm)

### 重要論文

- [Gradient-Based Learning Applied to Document Recognition (1998)](http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf)
- [A Path Towards Autonomous Machine Intelligence (2022)](https://openreview.net/pdf?id=BZ5a1r-kVsf)
- [Deep Learning (Nature, 2015)](https://www.nature.com/articles/nature14539)

### 相關報導

- [Fortune: The rise of Yann LeCun](https://fortune.com/2025/11/11/who-is-yann-lecun-career-meta-ai-chief-scientist-nyu-turing/)
- [科學人：世界模型可能開啟 AI 的下一場革命](https://www.scientificamerican.com/article/world-models-could-unlock-the-next-revolution-in-artificial-intelligence/)

---

## 照片來源建議

以下是可供挑選的 Yann LeCun 照片來源：

1. **Wikimedia Commons**：有多張 CC 授權照片
   - [Wikimedia Commons: Yann LeCun](https://commons.wikimedia.org/wiki/Category:Yann_LeCun)

2. **Meta AI 官網**：有官方肖像照
   - [Meta AI: Yann LeCun](https://ai.meta.com/people/396469589677838/yann-lecun/)

3. **個人網站**：有各種場合的照片
   - [yann.lecun.com](http://yann.lecun.com/)

建議選用 Meta AI 官網或近期演講的照片，呈現其作為科技領袖的形象。

---

## 相關人物

- [傑佛瑞・辛頓 Geoffrey Hinton](/people/geoffrey-hinton/)：博士後導師、圖靈獎共同得主
- [約書亞・班吉歐 Yoshua Bengio](/people/yoshua-bengio/)：圖靈獎共同得主、長期合作者
