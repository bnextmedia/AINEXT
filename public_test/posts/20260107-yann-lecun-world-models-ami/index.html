<!DOCTYPE html>
<html lang="en" >
  <head>
  <title>Yann le cun： llm 永遠無法達到人類智慧，世界模型才是正途 | AINEXT</title>
  <meta charset='utf-8'>
  <meta name="viewport" content ="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">


<meta name="keywords" content="AINEXT">
<meta property="og:locale" content='en_US'>
<meta property="og:type" content="article">
<meta property="og:title" content="Yann LeCun：LLM 永遠無法達到人類智慧，世界模型才是正途">
<meta property="og:description" content="
本文整理自 The Information Bottleneck Podcast 2025 年 12 月播出的單集。


  
    ">
<meta property="og:url" content="https://bnextmedia.github.io/AINEXT/posts/20260107-yann-lecun-world-models-ami/">
<meta property="og:image" content="https://bnextmedia.github.io/AINEXT/images/images/logo.png">
<link rel="canonical" href="https://bnextmedia.github.io/AINEXT/posts/20260107-yann-lecun-world-models-ami/">

<link rel="apple-touch-icon" sizes="180x180" href='https://bnextmedia.github.io/AINEXT/apple-touch-icon.png'>
<link rel="icon" type="image/png" sizes="32x32" href='https://bnextmedia.github.io/AINEXT/favicon-32x32.png'>
<link rel="icon" type="image/png" sizes='16x16' href='https://bnextmedia.github.io/AINEXT/favicon-16x16.png'>
<link rel="manifest" href='https://bnextmedia.github.io/AINEXT/site.webmanifest'>

<link rel="stylesheet" href="https://bnextmedia.github.io/AINEXT/css/styles.648e60c6d86809f863ae1346848574b9c685732794e7851c7d3e557de9ddd293bc1c209f963d5041785c2fd4268470bdfde453a99f550b655d1b4f825eed4682.css" integrity="sha512-ZI5gxthoCfhjrhNGhIV0ucaFcyeU54UcfT5Vfend0pO8HCCflj1QQXhcL9QmhHC9/eRTqZ9VC2VdG0&#43;CXu1Ggg==">
</head>

  <body>
    <div class="nav-drop">
  <div class="nav-body">
      <a href="https://bnextmedia.github.io/AINEXT/" class="nav_item">首頁</a>
      <a href="https://bnextmedia.github.io/AINEXT/archives/" class="nav_item">文章列表</a>
    <div class="nav-close"></div><div class="color_mode">
  <label for="mode">Toggle Dark Mode</label>
  <input type="checkbox" class="color_choice" id="mode">
</div>

  </div>
</div>
<header class="nav">
  <nav class="nav-menu">
    <a href=https://bnextmedia.github.io/AINEXT/ class="nav-brand nav_item">
        <img src="https://bnextmedia.github.io/AINEXT/images/logo.png" alt="AINEXT " class="logo-light" width="130px" />
        <img src="https://bnextmedia.github.io/AINEXT/images/logo-dark.png" alt="AINEXT " class="logo-dark" width="130px" /></a>
    
    
    <div class="nav-links">
        <a href="https://bnextmedia.github.io/AINEXT/" class="nav-link">首頁</a>
        <a href="https://bnextmedia.github.io/AINEXT/archives/" class="nav-link">文章列表</a>
    </div>
    
    <div class="nav_bar-wrap">
      <div class="nav_bar"></div>
    </div>
  </nav>
</header>

<style>
 
.nav-links {
  display: flex;
  flex-direction: row;
  gap: 1.5rem;
  align-items: center;
  white-space: nowrap;
}

.nav-link {
  color: var(--text);
  text-decoration: none;
  font-size: 0.95rem;
  padding: 0.5rem 0;
  transition: color 0.2s ease;
}

.nav-link:hover {
  color: var(--theme);
}

 
@media (min-width: 768px) {
  .nav_bar-wrap {
    display: none;
  }
}

 
@media (max-width: 767px) {
  .nav-links {
    display: none;
  }
  
  .nav_bar-wrap {
    display: grid;
  }
}

 
.logo-dark {
  display: none;
}

html[data-mode="dark"] .logo-light {
  display: none;
}

html[data-mode="dark"] .logo-dark {
  display: block;
}

 
@media (prefers-color-scheme: dark) {
  html:not([data-mode="light"]) .logo-light {
    display: none;
  }
  
  html:not([data-mode="light"]) .logo-dark {
    display: block;
  }
}

 
.nav {
  position: relative !important;
  background: var(--bg);
  padding: 0.5rem 0;
  border-bottom: 1px solid var(--border);
}

.mt {
  margin-top: 2rem !important;
}

 
.post {
  padding-top: 1rem;
}

.post_date {
  margin-top: 0;
}

 
.archive {
  padding-top: 1rem;
}

.archive_title {
  margin-top: 0;
}
</style>


    <main>
      
  <div class="wrap mt post">
    <div><p class=post_date>07. January 2026</p>
      <h1 class="post_title">Yann LeCun：LLM 永遠無法達到人類智慧，世界模型才是正途</h1>
      <div class="post_body">
        <div class="post_inner">
        
        
          <blockquote>
<p>本文整理自 The Information Bottleneck Podcast 2025 年 12 月播出的單集。</p>
</blockquote>
<div class="media-embed">
  <div class="video-container">
    <iframe 
      src="https://www.youtube.com/embed/7u-DXVADyhc" 
      allowfullscreen 
      title="YouTube Video"
      loading="lazy"
    ></iframe>
  </div>
</div>

<style>
.media-embed {
  max-width: 100%;
  margin: 1rem 0;
}

.video-container {
  position: relative;
  padding-bottom: 56.25%;
  height: 0;
  overflow: hidden;
}

.video-container iframe {
  position: absolute;
  top: 0;
  left: 0;
  width: 100%;
  height: 100%;
  border: 0;
  border-radius: 12px;
}
</style>

<hr>
<h2 id="65-歲創業為什麼離開-meta">65 歲創業：為什麼離開 Meta？</h2>
<p>Yann LeCun 在 Meta 待了 12 年，一手創建了 FAIR（Fundamental AI Research Lab），推動開放研究文化，讓 PyTorch 成為業界標準。然而，他觀察到產業風向正在改變——不只是 OpenAI，連 Google 和 Meta 都開始變得封閉，減少發表論文。</p>
<p>「如果你不發表，你很容易被自己騙。」LeCun 說。他堅信研究必須公開，讓社群檢驗，否則只會陷入內部炒作的迷思。</p>
<p>這促使他在 65 歲創辦 Advanced Machine Intelligence（AMI），專注於世界模型（World Models）與規劃能力。公司在巴黎和紐約都設有辦公室，刻意避開矽谷的「單一文化」。</p>
<p><strong>他的使命很簡單：增加世界上的智慧總量。</strong></p>
<p>「智慧是最稀缺的資源，」他說，「這就是為什麼我們花這麼多資源在教育上。增加智慧對人類和地球都是好事。」</p>
<hr>
<h2 id="llm-的根本問題處理不了真實世界">LLM 的根本問題：處理不了真實世界</h2>
<p>LeCun 對大型語言模型的批評一針見血：</p>
<blockquote>
<p>「我們永遠、永遠不可能只靠訓練文字就達到人類等級的 AI。這根本不會發生。」</p>
</blockquote>
<p>他的論點基於資料量的對比。訓練一個頂級 LLM 需要約 32 兆個 token（約 10^14 bytes），相當於網路上幾乎所有可用的文字資料。但這麼多資料換算成影片，只有 15,000 小時——大約等於：</p>
<ul>
<li>30 分鐘的 YouTube 上傳量</li>
<li>一個四歲小孩一生看過的視覺資訊</li>
</ul>
<p>問題在於，文字資料是由孤立事實組成的，冗餘度低。但真實世界的資料（如影片）有著豐富的結構和冗餘性，這正是自監督學習能發揮的地方。</p>
<p><strong>LLM 無法處理高維度、連續、有雜訊的資料</strong>——這正是現實世界的特性。你不能用離散的 token 來表示空氣流動、物體碰撞、或是一杯咖啡被打翻時液體的物理行為。</p>
<hr>
<h2 id="世界模型不是模擬器">世界模型不是模擬器</h2>
<p>很多人誤解世界模型，以為它要像《星艦迷航》的全息甲板一樣重現每個細節。LeCun 說這完全搞錯方向。</p>
<p>他用計算流體力學（CFD）舉例：工程師模擬飛機周圍的氣流時，不會去模擬每個空氣分子的碰撞，而是用抽象的方式——把空間切成小方塊，每個方塊只用速度、密度、溫度幾個數字來代表。</p>
<p>「如果我問你木星 100 年後會在哪裡，你只需要六個數字：三個位置、三個速度。其他資訊都不重要。」</p>
<p><strong>世界模型的關鍵是在抽象表示空間（abstract representation space）中做預測</strong>，只模擬相關的部分，忽略無法預測的細節。這正是 JEPA（Joint Embedding Predictive Architecture）的核心理念。</p>
<hr>
<h2 id="jepa在表示空間中預測">JEPA：在表示空間中預測</h2>
<p>JEPA 不同於傳統的生成式模型。傳統方法試圖重建輸入的每個細節（如自編碼器），但 LeCun 發現這是錯誤的直覺——堅持讓表示包含所有資訊是個壞主意。</p>
<p>JEPA 的做法是：</p>
<ol>
<li>把輸入 X 和目標 Y 都通過編碼器，得到各自的表示</li>
<li>訓練預測器從 X 的表示預測 Y 的表示</li>
<li>關鍵：預測在抽象空間進行，不重建原始細節</li>
</ol>
<p>但這有個大問題：系統可能會「崩塌」（collapse），產生恆定的表示來讓預測變得簡單。LeCun 和團隊花了多年解決這個問題，從對比學習到 Barlow Twins，再到 VICReg（variance-invariance-covariance regularization），最終發展出 SigReg 和 LE-JEPA。</p>
<p><strong>VJPA2</strong>（去年夏天發布）已經在相當於一世紀的影片資料上訓練，產生了優質的視覺表示。</p>
<hr>
<h2 id="達到狗的智慧是最難的一步">達到狗的智慧是最難的一步</h2>
<p>當被問到何時能達到人類等級的 AI，LeCun 先否定了「通用智慧」這個概念：</p>
<blockquote>
<p>「通用智慧根本不存在，這個概念毫無意義。人類智慧是高度專業化的——我們擅長處理現實世界、擅長理解其他人，但我們下棋很爛。」</p>
</blockquote>
<p>他認為，最樂觀的情況下，5-10 年內可能達到接近狗的智慧程度。但這是最難的一步。</p>
<p>為什麼？因為一旦達到狗的程度，大部分的基礎建設就完成了。從靈長類到人類，除了腦容量之外，主要差異只是語言。而語言由大腦中很小的區域（韋尼克區和布洛卡區）處理，在不到一百萬年內演化出來，不會太複雜。</p>
<p>「我們已經有 LLM 可以處理語言了。我們現在研究的是前額葉皮層——那是世界模型所在的地方。」</p>
<hr>
<h2 id="矽谷的單一文化問題">矽谷的「單一文化」問題</h2>
<p>LeCun 對矽谷的批評很直接：所有公司都在做同樣的事。</p>
<p>OpenAI、Meta、Google、Anthropic 都在追逐 LLM。競爭太激烈，沒有人敢採用不同的技術，因為害怕落後。這創造了「羊群效應」和單一文化。</p>
<blockquote>
<p>「你被 LLM 洗腦了（LLM-pilled）。你以為只要擴大 LLM、訓練更多合成資料、僱用數千人做後訓練，就能達到超級智慧。這完全是胡扯。」</p>
</blockquote>
<p>這種單一文化的風險是被場外的創新突襲——像 DeepSeek 這樣的中國團隊提出新方法時，矽谷公司都很震驚：「什麼？矽谷以外的人也能有原創想法？」</p>
<p>更諷刺的是：美國公司越來越封閉，中國公司卻完全開源。目前最好的開源模型是中國的，這讓很多美國業界人士很不安。</p>
<hr>
<h2 id="安全性內建護欄而非事後微調">安全性：內建護欄，而非事後微調</h2>
<p>LeCun 對 AI 安全的看法不同於「末日論者」。他認為每種強大技術都有正面和負面效果，關鍵在於工程上如何處理。</p>
<p>他用噴射引擎舉例：一開始跑 10 分鐘就爆炸，但經過數十年的工程改進，現在可以安全飛行 17 小時橫跨半個地球。AI 也會經歷同樣的過程。</p>
<p>但他強調，<strong>微調 LLM 來防止危險行為是錯誤的方法</strong>——總是可以被越獄。</p>
<p>正確的做法是建立「目標驅動的 AI 架構」（objective-driven AI）：</p>
<ol>
<li>系統有世界模型，能預測行動的後果</li>
<li>通過優化來找出達成目標的行動序列</li>
<li>同時滿足一系列護欄約束</li>
</ol>
<p>「這是<strong>架構上</strong>的安全，不是微調。系統無法逃脫這些約束，因為它必須通過優化來滿足它們。」</p>
<hr>
<h2 id="如果世界模型成功了">如果世界模型成功了</h2>
<p>當被問到 20 年後的願景，LeCun 引用了 Linus Torvalds 的名言：「目標是全球統治。」</p>
<p>他笑著說這很好笑，但 Linux 確實做到了——幾乎世界上每台電腦都跑 Linux（除了少數桌機和 iPhone）。</p>
<p>他的願景是建立一套訓練智慧系統的方法，讓 AI 在日常生活中幫助人類和整個地球。這些系統會放大人類智慧，而非取代或統治人類。</p>
<blockquote>
<p>「不是因為某個東西聰明，它就想要統治。這是兩回事。即使在人類中，也不是最聰明的人想要支配別人。」</p>
</blockquote>
<hr>
<h2 id="給年輕人的建議">給年輕人的建議</h2>
<p>LeCun 建議想進入 AI 領域的年輕人：學習有長期價值的東西，以及學習如何學習。</p>
<p>諷刺的是，身為電腦科學教授，他說：「電腦科學通常不是那種有長期價值的東西。」</p>
<p>他推薦的基礎：</p>
<ul>
<li><strong>數學</strong>：微積分、機率論、線性代數</li>
<li><strong>工程</strong>：控制理論、訊號處理、最佳化</li>
<li><strong>物理</strong>：關於如何對現實建立預測模型</li>
</ul>
<p>「物理學是關於：我應該用什麼來表示現實，才能做出預測。這正是智慧的本質。」</p>
<hr>
<h2 id="結語歷史會重演">結語：歷史會重演</h2>
<p>LeCun 在最後提醒：不要被當前的 AI 熱潮沖昏頭。</p>
<p>在他的職業生涯中，「當前主流技術將帶我們走向人類智慧」這種幻覺已經發生過三次，在他之前可能發生過五六次。</p>
<p>1950 年代有 General Problem Solver，1980 年代有專家系統和知識工程師。每次都有人說「10 年內會有超級智慧機器」，每次都證明是錯的。</p>
<p><strong>當前的 LLM 熱潮可能也是同樣的情況。</strong></p>
<p>但這不代表 AI 不會進步。只是真正的突破可能來自完全不同的方向——比如世界模型、JEPA，或是我們還沒想到的東西。</p>
<p>而這正是 LeCun 在 65 歲創業的原因。</p>

        </div>
        <div class="post_extra mb-2">
          
<div class="copy" data-before="分享故事" data-after="已複製">
  <svg class="icon">
    <use xlink:href="#copy"></use>
  </svg>
</div>
        </div>
        <div>
        
        </div>
      </div>
    </div>
    <a href=https://bnextmedia.github.io/AINEXT/ class="post_nav"><span class="post_next">Latest Posts
      <svg class="icon icon_scale">
        <use xlink:href="#double-arrow"></use>
      </svg>
    </span></a>
  </div>

    </main>
    <footer class="footer wrap pale">
  <p>&copy;&nbsp;<span class="year"></span>&nbsp;AINEXT</p>
  <p class="attribution upcase">由 <a href = 'https://bnextmedia.github.io/AINEXT/' target = '_blank' title = '領英個人檔案' rel = 'nonopener'>AINEXT</a> 設計</p>
</footer>


<script src="https://bnextmedia.github.io/AINEXT/js/index.min.0c2fb80a1ade817d7387f0de8ee061e7de6878a65a420dc61a6e0d0b3bb765c4c0394caefa7c40b16d39c7d74283b3cab364aa109f58cad99d149ec813f930c8.js"></script>

    <svg width="0" height="0" class="hidden">
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 699.428 699.428" id="copy">
    <path d="M502.714 0H240.428C194.178 0 153 42.425 153 87.429l-25.267.59c-46.228 0-84.019 41.834-84.019 86.838V612c0 45.004 41.179 87.428 87.429 87.428H459c46.249 0 87.428-42.424 87.428-87.428h21.857c46.25 0 87.429-42.424 87.429-87.428v-349.19L502.714 0zM459 655.715H131.143c-22.95 0-43.714-21.441-43.714-43.715V174.857c0-22.272 18.688-42.993 41.638-42.993l23.933-.721v393.429C153 569.576 194.178 612 240.428 612h262.286c0 22.273-20.765 43.715-43.714 43.715zm153-131.143c0 22.271-20.765 43.713-43.715 43.713H240.428c-22.95 0-43.714-21.441-43.714-43.713V87.429c0-22.272 20.764-43.714 43.714-43.714H459c-.351 50.337 0 87.975 0 87.975 0 45.419 40.872 86.882 87.428 86.882H612v306zm-65.572-349.715c-23.277 0-43.714-42.293-43.714-64.981V44.348L612 174.857h-65.572zm-43.714 131.537H306c-12.065 0-21.857 9.77-21.857 21.835 0 12.065 9.792 21.835 21.857 21.835h196.714c12.065 0 21.857-9.771 21.857-21.835 0-12.065-9.792-21.835-21.857-21.835zm0 109.176H306c-12.065 0-21.857 9.77-21.857 21.834 0 12.066 9.792 21.836 21.857 21.836h196.714c12.065 0 21.857-9.77 21.857-21.836 0-12.064-9.792-21.834-21.857-21.834z"></path>
  </symbol>
  <symbol viewBox="0 0 53 42" xmlns="http://www.w3.org/2000/svg" id="double-arrow">
    <path d="M.595 39.653a1.318 1.318 0 0 1 0-1.864L16.55 21.833a1.318 1.318 0 0 0 0-1.863L.595 4.014a1.318 1.318 0 0 1 0-1.863L2.125.62a1.318 1.318 0 0 1 1.864 0l19.35 19.349a1.318 1.318 0 0 1 0 1.863l-19.35 19.35a1.318 1.318 0 0 1-1.863 0zm29 0a1.318 1.318 0 0 1 0-1.864L45.55 21.833a1.318 1.318 0 0 0 0-1.863L29.595 4.014a1.318 1.318 0 0 1 0-1.863l1.53-1.53a1.318 1.318 0 0 1 1.864 0l19.35 19.349a1.318 1.318 0 0 1 0 1.863l-19.35 19.35a1.318 1.318 0 0 1-1.863 0z"></path>
  </symbol>
</svg>
  </body>
</html>
