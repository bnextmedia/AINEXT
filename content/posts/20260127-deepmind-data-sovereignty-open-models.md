---
title: "資料主權是數位自保還是自我設限？DeepMind 高管提出反直覺的全球化資料主張"
date: 2026-01-27T11:00:00+08:00
description: "Google DeepMind 前沿 AI 全球事務副總裁 Tom Lue 認為，各國競相推動資料在地化是短視的。真正通用的 AI 需要全球多元資料，否則只會被少數國家的網路數據主導。他也解釋了為什麼前沿模型不應該輕易開源——因為開源是不可逆的。"
tags: ["Google DeepMind", "Tom Lue", "資料主權", "開源模型", "AlphaFold", "AI 治理", "Podcast"]
categories: ["AI 產業動態"]
source_url: "https://www.youtube.com/watch?v=mwrBbZTS2dg"
source_name: "AI Across Borders by Dr. Ayesha Khanna"
draft: false
---

> 本文整理自 AI Across Borders Podcast 2026 年 1 月 24 日發布的單集，由 Dr. Ayesha Khanna 主持，來賓為 Google DeepMind VP of Frontier AI Global Affairs Tom Lue。

{{< youtube mwrBbZTS2dg >}}

{{< spotify "episode/70KdPQD3VgWNEWkeKKQVpA" >}}

---

## 誰在說話？

**Tom Lue** 是 Google DeepMind 前沿 AI 全球事務副總裁，掌管法務、公共政策和前沿安全治理。他的父母來自臺灣，本人橫跨法律、公共政策與科技領域，從歐巴馬白宮到 Waymo 再到 DeepMind。在這集訪談中，他對當前全球 AI 治理的兩個熱門議題——資料主權和開放模型——提出了不太一樣的看法。

主持人 **Dr. Ayesha Khanna** 是新加坡 AI 教育公司 Amplify 創辦人，長期從亞洲視角追蹤全球 AI 政策動態。

## 資料在地化的陷阱

當被問到在 AI 治理上，他和各國政府之間最大的歧見是什麼時，Tom Lue 毫不遲疑地指向了「資料主權」這個議題。

他觀察到一股全球性的趨勢：越來越多政府要求資料在地化，強調主權 AI，希望把資料收集範圍縮小、存放在本地、封鎖在高度安全的在地環境裡。Tom Lue 認為這個方向在長期來看是錯的。

他的理由很直接：如果你要建造真正通用、真正智慧的 AI，你需要的是全球多元且具代表性的資料。這種 AI 要能理解世界各地不同社會的完整人類脈絡。把資料鎖在國界之內，只會讓模型的世界觀受限於本地數據的範圍。

主持人 Ayesha Khanna 立刻提出了對立面的論點：如果你不保護自己的主權資料，你就會被主流訓練文本的價值觀「數位殖民」——不管那是法國的、英國的、美國的還是中國的。

Tom Lue 的回應是：這恰恰說明了為什麼需要更開放的全球化資料策略，而不是更封閉的。如果沒有一個讓全球都能取用多元資料的機制，AI 就會被擁有最多網路數據的國家所主導。與其築牆，不如建公路。

他舉了新加坡的例子。新加坡推動了 SEA-LION 和 SEALD 計畫，利用公開的資料集來訓練東南亞語言模型，並以開源方式讓整個東南亞地區使用。Tom Lue 認為這是「資料公地」（data commons）概念的最佳實踐——用公開可用的資料確保 AI 不被少數網路大國壟斷。

他也建議，各國應該投入更多資源在資料公地上，例如把鎖在政府機構裡的資料開放出來，或與世界銀行等國際機構合作，建立更具全球代表性的公共資料集。

## 開放模型的不可逆風險

談完資料，話題轉向了另一個全球 AI 界的辯論焦點：模型到底應該開源還是封閉？

Tom Lue 先表態：Google 是開源的堅定支持者。從 TensorFlow 到 Android，Google 長年維護著龐大的開源生態系。DeepMind 自己也有開源模型 Gemma，在社群中獲得了廣泛使用。許多學者告訴他，開源模型讓他們能做更多測試、研究、開發和微調，靈活度大幅提升。

但他話鋒一轉：在最前沿的模型上，必須謹慎。

原因在於兩個字：不可逆。一旦你把前沿模型開源出去，就收不回來了。而前沿模型的一個核心特性是「湧現能力」（emergent capabilities）——模型展現出開發者事先沒有預料到的能力。Tom Lue 講了一個具體的例子：他的一個同行告訴他，某家前沿實驗室發布了一個模型之後，接到了冰島政府的電話——原來這個模型的冰島語能力是所有模型中最強的，但開發團隊根本沒有刻意訓練它說冰島語。這種能力是自己冒出來的。

湧現能力可以是驚喜，也可以是風險。如果一個模型在你不知道的情況下展現出某種危險能力，而你已經把它開源了，那你完全沒有補救的空間。所以 DeepMind 的策略是：前沿模型先以封閉方式發布，觀察幾個月，確認能力範圍和使用方式之後，再考慮開源。而且前沿模型的技術迭代速度極快——今天的前沿模型六個月後就會被超越——所以這個等待期其實不長。

Tom Lue 也回應了來自開發中國家的關切。主持人提到 UAE 和中國都在積極推動開源模型，全球南方普遍相信開源能民主化 AI 的取用。Tom Lue 不反對這個目標，但他強調這是一個風險與效益的權衡問題，而不是一個意識形態的選擇。

## 全球 AI 治理的演變

Tom Lue 還分享了他參與國際 AI 高峰會的觀察。他追溯了一條演變軌跡：2023 年在英國 Bletchley Park 舉行的首屆全球 AI 安全高峰會，焦點放在最嚴重的風險上；法國高峰會轉向了行動導向，討論如何把握 AI 的機會；而即將在 2026 年 2 月於印度舉行的高峰會，傳出的訊號是要以「民主化」和「全球南方」為核心議題。

他提到 Google DeepMind 倡導的幾個治理原則：第一，各國應投資 AI 基礎設施（資料、能源、算力、人才）；第二，建立促進創新的監管框架而非壓制性的水平監管；第三，推動國際標準的協調一致，避免企業面對五十套互相矛盾的法規。

在國家層面，他點名了幾個他認為做得比較好的：新加坡（推出 AI Verify 等標準化工具）、日本（大力投資基礎設施和能力建設）、美國（現任政府的 AI 行動計畫方向正確）。

最後，他用 AI 在全球公益上的兩個案例收尾。第一個是 Google 與芝加哥大學合作，利用 AI 在印度預測季風——結果在 30 天的預測窗口內大幅提升了準確度，讓參與試驗的農民年收入翻倍。第二個是 AlphaFold，DeepMind 解決了生物學界五十年的大挑戰——從胺基酸序列預測蛋白質的 3D 結構。過去一個博士生整篇論文只能預測一個蛋白質結構，現在 AlphaFold 幾秒鐘就能完成。DeepMind 已經將兩億個已知蛋白質的結構全部公開，供全球研究者免費使用，用途涵蓋被忽視的疾病、抗藥性研究，甚至設計能分解海洋塑膠的酵素。

## 我的觀察

臺灣在資料主權的議題上，處境比大多數國家都更微妙。

一方面，臺灣是全球半導體供應鏈的關鍵節點，美中兩大陣營都在拉攏臺灣的產業資源，同時也各自建構自己的資料治理體系。美國推動的資料流通框架和中國的資料在地化要求，方向截然不同，臺灣夾在中間，不可能兩邊都站。另一方面，臺灣自身的資料體量和語言資源在全球 AI 訓練的版圖中微不足道——繁體中文在全球網路內容中的佔比極低，如果臺灣選擇把資料鎖在國內，訓練出來的模型只會更狹隘。

Tom Lue 提出的「資料公地」概念，對臺灣其實是一條值得認真考慮的路。臺灣不需要自己從零訓練一個基礎模型來跟 Gemini 或 GPT 競爭，但可以積極參與多語言、多文化的開放資料集建設——類似新加坡的 SEA-LION 計畫。繁體中文的高品質資料集如果能成為全球 AI 訓練的標準素材之一，臺灣的語言和文化就不會在 AI 時代被邊緣化。

至於開放 vs. 封閉模型的辯論，Tom Lue 的「不可逆」論點特別值得臺灣的政策制定者注意。臺灣目前在推動公部門和企業導入 AI 時，對於該使用開源模型還是商業模型，往往缺乏系統性的風險評估框架。「開源比較便宜」或「開源比較透明」的直覺判斷，忽略了一個前提：前沿模型的湧現能力意味著風險也是湧現的，而開源之後的補救空間幾乎為零。這不是說臺灣不應該用開源模型，而是在選擇的時候，需要一套更細緻的判斷標準——這正是臺灣目前欠缺的。
