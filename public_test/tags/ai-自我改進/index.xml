<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI 自我改進 on AINEXT</title>
    <link>https://bnextmedia.github.io/AINEXT/tags/ai-%E8%87%AA%E6%88%91%E6%94%B9%E9%80%B2/</link>
    <description>Recent content in AI 自我改進 on AINEXT</description>
    <generator>Hugo</generator>
    <language>zh-TW</language>
    <lastBuildDate>Wed, 24 Dec 2025 01:34:00 +0800</lastBuildDate>
    <atom:link href="https://bnextmedia.github.io/AINEXT/tags/ai-%E8%87%AA%E6%88%91%E6%94%B9%E9%80%B2/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Codex 用 Codex 來訓練自己——AI 自我改進的第一個徵兆</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251224-openai-codex-trains-itself/</link>
      <pubDate>Wed, 24 Dec 2025 01:34:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251224-openai-codex-trains-itself/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Lenny&amp;rsquo;s Podcast 2024 年 12 月播出的單集，主持人 Lenny Rachitsky 專訪 OpenAI Codex 產品負責人 Alexander Embiricos。&#xA;收聽連結：&lt;a href=&#34;https://www.youtube.com/watch?v=z1ISq9Ty4Cg&#34;&gt;YouTube&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;ai-在值班&#34;&gt;AI 在值班&lt;/h2&gt;&#xA;&lt;p&gt;OpenAI 內部有一個有趣的現象：Codex 正在幫忙訓練 Codex。&lt;/p&gt;&#xA;&lt;p&gt;這不是一個概念性的描述，而是字面上的意思。Alexander Embiricos 在訪談中提到，Codex 寫了很多管理自己訓練運作的程式碼。更具體地說，他們讓 Codex「值班」——持續監控訓練過程中的各種圖表和指標，評估這些數據隨時間的變化，然後判斷需要採取什麼行動。&lt;/p&gt;&#xA;&lt;p&gt;這代表什麼？想像一下訓練大型語言模型的場景。訓練過程會產生大量監控數據：loss 曲線、梯度變化、記憶體使用、GPU 利用率。傳統上，這些數據需要人類工程師盯著看，發現異常時做判斷——該調整學習率嗎？哪裡有 bug？需要重啟某個節點嗎？&lt;/p&gt;&#xA;&lt;p&gt;現在，Codex 可以做這件事。它不只是被動地跑程式碼，而是主動地監控、分析、做決策。Embiricos 說，Codex 的 code review 功能已經抓到了不少錯誤，包括一些「相當有趣的配置錯誤」。這些是人類工程師可能會漏掉的、但 agent 因為持續監控而能夠發現的問題。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;karpathy-的-bug&#34;&gt;Karpathy 的 Bug&lt;/h2&gt;&#xA;&lt;p&gt;這種能力的具體威力，可以從 Andrej Karpathy 的經驗看出來。&lt;/p&gt;&#xA;&lt;p&gt;Karpathy 是 OpenAI 的共同創辦人、前特斯拉 AI 總監，是這個領域最頂尖的人之一。他在 Twitter 上分享過：他遇到最棘手的 bug——那種花好幾個小時也搞不清楚原因的問題——他會丟給 Codex，讓它跑一個小時。結果 Codex 把問題解決了。&lt;/p&gt;&#xA;&lt;p&gt;關鍵不是 Codex 比 Karpathy 聰明，而是它可以用不同方式工作。持續嘗試、不會累、不會分心、不會因為挫折失去耐心。當一個問題需要的是大量試錯和排查，而不是天才級的洞察，這種「持久力」就變成優勢。&lt;/p&gt;&#xA;&lt;p&gt;把這個能力應用到訓練監控上，你得到的是一個永遠不會疲倦的值班工程師。它可以 24 小時盯著訓練曲線，在任何異常發生的第一時間就做出反應。人類工程師需要睡覺、需要休息、注意力會分散。Codex 不需要。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;遞迴改進的早期形態&#34;&gt;遞迴改進的早期形態&lt;/h2&gt;&#xA;&lt;p&gt;這讓我想到一個更大的問題：我們是不是在看 AI 遞迴自我改進的早期形態？&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
