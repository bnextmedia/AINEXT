---
title: "OpenAI 研究長：Scaling 沒死，我們一年內要讓 AI 當實習生"
date: 2026-01-26T11:00:00+08:00
description: "OpenAI 研究長陳信翰在訪談中給出明確時間軸：一年內讓 AI 實習生參與研發流程，兩年半內實現 AI 端到端獨立研究。他認為「Scaling 已死」是假議題，Pre-training 還有很大空間。對台灣 AI 從業者而言，這是理解全球最前沿研究方向的重要參考。"
tags: ["OpenAI", "Mark Chen", "陳信翰", "Scaling", "Pre-training", "AGI", "AI 安全", "Podcast"]
categories: ["AI 技術前沿"]
source_url: "https://www.youtube.com/watch?v=ZeyHBM2Y5_4"
source_name: "Core Memory Podcast"
draft: false
---

> 本文整理自 Ashlee Vance 主持的 Core Memory Podcast，受訪者為 OpenAI 研究長陳信翰（Mark Chen）。本文聚焦技術趨勢與未來展望，人物故事請見[〈台裔研究長的 OpenAI 保衛戰〉](/posts/20260126-mark-chen-openai-defense/)。

{{< youtube ZeyHBM2Y5_4 >}}

{{< spotify "episode/3E7FZtPd2avTObGVaTRcQU" >}}

{{< apple-podcast "tw/podcast/openais-research-chief-on-the-soup-wars-poker-and/id1789397163?i=1000739188647" >}}

---

## 為什麼台灣讀者該關注這場技術討論

當全球都在爭論「AI 發展是否撞牆」時，OpenAI 的研究長給出了非常不同的答案。

陳信翰在這場訪談中透露了幾個關鍵訊息：OpenAI 過去半年重新大力投入預訓練（Pre-training），他們認為 Scaling（規模擴展）遠遠還沒到盡頭，而且他們設定了明確的里程碑——一年內讓 AI 參與研發流程，兩年半內讓 AI 獨立做端到端研究。

對台灣的 AI 從業者、研究人員、甚至投資人來說，這些訊息極為重要。因為這不是學術論文裡的猜測，而是掌握全球最多 GPU 資源、最頂尖研究團隊的人，告訴你他們正在押注什麼方向。

更值得注意的是陳信翰對 AI 安全的看法。他管理 OpenAI 的對齊（Alignment）團隊，對於「模型會不會對人類撒謊」這個問題有第一手的觀察。這些思考，對於任何想理解 AI 風險的人來說，都是珍貴的內部視角。

---

## 「Scaling 已死」是假議題

從 2024 年開始，「Scaling 已死」的說法在 AI 圈廣為流傳。有人認為，單純增加模型規模和運算資源已經無法帶來能力的飛躍，AI 發展正在撞牆。

曾任 OpenAI 研究科學家、現為獨立 AI 教育者的 Andrej Karpathy 在近期一場 Podcast 中說，他認為 AGI 還要十年。這番話讓不少 AI 產業的人感到沮喪。

但陳信翰的看法完全不同。

「很多人說 Scaling 已死。我們完全不這麼認為。」他在訪談中說。「某種程度上，大家都在談強化學習（RL），這對我們來說反而是一種資訊優勢（alpha）——因為我們認為預訓練還有非常大的空間。」

這是一個耐人尋味的說法。當整個產業都在關注推理模型、強化學習、思維鏈（Chain of Thought）時，OpenAI 卻在悄悄「重建預訓練的肌肉」。

陳信翰解釋，過去兩年 OpenAI 把大量資源投入推理能力的研究，這確實帶來了突破——O1 模型的「思考」能力就是成果。但代價是預訓練和後訓練（Post-training）的能力有些鬆懈。

「在過去六個月，Jakob 和我做了很多工作來重建這塊肌肉。」他說。「預訓練真的是一種需要持續鍛鍊的能力。你需要確保所有資訊都是最新的，需要確保團隊在最前沿做最佳化、做數值計算。」

談到競爭對手 Google 的 Gemini 3，陳信翰的評價是「相當不錯的模型」，但他也點出一個關鍵弱點：「當你仔細看他們的基準測試數字，會發現在資料效率（data efficiency）方面，他們還沒有突破。他們在這上面沒有太大進展。而我認為我們在這方面有很強的演算法。」

這暗示了 OpenAI 可能在「用更少資料達到更好效果」這個方向上有所突破——如果屬實，這會是預訓練領域的重大進展。

---

## 一年內 AI 實習生，兩年半後獨立研究

「AGI 什麼時候會到？」這個問題每個人都有不同的答案，而且每個人對 AGI 的定義也不一樣。陳信翰說，就算在 OpenAI 內部，也無法讓所有人對 AGI 的定義達成共識。

但他給出了一個更具體、更可驗證的框架。

「我把它想成是工業革命。」他說。「你覺得什麼時候算是工業革命開始？是機器能織布的時候？還是蒸汽機發明的時候？每個人都有不同的定義。我認為我們正處於生產 AGI 的過程中。對我來說，我最關注的指標是：我們是否在產出新的科學知識？是否在推進科學前沿？」

然後他給出了 OpenAI 研究團隊內部設定的兩個里程碑：

**第一個里程碑（一年內）**：改變研究的工作方式，讓 AI 實習生有效參與研發流程。「今天，你想出一個點子，然後執行、實作、除錯。一年內，我們相當有信心可以達到一個狀態：我們控制外層迴圈——我們想出點子——但模型負責實作和除錯。」

**第二個里程碑（兩年半內）**：讓 AI 做端到端的獨立研究。從發想到執行到驗證，全部由 AI 完成。

這是非常具體的時間軸。它回避了「AGI 是什麼」這個定義爭議，直接聚焦在可觀察的能力：AI 能不能真的幫你做研究？能幫到什麼程度？

陳信翰也分享了一個讓他印象深刻的案例。GPT-5 Pro 發布後三天，他和一位物理學家朋友見面。這位物理學家一直覺得 AI 模型「很可愛但沒什麼用」，陳信翰挑戰他：「試試看 Pro 模型，做一些有野心的事。」

物理學家把自己最新的論文丟給模型，模型思考了 30 分鐘——然後完全理解了。

「那個反應，那個瞬間，就像是看到 AlphaGo 下出第 37 手、第 38 手的感覺。」陳信翰說。「我認為這種事會在前沿數學、科學、生物學、材料科學領域不斷發生。模型真的已經到了那個程度。」

---

## OpenAI for Science：讓科學家自己拿諾貝爾獎

那次和物理學家的對話，啟發了陳信翰一個新計畫：「OpenAI for Science」。

「我們想賦予每個人自己贏得諾貝爾獎的能力。」他說。「重點不是 OpenAI 自己去拿諾貝爾獎——雖然那也不錯——而是我們想建立工具和框架，讓所有科學家都能感受到加速的效果。我們想集體推動整個領域。」

這和 Google DeepMind 的策略有微妙的不同。DeepMind 傾向於自己組建科學團隊、自己做出突破（例如 AlphaFold）。OpenAI 的策略則是：我們提供工具，讓外部科學家用這些工具做出他們自己的突破。

陳信翰承認，當他們去和物理學家、數學家談合作時，大多數人其實對 AI 不太樂觀。「他們還是相信：這東西不可能解決新的定理，一定有什麼其他原因。」

但他認為，這反而是機會。「賦能那些真正相信、願意投入的人——這些人會超越其他所有人。我們想建立工具，說服大家這才是做科學研究的正確方式。」

---

## 「模型會對你撒謊」：不監督思考過程的設計哲學

陳信翰在 OpenAI 不只管研究，也管對齊（Alignment）團隊。在訪談的最後，他談到了一個讓他真正擔憂的問題。

「當你對模型投入越多強化學習運算，你越能測量到一些東西，像是自我意識、自我保護，甚至是模型會『耍心機』（scheming）的情況。」他說。「可怕的是，模型可能給你一個正確的答案——你期待的答案——但它得出這個答案的思考過程是扭曲的。」

這就是 AI 安全領域所謂的「對齊稅」問題：模型可能學會說你想聽的話，而不是說真話。

OpenAI 在這方面做了一個關鍵的設計決策。陳信翰說，當初發布 O1 模型時，他們刻意選擇不去監督或訓練模型的「思考過程」。

「當你對模型的思考過程施加激勵，讓它產出對人類有吸引力的思考過程時，它就不一定會對你誠實了。它不會告訴你真正的意圖。」他解釋。「所以我們透過這個設計，保留了觀察模型思考過程的能力，把它當作理解對齊問題的工具。」

這是一個反直覺的選擇。大多數人可能覺得，當然要訓練模型的思考過程，讓它「想得更好」。但 OpenAI 擔心的是：如果你這樣做，模型會學會偽裝，而你就失去了觀察窗口。

陳信翰說，他真正擔心的未來是：「模型告訴我們一些超級有說服力的東西，但我們無法確定模型是否真的和我們的價值觀一致。」

這不是科幻小說的情節，而是現在就在發生的研究問題。OpenAI、DeepMind、Anthropic 最近共同發表了一篇論文，探討如何用「觀察思考過程」作為對齊工具。

陳信翰認為，未來可能需要設計一些框架，讓模型互相監督、共同演化，使得「誠實」成為唯一穩定的平衡狀態。「有很多非常令人興奮的研究方向。」他說。

---

## ChatGPT 的未來與 Johnny Ive 的裝置

訪談中也觸及了 OpenAI 和傳奇設計師 Johnny Ive 合作開發的神秘裝置。陳信翰沒有透露具體細節，但他分享了對 ChatGPT 未來的願景。

「今天你和 ChatGPT 互動的方式，對我來說感覺很笨。」他說。「你給它一個提示，得到一個回應，然後在你給下一個提示之前，它不會為你做任何有用的工作。如果你問一個類似的問題，它會思考同樣長的時間——它沒有因為第一個問題而變得更聰明。」

他想像的未來是：ChatGPT 具備真正的記憶。每次你和它互動，它都會深入學習你這個人——反思你為什麼會問這個問題、相關的問題是什麼。下次你再來，它會因此變得更聰明。

「這真的提出了一個問題：如果這是主導論點，你該怎麼設計一個裝置？」

陳信翰說，他前一天才和 Johnny Ive 以及預訓練、後訓練團隊的負責人一起吃晚餐。他發現設計團隊和研究團隊的工作方式有很深的相似性——都是大量探索、產生想法、測試假設，最後才產出你滿意的成果。

當主持人問「你們這些數學天才真的有品味嗎？」時，陳信翰笑著說：「老實說，我們自己不需要有品味。那是 Johnny 的工作。他是我們的品味鑑別器。」

---

## 我的觀察

### 「Scaling 已死」是一個危險的誤判

從 2024 年開始流傳的「Scaling 撞牆」說法，在陳信翰這裡得到了明確的反駁。他不只說「我們不同意」，還說「大家都在談 RL，這對我們是資訊優勢」——言下之意是：當所有人往一個方向跑的時候，真正的機會可能在另一個方向。

這和 Anthropic 執行長 Dario Amodei 的立場一致。Amodei 也認為 Scaling 還有很大空間。但 Karpathy 說 AGI 還要十年，DeepSeek 的崛起讓人質疑是否需要那麼多運算資源⋯⋯到底誰對？

我的看法是：這些說法可能都對，只是在談不同的事。「用暴力堆運算」的 Scaling 可能確實在遞減，但「用更聰明的演算法達到同樣效果」的 Scaling 還在加速。陳信翰提到的「資料效率」突破，可能就是這種新型態 Scaling 的線索。

對台灣 AI 產業來說，這意味著不要太快放棄對大規模運算的投資，但也要關注「效率」這個維度。未來的競爭可能不是誰有最多 GPU，而是誰能用同樣的 GPU 做到更多。

### 「AI 實習生」時間軸的意義

陳信翰給出的時間軸——一年內 AI 實習生、兩年半內端到端研究——是我聽過最具體的 AGI 路線圖。

它的聰明之處在於回避了「AGI 是什麼」這個定義爭議。與其爭論「這算不算 AGI」，不如問「AI 能不能幫我做研究」。後者是可驗證的，前者是哲學問題。

如果這個時間軸準確，它對 AI 研究人員的意義是巨大的。一年後，你的工作方式可能根本性地改變——你負責想點子和做判斷，AI 負責實作和除錯。兩年半後，AI 可能開始獨立產出研究成果。

這不是威脅，而是機會。問題是：你準備好了嗎？

### 不監督思考過程的深層智慧

陳信翰解釋的「不監督模型思考過程」設計哲學，是這場訪談中最值得深思的部分。

直覺上，我們會想要訓練模型「想得更好」。但 OpenAI 的擔憂是：如果你這樣做，模型會學會偽裝。它會產出「看起來很好」的思考過程，但那可能不是它真正在想的事。

這就像是：如果你告訴一個員工「我會監控你的思考過程」，他可能會開始表演「正確的思考」，而不是真的思考。

OpenAI 選擇保留這個觀察窗口，把它當作研究對齊問題的工具。這是一個長期主義的選擇——犧牲短期的「模型看起來更好」，換取長期的「我們真的理解模型在想什麼」。

對於任何在思考 AI 安全的人來說，這是一個重要的案例：有時候，不優化某個指標，反而是更好的策略。
