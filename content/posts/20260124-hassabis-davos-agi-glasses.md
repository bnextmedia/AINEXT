---
title: "Demis Hassabis 達沃斯專訪：AGI 不是行銷術語，AI 眼鏡今夏登場"
date: 2026-01-24T09:00:00+08:00
description: "Google DeepMind 執行長 Demis Hassabis 在達沃斯論壇接受專訪，公開反駁 Sam Altman 對 AGI 的重新定義，強調我們距離真正的 AGI 還有五到十年。他同時宣布 Google 與 Warby Parker、Samsung 合作的 AI 眼鏡將在今年夏天推出，並透露影片模型 VEO 可能比語言模型更接近 AGI。"
tags: ["Demis Hassabis", "Sam Altman", "AGI", "Google DeepMind", "OpenAI", "AI 眼鏡", "VEO", "Gemini", "Podcast"]
categories: ["AI 產業動態"]
source_url: "https://www.youtube.com/watch?v=bgBfobN2A7A"
source_name: "Big Technology Podcast"
draft: false
---

> 本文整理自 Big Technology Podcast 2026 年 1 月在達沃斯論壇的專訪。

{{< youtube bgBfobN2A7A >}}

{{< spotify "episode/4NRXwYLXm1vo5pq3GCdOLy" >}}

{{< apple-podcast "tw/podcast/google-deepmind-ceo-demis-hassabis-ais-next-breakthroughs/id1522960417?i=1000746108312" >}}

---

在今年的達沃斯世界經濟論壇上，Google DeepMind 執行長 Demis Hassabis 接受了 Big Technology Podcast 主持人 Alex Kantrowitz 的專訪。這場對話涵蓋了 AI 產業最核心的幾個問題：我們離 AGI 還有多遠？為什麼影片生成模型可能比語言模型更接近 AGI？以及 Google 的 AI 眼鏡何時會問世？

Hassabis 的回答既坦率又尖銳，特別是當話題轉向 OpenAI 執行長 Sam Altman 對 AGI 的定義時。

## AGI 不該淪為行銷術語

Kantrowitz 向 Hassabis 提到，Altman 在去年底曾表示 AGI 的定義太模糊，希望大家能同意「我們已經跨過 AGI，正在邁向超級智慧」。

Hassabis 的回應毫不客氣：「我相信他確實希望如此，但答案是：絕對不是。我不認為 AGI 應該被轉變成行銷術語，或用於商業利益。AGI 一直有科學上的定義。」

在 Hassabis 看來，AGI 指的是一個能夠展現人類所有認知能力的系統——他特別強調「所有」這個詞。這包括我們一直讚頌的最高層次人類創造力，那些我們崇拜的科學家和藝術家所展現的能力。AGI 不只是解決數學方程式或證明猜想，而是要能提出突破性的猜想；不是解決物理或化學中的某個問題，甚至不是像 AlphaFold 那樣解決蛋白質摺疊，而是要能像愛因斯坦提出廣義相對論那樣，創造全新的物理理論。

他還將這個標準延伸到藝術領域：真正的 AGI 不只是創造已知風格的拼貼，而是要像畢卡索或莫札特那樣，開創我們從未見過的全新藝術類型。甚至在身體智慧方面，Hassabis 也設下了門檻——人類能打運動、控制身體到令人驚嘆的程度，但在機器人領域，我們離這個目標還很遠。

「我認為我們距離那個目標還有五到十年，」他說。

## 如果真的快 AGI 了，為什麼還在煩惱廣告？

訪談中最精彩的時刻之一，是討論 AI 助理是否該加入廣告。Kantrowitz 提到社群媒體上有人說：「這些人離 AGI 還遠得很。如果這真的是會顛覆世界的技術，商業模式怎麼會是廣告？」

Hassabis 接過話題，說了一句意味深長的話：「如果真的相信 AGI 就在眼前，為什麼還要煩惱廣告呢？所以這是一個合理的問題。」

這句話精準地戳中了一個矛盾：一邊宣稱 AGI 即將改變一切，一邊又急著找傳統的廣告商業模式。談到 Gemini 是否會加入廣告，Hassabis 表示目前沒有計畫，但會密切關注 ChatGPT 的做法。他提出了一個核心問題：如果你想要一個為你工作的助理，最重要的是什麼？信任。還有安全和隱私，因為你可能要把生活的方方面面分享給這個助理，你需要確信它是在為你的最佳利益服務。他警告，廣告模式可能會滲透進助理的推薦中，讓使用者困惑這個助理到底是在為我推薦，還是在為廣告主推薦。

## 通往 AGI 還需要一到兩個重大突破

面對「大型語言模型是否撞牆」的質疑，Hassabis 給出了他的判斷：在達到 AGI 之前，我們可能還需要一到兩個重大突破。他認為這些突破會在幾個方向：持續學習、更好的記憶、更有效率的上下文窗口。現在的模型會儲存所有東西，但大腦不是這樣運作的——只儲存重要的東西會有效率得多。

Kantrowitz 點出一個關鍵問題：現在的 AI 是「金魚腦」，它可以搜尋網路、找到資訊，但對話結束後就全部忘記，模型本身並沒有改變。Hassabis 坦承這確實是待解決的問題。在他看來，學習是 AGI 的關鍵特徵，幾乎可以說是定義性的特徵。當我們說「通用」，指的是通用學習能力——能學習新知識，能跨領域學習。對他來說，學習和智慧一直是同義詞。

他提到 DeepMind 過去在 AlphaZero 上的成功——從零開始學習，在已有知識上持續累積。但那是在遊戲這種較簡單的領域，遊戲顯然比混亂的真實世界簡單得多。真正的挑戰是：能否將這些技術擴展到真實世界的問題？

對於 Yann LeCun 認為大型語言模型是「死胡同」的觀點，Hassabis 明確表示不同意。他認為無論你屬於哪個陣營，我們都會需要大型基礎模型作為最終 AGI 系統的關鍵組成部分。唯一的爭論是：大型基礎模型會是「關鍵元件」還是「唯一元件」？DeepMind 的優勢在於研究資源夠深，可以同時推進兩條路線：擴展現有架構，同時探索全新的藍天構想。

## 影片模型可能比語言模型更接近 AGI

訪談中最出人意料的段落，是 Hassabis 被問到哪個系統最接近 AGI。他的答案不是 Gemini，而是影片生成模型。

他解釋，一個能生成十秒、二十秒逼真場景的影片模型，其實是一個物理世界的模型——在物理學領域稱之為「直覺物理」。它已經直覺性地理解液體和物體在世界中如何運作。展現理解的一種方式，就是能夠生成至少對人眼來說足夠真實的內容。雖然從物理學角度還不完全準確，但這是朝向「世界模型」的重要一步。

為什麼世界模型對 AGI 如此重要？Hassabis 給了一個生動的例子：人類可以毫不費力地做長期規劃，比如決定花四年取得學位，這樣會有更好的資歷，十年後能找到更好的工作。這是我們都能輕鬆做到的長期規劃。但現在的 AI 系統做不到這點，它們可以做短期規劃，但沒有這種世界模型，就無法進行長時間跨度的規劃。這在機器人領域尤其重要——你希望機器人能在真實世界中規劃，能想像從當前狀態出發的多種可能軌跡，以完成某項任務。

Hassabis 也談到他對「混合系統」的興趣——有時稱為「神經符號系統」。AlphaFold 和 AlphaGo 就是例子：結合神經網路與蒙地卡羅樹搜索。DeepMind 正在做一些有趣的工作，將大型語言模型與演化方法結合，像 AlphaEvolve，來真正發現新知識。

## AI 眼鏡今夏登場

Kantrowitz 提到他看了 Google 的紀錄片《The Thinking Game》，片中 Hassabis 和同事們不斷舉起手機對著東西問 AI 助理。他直言：「這個人需要智慧眼鏡，手機是錯誤的形態因素。」

Hassabis 完全同意。當你在內部實際使用這些東西時，這一點非常明顯。像影片中那樣舉著手機讓它告訴你關於真實世界的資訊——它能運作是很神奇，但這顯然不是很多情境下的正確形態因素。做菜時、在城市裡走動問路或要推薦時、甚至幫助視障人士，這些場景都需要解放雙手。對戴眼鏡的人來說，最明顯的答案就是把它放在眼鏡上。

Google 在智慧眼鏡領域有著複雜的歷史。Hassabis 坦承 Google Glass 可能太早了，但他分析了失敗的原因：形態因素太笨重，電池續航等問題，這些現在基本上已經解決了。但他認為最關鍵的是另一個原因：缺少殺手級應用。在他看來，殺手級應用是一個通用數位助理，陪伴你，在日常生活中幫助你，可以在任何介面上使用——電腦、瀏覽器、手機，也包括眼鏡這樣的裝置。

為什麼現在是對的時機？Hassabis 給出了一個關鍵原因：有了 Gemini 3，他感覺我們終於有了足夠強大的 AI，可以讓這個願景成為現實。他透露 Google 已經與 Warby Parker、Gentle Monster 和 Samsung 建立了合作關係，一起打造下一代眼鏡，預計今年夏天左右開始看到成果。目前還在原型階段，但他認為這會發生得非常快，而且會是一個全新品類的定義性技術。

有趣的是，Hassabis 透露他個人花時間在這個專案上。他喜歡把自己的時間花在最前沿的事物上，這通常也是最難的事情。他目前親自參與的領域包括：智慧眼鏡、機器人、以及世界模型。

---

## 我的觀察

這場訪談最有價值的地方，不在於 Hassabis 透露了什麼產品計畫，而在於他展現了一種與 OpenAI 截然不同的思維方式。

當 Sam Altman 急著宣布我們已經跨過 AGI、急著在 ChatGPT 上加廣告時，Hassabis 卻在說我們還需要一到兩個重大突破，還有五到十年的路要走。這不是謙虛，這是對「智慧」這個詞的不同理解。

Altman 眼中的 AGI，似乎是一個能通過各種考試、能寫程式、能對話的系統。但 Hassabis 眼中的 AGI，是能像愛因斯坦一樣創造全新理論、像畢卡索一樣開創全新藝術流派的系統。這兩個標準之間的差距，不是程度上的差距，而是本質上的差距。

Hassabis 那句「如果真的相信 AGI 就在眼前，為什麼還要煩惱廣告呢」堪稱整場訪談最精彩的一句話。表面上是在評論商業模式，實際上是在說：你們的行動透露了你們真正相信的東西。如果 OpenAI 真的相信 AGI 會在一兩年內顛覆一切，那現在急著搞廣告收入是什麼意思？這不是自相矛盾嗎？

另一個值得注意的觀點是 Hassabis 對影片模型的看法。多數人看到 Sora、VEO 這類影片生成模型時，想的是可以做很酷的影片。但 Hassabis 看到的是完全不同的東西：AI 終於開始理解物理世界了。要生成一段逼真的影片，模型必須「知道」水會往下流、球會彈跳、光線會反射、物體會遮擋。這些看似簡單的常識，其實是數十億年演化教會我們的直覺物理。這就是為什麼 Hassabis 說影片模型可能比語言模型更接近 AGI——它在建立對真實世界的理解，而不只是對文字的理解。

至於 AI 眼鏡，這場眼鏡大戰的本質不是硬體之爭，而是 AI 能力之爭。Meta 的 Ray-Ban 智慧眼鏡已經在市場上，整合了 Meta AI，可以看、可以聽、可以回答問題。Google 的回應是：我們有 Gemini 3。誰的 AI 更聰明、更有用、更自然，誰就能贏得這個新品類。Hassabis 刻意提到與時尚品牌和消費電子巨頭的合作，這是在說 Google 不只有 AI 技術，還有設計和製造能力。

不過，有一件事 Hassabis 沒有多談：隱私。一副隨時在看、隨時在聽的眼鏡，會引發什麼樣的社會反應？Google Glass 當年被禁止進入很多場所，臉部辨識、持續錄影的疑慮從未消失。當 AI 眼鏡真的普及時，我們作為社會準備好了嗎？這可能是比技術更難解決的問題。
