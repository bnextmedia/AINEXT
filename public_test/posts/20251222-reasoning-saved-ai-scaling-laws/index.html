<!DOCTYPE html>
<html lang="en" >
  <head>
  <title>Reasoning 如何拯救 ai：一場你不知道的 18 個月危機 | AINEXT</title>
  <meta charset='utf-8'>
  <meta name="viewport" content ="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">


<meta name="keywords" content="AINEXT">
<meta property="og:locale" content='en_US'>
<meta property="og:type" content="article">
<meta property="og:title" content="Reasoning 如何拯救 AI：一場你不知道的 18 個月危機">
<meta property="og:description" content="如果不是 Reasoning 模型的出現，AI 的進展可能在 2024 年就停滯了。這個說法聽起來驚人，但背後有著嚴謹的技術邏輯——而且這個故事鮮為人知。
Gavin Baker 是 Atreides 投資公司創辦人，曾任 Fidelity 科技基金經理人，長期追蹤 AI 與半導體產業。2024 年 12 月，他接受知">
<meta property="og:url" content="https://bnextmedia.github.io/AINEXT/posts/20251222-reasoning-saved-ai-scaling-laws/">
<meta property="og:image" content="https://bnextmedia.github.io/AINEXT/images/images/logo.png">
<link rel="canonical" href="https://bnextmedia.github.io/AINEXT/posts/20251222-reasoning-saved-ai-scaling-laws/">

<link rel="apple-touch-icon" sizes="180x180" href='https://bnextmedia.github.io/AINEXT/apple-touch-icon.png'>
<link rel="icon" type="image/png" sizes="32x32" href='https://bnextmedia.github.io/AINEXT/favicon-32x32.png'>
<link rel="icon" type="image/png" sizes='16x16' href='https://bnextmedia.github.io/AINEXT/favicon-16x16.png'>
<link rel="manifest" href='https://bnextmedia.github.io/AINEXT/site.webmanifest'>

<link rel="stylesheet" href="https://bnextmedia.github.io/AINEXT/css/styles.648e60c6d86809f863ae1346848574b9c685732794e7851c7d3e557de9ddd293bc1c209f963d5041785c2fd4268470bdfde453a99f550b655d1b4f825eed4682.css" integrity="sha512-ZI5gxthoCfhjrhNGhIV0ucaFcyeU54UcfT5Vfend0pO8HCCflj1QQXhcL9QmhHC9/eRTqZ9VC2VdG0&#43;CXu1Ggg==">
</head>

  <body>
    <div class="nav-drop">
  <div class="nav-body">
      <a href="https://bnextmedia.github.io/AINEXT/" class="nav_item">首頁</a>
      <a href="https://bnextmedia.github.io/AINEXT/archives/" class="nav_item">文章列表</a>
    <div class="nav-close"></div><div class="color_mode">
  <label for="mode">Toggle Dark Mode</label>
  <input type="checkbox" class="color_choice" id="mode">
</div>

  </div>
</div>
<header class="nav">
  <nav class="nav-menu">
    <a href=https://bnextmedia.github.io/AINEXT/ class="nav-brand nav_item">
        <img src="https://bnextmedia.github.io/AINEXT/images/logo.png" alt="AINEXT " class="logo-light" width="130px" />
        <img src="https://bnextmedia.github.io/AINEXT/images/logo-dark.png" alt="AINEXT " class="logo-dark" width="130px" /></a>
    
    
    <div class="nav-links">
        <a href="https://bnextmedia.github.io/AINEXT/" class="nav-link">首頁</a>
        <a href="https://bnextmedia.github.io/AINEXT/archives/" class="nav-link">文章列表</a>
    </div>
    
    <div class="nav_bar-wrap">
      <div class="nav_bar"></div>
    </div>
  </nav>
</header>

<style>
 
.nav-links {
  display: flex;
  flex-direction: row;
  gap: 1.5rem;
  align-items: center;
  white-space: nowrap;
}

.nav-link {
  color: var(--text);
  text-decoration: none;
  font-size: 0.95rem;
  padding: 0.5rem 0;
  transition: color 0.2s ease;
}

.nav-link:hover {
  color: var(--theme);
}

 
@media (min-width: 768px) {
  .nav_bar-wrap {
    display: none;
  }
}

 
@media (max-width: 767px) {
  .nav-links {
    display: none;
  }
  
  .nav_bar-wrap {
    display: grid;
  }
}

 
.logo-dark {
  display: none;
}

html[data-mode="dark"] .logo-light {
  display: none;
}

html[data-mode="dark"] .logo-dark {
  display: block;
}

 
@media (prefers-color-scheme: dark) {
  html:not([data-mode="light"]) .logo-light {
    display: none;
  }
  
  html:not([data-mode="light"]) .logo-dark {
    display: block;
  }
}

 
.nav {
  position: relative !important;
  background: var(--bg);
  padding: 0.5rem 0;
  border-bottom: 1px solid var(--border);
}

.mt {
  margin-top: 2rem !important;
}

 
.post {
  padding-top: 1rem;
}

.post_date {
  margin-top: 0;
}

 
.archive {
  padding-top: 1rem;
}

.archive_title {
  margin-top: 0;
}
</style>


    <main>
      
  <div class="wrap mt post">
    <div><p class=post_date>22. December 2025</p>
      <h1 class="post_title">Reasoning 如何拯救 AI：一場你不知道的 18 個月危機</h1>
      <div class="post_body">
        <div class="post_inner">
        
        
          <p>如果不是 Reasoning 模型的出現，AI 的進展可能在 2024 年就停滯了。這個說法聽起來驚人，但背後有著嚴謹的技術邏輯——而且這個故事鮮為人知。</p>
<p>Gavin Baker 是 Atreides 投資公司創辦人，曾任 Fidelity 科技基金經理人，長期追蹤 AI 與半導體產業。2024 年 12 月，他接受知名投資 Podcast《Invest Like the Best》主持人 Patrick O&rsquo;Shaughnessy 專訪，深入剖析了 AI 產業的競爭格局、技術演進與投資邏輯。在這場近兩小時的對談中，他揭露了一個公開市場投資人普遍忽略的事實：基於預訓練規模定律的邏輯，2024 和 2025 年的 AI 進展「理論上不應該發生」。這個看似矛盾的陳述，需要從 Scaling Laws 的本質說起。</p>
<hr>
<h2 id="scaling-laws我們精確測量卻不理解的神秘法則">Scaling Laws：我們精確測量卻不理解的神秘法則</h2>
<p>要理解 Reasoning 為什麼「拯救」了 AI，首先要理解什麼是 Scaling Laws（規模定律）。這個概念是當前 AI 發展的核心驅動力，但它的本質卻帶有一種令人不安的神秘性。</p>
<p>Pre-training Scaling Laws（預訓練規模定律）並非像牛頓力學那樣的物理定律，而是一個「經驗觀察」。研究人員發現，當你增加模型的參數量、訓練資料量、以及運算量時，模型的表現會以一種可預測的方式提升。這個觀察已經被精確測量並持續驗證了很長時間，成為各大 AI 實驗室投入數十億美元建設超大規模運算叢集的理論基礎。然而，沒有人真正知道這個定律為什麼會成立。</p>
<p>Baker 用了一個精妙的比喻來描述這種認知落差。古埃及人可以精確測量太陽的運行軌跡，精確到能夠把金字塔的東西軸完美對準春分點，巨石陣的建造者同樣展現了對太陽週期的精確掌握。但他們完全不懂軌道力學，不知道地球繞著太陽轉，不知道為什麼太陽會東升西落、為什麼會有四季變化。他們的神話中，太陽是由神駕著戰車拉過天空。當代 AI 研究者對 Scaling Laws 的理解，與古人對太陽的理解處於類似的階段：精確測量，但缺乏根本性的理解。</p>
<p>這種認知狀態帶來了一個實際問題：既然我們不知道 Scaling Laws 為什麼會成立，我們也無法確定它什麼時候會停止成立。每一次新模型的訓練，都是對這個經驗定律的又一次驗證。這就是為什麼 2024 年底 Google 發布 Gemini 3 時，業界如此關注——它證明了預訓練規模定律在又一個數量級上依然有效。這個確認對於整個產業的信心至關重要，因為目前所有的大規模資本支出，都是基於這個定律會繼續成立的假設。</p>
<hr>
<h2 id="blackwell-延遲科技史上最複雜的產品轉換">Blackwell 延遲：科技史上最複雜的產品轉換</h2>
<p>2024 年，Nvidia 的新一代晶片 Blackwell 遭遇了嚴重的產品延遲。這不是普通的供應鏈問題或良率挑戰，而是科技史上「最複雜的產品轉換」之一。理解這次延遲的嚴重性，需要先理解從 Hopper 到 Blackwell 究竟改變了什麼。</p>
<p>從 Hopper 世代升級到 Blackwell，改變的不只是晶片本身，而是整個資料中心的基礎架構。冷卻系統從空氣冷卻改為液體冷卻，這意味著需要全新的管路、泵浦、冷卻液分配單元。機架重量從約 1,000 磅暴增到 3,000 磅，許多現有資料中心的地板根本承受不了這個重量，需要結構補強甚至重建。功耗從約 30 千瓦（相當於 30 個美國家庭用電量）躍升到 130 千瓦，這不只是電費問題，而是需要全新的供電基礎設施、變壓器、配電系統。</p>
<p>Baker 用一個生動的比喻來形容這種轉換的複雜度：想像你要換一支新 iPhone，但你必須先把家裡所有插座換成 220 伏特、裝一個 Tesla Powerwall 儲能系統、裝一台備用發電機、裝太陽能板來應付暴增的用電需求，然後還要加固地板，因為地板承受不了這支新手機的重量。這聽起來荒謬，但這正是資料中心營運商在 2024 年面對的現實。他們不是在升級伺服器，而是在重建整個基礎設施。</p>
<p>更棘手的是，這些極其複雜的機架必須穩定運作才能發揮作用。Blackwell 的設計密度極高，散熱成為巨大挑戰。即使所有基礎設施都到位，要讓這些機架持續穩定運作、把熱量有效排出，也需要大量的工程調校。這就是為什麼 Blackwell 在 2024 年底才開始真正大規模部署，比原本預期晚了將近一年。</p>
<hr>
<h2 id="一個被忽略的危機ai-進展理論上應該停滯">一個被忽略的危機：AI 進展理論上應該停滯</h2>
<p>這場延遲帶來了一個很少被公開討論的危機。根據預訓練規模定律的邏輯，AI 能力的提升需要更大規模的運算。當 XAI 在 2024 年初成功讓 20 萬張 Hopper GPU 協同運作（也就是業界所說的「連貫」運作，每個 GPU 都知道其他 GPU 在「想」什麼，透過高速網路共享記憶體）之後，Hopper 世代的算力天花板基本上已經觸及。物理定律限制了你能讓多少張 GPU 保持連貫，大約就是 20 萬到 30 萬張的量級。</p>
<p>這意味著，要繼續推動預訓練規模定律、訓練出更強大的基礎模型，就必須等待下一代晶片。Blackwell 的運算效能遠超 Hopper，理論上可以在相同數量的 GPU 上實現數倍的等效算力。但 Blackwell 延遲了。與此同時，Google 的下一代 TPU 也還沒準備好。整個產業陷入了一個尷尬的真空期。</p>
<p>如果你嚴格按照預訓練規模定律的邏輯推演，2024 年到 2025 年這段期間，AI 能力應該會停滯。已經沒有更多的 Hopper 算力可以投入，Blackwell 又還沒到位。大眾投資人對這個問題並不敏感，因為他們看到的是持續發布的新模型、持續改善的基準測試分數、持續擴張的應用場景。但這些進展的來源，與過去幾年截然不同。</p>
<hr>
<h2 id="reasoning-的出現兩個新的規模定律">Reasoning 的出現：兩個新的規模定律</h2>
<p>就在 AI 可能停滯的關鍵時刻，Reasoning（推理）模型出現了。2024 年 10 月，OpenAI 發布了 o1 模型，這是第一個真正意義上的 Reasoning 模型。它的出現，為 AI 開闢了一條不依賴硬體升級的進步路徑。</p>
<p>傳統的預訓練規模定律之外，現在有了兩個新的規模定律。第一個是 Post-training Scaling Laws（後訓練規模定律），核心技術是「帶有可驗證獎勵的強化學習」（Reinforcement Learning with Verified Rewards, RLVR）。「可驗證」是這裡的關鍵概念。Andrej Karpathy（前 Tesla AI 總監、OpenAI 共同創辦人）有一句名言：「在軟體領域，任何你能規格化的東西，你就能自動化。在 AI 領域，任何你能驗證的東西，你就能自動化。」這是一個重要的區別。如果一個任務的結果有明確的對錯判斷——數學證明是否正確、程式碼是否能執行、答案是否符合事實——那麼你就可以用強化學習來大幅提升模型在這類任務上的表現。</p>
<p>第二個新的規模定律是 Test-time Compute（推論時運算）。傳統模型在回答問題時，運算量基本上是固定的，不管問題多難，模型都是「想」差不多長的時間就給出答案。但 Reasoning 模型可以在回答問題時進行更長時間的「思考」，在內部進行多步推理、自我檢查、嘗試不同的解題路徑。你投入越多的推論時運算，模型的表現就越好。這創造了一個新的規模維度：即使基礎模型不變，你也可以透過增加推論時運算來提升表現。</p>
<p>這兩個新的規模定律帶來了驚人的進展速度。ARC-AGI 是一個專門測試 AI 泛化能力的基準測試，被認為是衡量「真正智慧」的重要指標。在過去四年間，最好的 AI 模型在這個測試上的表現從 0% 緩慢爬升到 8%。但在 o1 發布後的短短三個月內，這個數字從 8% 躍升到了 95%。這種跳躍式的進步，完全來自後訓練和推論時運算的改善，而非更大規模的預訓練。</p>
<hr>
<h2 id="拯救與彌補reasoning-如何讓-ai-穿越硬體真空期">拯救與彌補：Reasoning 如何讓 AI 穿越硬體真空期</h2>
<p>從產業發展的角度來看，Reasoning 模型的出現具有雙重意義。表面上，它是一項技術突破，開闢了新的能力提升路徑。但更深層的意義在於，它彌補了 Blackwell 延遲造成的 18 個月空白期，讓 AI 在硬體升級停滯的情況下繼續展現進步。</p>
<p>這個時機的巧合（或者說必然）值得深思。如果 Reasoning 沒有在 2024 年下半年出現，整個 AI 產業會面臨什麼局面？從 2024 年中到 2025 年底的 Gemini 3 發布，整整 18 個月的時間，預訓練規模定律無法推動任何實質進展。市場會看到什麼？數百億美元的資本支出，但模型能力停滯不前。投資人會如何反應？那些押注在 AI 革命上的科技股會經歷什麼？整個敘事可能會從「AI 正在改變世界」轉變為「AI 遇到了天花板」。</p>
<p>Reasoning 的出現讓這個假設情境沒有發生。公眾看到的是持續的進步：更強的程式碼生成能力、更好的數學推理、更可靠的事實性回答。這些進步來自後訓練和推論時運算的改善，而非更大的基礎模型。但對於不深入追蹤技術細節的觀察者來說，進步就是進步，來源並不重要。AI 的敘事得以延續，資本繼續流入，產業繼續擴張。</p>
<p>從技術演進的角度，這段時期也有其積極意義。它證明了 AI 能力的提升不只有一條路徑。預訓練規模定律仍然重要，但它不再是唯一的遊戲。後訓練和推論時運算提供了互補的提升維度。更重要的是，這三個規模定律是「相乘」而非「相加」的關係。當 Blackwell 終於大規模部署，新的基礎模型開始訓練時，這些模型將同時受益於更強大的預訓練、更成熟的後訓練技術、以及更充裕的推論時運算資源。三重加乘效應，意味著未來幾年的模型進步可能遠超過去任何時期。</p>
<hr>
<h2 id="gemini-3-的驗證預訓練規模定律依然有效">Gemini 3 的驗證：預訓練規模定律依然有效</h2>
<p>2024 年底，Google 發布了 Gemini 3。這個發布之所以重要，不只是因為它是一個強大的新模型，更因為它提供了一個關鍵的驗證：預訓練規模定律在新的數量級上依然有效。</p>
<p>這個驗證為什麼重要？因為 Gemini 3 是自 Hopper 世代以來，第一個真正測試預訓練規模定律的重大模型。在 Reasoning 崛起的這段期間，產業的注意力大多集中在後訓練和推論時運算上。預訓練規模定律雖然是整個大型語言模型革命的基礎，但它已經有一段時間沒有被新的大規模實驗所驗證了。理論上，它可能已經開始失效而我們還不知道。</p>
<p>Google 在發布 Gemini 3 時明確表示，模型的表現符合預訓練規模定律的預期。這是一個極其重要的數據點。它意味著，當 Blackwell 和後續的 Rubin 晶片大規模部署後，投入更多算力訓練更大的模型，依然會帶來可預期的能力提升。整個產業數千億美元的資本支出計畫，其底層假設依然成立。</p>
<p>Gemini 3 也展現了實際的能力躍進。它是第一個成功幫 Baker 完成餐廳訂位的 AI 模型——不是推薦餐廳，而是實際完成訂位這個動作。這聽起來是個小事，但它標誌著一個重要的轉折：AI 開始能夠「做事」，而不只是「說話」。如果 AI 能訂餐廳，那離訂飯店、訂機票、叫車就不遠了。一個真正的個人助理開始成形。</p>
<hr>
<h2 id="2026-年展望三重規模定律的加乘效應">2026 年展望：三重規模定律的加乘效應</h2>
<p>展望未來，Baker 預測第一個在 Blackwell 上訓練的模型將在 2026 年初問世，最可能來自 XAI。這個預測基於一個簡單的事實：沒有人建資料中心比 Elon Musk 更快。Nvidia 執行長黃仁勳已經公開證實了這一點。XAI 部署新 GPU 的速度最快，因此能最先與 Nvidia 合作解決新晶片的各種問題，也最先完成大規模訓練。</p>
<p>但取得 Blackwell 只是第一步。即使你擁有了這些晶片，也需要六到九個月的時間才能讓它們的表現達到前一代 Hopper 的水準。這不是硬體問題，而是軟體和工程調校的問題。Hopper 已經被各團隊用了兩年多，每個人都知道怎麼最佳化它，軟體堆疊已經針對它的特性精細調校，工程師熟悉它的所有怪癖和最佳實踐。Blackwell 是全新的，所有這些知識都需要重新累積。歷史經驗顯示，當 Hopper 剛推出時，也花了六到十二個月才真正超越前一代的 Ampere。</p>
<p>當 Blackwell 模型終於問世，它們將展現三重規模定律加乘的威力。更大規模的預訓練帶來更強的基礎能力，更成熟的後訓練技術帶來更好的指令遵循和推理能力，更充裕的推論時運算帶來更深入的思考和更可靠的答案。GB300（Blackwell 的改進版）和 AMD 的 MI450 帶來的每 Token 成本大幅下降，意味著這些模型可以被允許「思考」更長時間，執行更複雜的任務。</p>
<p>這種能力提升會如何轉化為實際應用？一些領先的科技公司已經讓 AI 處理超過 50% 的客戶支援工作。這是一個價值 4,000 億美元的產業。AI 在說服和溝通方面的能力，直接對應到銷售和客戶支援這兩個核心商業功能。如果把企業的功能簡化為三件事——製造產品、銷售產品、支援客戶——到 2026 年底，AI 可能已經能夠很好地處理其中兩項。機器人技術也終於開始進入實用階段，各種新創公司正在湧現，儘管大規模量產的競爭最終可能集中在 Tesla 的 Optimus 和中國廠商之間。</p>
<hr>
<h2 id="投資視角這場技術演進的資本意涵">投資視角：這場技術演進的資本意涵</h2>
<p>從投資的角度來看，這段技術演進史揭示了幾個重要的洞察。預訓練規模定律依然有效，這意味著「更大就是更好」的資本競賽還會持續。那些能夠取得最大規模算力的玩家，在基礎模型競爭中仍具有結構性優勢。這解釋了為什麼 Meta、Microsoft、Google、Amazon 都在競相擴張資料中心，為什麼 OpenAI 提出了 1.4 兆美元的 Stargate 計畫。</p>
<p>Reasoning 模型的出現創造了新的競爭維度，但也加高了進入門檻。後訓練需要大量的人類反饋數據和精細的工程調校，推論時運算需要龐大的即時算力支撐。這些都是資本密集且知識密集的能力。更重要的是，Reasoning 創造了一個飛輪效應：用戶使用產生數據，數據被用來改進模型，改進的模型吸引更多用戶。這個飛輪過去在 Netflix、Amazon、Google 運轉了十幾年，現在終於開始在 AI 領域轉動。領先者的優勢將越來越難以追趕。</p>
<p>Blackwell 的延遲給了 Google 一個暫時的喘息空間。在 Blackwell 部署困難的這段期間，Google 的 TPU v6 和 v7 成為相對先進的選擇，讓 Google 得以維持「Token 低成本生產者」的地位，對競爭對手施加價格壓力。但這個優勢窗口正在關閉。當 Blackwell 和後續的 Rubin、GB300 大規模部署，成本結構將重新洗牌。那些擁有最新 Nvidia 硬體的玩家將奪回成本優勢，而 Google 的戰略計算將需要調整。</p>
<p>綜觀這一切，一個更宏觀的模式浮現：無論 AI 發展遇到什麼瓶頸，似乎總能找到突破口。硬體升級停滯？Reasoning 填補空白。電力供應受限？太空資料中心的可能性正在浮現。稀土供應被中國掌控？替代供應鏈和新提煉技術正在加速發展。這種「AI 需要什麼就得到什麼」的模式，究竟是巧合、是市場機制的自然調節、還是某種更深層的技術演進必然性？這個問題本身，或許就是理解當前 AI 革命最重要的線索。</p>
<hr>
<p><em>本文為 AINEXT 系列報導「Gavin Baker 談 AI 產業」第一篇。下一篇將探討 Baker 對太空資料中心的驚人分析。</em></p>

        </div>
        <div class="post_extra mb-2">
          
<div class="copy" data-before="分享故事" data-after="已複製">
  <svg class="icon">
    <use xlink:href="#copy"></use>
  </svg>
</div>
        </div>
        <div>
        
        </div>
      </div>
    </div>
    <a href=https://bnextmedia.github.io/AINEXT/ class="post_nav"><span class="post_next">Latest Posts
      <svg class="icon icon_scale">
        <use xlink:href="#double-arrow"></use>
      </svg>
    </span></a>
  </div>

    </main>
    <footer class="footer wrap pale">
  <p>&copy;&nbsp;<span class="year"></span>&nbsp;AINEXT</p>
  <p class="attribution upcase">由 <a href = 'https://bnextmedia.github.io/AINEXT/' target = '_blank' title = '領英個人檔案' rel = 'nonopener'>AINEXT</a> 設計</p>
</footer>


<script src="https://bnextmedia.github.io/AINEXT/js/index.min.0c2fb80a1ade817d7387f0de8ee061e7de6878a65a420dc61a6e0d0b3bb765c4c0394caefa7c40b16d39c7d74283b3cab364aa109f58cad99d149ec813f930c8.js"></script>

    <svg width="0" height="0" class="hidden">
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 699.428 699.428" id="copy">
    <path d="M502.714 0H240.428C194.178 0 153 42.425 153 87.429l-25.267.59c-46.228 0-84.019 41.834-84.019 86.838V612c0 45.004 41.179 87.428 87.429 87.428H459c46.249 0 87.428-42.424 87.428-87.428h21.857c46.25 0 87.429-42.424 87.429-87.428v-349.19L502.714 0zM459 655.715H131.143c-22.95 0-43.714-21.441-43.714-43.715V174.857c0-22.272 18.688-42.993 41.638-42.993l23.933-.721v393.429C153 569.576 194.178 612 240.428 612h262.286c0 22.273-20.765 43.715-43.714 43.715zm153-131.143c0 22.271-20.765 43.713-43.715 43.713H240.428c-22.95 0-43.714-21.441-43.714-43.713V87.429c0-22.272 20.764-43.714 43.714-43.714H459c-.351 50.337 0 87.975 0 87.975 0 45.419 40.872 86.882 87.428 86.882H612v306zm-65.572-349.715c-23.277 0-43.714-42.293-43.714-64.981V44.348L612 174.857h-65.572zm-43.714 131.537H306c-12.065 0-21.857 9.77-21.857 21.835 0 12.065 9.792 21.835 21.857 21.835h196.714c12.065 0 21.857-9.771 21.857-21.835 0-12.065-9.792-21.835-21.857-21.835zm0 109.176H306c-12.065 0-21.857 9.77-21.857 21.834 0 12.066 9.792 21.836 21.857 21.836h196.714c12.065 0 21.857-9.77 21.857-21.836 0-12.064-9.792-21.834-21.857-21.834z"></path>
  </symbol>
  <symbol viewBox="0 0 53 42" xmlns="http://www.w3.org/2000/svg" id="double-arrow">
    <path d="M.595 39.653a1.318 1.318 0 0 1 0-1.864L16.55 21.833a1.318 1.318 0 0 0 0-1.863L.595 4.014a1.318 1.318 0 0 1 0-1.863L2.125.62a1.318 1.318 0 0 1 1.864 0l19.35 19.349a1.318 1.318 0 0 1 0 1.863l-19.35 19.35a1.318 1.318 0 0 1-1.863 0zm29 0a1.318 1.318 0 0 1 0-1.864L45.55 21.833a1.318 1.318 0 0 0 0-1.863L29.595 4.014a1.318 1.318 0 0 1 0-1.863l1.53-1.53a1.318 1.318 0 0 1 1.864 0l19.35 19.349a1.318 1.318 0 0 1 0 1.863l-19.35 19.35a1.318 1.318 0 0 1-1.863 0z"></path>
  </symbol>
</svg>
  </body>
</html>
