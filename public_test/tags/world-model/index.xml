<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>World Model on AINEXT</title>
    <link>https://bnextmedia.github.io/AINEXT/tags/world-model/</link>
    <description>Recent content in World Model on AINEXT</description>
    <generator>Hugo</generator>
    <language>zh-TW</language>
    <lastBuildDate>Mon, 22 Dec 2025 22:25:00 +0800</lastBuildDate>
    <atom:link href="https://bnextmedia.github.io/AINEXT/tags/world-model/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>深度學習教父的 AI 安全方案——為什麼「目標驅動架構」比微調更安全？</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251222-yann-lecun-objective-driven-ai-safety/</link>
      <pubDate>Mon, 22 Dec 2025 22:25:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251222-yann-lecun-objective-driven-ai-safety/</guid>
      <description>&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/7u-DXVADyhc&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Information Bottleneck Podcast EP20 對 Yann LeCun 的專訪。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;AI 安全是當前最熱門的話題之一。各大實驗室花費大量資源做 RLHF（人類反饋強化學習）、Constitutional AI、紅隊測試，試圖讓他們的模型更安全、更不容易說出有害的內容。&lt;/p&gt;&#xA;&lt;p&gt;但 Yann LeCun 認為，這些方法從根本上就是錯的。&lt;/p&gt;&#xA;&lt;p&gt;在最近的 Information Bottleneck 訪談中，這位圖靈獎得主提出了一個不同的思路：AI 安全不應該靠事後的微調和過濾，而應該從架構本身就保證安全。這個想法的核心是他一直在推動的「目標驅動架構」（objective-driven architecture）——一個與當前 LLM 範式根本不同的 AI 系統設計方式。&lt;/p&gt;&#xA;&lt;h2 id=&#34;llm-安全的根本困境&#34;&gt;LLM 安全的根本困境&lt;/h2&gt;&#xA;&lt;p&gt;為什麼 LLM 這麼難做到安全？LeCun 的分析直指問題核心：微調不是根本解法。&lt;/p&gt;</description>
    </item>
    <item>
      <title>「LLM 永遠無法達到人類智慧」——Yann LeCun 的技術宣戰</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251222-yann-lecun-llm-cannot-reach-human-intelligence/</link>
      <pubDate>Mon, 22 Dec 2025 22:20:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251222-yann-lecun-llm-cannot-reach-human-intelligence/</guid>
      <description>&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/7u-DXVADyhc&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Information Bottleneck Podcast EP20 對 Yann LeCun 的專訪。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;Yann LeCun 與矽谷主流的分歧，不是「A 方法好還是 B 方法好」這種程度的爭論。他認為 LLM 這整條路線從根本上就走錯了。在最近的 Information Bottleneck 訪談中，這位圖靈獎得主花了將近兩個小時，詳細解釋為什麼他認為 LLM 是死胡同，以及他認為正確的方向是什麼。&lt;/p&gt;&#xA;&lt;p&gt;這不是學術象牙塔裡的辯論。LeCun 剛離開 Meta，創辦了一家專注於 World Model 的新公司 AMI。他把自己的信念付諸行動，用創業來押注這個與主流完全不同的技術路線。&lt;/p&gt;&#xA;&lt;h2 id=&#34;文字資料的資訊量少得可憐&#34;&gt;文字資料的資訊量，少得可憐&lt;/h2&gt;&#xA;&lt;p&gt;LeCun 的核心論點之一，是關於資料量的數學計算。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Yann LeCun 65歲創業宣言——為什麼他要與整個矽谷對賭？</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251222-yann-lecun-65-startup-world-model/</link>
      <pubDate>Mon, 22 Dec 2025 22:10:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251222-yann-lecun-65-startup-world-model/</guid>
      <description>&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/7u-DXVADyhc&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Information Bottleneck Podcast EP20 對 Yann LeCun 的專訪。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;Yann LeCun 65 歲了。圖靈獎得主、卷積神經網路發明者、Meta FAIR 創辦人。按理說，這個年紀可以退休了。他太太也這麼希望。&lt;/p&gt;&#xA;&lt;p&gt;但他選擇創業。&lt;/p&gt;&#xA;&lt;p&gt;離開待了 12 年的 Meta，創辦一家叫 Advanced Machine Intelligence（AMI）的新公司，專注於 World Model——一個與當前 LLM 路線完全不同的技術方向。當所有人都在追逐更大的語言模型時，他決定走另一條路。這個想法他想了將近十年，現在終於要動手做了。&lt;/p&gt;&#xA;&lt;h2 id=&#34;為什麼離開-meta&#34;&gt;為什麼離開 Meta？&lt;/h2&gt;&#xA;&lt;p&gt;LeCun 創辦 FAIR（Facebook AI Research）超過十年了。這個實驗室影響力很大——PyTorch 是從這裡出來的，更重要的是，它建立了一種「什麼都發表」的文化。FAIR 帶頭開放，逼得 Google 這種本來很封閉的公司也開始發論文。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
