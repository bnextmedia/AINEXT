---
title: "Yann LeCun 65歲創業宣言——為什麼他要與整個矽谷對賭？"
date: 2025-12-22T22:10:00+08:00
description: "圖靈獎得主 Yann LeCun 在 65 歲離開 Meta，創辦專注於 World Model 的新公司 AMI。他認為當前 LLM 路線是死胡同，矽谷陷入羊群效應。本文剖析他為何選擇與主流對賭，以及他對達到「狗級智慧」需要 5-10 年的時間表預測。"
tags: ["Yann LeCun", "World Model", "JEPA", "Meta", "AI 創業"]
categories: ["AI 技術前沿"]
source_url: "https://www.youtube.com/watch?v=7u-DXVADyhc"
source_name: "Information Bottleneck Podcast"
draft: false
---

{{< youtube 7u-DXVADyhc >}}

---

> 本文整理自 Information Bottleneck Podcast EP20 對 Yann LeCun 的專訪。

Yann LeCun 65 歲了。圖靈獎得主、卷積神經網路發明者、Meta FAIR 創辦人。按理說，這個年紀可以退休了。他太太也這麼希望。

但他選擇創業。

離開待了 12 年的 Meta，創辦一家叫 Advanced Machine Intelligence（AMI）的新公司，專注於 World Model——一個與當前 LLM 路線完全不同的技術方向。當所有人都在追逐更大的語言模型時，他決定走另一條路。這個想法他想了將近十年，現在終於要動手做了。

## 為什麼離開 Meta？

LeCun 創辦 FAIR（Facebook AI Research）超過十年了。這個實驗室影響力很大——PyTorch 是從這裡出來的，更重要的是，它建立了一種「什麼都發表」的文化。FAIR 帶頭開放，逼得 Google 這種本來很封閉的公司也開始發論文。

但風向變了。過去幾年，各家 AI 實驗室開始收緊。OpenAI 早就這樣了，Google 在跟進，連 Meta 內部也出現類似趨勢。FAIR 被推著做更短期的專案，發更少的論文，更多時間花在配合 LLM 前沿模型的開發。

「如果你不發表你的研究，你就很容易被自己騙。」LeCun 說。「你做出了什麼東西，覺得這是切片麵包以來最棒的發明。但如果你不把它提交給社群檢驗，你可能只是在自欺欺人。」他見過太多這樣的例子：企業研究實驗室裡充斥著內部 hype，卻完全沒意識到外面的人正在做更好的東西。

這種封閉趨勢讓他不舒服。更重要的是，他感興趣的研究方向——World Model、規劃、抽象表徵學習——並不是 Meta 目前優先投資的領域。所以他決定，是時候把這些想法帶到外面去實現了。

## World Model 是什麼？為什麼不是 LLM？

AMI 的核心技術方向是 World Model。這不是一個新概念——LeCun 從 2015、2016 年就開始公開倡導這個想法。他在 2016 年 NeurIPS 的主題演講中，就把 World Model 作為核心論點：這才是我們應該研究的方向。

那什麼是 World Model？簡單說，它是一個能夠預測「如果我採取某個行動，世界會發生什麼變化」的系統。有了這個預測能力，AI 系統就可以透過「規劃」來達成目標——想像各種可能的行動序列，預測每一個序列會帶來的結果，然後選擇能最佳達成目標的那一個。

這聽起來很直覺，但關鍵在於「怎麼做預測」。LeCun 認為，當前主流的方法都走錯了方向。

LLM 的做法是把所有資料都轉換成離散的 token，然後預測下一個 token。這對文字來說還算有效，但對於高維度、連續、有噪音的資料——比如影片——就完全行不通了。你沒辦法用 token 的方式有效表達一個影片的內容，因為影片中的「細節」太多了，大部分都是不可預測的噪音。

另一種流行的做法是影片生成模型，像 Sora 這樣的系統。但 LeCun 認為這也是錯的。「產生看起來漂亮的影片，並不代表你真的理解了世界的動力學。」這些系統可能只是學會了如何產生「看起來合理」的像素，但對於物體為什麼會這樣移動、物理定律是什麼，可能完全沒有概念。

LeCun 主張的方法是 JEPA（Joint Embedding Predictive Architecture，聯合嵌入預測架構）。核心想法是：不要在像素層級做預測，而是先把輸入轉換成一個「抽象表徵」，然後在這個抽象空間裡做預測。抽象表徵會自動忽略那些不可預測的細節（噪音），只保留真正重要的結構性資訊。

這就像物理學家處理氣體的方式。你可以嘗試模擬盒子裡每一個分子的運動軌跡，但這既不可能也沒必要。物理學家發明了「溫度」、「壓力」這些抽象概念，用 PV=nRT 這樣的簡單公式就能做出準確的預測。World Model 應該也是這樣運作的：在抽象層級做預測，而不是試圖重建所有細節。

## 矽谷的 LLM 單一文化

LeCun 對矽谷 AI 產業的批評毫不客氣。他用「LLM-pilled」這個詞來形容當前的主流思維：相信只要繼續擴大 LLM 規模、用更多合成資料訓練、請更多人做後訓練微調、發明新的強化學習技巧，就能達到超級智慧。

「這完全是妄想，永遠不會成功。」

他觀察到一個有趣的現象：因為競爭太激烈，所有公司都必須做跟別人一樣的事。如果你走一條不同的路線，你就冒著落後的風險。結果就是羊群效應——OpenAI、Google、Anthropic、Meta，大家都在做本質上相同的事情。

當有人從完全不同的方向突破時，整個產業都會措手不及。DeepSeek 就是一個例子。一家中國公司用不同的方法做出了讓矽谷驚訝的成果。「怎麼，矽谷以外的人也不笨，也能想出原創的點子？」LeCun 帶著一點諷刺說。

這也是為什麼他選擇在這個時機創業。現在有投資人願意資助「前幾年專注於研究」的新創公司，這在以前是不可能的。以前，要做長期研究只能去大公司的研究實驗室——AT&T 的貝爾實驗室、IBM 研究院、Xerox PARC、後來的微軟研究院和 Google Research。但現在，資本市場對 AI 的期望高到足以支持「研究導向」的新創公司。

## 時間表：最樂觀 5-10 年達到狗級智慧

訪談中自然會問到：什麼時候能達到人類水準的 AI？

LeCun 先吐槽了「通用智慧」（AGI）這個概念——「complete BS」（徹頭徹尾的鬼扯）。人類智慧看起來很「通用」，只是因為我們能想到的問題都是我們能處理的問題。但其實人類智慧是高度特化的：我們擅長處理物理世界和社會互動（因為演化讓我們這樣），但下棋超級爛。AlphaGo 出現之前，大家以為人類頂尖棋手只比「理想玩家」差兩三目，結果發現差了八九目。

所以更有意義的問題是：什麼時候機器能在「所有人類擅長的領域」達到人類水準？

LeCun 的回答是：最樂觀的情況下，5-10 年內可能達到「狗級智慧」或接近人類的水準。但這是「最樂觀」的估計，前提是 World Model、規劃、處理連續高維資料的技術在接下來幾年取得重大進展。

「最困難的部分是達到狗的程度。」他說。「一旦你達到狗的程度，你基本上就有了大部分需要的元件。」從狗到人的差距，主要是語言能力，而這恰恰是 LLM 已經做得不錯的地方。LLM 可能會變成未來 AI 系統的「韋尼克區和布洛卡區」（大腦中負責語言理解和產生的區域），而 World Model 則是「前額葉皮質」（負責規劃和推理）。

但他也強調，很可能我們還會遇到目前看不到的障礙，就像 AI 歷史上多次發生的那樣。那種情況下，可能需要 20 年甚至更久。

## 這場豪賭的意義

65 歲創業，賭上自己的學術聲譽和最後一段職業生涯，去押注一個與主流完全不同的技術路線。大多數人到了這個年紀會選擇安穩，而不是跟整個矽谷對賭。

LeCun 在訪談結尾解釋了他的動機。他一直相信「增加世界上的智慧」是一件本質上好的事情。這可以透過教育來實現（所以他是教授），也可以透過讓機器輔助人類來實現（所以他研究 AI）。儘管有各種關於 AI 風險的擔憂，他認為這些都是可以透過工程手段解決的問題，就像噴射引擎一開始也會爆炸，但現在可以讓你安全飛越半個地球。

「我有使命感。」

這場賭注的結果，可能要好幾年才會揭曉。但這是少數有資格挑戰主流的人之中，真正願意把信念付諸行動的。不管最後誰對誰錯，這本身就說明了一些事情。
