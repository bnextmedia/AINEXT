---
title: "AI CapEx 是美麗的泡沫嗎？半導體分析師算了一筆帳"
date: 2026-02-09T11:00:00+08:00
description: "鄧紫棋唱著「美麗的泡沫，雖然一剎花火」，華爾街也在問同樣的問題：AI 基礎設施每年燒掉 5,000 億美元的資本支出，到底是泡沫還是合理投資？SemiAnalysis 創辦人 Dylan Patel 用 token 經濟學、GitHub 數據和漢堡的用水量，拆解了這道題。"
tags: ["AI CapEx", "Dylan Patel", "SemiAnalysis", "能源", "Claude Code"]
categories: ["AI 產業動態"]
image: "/images/posts/20260209-nvidia-chip-empire-strategy.webp"
source_url: "https://www.youtube.com/watch?v=DqBMzuzxZog"
source_name: "MAD Podcast"
related_companies: ["nvidia", "openai"]
related_people: ["jensen-huang"]
draft: false
---

> 本文整理自 MAD Podcast 2026 年 2 月播出的單集。

{{< youtube DqBMzuzxZog >}}

---

## 陽光下的泡沫是彩色的

鄧紫棋在〈泡沫〉裡唱：「早該知道泡沫一觸就破」。華爾街分析師看著超大規模企業今年預計砸下 5,000 億美元的資本支出，心裡也在唱差不多的歌。2,000 億、3,000 億、5,000 億，數字一年比一年瘋狂，但 AI 的營收真的接得住嗎？這些錢最終會變成利潤回來，還是會像泡沫一樣，「一觸就破」？

半導體研究機構 SemiAnalysis 的創辦人 Dylan Patel 對這個問題的回答，不是喊口號，而是拿出計算機。他先把自己的立場講清楚：「我顯然是多頭（maxi）。我的公司就是靠分析半導體供應鏈和做顧問賺錢的，所以我當然有偏見。」但他隨即拿出了一串讓人很難反駁的數字。

---

## Token 經濟學：一筆簡單的帳

Dylan Patel 的核心論點可以簡化成一道算術題。生成式 AI 的產業營收，2023 年還不到 10 億美元。2024 年大約 100 億，2025 年大約 300 到 400 億。到 2026 年底，他認為整個產業可以達到 1,000 億美元以上的年度經常性收入（ARR）。這個數字怎麼來的？他拆解了各家公司的推估：OpenAI 約 450 到 500 億、Anthropic 約 350 到 400 億，再加上 Google（Vertex AI、Gemini API）、Amazon（Bedrock API）、Microsoft（Azure Foundry API）等平台上的模型服務收入。

如果 1,000 億美元的營收是可信的，那麼以 50% 的毛利率計算，就是 500 億美元的銷貨成本。這 500 億的成本需要跑在基礎設施上，而這些基礎設施以五年折舊來算，對應的是大約 2,500 億美元的累積資本支出。但超大規模企業今年的 AI 基礎設施支出可能高達 5,000 億美元，足足是「需要」的兩倍。

所以是泡沫嗎？不一定。因為這道算術少算了一個關鍵變數：R&D。去年那些「超額」的資本支出，也就是營收還沒追上的那部分投資，正是讓今年的模型變得這麼厲害的原因。Microsoft 2024 年為 OpenAI 花的資本支出，直接導致了 2025 年模型品質的大幅躍升。那些晶片現在還在服役，折舊還沒攤完，但它們訓練出來的模型已經讓每個用過 Claude Code 的人感受到生產力的爆發。

---

## 2% 的 GitHub Commits 背後的兆元市場

Dylan Patel 丟出了一個讓人眼睛一亮的數據點：目前 GitHub 上大約 2% 的 commit 是由 Claude Code 產生的。你可以在 commit 裡關掉這個標記，但有 2% 是明確標注為 AI 生成的程式碼。加上 Codex、Cursor 和其他工具，AI 生成的程式碼可能已經佔了 GitHub commit 的 5% 以上。

這個數字之所以重要，是因為全球軟體開發人員的薪資總額約為 2 兆美元。如果 AI 已經在做 5% 的工作，光是用最粗略的方式換算，那就是 1,000 億美元等級的生產力。但 AI 產業實際收到的營收遠低於此，這代表 AI 目前是在「低估自己創造的價值」。Dylan Patel 用了一個很直接的說法：AI is under-earning the value it produces in the world（AI 正在低估它為世界創造的價值）。

他用自己公司的一個案例來說明這種價值創造有多具體。SemiAnalysis 的一位分析師，背景是半導體機械系統工程，不是軟體開發者。這個人用 Claude Code 做了一件事：把公司追蹤的全球晶圓廠資料集（透過衛星影像計算出的每座工廠面積）和一家上市公司的財報資料串在一起，讓 AI 自動抓取公開財報、清理資料、排除五年前一筆併購的影響做 pro forma 分析、畫圖表、最後還寫好研究報告。整個過程他沒有全職投入，大概花了三個小時，其間他同時在做其他工作，就是把指令丟給模型，去忙別的事，回來再看結果。

他進一步指出，這種轉變對初級分析師的衝擊是立即性的。不管是創投、成長型基金、公開市場還是私募，初級分析師的核心工作就是找資料、清理資料、做圖表。現在這些事情用 Claude Code 就能做到。很多公司已經停止招聘 L4 等級的工程師，因為同樣的工作直接交給 AI 就好。全球有 2 兆美元的軟體相關薪資，加上更多的知識工作者薪資，正在面臨這種被 AI 工具接管的趨勢。

---

## 漢堡用水量的啟示：AI 最被誤解的環境問題

在 CapEx 泡沫論之外，AI 基礎設施還面臨另一個輿論壓力：環境影響。資料中心用太多電、用太多水，成了反 AI 運動的重要彈藥。紐澤西州甚至因為電價上漲而影響了地方選舉，選民把怒氣發洩在一座 Microsoft/Nebius 的資料中心上。

Dylan Patel 對這個議題的態度是：水資源的爭議根本站不住腳，而且他花了功夫去驗證。SemiAnalysis 的研究團隊把 AI 資料中心的用水量和漢堡進行了比較。結果是：整座馬斯克的 Colossus 資料中心（這是當時最大的 AI 訓練叢集之一），其用水量大約等於兩間半的 In-N-Out 漢堡店。

這個比較之所以成立，是因為牛肉生產的耗水量極為驚人。養一頭牛不只是讓牛喝水，而是要種大量的玉米、黃豆、苜蓿來做飼料，這些農作物的灌溉才是真正的用水大戶。一個普通使用者一整年用 ChatGPT 消耗的水量，大約等於一個漢堡。資料中心的冷卻系統多數是封閉迴路，蒸發冷卻確實會消耗一些水，但這麼做其實減少了耗電，對環境的淨效益是正的。

至於紐澤西州電價上漲的事，Dylan Patel 指出真正原因是超級風暴桑迪幾年前摧毀了該州的電力基礎設施，重建費用最終轉嫁到消費者的電費上。和那座資料中心根本沒有關係，但它變成了一個方便的代罪羔羊。類似的狀況也發生在路易斯安那州 Meta 的巨型資料中心（計畫容量 4 到 5 GW），當地居民抱怨水質變差，但真正的汙染源是該地區的壓裂（fracking）作業，那些天然氣大部分被液化後出口到亞洲。

---

## 模型進步不停，泡沫就不會破

回到最核心的問題：CapEx 到底是不是泡沫？Dylan Patel 給了一個非常清楚的條件判斷。只要模型持續進步，這些投資就不是泡沫。過去幾年的事實是：每投入更多算力，模型的表現就以可預測的方式提升，而更好的模型直接轉化為更多的使用需求和營收。

但如果模型進步停滯呢？如果 scaling laws 撞牆、沒有新的研究方向了呢？那所有的支出就真的打了水漂。Dylan Patel 坦言這是最大的風險，但他從自己的觀察中看到了相反的信號。他提到，OpenAI 目前擁有比 Anthropic 更好的強化學習（RL）堆疊，但預訓練模型卻不如 Anthropic。而 Google 的預訓練模型比 OpenAI 和 Anthropic 都好，但 RL 堆疊又落後。這意味著每一家都有明確的進步空間：OpenAI 改善預訓練，Google 改善 RL，Anthropic 在兩邊都持續推進。當這些改善落實，模型的能力會出現另一波顯著提升。

他用一個他認為具有標誌性的「時刻」來說明模型進步帶來的經濟影響。ChatGPT 是一個時刻，Ghibli 風格圖片生成是一個時刻，而他認為 Claude Code 搭配 Opus 4.5 是最新的一個時刻。這是一個「工作方式永久改變」的時刻。SemiAnalysis 有 54 個人，大約一半本來就會寫程式，另一半正在被推著學習用 Claude Code。有人來自半導體顧問背景，有人在晶圓廠工作過，有人做的是半導體封裝工程，現在他們都在用 Claude Code 來自動化研究和分析流程。

---

## 電力才是真正的瓶頸，但答案不是核能

如果 AI 的資本支出不是泡沫，那下一個問題就是：有沒有可能根本蓋不出足夠的基礎設施？這裡最大的瓶頸不是晶片、不是記憶體，而是電力。

Dylan Patel 對核能的態度出乎很多人意料：他「很喜歡核能」，但認為在 AI 的發展時程內，核能根本來不及。就連中國蓋一座核電廠也要五年，在美國更是遙遙無期。核能適合長期佈局，但 AI 對電力的需求是現在就要、明年就要更多。

現實中正在發生的，是天然氣方案。Dylan Patel 透露，他的一個客戶買下了一座退役的燃煤電廠並重新啟動，現在有某家超大規模企業想買下它的全部電力輸出，並在旁邊蓋資料中心。風力加天然氣備援、太陽能加天然氣備援，這種「再生能源搭配化石燃料」的模式，正在成為 AI 資料中心電力供應的主流方案。有些資料中心走「behind the meter」模式，完全不接入電網（比如 Elon Musk 的部分 Colossus 設施、OpenAI 在德州 Abilene 的部分建設），有些則和電網連接但搭配自有發電設施。

有趣的是，AI 的資本支出熱潮正在產生一些意想不到的「和平紅利」。超大規模企業在建設資料中心的同時，經常需要升級當地的輸電網路，這些升級最終也讓一般居民受惠。電工、水管工等技術工人的工資正在飆升。這些被 AI 投資帶動的基礎建設改善和就業機會，是很多人在討論 CapEx 泡沫時容易忽略的正面外溢效果。

---

## 我的觀察

Dylan Patel 這道算術題的精妙之處，在於它把一個情緒化的爭論拉回到數字上。「泡沫」這個詞自帶情緒，暗示著「被騙」「不理性」「遲早要崩」。但如果你用 1,000 億美元的產業營收、2% 以上的 GitHub commit、2 兆美元的軟體薪資市場這些數字來衡量，情況就不那麼像泡沫了。

真正的風險不是「花太多錢」，而是「模型進步停下來」。這是 Dylan Patel 反覆強調的一點。只要每一代模型都比上一代更好、能做的事情更多、為使用者創造的價值更大，那投入更多資本來訓練更大的模型就說得通。但一旦 scaling laws 撞牆，一旦下一代模型不再比這一代好多少，那所有的支出就會瞬間從「投資」變成「浪費」。

鄧紫棋在歌裡問：「如果能夠看破，有什麼難過？」Dylan Patel 的回答是：與其焦慮它是不是泡沫，不如看清楚這些錢買到了什麼。買到了更好的模型、買到了 AI 工具正在接管 5% 的軟體開發工作、買到了一個分析師用三小時就能完成過去需要一整週的研究。這些不是虛幻的承諾，而是已經在發生的生產力轉變。至於它最終是不是泡沫，答案藏在下一代模型的能力裡。
