---
title: "驗證者法則：為什麼容易打分數的任務，會最先被 AI 征服"
date: 2025-12-25T11:00:00+08:00
description: "OpenAI o1 共同創作者 Jason Wei 提出「驗證者法則」：AI 訓練能力與任務可驗證性成正比。這個框架解釋了為什麼 AI 在某些領域進步神速，在某些領域卻停滯不前，也指出了下一波突破會發生在哪裡。"
tags: ["Jason Wei", "OpenAI", "AlphaEvolve", "強化學習", "Stanford"]
categories: ["AI 產業"]
source_url: "https://www.youtube.com/watch?v=b6Doq2fz81U"
source_name: "Stanford AI Club"
draft: false
---

{{< youtube b6Doq2fz81U >}}

---

> 本文整理自 Stanford AI Club 2025 年的演講。

如果你想預測 AI 在哪個領域會有下一個大突破，Jason Wei 給了一個簡單的答案：看那個領域的任務有多容易被驗證。

Jason Wei 是 OpenAI o1 和 Deep Research 的共同創作者，學術引用超過 9 萬次。他在 Stanford AI Club 的演講中提出了一個他稱為「Verifier's Law」（驗證者法則）的概念。這個法則很簡單，但解釋力驚人：**AI 被訓練來解決某個任務的能力，與這個任務有多容易被驗證成正比。**

換句話說，如果一個任務的答案很容易打分數，AI 就能快速進步。如果答案很難評判好壞，AI 就會卡住。

## 驗證的不對稱性

要理解這個法則，先要理解「驗證不對稱性」這個老概念。有些問題，解決很難，但驗證很簡單。

數獨是經典例子。填好一個困難的數獨可能要花半小時，但檢查答案對不對只要幾秒：每行、每列、每個九宮格都是 1 到 9，沒有重複，就對了。

寫出能運作的 Twitter 需要數百個工程師（或者如果 Elon 在管，可能只要幾十個），但驗證它能不能用？打開網頁點一點就知道了。

競賽數學題介於中間。解題很難，驗證也不算簡單——你得把整個推導過程看過一遍才能確認對不對。

但反過來的情況也存在。寫一篇看起來正確的事實文章很容易，但逐一查證每個事實可能極其費時。你可以在十秒內聲稱「只吃野牛肉是最佳飲食法」，但要驗證這個說法，你需要大規模臨床試驗、長期追蹤、還要控制一堆變數。

Jason Wei 用一張二維圖來呈現這個光譜。X 軸是「生成難度」，Y 軸是「驗證難度」。數獨在左上角（生成難，驗證易）。寫 Twitter 在右上角（生成更難，驗證易）。聲稱最佳飲食法在左下角（生成易，驗證難）。

關鍵洞察是：你可以透過「提供額外資訊」來移動一個任務在這張圖上的位置。比如競賽數學題，如果我給你答案，驗證就變成只要比對數字。寫程式，如果我給你測試案例（像 SWE-Bench 那樣），驗證也變成跑一下看過不過。

這意味著：**設計好的評估方式，本身就是在為 AI 進步鋪路。**

## 五個驗證性指標

Jason Wei 進一步把「可驗證性」拆成五個具體指標：

**一、是否有客觀正確答案？**

有些任務有明確對錯。1+1=2，對就是對，錯就是錯。但「這首詩寫得好不好」就沒有客觀答案——你覺得好，我可能覺得太做作。

**二、驗證速度有多快？**

跑一段程式看它會不會崩潰，幾秒鐘就知道了。但評估一個新藥的效果，可能需要十年的追蹤。

**三、能不能同時驗證大量答案？**

如果你能平行驗證一百萬個候選解，訓練速度就能大幅提升。這通常意味著驗證過程可以被自動化、程式化。

**四、雜訊低不低？**

同樣的輸入，每次驗證都得到同樣的結果嗎？數學題是這樣，但「這個笑話好不好笑」就不是——今天心情好覺得好笑，明天心情差可能就覺得無聊。

**五、獎勵是連續的還是二元的？**

只能說「對」或「錯」，不如能說「這個解 70 分，那個解 85 分」。連續的獎勵信號讓模型更容易找到改進方向。

把這五個因素加起來，你就能大致判斷一個任務有多容易被 AI 征服。

## AlphaEvolve：驗證者法則的最佳案例

Jason Wei 在演講中特別提到 DeepMind 的 AlphaEvolve 作為這個法則的完美展示。

AlphaEvolve 做的事情很聰明：它專挑符合驗證不對稱性的問題來解。比如：在一個大六邊形裡塞 11 個小六邊形，求能包住它們的最小外框。

這個問題符合所有五個指標：有客觀答案（外框大小是個數字）、驗證很快（畫出來量一下）、可以大量平行驗證（純粹運算）、沒有雜訊（同樣的擺法永遠得到同樣的外框大小）、獎勵連續（外框越小分數越高）。

AlphaEvolve 的做法是這樣的：讓大型語言模型生成一堆候選解，用程式自動評分，挑出最好的幾個，把它們餵回給語言模型當作「靈感」，然後生成下一批候選解。重複這個過程幾千次、幾萬次。

因為驗證成本極低，它可以嘗試天文數字的可能性。最後在很多問題上，它找到了超越人類已知最佳解的答案。

這個案例揭示了一個重要的策略轉向：傳統機器學習在意的是「從訓練資料泛化到測試資料」。但 AlphaEvolve 根本不在意泛化——它就是要解這一個特定問題，訓練集和測試集是同一個東西。

這只有在驗證成本極低的情況下才玩得起來。但一旦條件滿足，效果驚人。

## 這對創業者意味著什麼

Jason Wei 認為，驗證者法則有兩個直接的應用意涵。

**第一，容易驗證的任務會最先被自動化。**

如果你的工作主要是做那些「對錯分明、可以程式化檢查」的事，你該開始想下一步了。程式除錯、資料處理、標準化文書——這些都是 AI 很快會做得比人類好的領域。

**第二，「設計評估方式」本身就是一門生意。**

如果你能把一個原本難以驗證的領域變成可量化的，你就是在為 AI 進步鋪路。這可能是下一波 AI 創業的藍海。

他舉了一個例子：個人健康。過去，評估一個飲食法好不好需要大規模臨床試驗，成本極高。但如果有人能設計出有效的短期代理指標——比如透過連續血糖監測、睡眠品質、發炎指數等數據來預測長期健康——這個領域就可能被 AI 快速攻破。

這不是科幻。這是正在發生的事。

## 過去五年所有被攻破的 AI 評測都符合這個法則

最後一個觀察：回顧過去五年，所有被 AI 攻破的重要評測——MMLU、GSM8K、HumanEval、SWE-Bench——都是容易驗證的任務。

這不是巧合。這就是驗證者法則在起作用。

所以下次當你想預測 AI 會往哪個方向突破，別問「這個問題有多難」。問「這個問題的答案有多容易打分數」。

答案容易打分數的地方，就是 AI 下一個戰場。
