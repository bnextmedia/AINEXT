---
title: "當大數據遇上國家機器：從 Palantir 看監控社會的邊界"
date: 2026-01-04T15:00:00+08:00
description: "前美國國家安全局局長 Michael Hayden 曾說：「我們根據 metadata 殺人。」這句話揭示了大數據時代的殘酷現實。從德國預測性警務實驗到美國 ICE 移民追蹤，Palantir 的技術已經深入國家機器的核心。本文從歐威爾《1984》到祖博夫《監控資本主義時代》，探討當「看見一切」的權力落入政府手中，我們該如何劃定界線。"
tags: ["Palantir", "監控社會", "預測性警務", "隱私權", "大數據", "1984"]
categories: ["科技趨勢"]
source_url: "https://www.youtube.com/watch?v=hN-mEGLF_6w"
source_name: "DW Documentary"
draft: false
---

> 本文整理自 DW Documentary 於 2026 年 1 月播出的紀錄片《Silicon Valley mastermind - Who's behind Palantir's "Gotham" surveillance software?》
> 🎬 YouTube：[觀看連結](https://www.youtube.com/watch?v=hN-mEGLF_6w)

「We kill people based on metadata.」（我們根據 metadata 殺人。）

這句話出自前美國國家安全局（NSA）局長 Michael Hayden 之口，而 Palantir 正是那種能把 metadata 轉化為「可行動情報」的公司。當一家科技公司的技術可以直接影響生死決策時，我們該如何思考監控與自由的邊界？

## 預測性警務：德國的實驗與反思

紀錄片花了相當篇幅討論德國黑森邦（Hessen）使用 Palantir 進行「預測性警務」（predictive policing）的案例。這個故事的根源可以追溯到 1970 年代。

Horst Herold 是當時德國聯邦刑事警察局的局長。在那個電腦還是龐然大物的年代，他就提出了一個激進的構想：用電腦分析犯罪數據，預測未來的犯罪案件，然後主動部署警力。這個想法在當時被認為是科幻小說的情節，但 Herold 開始著手建構這樣的系統。

某種程度上，Palantir 實現了 Herold 半個世紀前的願景。紀錄片的受訪者評論：「有人會說，Palantir 的軟體是 Horst Herold 方法論的進一步發展。」

預測性警務的運作邏輯是這樣的：系統分析歷史犯罪數據、地理資訊、社會經濟指標、天氣模式、甚至社群媒體活動，試圖預測哪些地區、哪些時段最可能發生犯罪。更進一步，系統甚至可以生成「高風險人物」名單——那些根據數據模型判斷最可能犯罪的人。

這讓人想起科幻作家 Philip K. Dick 的短篇小說《關鍵報告》（The Minority Report），後來被導演史蒂芬·史匹柏（Steven Spielberg）拍成電影《關鍵報告》。故事中，「先知」可以預見未來的謀殺案，警方據此在犯罪發生前就逮捕「未來的殺人犯」。這聽起來是完美的犯罪預防，但故事的核心問題是：一個人可以因為「即將犯下」的罪行而被懲罰嗎？

現實中的預測性警務沒有先知，只有演算法。但演算法的偏見可能比先知更危險，因為它們被包裝在「科學」和「客觀」的外衣下。

## 自我實現的預言：誰被盯上？

預測性警務最大的問題在於它可能創造「自我實現的預言」。

假設演算法判定某個社區是「高犯罪風險區」，警方就會在那裡部署更多警力、進行更多盤查。更多盤查自然會「發現」更多違規行為——可能只是輕微的持有大麻、交通違規、或其他在其他社區會被忽略的小事。這些「發現」被記錄下來，成為新的數據，進一步「證實」了演算法的判斷。如此循環，某些社區就被永久標記為「危險區域」。

這些社區往往是低收入社區、少數族裔聚居區。演算法並不是「客觀」的——它反映的是歷史上不平等執法的累積結果。一個世代前的種族歧視，透過數據「洗白」成今天的「風險評估」。

哲學家韓炳哲（Byung-Chul Han）在《透明社會》（The Transparency Society）中提出了一個相關的觀察。他認為，當代社會對「透明」的追求，本身就是一種控制機制。當一切都必須被看見、被記錄、被分析，隱私就不再是權利，而是一種需要被克服的「障礙」。預測性警務把這種邏輯推到極致：你的行為、你的社交圈、你所在的地點，都被納入一個判斷你是否「可疑」的演算法中。

2023 年，德國聯邦憲法法院做出了一項重要判決，對自動化數據分析的使用範圍設下了限制。法院認為，警方不能無限制地將不同來源的數據進行自動化串聯，這違反了基本法對人格尊嚴和資訊自決權的保護。

這個判決對 Palantir 在德國的業務造成衝擊，雖然既有合約並未被取消。但它也顯示，至少在德國，司法系統願意對監控技術的擴張說「不」。

## ICE 與家庭分離：當演算法追蹤人類

如果預測性警務是抽象的倫理問題，Palantir 與美國移民及海關執法局（ICE）的合作則是具體的人道災難。

「Palantir，你知道這是真的，ICE 的罪行靠你成真。你把孩子關進籠子裡。」抗議者在 Alex Karp 家門口高喊這些口號。這不是誇大其詞。

Palantir 的軟體被 ICE 用來追蹤無證移民。系統可以整合各種數據來源——社群媒體帳號、手機定位、交通紀錄、雇主資訊、親友關係網絡——建構出一個人的完整圖像，然後判斷這個人可能在哪裡出現。

這種能力在川普政府第一任期的「零容忍」政策下被充分利用。成千上萬的家庭被拆散，兒童被關押在拘留設施中，有些甚至與父母失去聯繫。雖然 Palantir 辯稱他們的軟體只是用來追捕「有犯罪紀錄」的移民，但批評者指出，系統本身並不區分「好」移民和「壞」移民——這個區分是由使用系統的人來做的。

紀錄片中有一位猶太裔抗議者的證詞特別令人動容：「我是猶太人，我的祖先死於大屠殺。我的祖母在水晶之夜後勉強逃脫。如果我們不能把歷史教訓應用到現在，學歷史還有什麼意義？」

她站在 Alex Karp——同樣是猶太裔——的家門口，呼籲他反思自己的公司正在做的事。這種歷史的迴響讓 ICE 爭議有了更深的層次：科技可以被用來追蹤任何群體，而今天被追蹤的對象，取決於掌權者的決定。

## 從《1984》到《美麗新世界》：兩種監控的隱喻

思考 Palantir 及其代表的監控能力，有兩部經典文學作品值得重溫。

喬治·歐威爾（George Orwell）在《一九八四》（1984）中描繪了一個「老大哥」無所不在的社會。「老大哥在看著你」（Big Brother is watching you）這句話成為監控國家的代名詞。在歐威爾的想像中，監控是外部強加的壓迫——電幕無處不在，思想警察隨時可能敲門，人們活在恐懼中。

阿道斯·赫胥黎（Aldous Huxley）的《美麗新世界》（Brave New World）提供了另一種圖像。在那個世界裡，沒有思想警察，因為根本不需要。人們被娛樂、藥物、性和消費馴化到不再渴望自由。他們不是被迫放棄隱私，而是自願暴露一切，因為他們已經不在乎。

尼爾·波斯曼（Neil Postman）在《娛樂至死》（Amusing Ourselves to Death）中比較這兩種願景，認為赫胥黎的預言更準確地描述了我們的現實。我們不是被強迫監控，而是自願在社群媒體上分享位置、照片、想法。我們用隱私換取便利，用數據換取「免費」服務。

Palantir 的存在讓這兩種圖像都變得不完整。它同時具備歐威爾式的威脅（國家機器用它來追蹤公民）和赫胥黎式的基礎（它分析的數據很大程度上是我們自願產生的）。這是一種新型態的監控，既是強制的，也是同謀的。

## 祖博夫的「監控資本主義」

哈佛商學院教授肖莎娜·祖博夫（Shoshana Zuboff）在她 2019 年的巨著《監控資本主義時代》（The Age of Surveillance Capitalism）中，為這種新型態監控提供了一個分析框架。

祖博夫認為，監控資本主義是一種新的經濟邏輯。它的原物料是人類行為數據，它的產品是對未來行為的預測，它的市場是那些願意為這些預測付費的企業和政府。Google 和 Facebook 是這個體系的先驅——它們提供「免費」服務，實際上是在提取用戶的行為數據，把這些數據轉化為精準廣告投放的能力。

Palantir 在這個圖像中佔據一個特殊位置。它不是透過廣告賺錢，而是直接把監控能力賣給政府。某種程度上，這更接近傳統意義上的「國家監控」，但它使用的技術和數據來源，很多是監控資本主義體系產生的副產品。

祖博夫在書中提出一個尖銳的問題：我們是否還有選擇的權利？當參與數位生活意味著必須放棄隱私，當不使用智慧型手機就無法正常生活在社會中，「同意」還有什麼意義？

這個問題在 Palantir 的脈絡中更加尖銳。即使你不使用社群媒體、不用智慧型手機，你的監視器畫面、你的銀行交易、你親友的數據，仍然可以被整合起來建構出你的圖像。你無法「選擇退出」，因為這個系統不需要你的同意。

## 誰來監控監控者？

紀錄片揭露了 Palantir 內部嚴格的保密文化。離職員工被要求簽署保密協議，承諾永遠不會說公司壞話。公司甚至開發了軟體來偵測內部洩密者——也就是說，Palantir 用監控技術來監控自己的員工。

這種保密性讓外界很難了解 Palantir 到底在做什麼。它的政府合約細節很少被公開，它的技術能力邊界無從得知。在這種不透明的狀態下，民主監督如何可能？

這讓人想起古羅馬詩人尤維納利斯（Juvenal）的名言：「Quis custodiet ipsos custodes?」——誰來監視監視者？

民主社會對執法權力的控制，建立在「可見性」的基礎上。警察的行為要受到法律約束，法院可以審查證據是否合法取得，公民可以對濫權行為提出申訴。但當演算法成為判斷的依據，當數據分析的過程是「黑箱」，這些傳統的制衡機制就失效了。

被 Palantir 系統標記為「可疑」的人，可能永遠不知道自己被標記了，也不知道是根據什麼被標記的。他們無從挑戰這個判斷，因為判斷的過程是商業機密。

## Skykit：戰場上的 AI

紀錄片還提到了 Palantir 的一個產品：Skykit。這是一套為「斷網、惡劣、敵對、極端環境」設計的可攜式系統，包含雙螢幕、四旋翼無人機、追蹤攝影機，全部運行 Palantir 的 AI 平台演算法。

這個產品清楚地展示了 Palantir 在軍事領域的野心。它不只是提供數據分析，而是要成為戰場決策的核心基礎設施。當 AI 演算法直接參與戰場目標的選定，這就不再只是「偶爾被用來殺人」，而是殺人本身就是設計目的。

Alex Karp 對此並不迴避。他公開表示，Palantir 的使命是「讓西方，特別是美國，成為世界上最強大的力量」。在他的敘事中，這是民主陣營與威權體制的競爭，而 Palantir 選擇站在民主這一邊。

但批評者會問：當民主國家使用的工具和威權國家越來越像，「民主」這個詞還有什麼意義？預測性警務、大規模監控、算法判決——這些在威權國家被視為壓迫工具的東西，在民主國家就變成了「安全措施」嗎？

## 邊界在哪裡？

紀錄片中有一段來自蘇聯出生的受訪者的評論特別發人深省：「如果你面前有一個非常大的目標——修復世界——那麼把人當成物品來折磨，就變得非常容易。」

這是對所有「以大義之名」的技術濫用的警告。Palantir 聲稱自己在保護西方民主、打擊恐怖主義、維護國家安全。這些都是「大目標」，而在大目標面前，個人的隱私、自由、甚至生命，都可能被視為可接受的代價。

但民主的核心恰恰是拒絕這種邏輯。民主的承諾是：沒有任何目標大到可以踐踏個人的基本權利。這就是為什麼我們需要正當程序、需要無罪推定、需要對政府權力的限制——即使這些限制可能讓「抓壞人」變得更困難。

Palantir 代表的技術能力正在侵蝕這個承諾。不是因為 Palantir 本身是邪惡的，而是因為這種「看見一切」的能力，必然會重新定義權力與個人之間的關係。

歐威爾在《一九八四》中寫道：「如果你想要一個關於未來的圖像，想像一隻靴子踩在人臉上——永遠。」

今天的圖像或許不是靴子，而是演算法。不是踩踏，而是預測、分類、追蹤。但效果可能同樣令人窒息——一個你永遠無法逃脫的數位目光，一個永遠在判斷你、評估你、決定你值得什麼待遇的系統。

我們還有時間劃定界線。德國憲法法院的判決是一個開始。公民對監控技術的質疑是另一個開始。但時間不多了。每一次我們接受「為了安全」的權力擴張，界線就又模糊了一點。

而一旦界線消失，想要重建就會非常、非常困難。
