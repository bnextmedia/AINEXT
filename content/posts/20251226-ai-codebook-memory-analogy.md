---
title: "AI 的「密碼本」越大越聰明：一位 KAIST 教授的記憶體比喻"
date: 2025-12-26T11:00:00+08:00
description: "KAIST 金正鎬教授用「密碼本」比喻解釋 AI 如何運作：Transformer 模型的 Encoder 把人類語言轉成密碼，Decoder 再解密成答案。這本密碼本越大，AI 就越聰明。而儲存這本密碼本的記憶體，才是決定 AI 能力的關鍵。"
tags: ["Transformer", "KV Cache", "HBM", "HBF", "記憶體", "金正鎬", "AI 原理"]
categories: ["AI 技術前沿"]
source_url: "https://www.youtube.com/watch?v=uJWZQb9rWUk"
source_name: "삼프로TV 언더스탠딩"
draft: false
---

> 本文整理自韓國財經節目《삼프로TV 언더스탠딩》2025 年 11 月播出的單集，來賓為 KAIST 電子及電機工程學部金正鎬教授。

{{< youtube uJWZQb9rWUk >}}

---

如果要用一句話解釋 AI 是怎麼回答你的問題的，KAIST 電子及電機工程學部的金正鎬（Kim Jung-ho）教授會這樣說：「它在翻一本巨大的密碼本。」

這位韓國頂尖的半導體專家，是 HBM 技術發展的重要推手之一。在韓國財經節目《삼프로TV 언더스탠딩》中，他用了一個精妙的比喻，把複雜的 AI 技術原理講得讓一般人都能理解。而這個比喻的核心訊息是：AI 的能力，很大程度上取決於它的「密碼本」有多大——而那本密碼本，就儲存在記憶體裡。

## Encoder 和 Decoder：翻譯人類語言的密碼機

當你問 ChatGPT 一個問題時，背後其實發生了兩件事。

首先，你的問題會被送進一個叫做 Encoder（編碼器）的系統。這個系統的工作是把人類的語言——無論是英文、中文還是韓文——轉換成一種「機器能理解的語言」。金教授把這種語言稱為「密碼」，更詩意一點的說法是「神的語言」或「外星人的語言」。總之，這是一套人類無法直接閱讀的符號系統。

這套密碼會被記錄在一本「密碼本」裡。技術上，這本密碼本叫做 Prior（先驗知識）或 KV Cache。它記錄了所有詞彙之間的關係、每個概念的重要性、以及各種知識的連結方式。

接下來，當 AI 要回答你的問題時，它會啟動 Decoder（解碼器）。Decoder 的工作是根據你的問題，去翻那本密碼本，找到對應的答案，再把答案從「機器語言」翻譯回人類語言。

金教授用了一個更生動的比喻：密碼本就像聖經，而 Decoder 就像牧師或神職人員。聖經是用一種神聖的、需要詮釋的語言寫成的，而牧師的工作就是把聖經的內容翻譯成信徒能理解的話。AI 做的事情也類似——它在解讀一本巨大的「知識聖經」，然後用你能理解的語言告訴你答案。

## 每說一個字，都要查一次密碼本

這裡有一個關鍵的技術細節：AI 不是一次想好整個答案再說出來，而是一個字、一個字地「吐」出來。每吐一個字，它都要回去查一次密碼本。

舉個例子：當 AI 要把 "I am a boy" 翻譯成「我是一個男孩」時，它會先看密碼本，判斷「我」這個字應該先出來。然後，它會帶著「我」這個資訊再查一次密碼本，判斷下一個字應該是「是」。接著，帶著「我是」再查一次，判斷下一個字是「一」。如此反覆，直到整個句子完成。

這意味著什麼？如果答案有 100 個字，AI 就要查 100 次密碼本。如果同時有 1000 個人在問問題，AI 就要在極短時間內查詢密碼本上萬次。這對記憶體的讀取速度提出了極高的要求。

更麻煩的是，這本密碼本本身就非常龐大。以目前最先進的大型語言模型來說，參數量動輒數千億，這些參數就是密碼本的內容。換算成儲存空間，可能是數百 GB 甚至更多。要在毫秒級的時間內從這麼大的資料中找到需要的資訊，記憶體的頻寬就變成了決定性因素。

## 密碼本越大，AI 越聰明

金教授指出，AI 能力的提升，很大程度上就是靠「密碼本變大」來實現的。

早期的語言模型，密碼本比較小，就像一本簡易字典。它能處理簡單的翻譯和問答，但遇到複雜的問題就答不上來。後來的模型，密碼本變成了一套百科全書。它不只記錄了詞彙的意思，還記錄了各種知識之間的關聯、不同語境下的用法、甚至是邏輯推理的模式。

而現在，研究者們想做的事情更進一步：不只是文字的密碼本，還要加入圖片、影片、音樂的密碼本。當 AI 能「理解」一部電影裡的每個畫面、每段對話、每個情緒表達，並把這些都編碼成密碼本，它就能做到根據簡單描述生成完整的電影。

但這也帶來了一個問題：密碼本越大，需要的記憶體就越多。文字的密碼本可能是幾百 GB，加入圖片可能變成幾 TB，加入影片可能變成幾十 TB。而這些資料都需要放在 GPU「伸手可及」的地方，才能快速查詢。

## HBF：給 AI 一個更大的書庫

這就是金教授力推 HBF 技術的原因。

目前的 AI 晶片主要靠 HBM（高頻寬記憶體）來儲存密碼本。但 HBM 的容量有限，最先進的產品大約是 192GB。對於純文字的 AI 模型來說，這可能勉強夠用。但當 AI 開始處理影片生成、多模態理解時，HBM 就不夠了。

HBF（High Bandwidth Flash）的概念是：在 HBM 旁邊再加一層記憶體，用 NAND Flash 技術製作。NAND Flash 的儲存密度比 DRAM（HBM 的基底材料）高得多，同樣的空間可以放進十倍的資料量。雖然 NAND Flash 的讀取速度比 DRAM 慢一些，但比起從遠端儲存系統調資料，還是快太多了。

用金教授的比喻來說：HBM 是書桌旁邊的小書架，放著最常用的幾本參考書。HBF 則是地下室的大書庫，放著整套百科全書和各種專業典籍。當書桌上找不到需要的資料時，走一趟地下室比去公共圖書館快多了。

## 密碼本的未來

金教授預估，HBF 產品可能在 2027 年左右問世。到那時候，AI 晶片的架構會變成「GPU + HBM + HBF」的三層結構。密碼本會被分層儲存：最常用的放在 HBM，次常用的放在 HBF，很少用的放在遠端儲存。

這個架構變化意味著什麼？首先，AI 的能力上限會進一步提升。更大的密碼本意味著更多的知識、更細緻的理解、更準確的回答。其次，記憶體在 AI 產業鏈中的重要性會持續上升。誰能做出更大容量、更高頻寬的記憶體，誰就掌握了 AI 發展的關鍵。

金教授的結論很明確：GPU 的發展已經接近瓶頸，未來的創新會發生在記憶體端。當密碼本變得越來越大，儲存密碼本的記憶體就會成為 AI 時代最重要的「基礎設施」。

---

下次當你使用 ChatGPT 時，可以想像一下：在某個資料中心裡，有一本比整個圖書館還大的密碼本，正在以每秒數萬次的速度被翻閱。而這本密碼本的大小，決定了 AI 能有多聰明。
