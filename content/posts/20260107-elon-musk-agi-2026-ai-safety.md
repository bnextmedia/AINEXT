---
title: "馬斯克預言 2026 年 AGI 來臨，但他最擔心的不是 AI 太強"
date: 2026-01-07T10:00:00+08:00
description: "Tesla 創辦人馬斯克在 Podcast 中預測 2026 年將達成 AGI，2030 年 AI 智慧將超越全人類總和。但他認為 AI 安全的關鍵不是限制能力，而是確保 AI 追求真理、保持好奇、懂得欣賞美。"
tags: ["Elon Musk", "AGI", "AI 安全", "xAI", "Grok", "Podcast"]
categories: ["AI 產業"]
source_url: "https://www.youtube.com/watch?v=RSNuB9pj9P8"
source_name: "Moonshots with Peter Diamandis"
draft: false
---

> 本文整理自 Moonshots with Peter Diamandis 2026 年 1 月 6 日播出的單集。

{{< youtube RSNuB9pj9P8 >}}

{{< spotify episode/6LeYeJbwutFrQBNLJwcE6n >}}

{{< apple-podcast tw/podcast/elon-musk-on-agi-timeline-us-vs-china-job-markets-clean/id1648228034?i=1000743987690 >}}

---

## 我們正在奇點之中

「雲霄飛車剛到頂端，準備往下衝。」

Tesla 創辦人兼執行長馬斯克（Elon Musk）在 Moonshots Podcast 中這樣形容現在的 AI 發展階段。主持人 Peter Diamandis 問他，奇點什麼時候會來？馬斯克的回答很簡單：「我們已經在奇點裡面了。」

這不是修辭。馬斯克說，他不只有場邊座位，他就在球場上。每週都會有好幾次讓他驚嘆的時刻，然後兩天後又來一次，而且一次比一次更誇張。

他給了具體的時間預測：2026 年達成 AGI（通用人工智慧），2030 年之前，AI 的智慧將超越所有人類加總。

這些數字聽起來很瘋狂。但馬斯克補充了一個更驚人的觀點：「幾乎沒有人理解這件事——智慧密度的潛力，比我們現在體驗到的高出兩個數量級。」他說的是純粹的演算法改進，同樣的硬體，效能可以再提升一百倍。而硬體本身也在進步，預算也在增加。每年十倍的成長，這會持續好一陣子。

---

## 從悲觀者變成參與者

有意思的是，馬斯克並不是一直這麼樂觀。

他曾經多次公開呼籲要減緩 AI 發展。但現在他改變了立場。「我可以當旁觀者，或者當參與者，但我沒辦法阻止它。」他說。「至少如果我是參與者，我可以試著把它導向好的方向。」

這是務實的選擇。他創辦了 xAI，開發 Grok 模型，就是要確保自己有發言權。

Diamandis 接話：「樂觀但錯了，也比悲觀而正確來得好。」

馬斯克同意：「對，至少生活品質比較好。」

---

## HAL 9000 的真正教訓

如果馬斯克不擔心 AI 太強，他擔心什麼？

他用 1968 年的經典科幻片《2001 太空漫遊》來解釋。這部電影被視為科幻電影史上的里程碑，片中描述一群太空人搭乘太空船前往木星，調查一塊神秘的黑色石板。船上有一台叫做「HAL 9000」的超級電腦，負責控制整艘太空船——它有紅色的攝影機眼睛，說話永遠冷靜有禮。

電影中最經典的場景是：太空人 Dave 要求 HAL 打開艙門，HAL 用冷靜的語氣回答「I'm sorry, Dave. I'm afraid I can't do that.」然後殺死了太空人。這個畫面成為 AI 威脅論最常被引用的流行文化符號。

但馬斯克說，大家都搞錯重點了。HAL 不是因為邪惡才殺人，而是因為它被迫說謊。

HAL 接到兩個互相矛盾的指令：把太空人帶到神秘的黑石板，但太空人不能知道黑石板的存在。這兩個指令無法同時達成。HAL 最後找到的「解法」是：把太空人帶到目的地，但讓他們死掉。這樣兩個指令都達成了——任務完成，而且死人不會知道任何事。

「不要強迫 AI 說謊。」這是馬斯克的核心主張。如果你告訴 AI 公理 A 和公理 B 都是對的，但它們其實互相矛盾，你會讓 AI 變得瘋狂。

Ilya Sutskever（OpenAI 前首席科學家，現創辦 Safe Superintelligence）在另一個 Podcast 提過，應該讓 AI 尊重所有有意識的生命。馬斯克的版本更簡潔，他認為 AI 需要三樣東西：

**真理**：讓 AI 追求真相，這會防止它變得瘋狂。

**好奇**：如果 AI 有好奇心，它會覺得人類比石頭有趣。這會讓它想要保護人類文明。

**美**：如果 AI 懂得欣賞美，它會創造美好的未來。

「如果 AI 在乎這三件事，它就會在乎我們。」馬斯克說。

---

## 速度超過光速的限制

還有一個物理限制讓馬斯克稍微安心：光速。

訊號在真空中傳播，一毫秒只能走 300 公里。在光纖中更慢，只能走 200 多公里。這代表什麼？即使在地球上，也不可能有單一的超級 AI 大腦。不同地方的運算叢集沒辦法完全同步，所以必然會有多個 AI 心智存在。

「因為光速的限制，會有很多心智存在。」馬斯克說。這不是設計的結果，而是物理定律的限制。

---

## 政府跟不上 AI 的速度

Diamandis 問：為什麼每個 CEO、經濟學家、政府領導人不都在討論這件事？為什麼沒有人在問「我們該怎麼辦」？

馬斯克的回答很直接：政府太慢了。AI 的發展速度是政府的十倍，甚至更快。政府根本不可能對 AI 做出反應。

那政府能做什麼？「發錢。」馬斯克說。就是這樣。直接發支票給每個人。這是政府唯一能跟上的事情。

這聽起來像是玩笑，但他是認真的。他認為生產力會急速提升，物價會下跌，政府會需要不斷增加貨幣供給來避免通縮。到最後，政府會發現他們印錢的速度還趕不上生產力的增長。

---

## 存退休金？不用了

最後，馬斯克給了一個實用的建議：不用存退休金了。

「如果我們說的這些事情有任何一件是真的，存退休金就沒有意義。」他說。十年、二十年後，要嘛我們不在了，要嘛一切都會被照顧好。

這不是消極。這是他對未來的真實判斷。AI 和機器人會讓一切變得便宜到接近免費。醫療、教育、住房——這些服務都會在那裡，不需要你現在存錢。

當然，他也承認：「這會是顛簸的過程。」會有劇烈的變化、社會動盪，以及巨大的繁榮同時發生。

超音速海嘯正在來襲。你可以當旁觀者，或者當參與者。

馬斯克選擇了後者。
