---
title: "Anthropic 被控「偷降 Opus」？AI 公司的信任危機"
date: 2025-12-25T12:00:00+08:00
description: "Opus 4.5 推出後獲得好評，但最近 Twitter 上出現大量使用者抱怨模型「變笨了」。是 Anthropic 偷偷降級模型來節省成本，還是使用者的期望值過高？這場爭議揭示了 AI 公司面臨的透明度挑戰。"
tags: ["Anthropic", "Claude", "Opus", "AI 爭議", "模型降級", "使用者信任"]
categories: ["AI 產業動態"]
source_url: "https://www.youtube.com/watch?v=f8I4cGrDFYA"
source_name: "Break Even Brothers Podcast"
draft: false
---

如果你有在關注 AI 社群的討論，最近應該看過不少關於 Opus 4.5 的抱怨。「Opus 變笨了」「模型被降級了」「Anthropic 在偷工減料」——這類貼文在 Twitter 和 Reddit 上此起彼落。Opus 4.5 明明在推出時獲得一片好評，怎麼突然變成眾矢之的？在最近一集 Break Even Brothers Podcast 中，兩位主持人深入討論了這場爭議的來龍去脈。

「如果你的 Twitter 動態跟我的差不多——我想我們追蹤的人應該有不少重疊——你應該有看到關於 Opus 4.5 的爭議，」一位主持人開場就說。他提到有一則爆紅的推文聲稱 Opus 4.5 被降級了，用起來「超級笨」。但有趣的是，在這則推文下方，一位 Anthropic 員工直接回覆，要求原 po 提供證據。

## 「降級陰謀論」的由來

這不是 Anthropic 第一次面對類似指控。Podcast 主持人回顧，之前就有過一輪關於 Opus 模型被「暗中降級」的風波。當時的陰謀論是這樣的：AI 公司先推出一個非常強大的模型，讓使用者「上癮」；等大家都離不開這個模型後，就偷偷降低模型的品質來節省運算成本。反正使用者已經付費了，他們也沒有太多選擇。

從商業邏輯來看，這個理論確實說得通。訓練和運行大型語言模型的成本極高，如果能在不被發現的情況下稍微降低輸出品質、減少運算量，公司可以省下大筆開銷。問題是：Anthropic 真的這樣做了嗎？

上一次爭議時，Anthropic 出面澄清，他們在部署模型到 Google 等雲端服務商時確實遇到了兩三個小 bug，這些 bug 影響了大約 15-20% 使用者的體驗。但公司強調，這些都是無心之過，他們並沒有故意降級模型。這次的爭議似乎是舊事重提，但 Anthropic 的回應態度比以前更積極。

## Anthropic 的回應：「給我證據」

在那則爆紅的抱怨推文下方，一位 Anthropic 員工直接留言：「嘿，你可以用 /feedback 或 /export 指令把你的對話記錄分享給我們看嗎？」這個回應相當直接——你說模型變笨了，那就拿出證據來。

原 po 回覆說那是之前的對話，沒辦法匯出。但 Anthropic 員工又追了一句：「你可以在 Claude Code 裡面恢復（resume）那個舊對話，然後再執行 /feedback 指令。」換句話說，Anthropic 把球丟回給批評者：你說有問題，那就讓我們看看到底發生了什麼事。

Podcast 主持人觀察到一個有趣的現象：原 po 似乎沒有再回覆這位 Anthropic 員工。「這讓我覺得有點好笑，」他說，「就像是⋯⋯好，你說模型有問題，人家請你拿出證據，然後你就消失了？」這當然不代表所有的抱怨都是無中生有，但至少說明 Anthropic 願意認真對待每一個具體的問題回報，而不是打太極。

## 「Opus 變笨」的另一種解釋

那麼，使用者感受到的「模型變笨」是純粹的錯覺嗎？Podcast 主持人提出了另一個可能的解釋。當一個全新的模型推出時，它相對於上一代是一個巨大的躍進。使用者會驚艷於這個進步，覺得新模型簡直神乎其技。但隨著時間過去，你習慣了新模型的能力水準，你的期望值也隨之提高。

「你對 Opus 或任何頂尖 AI 模型會有一定的期待，」他分析道。「如果它因為某些原因沒有達到這個期待——不管是他們真的降級了還是沒有，只是你的期望更高了——那就是這位發文者在講的情況。」換句話說，模型可能根本沒變，變的是使用者的心理基準線。

這是人之常情。你買了一支新手機，一開始覺得快得不得了；用了半年之後，同樣的速度你卻覺得好像變慢了。其實手機沒變，是你習慣了這個速度，開始渴望更快。AI 模型也是一樣。當 Opus 4.5 剛推出時，它比 Opus 4.0 強太多，讓人驚艷；但用久了之後，這個驚艷感消退，你開始期待更多，於是覺得「怎麼好像不如以前」。

## AI 公司的透明度挑戰

不過，Podcast 主持人也沒有完全否定「降級」的可能性。「我能想像這種事會發生，」另一位主持人坦言。他指出 Anthropic 似乎很受「炒作驅動」——新模型推出時鋪天蓋地的宣傳，讓很多人衝動訂閱。他在 Twitter 上看過有人說願意付 2000 美元買不被限流的 Opus 使用權。在這種情況下，公司確實有動機在使用者上鉤之後偷偷降低成本。

「如果這是真的——我強調這還沒有被證實——他們為什麼要這樣做？難道是為了省成本嗎？」他追問。「但他們大可以推出按 token 計價的方案啊。你有基本額度，超過就另外收費。既然使用者願意付更多錢，為什麼要偷偷降級而不是光明正大地多收費？」

這確實是個好問題。從商業角度看，直接提價或推出進階方案，比暗中降級要光明正大得多，風險也小得多。一旦被抓到偷偷降級，公司的信譽損失可能遠超過省下的運算成本。Anthropic 應該很清楚這一點。

值得一提的是，即使批評者沒有給出確鑿證據，Anthropic 的回應方式本身就傳達了一個訊號：我們願意接受檢驗。這跟那些對使用者回饋裝聾作啞的公司形成對比。主持人指出：「他們對回饋非常開放，我猜這場爭議大概幾週內就會平息。」

## 付費使用者的期待與 AI 公司的責任

這場爭議最終指向一個更大的問題：使用者對付費 AI 服務應該有什麼樣的期待？以及 AI 公司有責任提供什麼程度的透明度？

一方面，AI 模型的表現本來就有波動。同樣的 prompt，在不同時間、不同 context 下可能會得到不同品質的回應。這是大型語言模型的本質，不是 bug。但另一方面，付費使用者確實有權知道他們付費購買的是什麼。如果模型的基礎能力有任何調整——即使是為了修 bug——公司是否應該主動告知？

Podcast 主持人對 Anthropic 的整體評價仍然正面。他自己使用 Claude Code 中的 Opus 4.5，感覺「非常強大，而且持續強大」，沒有感受到任何降級。他也讚許 Anthropic 在 AI 開發領域的創新——Skills、MCP、Claude Code——這些都是業界領先的產品。「他們推出 Claude Code 的時候，那是市場上唯一一個真正好用的 coding CLI，」他回憶道。「其他公司，像是 Gemini、OpenAI，都還在追趕。」

但他也承認，Anthropic 歷史上確實有過 bug 影響模型表現的前例，這讓使用者的疑慮不是完全沒有道理。「希望未來不會再有任何消息說他們真的降級了，」他說。「那會失去很多使用者的信任，畢竟大家付的可是真金白銀。」

這場爭議大概不會是最後一次。隨著 AI 服務越來越普及、使用者付出的金額越來越高，對透明度和服務品質的要求也會水漲船高。AI 公司如何在商業利益和使用者信任之間取得平衡，將是 2026 年的重要課題。

本文整理自 Break Even Brothers Podcast 2025 年 12 月底播出的單集。
