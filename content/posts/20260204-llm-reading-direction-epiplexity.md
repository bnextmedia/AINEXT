---
title: "同樣的資料，不同的價值：為什麼 AI 正著讀學得比倒著讀好？"
date: 2026-02-04T11:00:00+08:00
description: "LLM 從左到右讀英文文本學得比從右到左好，但傳統資訊理論說兩個方向的資訊量一模一樣。一篇來自 NYU 和 CMU 的新論文用「epiplexity」概念解釋了這個矛盾，並揭示了資料品質的真正秘密。"
tags: ["epiplexity", "LLM", "資訊理論", "資料品質", "研究論文"]
categories: ["AI 技術前沿"]
image: "/images/posts/20260204-llm-reading-direction-epiplexity.webp"
source_url: "https://arxiv.org/abs/2601.03220"
source_name: "arXiv"
related_companies: ["openai", "anthropic"]
related_people: []
draft: false
---

![封面圖](/images/posts/20260204-llm-reading-direction-epiplexity.webp)

這裡有一個違反直覺的實驗結果：把一段英文文本反過來，一個字元一個字元地倒著排列，然後拿去訓練大型語言模型。字元完全一樣，出現頻率完全一樣，按照 Shannon 資訊理論，正著讀和倒著讀的資訊量完全相同。但模型在正著讀的資料上學得明顯比倒著讀好。

這不只是一個有趣的冷知識。它暴露了我們衡量「資訊」的標準工具的一個根本缺陷：Shannon 熵不在乎資料的順序，但學習者在乎。

2026 年 1 月，紐約大學（NYU）和卡內基美隆大學（CMU）的一組研究者在 arXiv 上發表了一篇論文，用一個叫做「epiplexity」的新概念解釋了為什麼同樣的資料、不同的排列方式，對 AI 的學習價值截然不同。更重要的是，這個概念揭示了一個更大的圖景：我們過去評估資料品質的方式，從根本上就問錯了問題。

## 正著讀 vs 倒著讀：一個 Shannon 理論解釋不了的現象

先把這個現象講清楚。

大型語言模型的訓練方式是「next token prediction」，也就是根據前面的 token 預測下一個 token。這個「前面」可以是從左到右，也可以是從右到左。如果你把訓練資料整個字串反轉，模型學到的其實是「根據右邊的 token 預測左邊的 token」。

按照 Shannon 資訊理論，一個序列的熵只取決於字元的聯合機率分布。把字串反轉不會改變任何字元的出現頻率，也不會改變任何 n-gram 的出現頻率（只是方向反了）。從資訊理論的角度，正序和反序包含的資訊量嚴格相等。

但實驗結果不這麼說。模型在正序文本上的學習效果顯著優於反序文本。這不是因為模型架構有什麼左右偏好（Transformer 本身是位置無關的，方向性來自位置編碼和注意力遮罩），而是因為英文的語言結構在正序方向上更容易被有限計算能力的模型捕捉。

想想英文的基本句型：主詞、動詞、受詞。當你從左到右讀「The cat sat on the mat」，看到「The cat」你就能預期一個動詞，看到「sat on」你就能預期一個名詞片語。這些預測是局部的、遞進的、可以用有限的上下文窗口捕捉的。但如果你倒過來讀「tam eht no tas tac ehT」，同樣的結構關係變得碎片化，有限算力的模型需要更大的上下文才能學到同樣的模式。

這個現象暴露了 Shannon 理論的一個根本限制：它衡量的是「理論上的資訊量」，但不區分「容易學的資訊」和「難學的資訊」。對一個有無限計算能力的理想觀察者來說，正著讀和倒著讀確實一樣。但現實中沒有這種觀察者。

## 密碼學早就知道的秘密

其實，資料方向會影響處理難度這件事，密碼學家很早就知道了。

整個公鑰密碼學的基礎就建立在「計算不對稱性」上。拿 RSA 來說：把兩個大質數相乘很容易，但把乘積分解回兩個質數極其困難。從乘法到因式分解、從加密到解密，正向和反向的資訊量完全相同（都是同樣的兩個數字），但計算複雜度相差幾個數量級。

論文指出，這跟語言模型正反讀文本的現象是同一回事。兩者都是「資訊理論上等價，但計算上不等價」的例子。Shannon 熵只看前者，對後者完全失明。

這不是小問題。如果我們連「同樣的資料、不同方向，學習效果不同」都無法用現有理論解釋，那我們拿什麼標準來評估一個資料集到底好不好？靠直覺嗎？

## Epiplexity：把「算力」放進資訊的定義裡

這篇論文的解決方案是引入 epiplexity（認知複雜度）這個概念。

核心想法很簡單：把觀察者的計算預算當作一個參數，放進資訊的定義裡。給定一組資料和一個計算預算，你能找到的最好壓縮模型有多「複雜」？這個複雜度就是 epiplexity。壓縮不掉的部分就是 time-bounded entropy（有時間限制的熵）。

Epiplexity 衡量的是「可學習的結構」，entropy 衡量的是「學不了的隨機性」。關鍵在於：這兩個值隨計算預算改變。算力越多，能提取的結構越多，epiplexity 越高。反過來，如果計算預算很小，即使資料裡有大量的結構，它也可能「看起來」是隨機的。

回到正反讀的問題。正序英文文本和反序英文文本的 Shannon 熵完全相同，但 epiplexity 不同。在典型的 LLM 訓練計算預算下，正序文本的 epiplexity 高於反序文本，因為英文的語法結構在正序方向上更容易被提取。模型從正序文本中能學到更多可遷移的結構（語法規則、語義模式、推理鏈），而從反序文本中學到的結構較少，較多內容被歸類為「在這個計算預算內無法預測的隨機性」。

這個解釋乾淨俐落：資料的學習價值不只取決於它「包含多少資訊」，更取決於在你的算力範圍內「能學到多少結構」。

## 西洋棋實驗：高結構資料帶來更好的泛化

論文不只解釋了正反讀的問題，還設計了一組西洋棋實驗來驗證 epiplexity 的預測能力。

研究者準備了兩種訓練資料：真實棋手的對局記錄和隨機產生的合法棋盤位置。兩種資料在分布匹配的意義上都是合格的訓練資料，模型在兩種資料上都能收斂。但真實對局有高 epiplexity（它們反映了策略邏輯、開局理論、殘局技巧等大量可學習的結構），而隨機位置的 epiplexity 低（每個位置之間沒有策略上的關聯）。

測試的方式是讓兩個模型解棋謎，也就是一種 out-of-distribution 的任務。棋謎的特徵是有明確的最佳解法，通常需要深度計算和策略推理。結果很明確：用真實對局訓練的模型在棋謎上的表現大幅優於用隨機位置訓練的模型。

這個結果用 Shannon 的框架很難解釋。兩種資料的熵可能相差不大（隨機位置的熵甚至可能更高），但學習效果天差地遠。用 epiplexity 來看就清楚了：真實對局裡的結構性資訊可以遷移到棋謎這個新任務上，而隨機位置裡缺乏這種可遷移的結構。

同樣的邏輯也適用於語言模型。OpenWebText（真實網頁文本）的 epiplexity 高於等量的隨機文本。從真實文本中學到的語法、語義、邏輯推理模式，可以遷移到翻譯、問答、摘要等各種下游任務。這就是為什麼「高品質資料」比「大量資料」重要，而 epiplexity 提供了一個量化「品質」的數學框架。

## AlphaZero 和 Rule 110：確定性過程也能「創造」可學習的結構

論文還用 epiplexity 解釋了另一個反直覺的現象：確定性過程如何「創造」資訊。

AlphaZero 只靠西洋棋的規則自我對弈。規則是完全確定性的，沒有任何隨機來源。按照 Shannon 理論，確定性轉換不能增加資訊量。但 AlphaZero 學到了人類棋手花了幾百年才發展出來的複雜策略，甚至發現了全新的下法。

用 epiplexity 來看：西洋棋規則本身很短（低 Kolmogorov 複雜度），但從規則推導出最優策略所需的計算量極大。這中間的「計算落差」就是 epiplexity 的來源。AlphaZero 透過大量的自我對弈，把這個計算落差轉化成了神經網路的權重，也就是以可直接查詢的形式「儲存」了大量的結構性資訊。

論文用細胞自動機的 Rule 110 做了另一個有力的示範。Rule 110 的規則只需要一行字就能寫完（極低的描述長度），但它被證明是圖靈完備的，能產生任意複雜的模式。對有限算力的觀察者來說，Rule 110 產生的序列包含大量可學習的結構，epiplexity 很高。但對無限算力的觀察者來說，這些結構都能直接從規則推導出來，沒什麼需要「學」的。

這個觀察對 AI 開發有直接的啟示。合成資料（synthetic data）最近越來越受到重視，而 epiplexity 框架告訴我們：合成資料的價值不在於它模仿了真實資料的分布，而在於它包含了多少在目標計算預算內可以被提取的結構。一個好的合成資料產生器，就是一個高效率的「epiplexity 放大器」。

## 為什麼這篇論文值得注意

在談實務影響之前，值得看看是誰在提出這套理論。

這篇論文來自紐約大學（NYU）的 Wilson 實驗室和卡內基美隆大學（CMU）的 Kolter 實驗室。Wilson 是貝氏深度學習和泛化理論的重量級人物，拿過 ICML 最佳論文獎；Kolter 是 CMU 機器學習系主任，同時擔任 OpenAI 安全委員會主席和非營利董事會成員，握有在必要時暫停模型發布的權力。第一作者 Marc Finzi 是 Wilson 的博士畢業生，現在在 CMU 跟 Kolter 做博士後，以「把數學歸納偏差嵌入神經網路」的研究聞名，曾共同證明 LLM 不需要專門訓練就能做零樣本時間序列預測（NeurIPS 2023）。共同作者 Pavel Izmailov 先後在 OpenAI（參與 o1 推理模型）、xAI、Anthropic（參與 Claude 3.7 Sonnet 和 Claude 4）工作，現在同時是 NYU 助理教授和 Anthropic 研究科學家。兩位博士生 Shikai Qiu（NYU，Two Sigma 獎學金，ICML 2024 oral）和 Yiding Jiang（CMU，Google 獎學金，ICLR 2024 oral）也各有頂級發表。

六人的合計引用數超過十萬次，但更重要的是他們同時連結著學術理論的最前沿和 OpenAI、Anthropic 的工程實踐。這群人在乎資料選擇的問題，某種程度上反映了前線實驗室正在碰到的真實瓶頸。

## 從「多少資料」到「什麼資料」

AI 前線實驗室現在面臨的核心問題之一就是資料。公開可用的高品質文本資料正在枯竭，繼續靠堆量的策略已經撞到了天花板。下一步的競爭，很可能就是誰能更聰明地選資料、造資料。

Epiplexity 提供了一個新的思路：不要問「這筆資料有多少 GB」，要問「在我的訓練預算下，這筆資料的 epiplexity 是多少」。一筆高 epiplexity 的小資料集，可能比一筆低 epiplexity 的大資料集更有價值。這跟過去幾年業界從「bigger is better」轉向「quality over quantity」的趨勢完全吻合，只是現在有了數學上的支撐。

當然，目前 epiplexity 的估測成本不低（論文提出的 requential coding 方法需要額外 2 到 10 倍的計算量），在工業級的大規模訓練場景中還不太實用。但 prequential coding（用訓練損失曲線來近似）提供了一個計算成本較低的替代方案，至少可以用來做資料集之間的相對比較。

不管 epiplexity 這個具體的概念最終能走多遠，它背後的核心問題是真實的：我們需要更好的方式來衡量資料對學習的價值。正著讀比倒著讀好，真實對局比隨機位置好，這些直覺我們都有。但直覺不能 scale。當你面對的是幾 TB 的候選資料集，需要決定哪些值得花幾千萬美元去訓練時，你需要的是一把尺，不是一個感覺。Epiplexity 或許就是這把尺的第一個原型。
