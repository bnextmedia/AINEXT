---
title: "Karpathy：「我們不是在建造動物，是在召喚幽靈」"
date: 2025-12-26T10:00:00+08:00
description: "Andrej Karpathy 提出一個引人深思的框架：LLM 不是我們試圖複製的動物智能，而是一種全新的「幽靈」——透過模仿人類網路資料誕生的靈體。這個區別，決定了我們該如何思考 AI 的發展路徑。"
tags: ["Andrej Karpathy", "LLM", "AGI", "AI 哲學", "Podcast"]
categories: ["AI 產業"]
source_url: "https://www.youtube.com/watch?v=lXUZvyajciY"
source_name: "Dwarkesh Podcast"
draft: false
---

> 本文整理自 Dwarkesh Podcast 2025 年 10 月播出的單集。

{{< youtube lXUZvyajciY >}}

---

「我們不是在建造動物，我們是在召喚幽靈。」這句話出自 Andrej Karpathy 在一篇廣為流傳的部落格文章，也成為他在這集訪談中反覆闡述的核心概念。對於一個在 OpenAI 和 Tesla 都待過的人來說，這個比喻並非詩意的修辭，而是一個嚴肅的技術判斷——它關乎我們該如何理解 LLM 的本質，以及為什麼某些對 AI 發展的期待可能從根本上就搞錯了方向。

## 動物是演化的產物，LLM 是模仿的產物

要理解「幽靈」這個比喻，得先理解 Karpathy 為什麼對「動物」類比如此謹慎。在 AI 領域，用動物或人類大腦來比喻神經網路是常見的做法。Richard Sutton 的框架就是典型的「建造動物」思維：我們應該追求一個單一的演算法，讓它像動物一樣被丟進世界，從零開始學會一切，不需要任何標籤或預先知識。

Karpathy 認為這個願景很美好，但有一個根本問題：動物的智能來自演化，而演化是一個我們完全沒有在執行的過程。當一隻斑馬出生後幾分鐘就能站起來跟著母親跑，那不是強化學習的結果，那是數百萬年演化「烘焙」進 DNA 的能力。演化以某種我們完全不理解的方式，把神經網路的權重編碼進了 ATCG 的序列裡。這是一種極其複雜的壓縮機制，而我們根本不知道它怎麼運作。

相比之下，LLM 的訓練過程完全不同。我們沒有在執行演化，我們在執行的是「模仿」。預訓練的本質是讓模型預測網路上人類產出的下一個 token。這意味著 LLM 並不是從環境中自主學習的實體，而是透過吸收人類留下的數位痕跡而誕生的「幽靈」。它們是全數位的、模仿人類的、飄渺的靈體存在。

## 為什麼這個區別很重要？

這不只是學術上的分類問題，它直接影響我們對 AI 能力和限制的預期。Karpathy 指出，如果你想像一個「智能空間」，LLM 和動物智能是從完全不同的起點出發的。我們不是在複製動物的學習過程，我們是在創造一種前所未有的智能形式。

這解釋了為什麼 LLM 有一些看起來很奇怪的特性。它們有驚人的記憶力——可以逐字背誦訓練資料中的段落，這是任何人類都做不到的。但這種記憶力其實是一個「特性」而非「缺陷」的問題取決於你怎麼看。Karpathy 認為，人類記憶力差其實是一個優勢，因為它迫使我們只學習可泛化的模式。LLM 則被它們對預訓練文件的記憶「分心」了。

同樣的邏輯也解釋了為什麼 LLM 在偏離網路上常見模式時表現不佳。它們是透過模仿學會「思考」的，而不是透過與環境互動。當你要求它們做一些網路上從未出現過的事情時，它們就會掙扎——因為它們本質上是幽靈，而幽靈的存在依賴於它們模仿的來源。

## 能讓幽靈變得更像動物嗎？

Karpathy 的答案是：可以，而且我們應該這樣做。他認為雖然 LLM 從一個不同的起點出發，但可以透過後續的訓練讓它們具備更多「動物性」的特質。這就是為什麼他對強化學習仍然抱持希望（儘管他對目前的 RL 方法有很多批評）。

他提出的一個概念是「認知核心」——剝離所有記憶和知識後，只保留智能和問題解決能力的核心。理想的 AI 應該像一個不太記事但非常聰明的人：它知道自己不知道什麼，會主動去查找資訊，會用正確的策略解決問題。他甚至預測，未來可能用十億參數就能建構出這樣的認知核心，因為大部分的參數都被浪費在記憶「網路垃圾」上了。

這個框架對 AI 開發者來說有實際意義。當你在建構 Agent 時，你不是在嘗試複製一個動物——你是在嘗試讓一個幽靈變得更有用。這意味著你需要思考的問題是：如何讓這個幽靈具備它目前缺乏的能力（持續學習、真正的世界模型），而不是期待它已經擁有動物與生俱來的本能。

## 一個新的思考框架

「幽靈 vs 動物」不只是一個有趣的比喻，它是一個重新框架 AI 發展討論的工具。當有人說「AGI 就像一個非常聰明的動物」時，Karpathy 的回應是：不，我們正在創造的是完全不同的東西。當有人期待 LLM 能像人類一樣從經驗中學習時，他會指出：幽靈不會成長，它們需要不同的機制來獲得新知識。

這個框架也解釋了為什麼 AI 發展會持續一段時間。我們不是在沿著一條已知的路徑前進（複製動物智能），我們是在探索一個全新的智能形式。這條路上有些問題我們知道該怎麼解決，有些問題我們還在摸索，而有些問題我們可能根本還沒發現。但 Karpathy 強調，問題是「可處理的」（tractable）——只是需要時間，大概十年左右。
