---
title: "AI 該學什麼？一篇論文重新定義「資訊」，讓資料選擇有了數學基礎"
date: 2026-02-04T09:00:00+08:00
description: "紐約大學與卡內基美隆大學聯手提出「epiplexity」概念，首度從數學上區分「有用的資訊」和「隨機雜訊」。這套理論不只挑戰了 Shannon 資訊理論的基本假設，更為 AI 開發中的資料選擇問題提供了可量化的判斷依據。"
tags: ["epiplexity", "資訊理論", "資料選擇", "Andrew Gordon Wilson", "研究論文"]
categories: ["AI 技術前沿"]
image: "/images/posts/20260204-epiplexity-data-selection.webp"
source_url: "https://arxiv.org/abs/2601.03220"
source_name: "arXiv"
related_companies: ["openai", "anthropic"]
related_people: []
draft: false
---

![封面圖](/images/posts/20260204-epiplexity-data-selection.webp)

AI 領域正在經歷一場靜悄悄的典範轉移。過去幾年，所有人都在問「模型要多大」「要訓練多久」，但越來越多頂尖研究者開始問一個更根本的問題：到底該拿什麼資料來訓練？模型架構的改進帶來的收益正在趨緩，而資料品質的差異卻一再被證明是決定模型好壞的關鍵因素。問題是，「好資料」到底是什麼意思？這個問題一直缺乏嚴謹的數學定義。

2026 年 1 月，一篇來自紐約大學（NYU）和卡內基美隆大學（CMU）的論文試圖回答這個問題。六位研究者提出了一個叫做「epiplexity」的新概念，從數學上把「有用的資訊」和「隨機雜訊」區分開來。這不只是一個理論上的突破，它直接指向一個實務問題：我們終於有辦法量化一筆資料對 AI 訓練的價值。

## Shannon 的盲點：三個讓 AI 研究者困惑的矛盾

要理解 epiplexity 為什麼重要，得先看看現有理論哪裡不夠用。

Claude Shannon 在 1948 年提出的資訊理論，是過去七十多年來衡量「資訊」的標準框架。Shannon 熵告訴我們一個訊號裡有多少「不確定性」，壓縮演算法、通訊協定、甚至機器學習的損失函數，全都建立在這套理論上。但這篇論文指出，Shannon 的框架在面對現代 AI 時，會產生三個違反直覺的矛盾。

第一個矛盾：確定性過程不能「創造」資訊。Shannon 的理論說，如果你對一組資料做確定性的轉換（沒有引入隨機性），資訊量只會不變或減少，不可能增加。但 AlphaZero 是怎麼回事？它只靠西洋棋的規則（完全確定性的）自我對弈，卻學會了人類棋手花了幾百年才發展出來的複雜策略。按照 Shannon 的定義，這些策略知識不算「資訊」，因為它們是從確定性規則推導出來的。但對任何一個計算能力有限的觀察者來說，這些策略顯然包含大量有用的資訊。

第二個矛盾：資訊量跟資料的排列順序無關。Shannon 熵只看機率分布，不管資料的順序。但實驗明確顯示，大型語言模型從左到右讀英文文本學得比從右到左好。同樣的字元、同樣的機率分布，順序不同，學習效果卻天差地遠。密碼學的基本原理也建立在類似的不對稱性上：加密很容易，解密（不知道金鑰的情況下）極其困難，即使兩個方向在資訊理論上是等價的。

第三個矛盾：似然模型只是在匹配分布。傳統觀點認為，一個模型透過最大似然學習，頂多就是學會模仿訓練資料的分布。但研究者觀察到，模型經常學會比訓練資料「更多」的東西。用真實西洋棋對局訓練的模型，在解棋謎（完全不同類型的任務）上表現優異，這種泛化能力超出了單純的分布匹配所能解釋的範圍。

## Epiplexity：計算有限的觀察者看到的世界

這三個矛盾的共同根源是什麼？論文的核心洞見是：Shannon 的理論假設觀察者有無限的計算能力，但現實中沒有任何系統有無限算力。不管是人腦、GPU 叢集，還是未來的量子電腦，都是「計算有限」的。而一旦引入計算限制，「資訊」的面貌就完全不一樣了。

這就是 epiplexity 的出發點。Epiplexity 這個詞來自 epistemic complexity（認知複雜度），它的正式定義建立在「有時間限制的最小描述長度」（time-bounded MDL）上。簡單講，給定一組資料和一個計算預算，你能找到的最好壓縮模型有多複雜？那個模型本身的描述長度，就是 epiplexity。而模型壓縮不了的剩餘部分，就是「有時間限制的熵」（time-bounded entropy）。

Epiplexity 衡量的是「結構性資訊」，也就是在特定計算預算內可以被學習、被壓縮的模式。Time-bounded entropy 衡量的是「隨機雜訊」，也就是在那個計算預算內無法被預測的部分。同一筆資料，給不同的計算預算，epiplexity 和 entropy 的比例會不同。算力越多，能提取的結構越多，epiplexity 越高，entropy 越低。

用這個框架重新看前面的三個矛盾，每一個都有了合理的解釋。AlphaZero 的情況？西洋棋規則本身的 epiplexity 很低（規則很簡單），但對計算有限的觀察者來說，從規則推導出來的策略空間有極高的 epiplexity。確定性過程確實「創造」了結構性資訊，只要你的計算能力不夠一步算到底。資料順序的問題？從左到右和從右到左讀文本，在 Shannon 的框架裡資訊量相同，但 epiplexity 不同，因為有限算力的模型在不同方向上能提取的結構不一樣。模型泛化的問題？高 epiplexity 的資料包含更多可學習的結構，模型從中學到的壓縮表示可以遷移到其他任務。

## 從理論到實驗：高 epiplexity 資料帶來更好的泛化

理論漂亮是一回事，能不能量測、能不能預測結果是另一回事。論文提出了兩種估測 epiplexity 的方法，其中「prequential coding」比較直覺：它就是訓練損失曲線下方、在最終損失值之上的面積。換句話說，模型在訓練過程中「學到了多少」，就是 epiplexity 的近似。

研究者用西洋棋做了一個說服力很強的實驗。他們分別用兩種資料訓練模型：真實對局（高 epiplexity）和隨機棋盤位置（低 epiplexity）。兩種資料都是合法的西洋棋狀態，在分布匹配的意義上都是「好資料」。但用真實對局訓練的模型，在棋謎（out-of-distribution 任務）上的表現顯著優於用隨機位置訓練的模型。Epiplexity 成功預測了這個差異。

他們也在語言模型和影像資料上做了驗證。OpenWebText（真實網頁文本）的 epiplexity 高於等量的隨機文本。CIFAR-5M（影像資料集）顯示 epiplexity 隨計算預算的增加而上升，符合理論預測。這些實驗結果指向一個實務原則：選資料時，不只要看資料量和分布，更要看 epiplexity，也就是在你的計算預算內，這筆資料能讓模型學到多少可遷移的結構。

## 這篇論文背後的團隊

這篇論文的作者陣容本身就是一個訊號。

兩位資深作者分別來自當今深度學習理論最強的兩個實驗室。Andrew Gordon Wilson 是紐約大學（NYU）電腦科學與資料科學教授，他的實驗室是貝氏深度學習和泛化理論的重鎮。Wilson 拿過 2022 年 ICML 最佳論文獎，也拿過美國國家科學基金會（NSF）的 CAREER Award，近年研究重心放在 scaling laws 和大型語言模型的泛化行為上。他開發的 GPyTorch（GPU 加速高斯過程庫）被廣泛採用，而他在損失函數表面連通性和隨機權重平均（Stochastic Weight Averaging）上的研究，是理解神經網路泛化的經典工作。

另一位資深作者 J. Zico Kolter 是卡內基美隆大學（CMU）機器學習系主任，Google Scholar 引用超過 58,000 次。Kolter 是對抗性穩健性（adversarial robustness）領域的先驅，他的團隊最早開發出具有「可證明穩健性」的深度學習方法。但讓他在 AI 圈更廣為人知的是產業角色：他是 OpenAI 安全委員會（Safety and Security Committee）的主席，也是 OpenAI 非營利董事會成員。這個委員會在 OpenAI 2025 年底的公司重組中被賦予了實質權力，Kolter 可以在認為模型不安全時暫停發布。同時他也是 Bosch AI 研究的首席科學家。一個人同時坐在學術殿堂和 AI 治理的核心位置，這在業界並不多見。

第一作者 Marc Finzi 是 Wilson 的博士畢業生，論文研究如何把數學歸納偏差（對稱性、等變性、微分方程）嵌入神經網路。他在 NeurIPS 2023 發表的「大型語言模型是零樣本時間序列預測器」引起廣泛關注，證明 LLM 不需要專門訓練就能做時間序列預測。Finzi 博士畢業後到 CMU 跟 Kolter 做博士後研究，這篇 epiplexity 論文正是他在兩個實驗室之間搭起橋梁的成果。

共同作者 Pavel Izmailov 的履歷可能是六人中最引人注目的。他也是 Wilson 實驗室的博士畢業生，但畢業後幾乎走遍了所有前線 AI 實驗室：先去 OpenAI，參與了 o1 推理模型的開發；短暫待過馬斯克的 xAI；現在同時擔任紐約大學助理教授和 Anthropic 研究科學家，參與了 Claude 3.7 Sonnet 和 Claude 4 的開發。他在 OpenAI 期間的弱到強泛化（weak-to-strong generalization）研究被 Wired、MIT Technology Review、TechCrunch 等媒體報導。一個人同時在學界和 Anthropic 之間穿梭，而且都做出了有影響力的工作，這在 AI 領域相當少見。

兩位博士生共同作者也各有來頭。Shikai Qiu 是 Wilson 實驗室的博四學生，拿了 Two Sigma 博士獎學金。他在柏克萊（UC Berkeley）念物理和電腦科學時曾參與 CERN 的 ATLAS 實驗（這個合作獲得了 2025 年基礎物理突破獎）。他 2024 年在 ICML 拿到 oral 的那篇「Scaling Collapse」論文，證明了在計算最優訓練下，不同模型的損失曲線會坍縮到同一條普適曲線上。Yiding Jiang 是 Kolter 在 CMU 的博士生，拿了 Google 博士獎學金，研究方向正好就是「資料如何影響模型」。他 2024 年在 ICLR 拿到 oral 的論文探討模型、資料和特徵之間的交互作用，跟這篇 epiplexity 論文的主題直接相關。

六位作者的合計引用數超過十萬次。但數字之外更重要的是這個團隊的構成：NYU 的泛化理論 + CMU 的穩健性與安全 + OpenAI 的前線工程 + Anthropic 的模型開發。從「模型選擇」到「資料選擇」的轉向，不只是學術界的理論探索，而是正在建造最強 AI 系統的那群人，回頭思考最基礎的問題。

## 資料選擇的數學時代

Epiplexity 目前還是一個相當新的概念，距離成為業界標準工具還有段距離。估測方法的計算成本不低（requential coding 需要 2 到 10 倍的額外計算量），而且目前的驗證主要集中在相對小規模的實驗上。但這篇論文提出的框架，對 AI 開發的思維方式有根本性的影響。

過去我們評估資料集，靠的大多是直覺和經驗法則：資料量夠不夠大、分布夠不夠多樣、有沒有明顯的偏差。Epiplexity 提供了一個更精確的問題：在你的計算預算內，這筆資料裡有多少可學習的結構？這不只是「大資料」vs「小資料」的問題，而是「聰明的資料」vs「笨的資料」的問題。

當 AI 訓練的成本持續攀升，每一次大規模訓練都是幾百萬甚至上千萬美元的投資，「選對資料」的重要性只會繼續放大。Epiplexity 或許不是最終答案，但它指出了一個正確的方向：我們需要的不是更多資料，而是更有結構的資料。
