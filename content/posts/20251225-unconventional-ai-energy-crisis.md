---
title: "AI 晶片新創押注「類腦計算」：當電網撐不住 GPU 的胃口"
date: 2025-12-25T14:00:00+08:00
description: "Unconventional AI 創辦人 Naveen Rao 認為，AI 產業正面臨能源瓶頸。美國資料中心已吃掉 4% 電網，未來十年還需要額外 400 GW。他的解方是回歸類比計算——用物理本身來執行運算，而非用數位電路去模擬。"
tags: ["Unconventional AI", "Naveen Rao", "AI 晶片", "能源危機", "類比計算"]
categories: ["AI 產業"]
source_url: "https://www.youtube.com/watch?v=wZ4DT20OHXE"
source_name: "NeurIPS 2024 訪談"
draft: false
---

> 本文整理自 NeurIPS 2024 期間的訪談。
> 🎧 收聽連結：[YouTube](https://www.youtube.com/watch?v=wZ4DT20OHXE)

---

2024 年夏天，美國西南部首次因為資料中心用電而出現區域性停電警報。這不是科幻小說的情節，而是已經發生的事。

Naveen Rao 是 Unconventional AI 的創辦人，他在這個時間點選擇創業，不是沒有原因的。「美國的資料中心已經吃掉全國 4% 的電網，」他在 NeurIPS 2024 的訪談中說，「想像一下，當這個數字變成 8%、10% 會發生什麼事。」根據業界估算，未來十年 AI 產業需要額外 400 GW 的電力供應。問題是，美國每年能新增的發電容量只有約 4 GW。數學不會說謊：我們根本來不及蓋電廠。

---

## 80 年前的選擇，今天的包袱

為什麼 AI 這麼耗電？答案要追溯到 1940 年代。

當時的工程師面臨一個選擇：類比計算還是數位計算。類比計算機其實更早出現，效率也更高，但有一個致命問題——製造變異。真空管的特性會隨著溫度、老化而改變，當你把系統做大，這些微小的差異會累積成無法容忍的誤差。數位計算繞過了這個問題：只要能可靠地區分「高電壓」和「低電壓」，製造精度就不那麼重要了。1945 年的 ENIAC 有 18,000 個真空管，靠的就是這個「高低」的二元簡化。

這個選擇讓計算能夠規模化，但也留下了代價。數位計算需要把所有東西轉換成數字，用數字去「模擬」物理現象。這中間有大量的能量浪費。當年沒人在乎這件事，因為摩爾定律會解決一切——晶片越做越小、越來越省電。但摩爾定律正在減速，而 AI 的算力需求卻在加速。這兩條曲線交叉的地方，就是我們現在站的位置。

---

## 用物理本身來計算

Naveen Rao 的想法很直接：既然問題出在「用數位去模擬」，那就別模擬了。

「類比計算的本質是找到一個物理系統，讓它的行為『類似於』你想要計算的東西，」他解釋。風洞就是一個例子。你可以用超級電腦去模擬空氣流過機翼的樣子，但計算流體力學出了名的難算，而且永遠有誤差。工程師至今還是會造風洞，把實際的模型放進去吹——讓空氣自己告訴你答案。這就是類比計算：用物理本身來計算物理。

大腦是另一個存在證明。人類大腦的功耗約 20 瓦，相當於一顆省電燈泡。貓的大腦只要 0.1 瓦。這些神經網路沒有「模擬」任何東西，它們的物理結構本身就是計算。神經元放電、化學物質擴散、突觸連結強化——這些物理過程直接構成了智慧，中間沒有任何抽象層。沒有作業系統，沒有 API，沒有記憶體和處理器之間的資料搬運。

Unconventional AI 想做的，就是在矽晶片上重現這種「物理即計算」的架構。不是打造「更快的 GPU」，而是打造一種根本不同的計算基板。

---

## 為什麼現在是對的時機

Naveen Rao 不是第一個想做類比 AI 晶片的人。學術界研究這個方向已經超過 40 年，為什麼現在才有機會商業化？

答案是 AI 本身改變了遊戲規則。傳統數位計算的優勢是「精確」和「通用」——你需要精確計算軌道才能發射火箭，你需要通用架構才能跑各種程式。但神經網路天生就是隨機的。它不需要精確到小數點後第 16 位，它需要的是大量的平行運算和模式匹配。這正是類比電路擅長的事。

「智慧是不同的野獸，」Rao 說。「你可以用數字來建構它，但它天生就是用數字建構的嗎？我不知道。」神經網路本質上是一種隨機機器，那為什麼我們要用高度精確、確定性的數位電路來跑它？這就像用計算機去算「大概是幾」——可以，但浪費。

另一個關鍵是製程技術的成熟。現在的 TSMC 能做到的精度，是 40 年前學術界做不到的。Rao 提到他們已經在跟 TSMC 接觸，確保設計出來的東西能夠大規模製造。「如果不能規模化生產，就沒辦法解決全球能源問題，」他說。目標是五年內拿出可量產的原型。

---

## 與巨頭的關係

NVIDIA 是房間裡的大象。所有做 AI 晶片的新創都會被問同一個問題：你們打算怎麼跟 NVIDIA 競爭？

Rao 的回答很務實：「我們在試圖打造一個比矩陣乘法更好的基板。會不會跟 NVIDIA 對立？我不知道。也許會合作。」他沒有把 NVIDIA 定位成敵人，而是把問題框架成「我們在做不同的事」。NVIDIA 的 CUDA 生態系統主宰了今天的 AI 訓練，但如果有一種根本更高效的計算方式出現，合作可能比對抗更合理。

Google 和他們的 TPU 是另一回事。Rao 認為 Google 是在做「漸進式改良」——讓現有架構更好、更省錢、跑得更快。這完全合理，他們有業務要維持。但 Unconventional 想做的是「典範轉移」，那是另一種時間尺度的事。

TSMC 則幾乎確定會是合作夥伴。不管你的設計多激進，最後都要有人幫你生產晶片。Rao 提到他們的第一顆原型晶片可能會是「有史以來最大的類比晶片」——這種等級的製造，全世界只有少數幾家公司做得到。

---

## 這對 AI 發展意味著什麼

如果 Unconventional AI 成功，影響不只是「省電」這麼簡單。

Rao 有一個更大的野心：他認為類比計算可能是通往 AGI 的關鍵拼圖。理由是「因果性」。數位計算是沒有時間概念的——你可以把程式暫停、倒轉、快轉，時間只是一個變數。但真實世界有時間，有因果，有不可逆性。大腦的物理結構天生就嵌入了時間——神經訊號需要時間傳遞，突觸強化需要時間累積。這種「動態系統」的特性，可能是理解因果關係的基礎。

「我認為任何以動態為基礎的東西——有時間、有因果性——會比沒有這些的東西更適合作為智慧的基底，」他說。這不是證明，是直覺。但如果他是對的，那目前所有基於 Transformer 的大模型，可能都走在一條「能用但不是最佳」的路上。

五到十年後回頭看，這家公司可能是一個瘋狂的嘗試，也可能是計算史上的轉折點。Rao 自己說得很清楚：「很多人說我瘋了。但人類需要一些瘋子去探索。」
