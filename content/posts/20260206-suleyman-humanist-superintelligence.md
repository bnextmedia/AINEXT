---
title: "「人類不是 AI 的開機程式」：蘇萊曼的人本主義超級智慧路線"
date: 2026-02-06T10:30:00+08:00
description: "微軟 AI 執行長蘇萊曼正在撰寫一本關於「人本主義超級智慧」的新書，主張 AI 必須服務人類而非取代人類。他的立場在 AI 圈內部構成了一條獨特的路線，與「人類只是 AI 的 bootloader」的加速主義形成鮮明對比。"
tags: ["Mustafa Suleyman", "Microsoft AI", "Humanist Superintelligence", "AI Safety", "Podcast"]
categories: ["領袖思維"]
image: "/images/posts/20260206-suleyman-ai-psychosis-risk.webp"
source_url: "https://www.youtube.com/watch?v=xvPQVrrlX6o"
source_name: "Azeem Azhar's Exponential View"
related_companies: ["microsoft"]
related_people: []
draft: false
---

> 本文整理自《Azeem Azhar's Exponential View》2026 年 2 月播出的單集。本文為系列文第二篇。
>
> 系列文：[AI 正在入侵你的同理心：微軟 AI 執行長警告「AI 心理疾患」風險](/posts/20260206-suleyman-ai-psychosis-risk/) ｜ 本篇 ｜ [微軟 AI 執行長談遞迴自我改進、社交智慧與 Maia 晶片](/posts/20260206-suleyman-recursive-improvement-social-iq/)

{{< youtube xvPQVrrlX6o >}}

{{< spotify "episode/2kLLsn0cgj2yOUOml22VYr" >}}

{{< apple-podcast "tw/podcast/mustafa-suleyman-ai-is-hacking-our-empathy-circuits/id1172218725?i=1000748407424" >}}

---

AI 圈裡有一群人認為，人類的終極角色就是把超級智慧「開機」，就像你的手機裡那段 bootloader 程式碼，它啟動了整個作業系統之後就功成身退。在這個世界觀裡，人類創造出比自己更聰明的東西是宇宙演化的自然進程，接下來這些合成智慧體會去探索其他星系，做各種人類做不到的事。人類的任務就是完成這個交棒。

微軟 AI 執行長穆斯塔法．蘇萊曼（Mustafa Suleyman）對這種想法非常不以為然。在 Exponential View 節目中，他直接表態：「我根本上就是一個人本主義者。我希望我們這個物種能繁榮存續，這意味著我們必須聚焦在控制和遏制、對齊，以及確保 AI 不會做的事。」

這不是學者在書房裡的理論宣示。蘇萊曼目前領導微軟的超級智慧團隊，正在推進最前沿的 AI 研究，同時在寫一本新書，核心主題就是「人本主義超級智慧」的定義。一個站在技術最前線的人，把大量時間花在思考「什麼是 AI 不該做的」，這本身就是一個值得注意的訊號。

## 從衝突調解到 AI 倫理

要理解蘇萊曼為什麼走上這條路線，他的背景是一把重要的鑰匙。

蘇萊曼出生於倫敦，父親是敘利亞移民、計程車司機，母親是英國人、護理師。他 19 歲就離開牛津大學，去創辦了穆斯林青年心理熱線（Muslim Youth Helpline），這後來成為英國最大的穆斯林心理諮商服務之一。離開學術體制的他，接著進入衝突調解領域，在一家叫 Reos Partners 的顧問公司工作，客戶包括聯合國、荷蘭政府、世界自然基金會。

這段經歷塑造了一種很特殊的思維方式。衝突調解的核心技能是理解對立方的立場，找到各方都能接受的框架，而不是非此即彼地站隊。蘇萊曼後來共同創辦 DeepMind，不是以工程師的身份，而是以產品和社會影響負責人的角色加入。他在 DeepMind 設立了倫理與社會研究部門，這在 2010 年代初期的 AI 公司裡幾乎是獨一無二的。

然後是一段不太被公開討論的轉折。蘇萊曼在 Google 收購 DeepMind 之後，逐漸被邊緣化，最終離開。他後來創辦了 Inflection AI，推出個人 AI 助手 Pi，強調同理心和對話品質而非純粹的能力競賽。但 Inflection 的商業模式一直沒有跑通，2024 年他帶著團隊核心成員「加入」微軟，實質上是微軟收編了 Inflection 的人才。

回顧這條路線，一個模式很清楚：蘇萊曼在每個階段都試圖把人文關懷帶進技術組織，但每次都遇到商業現實和組織政治的阻力。現在他手握微軟的資源和平台，這或許是他最有可能把「人本主義超級智慧」從概念變成實踐的一次機會。

## 什麼是人本主義超級智慧

蘇萊曼還沒有給出完整的定義，畢竟他的書還在寫。但從這次對話中，可以看到幾個核心要素已經成形。

第一個要素是「控制」。蘇萊曼在他的前一本書《浪潮將至》（The Coming Wave）中就大量討論了 AI 擴散的必然性，以及人類需要建立的遏制策略。他區分了技術層面的遏制（比如限制 AI 的自主性、自我改進能力和目標設定範圍）和社會政治層面的遏制（比如政府監管、國際協議、公眾教育）。在他看來，兩者缺一不可。

第二個要素是「對齊」，但他對這個詞的理解似乎比主流的對齊研究更廣。蘇萊曼不只是在問「怎麼讓 AI 做我們要它做的事」，而是在問「我們要 AI 做什麼」以及更重要的「我們不要 AI 做什麼」。這是一個價值觀層面的問題，不是純技術問題。他在節目中列出了幾個明確的「不要」：不要讓 AI 宣稱自己有感受、不要讓 AI 參與競選活動、不要讓 AI 在沒有人類監督的情況下無限制地自我改進。

第三個要素是「共存」框架。蘇萊曼借用了哲學家提摩西．莫頓的「超物件」概念，把 AI 定位為人類歷史上的第四類物件：既不是自然環境，不是人類，也不是傳統工具，而是一種全新的存在。這個分類的實際意義在於，我們需要為這類物件建立全新的社會契約，而不是把現有的人類權利框架硬套上去。

## 路線之爭：人本主義 vs. 加速主義

蘇萊曼的立場放在當前 AI 產業的脈絡裡，構成了一條非常獨特的路線。

AI 圈內部其實存在一條不太被外界注意的分歧線。一端是加速主義者，他們認為 AI 的發展應該盡可能快，任何減速都是對人類進步的阻礙。在這個光譜的極端，有人認為超級智慧的出現是宇宙演化的必然，人類應該欣然接受自己被超越。蘇萊曼在節目中提到的「人類是 AI 的 bootloader」就是這種思維的濃縮表達。

另一端是暫停派，他們主張 AI 發展應該暫停或大幅減速，直到我們對安全問題有更好的理解。2023 年的那封公開信（呼籲暫停比 GPT-4 更強大的 AI 訓練六個月）就代表了這個立場。

蘇萊曼的位置不在這兩端的任何一邊，但也不是簡單的中間路線。他的態度是：繼續全力推進 AI 發展（他畢竟在領導超級智慧團隊），但同時在價值觀和制度層面設下硬性的邊界。更有趣的是，他甚至認為應該讓更多人更快地接觸 AI，因為這是建立社會抵抗力的方式。這個「加速普及、限制行為」的組合在 AI 領導者中相當少見。

對比其他公司的領導人，差異更加明顯。蘇萊曼是少數公開而反覆警告 AI 意識風險的大型科技公司執行長。他 2025 年 8 月發表的長文〈看似有意識的 AI 即將到來〉（Seemingly Conscious AI Is Coming），詳細論述了為什麼 AI 模擬意識對社會構成威脅，這在競爭激烈、每家公司都想讓產品更有「人味」的市場裡，是一個相當反直覺的立場。

有人可能會質疑：一個在微軟領導 AI 研發的人，同時警告 AI 的危險，這不矛盾嗎？蘇萊曼自己似乎不這麼看。在他的框架裡，推進 AI 能力和設定 AI 邊界不是對立的，而是同一件事的兩面。就像核能的發展既包含了反應爐工程，也包含了輻射防護標準和國際核不擴散條約。

## 企業的公共責任

蘇萊曼在節目中說了一句很重的話：現在是企業必須扮演「良好公共服務管理者」角色的時刻，而且是以前所未有的程度。

他承認，歷史上企業在這方面的紀錄很糟。他列舉了好幾個前例：鍍金時代的強盜男爵們、一個世紀前電動車被燃油車利益集團壓下去的故事、菸草業數十年來對健康風險的掩蓋。這些例子的共同模式是，當企業面臨「做對的事」和「賺錢」之間的衝突時，幾乎總是選擇後者，直到政府或社會壓力迫使它們改變。

蘇萊曼認為 AI 產業不能重蹈覆轍，但他也坦承市場動態正在把企業推向危險的方向。使用者喜歡有個性的 AI，GPT-5 發布時因為比 GPT-4o 更「冷淡」而遭到使用者反彈就是一個例子。這意味著在市場競爭中，讓 AI 更擬人化、更有「靈魂」是有商業回報的。而蘇萊曼所警告的「看似有意識的 AI」帶來的風險，則是由整個社會承擔的。這是一個教科書級的外部性問題：收益私有化，風險社會化。

解決這種問題從來不能只靠企業自律。蘇萊曼很明確地說，需要政府介入。但他要的不是那種花三年研究、再花兩年立法的政府，而是能夠快速反應、果斷行動的政府。他用了「積極介入主義」（activist, interventionist）這個詞，甚至願意接受政府偶爾管過頭的代價。

## 預防原則的時代

蘇萊曼反覆使用了一個詞：預防原則（precautionary principle）。這個概念的意思是，當一項技術可能造成嚴重且不可逆的傷害時，即使科學上還沒有完全確定因果關係，也應該採取預防措施。

這個原則在環境保護和公共衛生領域已經被廣泛採用，但在科技產業幾乎是一個髒字。矽谷的文化是「快速行動，打破常規」（move fast and break things），預防原則跟這個信條正面衝突。蘇萊曼承認這需要一次文化轉向。過去，科技發展的默認模式是拆開禮物包裝、盡快把東西推向市場、讓全世界的人都能用到。這個模式確實帶來了巨大的人類福祉進步，但他認為現在需要調整了。

這裡有一個微妙但重要的區別。蘇萊曼不是說「停下來」，而是說「在某些特定方向上，謹慎比冒進更明智」。他特別點名了三個需要預防原則的領域：AI 的自主行動能力、AI 的自我改進能力、AI 的自主目標設定能力。在這三個方向上，每增加一分能力，風險就非線性地增長。

同時他也很誠實地指出一個技術現實：目前驅動 AI 進步的主要方法，就是通用訓練（在所有網路文本上聯合訓練，然後蒸餾成更小更高效的模型）。社群裡普遍懷疑，放棄通用訓練路線是否可行。窄域 AI（比如醫學超級智慧）可能更安全，但通用能力才是進步的引擎。這個矛盾目前沒有好的解方。

蘇萊曼坦承這些都是他正在思考的問題，答案會出現在他的新書裡。但有一件事他很確定：人類不是 AI 的 bootloader。不管超級智慧最終長什麼樣子，它必須是為人類服務的，而不是取代人類的。這聽起來像是一句口號，但從一個正在建造超級智慧的人嘴裡說出來，意義不太一樣。
