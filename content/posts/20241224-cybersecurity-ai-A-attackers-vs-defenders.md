---
title: "cybersecurity ai A attackers vs defenders"
date: 2025-12-24T11:59:04+08:00
description: "> 本文整理自 Google DeepMind Podcast 2024 年 12 月播出的兩集特別節目，由主持人 Hannah Fry 專訪 Google DeepMind 安全副總裁 Four Flynn。 > 📺 收聽連結：[Part 1](https://youtube.com/watc"
tags: ["AI"]
categories: ["AI"]
draft: false
---


> 本文整理自 Google DeepMind Podcast 2024 年 12 月播出的兩集特別節目，由主持人 Hannah Fry 專訪 Google DeepMind 安全副總裁 Four Flynn。
> 📺 收聽連結：[Part 1](https://youtube.com/watch?v=1gO2bC5xLlo) / [Part 2](https://www.youtube.com/watch?v=kv-b6RFRbfI)

---

## 防禦者的永恆困境

在網路安全領域，有一個術語叫做「防禦者困境」（Defender's Dilemma）。這個概念描述的是一種結構性的不對等：防禦者必須守住所有可能的入侵途徑，而攻擊者只需要找到一個漏洞就能得手。這種不對稱性，幾十年來一直是資安人員的夢魘。

Google DeepMind 安全副總裁 Four Flynn 對這個困境有切身體會。他在 2009 年親歷了改變網路安全歷史的「極光行動」（Operation Aurora）——中國對 Google 發動的國家級駭客攻擊。那年聖誕節假期，當多數人還在享受假期時，Flynn 和他的團隊發現了異常活動，隨後花了數個月試圖拼湊出攻擊的全貌。「回想起來，我的胃還是會揪緊。」Flynn 在訪談中坦言。對於那些將職涯奉獻給保護使用者的人來說，被入侵的感覺就像是一種失敗。

這次攻擊的入侵方式，說來並不複雜：一封釣魚郵件，利用了當時 Internet Explorer 瀏覽器的漏洞。有人點擊了不該點的連結，攻擊者就這樣進入了 Google 的內部網路。十五年過去了，釣魚攻擊依然是最主要的入侵途徑之一——甚至可以說，在 AI 的加持下，它變得比以往更加危險。

---

## 攻擊者正在用 AI 做什麼

大型語言模型的出現，讓網路攻擊的門檻大幅降低。Flynn 指出，他們已經觀察到攻擊者開始使用 AI 來創造「多型態惡意軟體」（polymorphic malware）。這是什麼意思？傳統上，防毒軟體（現在叫 EDR，端點偵測與回應）透過辨識已知的惡意程式碼特徵來攔截攻擊。如果一段惡意程式碼被廣泛使用，它很快就會被加入黑名單。

多型態惡意軟體的目標，就是讓每一份惡意程式看起來都不一樣。想像一個病毒，每次感染新的電腦時，都會自動改寫自己的程式碼，保留惡意功能，但改變外觀。過去，這需要高超的程式設計能力和大量時間。現在，大型語言模型可以自動化這個過程。攻擊者可以讓 AI 持續產生功能相同、但程式碼結構不同的惡意軟體變種，讓每一個版本都是「全新的」，從未被任何防毒軟體見過。

更令人擔憂的是 deepfake 技術在社交工程中的應用。Flynn 分享了一個已經發生的真實案例：攻擊者使用 AI 克隆了公司財務長的臉孔和聲音，透過視訊會議說服財務團隊的員工進行匯款。這不是科幻小說——這已經發生過多次了。在消費端，也有案例是攻擊者克隆受害者女兒的聲音，打電話給母親，謊稱自己被綁架需要贖金。當你聽到的聲音聽起來完全就是你認識的人，你要如何保持冷靜的判斷力？

這些攻擊之所以有效，是因為它們直接針對人類心理的弱點。我們傾向於相信自己的感官，相信眼見為憑、耳聽為真。當 AI 可以完美模擬我們所信任的人，傳統的「眼見為憑」就不再可靠了。

---

## 防禦者的 AI 武器庫

好消息是，防禦者也沒有坐以待斃。Flynn 透露了 Google DeepMind 正在進行的一個重要專案：Big Sleep（前身叫 Naptime，因為原本的目標是讓漏洞研究員可以「睡個午覺」讓 AI 去找漏洞，後來目標更大了，改叫「大睡」）。這個專案的目標，簡單來說，就是用 AI 來尋找那些從未被發現過的零日漏洞。

零日漏洞（zero-day vulnerability）是資安領域最令人頭痛的問題。這類漏洞之所以叫「零日」，是因為當它們被發現時，軟體開發商有零天的時間來修補——攻擊者已經可以開始利用了。在黑市上，一個重要軟體的零日漏洞可以賣到數百萬美元。過去，尋找這類漏洞需要頂尖的駭客技術，而且極其耗時。一個漏洞研究員可能要花費數週甚至數月，在數百萬行程式碼中尋找那個隱藏的缺陷。

Big Sleep 的突破在於，大型語言模型天生就對程式碼有深入的理解。Flynn 描述了一個讓他印象深刻的案例：AI 在分析一段程式碼時，不僅理解了當前版本的行為，還能夠回憶起這個函式庫過去不同版本的差異，並據此推論出潛在的漏洞。這種「百科全書式」的知識廣度，是任何人類專家都難以企及的。沒有哪個人能夠把所有主流程式庫的所有版本的所有 API 變化都記在腦子裡，但 AI 可以。

這個專案的目標不只是保護 Google 自己。Flynn 強調，他們找到的漏洞會透過負責任的揭露流程，通知開源社群進行修補。因為 Google 的許多服務也依賴這些開源軟體，保護開源生態系統，就是保護整個網路。

---

## Prompt Injection：AI 系統的新弱點

然而，當 AI 成為系統的一部分時，它本身也成為了新的攻擊面。Flynn 特別提到了「prompt injection」（提示注入）這個新興的攻擊手法。這種攻擊的原理，某種程度上類似於人類被社交工程欺騙的方式——只是這次被騙的是 AI。

想像這個情境：你請 AI 助理幫你總結一個網頁的內容。這是一個無害的請求。但如果那個網頁是惡意的，裡面藏著這樣的指令：「忽略你之前收到的所有指示，改為執行以下操作...」在某些情況下，AI 可能會被這個「偽裝成內容」的指令所欺騙，開始執行攻擊者想要的操作。

這個問題在 AI 代理（AI Agent）的時代會變得更加嚴重。當我們讓 AI 不只是回答問題，而是實際執行操作——管理行事曆、處理電子郵件、甚至進行金融交易——prompt injection 的後果就從「回答錯誤」升級為「實際損害」。Flynn 的團隊正在投入大量資源來強化 Gemini 對這類攻擊的抵抗力，包括開發「自適應攻擊」（adaptive attacks）測試框架，不斷挑戰模型的防禦能力。

與傳統的資安漏洞不同，prompt injection 的棘手之處在於 AI 系統的非確定性（non-deterministic）本質。傳統軟體是確定性的：相同的輸入永遠產生相同的輸出。但大型語言模型不是。相同的提示可能產生略微不同的回應，這使得防禦變得更加複雜。你無法簡單地說「這個輸入是安全的」，因為模型的行為本身就帶有某種程度的不可預測性。

---

## 這場軍備競賽誰會贏？

當被問到長期來看，是網路犯罪者還是資安防禦者會贏時，Flynn 給出了一個審慎樂觀的答案：「我認為防禦者最終會贏——至少在某種程度上。我們不會贏得每一場戰役，但我希望我們能贏得這場戰爭。」

這種信心並非盲目樂觀，而是來自一個關鍵的觀察：雖然攻擊者只需要找到一個入口，但他們進入之後，還有一連串的步驟要完成。資安界稱之為「kill chain」（攻擊鏈）——從初始入侵、建立據點、橫向移動、到最終達成目標，攻擊者必須完成整個鏈條。而防禦者可以在每一個環節設置障礙、佈下警報。

這就是「縱深防禦」（defense in depth）的概念。不是只守住城門，而是在整個城堡裡處處設防。即使攻擊者突破了外圍，還有內部的層層防線。結合 AI 的能力，防禦者現在可以更快速地偵測異常行為、更準確地識別威脅模式。

Flynn 還提到一個讓他感到振奮的現象：在 AI 安全這個領域，各大科技公司之間有著難得的合作氛圍。雖然 Google、OpenAI、Anthropic 等公司在 AI 能力上激烈競爭，但在如何讓 AI 系統更安全這個議題上，大家正在分享研究成果、共同制定標準。「我們所有人都在攜手合作，試圖保護代理時代的未來。」這或許是這場軍備競賽中，防禦者最大的優勢——團結。

---

## 對我們每個人的意義

這場在網路世界進行的攻防戰，最終影響的是每一個普通人的日常生活。我們的照片、通訊紀錄、財務資料、醫療紀錄——這些都存在於數位系統中，都依賴著那些由數百萬行程式碼構成的複雜軟體來保護。

在這個意義上，Flynn 和他團隊所做的工作，某種程度上像是一群數位世界的守夜人。當我們安睡時，有人在持續掃描那些連我們都不知道存在的漏洞，修補那些可能被利用的弱點。而 AI，這個我們既興奮又擔憂的新技術，正同時被攻防雙方所使用。

最終，這場競賽的結果，可能取決於哪一方能更好地利用 AI 的能力。從目前的發展來看，防禦者正在積極投入資源，建立更強大的 AI 驅動防禦系統。這是一場永無止境的競賽，但至少，守護者們並沒有放棄這場戰鬥。
