---
title: "02 data centers in space"
date: 2025-12-22T21:00:09+08:00
description: "未來三到四年內，世界上最重要的事情之一，將是太空資料中心的崛起。這不是科幻小說的情節，而是從第一原則推演出的必然結論。對於正在大舉投資電力基礎建設和地面資料中心的企業來說，這個發展方向值得認真對待。 Gavin Baker 是 Atreides 投資公司創辦人，曾任 Fidelity 科技基金經理"
tags: ["AI"]
categories: ["AI"]
draft: false
---


未來三到四年內，世界上最重要的事情之一，將是太空資料中心的崛起。這不是科幻小說的情節，而是從第一原則推演出的必然結論。對於正在大舉投資電力基礎建設和地面資料中心的企業來說，這個發展方向值得認真對待。

Gavin Baker 是 Atreides 投資公司創辦人，曾任 Fidelity 科技基金經理人，長期追蹤 AI 與半導體產業。在 2024 年 12 月與《Invest Like the Best》主持人 Patrick O'Shaughnessy 的對談中，他花了相當篇幅闡述太空資料中心的經濟邏輯。這個觀點乍聽之下像是科幻愛好者的狂想，但當你跟著他的推理走一遍，會發現這個結論幾乎無可避免。

---

## 資料中心的本質：兩個基本輸入

要理解為什麼太空資料中心具有優勢，首先要回到最基本的問題：運作一個資料中心需要什麼？答案出奇地簡單——電力、冷卻、晶片。就這三樣。晶片是運算的核心，而電力和冷卻則是讓晶片持續運作的基礎設施。當你把問題簡化到這個層次，就可以開始比較地球和太空作為資料中心地點的優劣。

在地球上，電力來源是一個持續的挑戰。你需要連接電網，或者自建發電設施。無論是核電、天然氣、太陽能還是風電，每種選擇都有其限制：核電審批耗時漫長、天然氣受制於燃料供應、太陽能和風電需要儲能設施來應對間歇性。更麻煩的是，AI 資料中心的用電需求正在以前所未有的速度增長。一個現代 AI 訓練叢集的功耗可以輕易達到數百兆瓦，相當於一個中型城市的用電量。找到足夠的電力供應，並且取得必要的審批和輸電基礎設施，已經成為建設資料中心的主要瓶頸。

冷卻同樣是一個棘手的問題。現代 AI 晶片的熱密度極高，從 Hopper 到 Blackwell 的世代升級中，冷卻系統從空氣冷卻轉向液體冷卻，機架中有相當比例的質量和體積都被冷卻設備佔據。HVAC 系統、冷卻分配單元、液冷管路——這些基礎設施不僅昂貴，而且需要持續的維護和能源消耗。在某些氣候條件下，冷卻本身消耗的能源可以佔到資料中心總能耗的相當比例。

---

## 太空中的電力：太陽系最便宜的能源

把資料中心放到太空中，電力問題會如何改變？答案是：幾乎完美解決。

在近地軌道上，衛星可以保持 24 小時都處於陽光下。這不是誇張——通過適當的軌道設計，衛星可以始終處於地球的向陽面。太陽光在太空中的強度比地表高約 30%，因為沒有大氣層的吸收和散射。這個強度差異，加上 24 小時不間斷的照射（相對於地表平均只有 12 小時日照，而且受天氣影響），意味著太空中的太陽輻射量是地球表面的大約六倍。

但更關鍵的優勢在於：因為 24 小時都有陽光，太空資料中心不需要電池。這一點的意義遠超出表面。在地面太陽能系統中，儲能設施往往佔據總成本的相當比例，而且電池有壽命限制、需要維護更換。在太空中，這整塊成本直接歸零。沒有陰天，沒有夜晚，沒有季節變化，只有穩定持續的太陽能供應。

這個經濟邏輯的結論是直接的：我們太陽系中成本最低的能源，就是太空中的太陽能。不是地球上的任何能源形式——無論是核電、天然氣、水力、地面太陽能——能夠與之競爭。當你的競爭對手需要支付電費，而你的電力本質上是免費的，這是一個根本性的成本優勢。

---

## 太空中的冷卻：在絕對零度旁邊免費散熱

如果說免費電力已經是一個巨大優勢，免費冷卻則讓這個優勢更加決定性。

在地球上，冷卻是一個工程挑戰和持續成本。熱量需要被帶走，但帶走熱量需要能量，而且需要複雜的基礎設施。液冷系統需要泵浦、管路、冷卻塔或冷卻機組。即使是最先進的冷卻技術，也無法逃避熱力學的基本限制：你需要把熱量傳遞到一個溫度更低的地方，而地球表面的環境溫度限制了你能達到的冷卻效率。

在太空中，情況完全不同。你只需要在衛星的背陽面放一個散熱器，那裡的環境溫度接近絕對零度（約 -270°C）。熱量會自然地通過輻射傳遞到這個極度寒冷的真空中。不需要泵浦，不需要冷卻液，不需要持續的能源消耗。在地面資料中心機架中佔據大量空間和重量的冷卻設備，在太空中可以大幅簡化。

這意味著什麼？更高比例的有效載荷可以是實際的運算晶片，而不是支援晶片運作的基礎設施。每公斤發射到太空的質量都是昂貴的，能夠減少非運算質量的比例，直接提升了整體經濟效益。更重要的是，這消除了冷卻作為系統瓶頸的可能性。在地面上，冷卻能力的上限往往決定了你能在一個機架中塞入多少運算能力。在太空中，這個限制大幅放寬。

---

## 太空中的網路：比光纖更快的連接

到這裡，一個自然的反駁是：即使電力和冷卻在太空更有優勢，網路連接呢？AI 訓練需要大規模的 GPU 叢集協同運作，這些 GPU 之間需要極高頻寬、極低延遲的連接。太空中的衛星如何彼此通訊？答案出人意料地有力：太空中的網路實際上可以比地面更快。

在地面資料中心裡，超過一定距離的機架之間是用光纖連接的。光纖的本質是什麼？是雷射光束在玻璃纖維中傳輸。光在玻璃中的傳播速度大約是真空中的 70%，因為玻璃的折射率會減慢光速。這是物理定律，無法改變。

在太空中呢？衛星之間可以直接用雷射通訊，而雷射在真空中的傳播速度就是光速——沒有介質減速。這意味著，如果你用雷射把太空中的衛星連接起來，你實際上擁有比地球上任何光纖網路都更快的連接。不是快一點點，而是快約 40%。

對於 AI 訓練來說，這種速度優勢具有實際意義。訓練大型模型時，GPU 之間需要頻繁交換梯度資訊，這個過程的速度直接影響訓練效率。在地面上，「連貫叢集」（coherent cluster）的規模受限於網路延遲和頻寬。在太空中，理論上可以建立更大規模的連貫叢集，因為 GPU 間的通訊更快。當然，訓練需要的叢集規模目前還遠超太空能夠部署的量，但對於推論（inference）來說，這個優勢已經非常實際。

---

## 推論服務的用戶體驗革命

讓我們思考一個具體的使用場景：你在手機上問 AI 助理一個問題。在現有架構下，這個請求會經歷怎樣的旅程？

首先，無線電波從你的手機傳到最近的基地台。然後信號進入光纖骨幹網路，被路由到某個城市的數據交換中心。從那裡，請求被轉發到某個大型資料中心——可能在同一個城市，也可能在千里之外。資料中心裡的 AI 模型處理你的請求，生成回應。然後整個路徑反向走一遍，回應才到達你的手機。

這個往返過程涉及多次光電轉換、多個路由節點、數百甚至數千公里的傳輸距離。即使每一段都已經高度最佳化，累積的延遲依然可觀。對於需要即時互動的 AI 應用——語音助理、即時翻譯、AR/VR 體驗——這種延遲是用戶體驗的關鍵限制。

現在想像太空資料中心的場景。Starlink 已經展示了衛星直接與手機通訊的能力，不需要透過地面基地台。如果推論運算就在軌道上進行，請求的路徑變得極其簡短：手機到衛星，衛星處理，衛星回傳手機。兩跳完成，相對於地面架構的多跳路徑，延遲可以大幅降低。

這不只是技術優化，而是用戶體驗的質變。當 AI 回應的延遲從數百毫秒降低到數十毫秒，互動的感覺從「等待機器回答」變成「自然對話」。這種體驗差異會直接反映在用戶採用率和付費意願上。從商業角度看，能夠提供最低延遲 AI 服務的供應商，將擁有難以複製的競爭優勢。

---

## 實現的關鍵：發射成本與 Starship

當然，太空資料中心不會憑空出現。目前的主要瓶頸是發射成本和運載能力。把大量的伺服器設備送入軌道，需要頻繁、大量、低成本的發射能力。這正是 SpaceX 的 Starship 的意義所在。

Starship 是人類歷史上最大的運載火箭，設計目標是完全可重複使用，大幅降低每公斤入軌成本。傳統火箭的發射成本約為每公斤數千到數萬美元不等，而 Starship 的目標是將這個數字降低到數百美元甚至更低。只有在這個成本水準上，大規模的太空資料中心才具有經濟可行性。

SpaceX 在可回收火箭技術上已經領先多年。獵鷹九號的一級火箭已經可以常規回收和重複使用，大幅降低了發射成本。Starship 的設計更進一步，目標是連二級火箭都可以回收。Blue Origin 最近也成功完成了火箭著陸，顯示這個領域的競爭正在加速。但就目前而言，SpaceX 的領先優勢依然顯著，而且 Starship 的運載能力遠超其他任何現役或在研的火箭。

要讓太空資料中心成為主流，需要大量的 Starship 進行頻繁發射。這需要時間來建立產能和累積運營經驗。按照目前的發展速度，真正大規模的太空運算部署可能還需要五到六年。但技術路徑已經清晰，經濟邏輯已經成立，剩下的只是執行和時間。

---

## Elon Musk 帝國的匯流

一個有趣的觀察是，SpaceX、Tesla、XAI 這三家 Elon Musk 旗下的公司，正在形成一種戰略匯流。這種匯流不是巧合，而是各自發展軌跡的自然交匯。

Musk 本人在訪談中曾表示，這三家公司正在匯流。具體而言：XAI 的 AI 模型將成為 Tesla Optimus 人形機器人的「智慧模組」，使用 Tesla 開發的視覺感知系統。SpaceX 則將運營太空資料中心，為 XAI、Tesla 以及其他公司提供 AI 運算服務。每一家公司的能力都在為其他公司創造競爭優勢。

XAI 作為 AI 實驗室，如果能優先使用太空資料中心的算力，將在成本上獲得結構性優勢。Tesla 擁有龐大的客戶基礎和即時數據流，可以為 XAI 的模型訓練和改進提供獨特的數據資源。Optimus 機器人如果大規模部署，將創造對 AI 推論算力的龐大需求，而這些需求可以由太空資料中心來滿足。三家公司形成了一個相互強化的生態系統。

當然，這種整合也帶來治理挑戰。Tesla 是上市公司，任何與 XAI 或 SpaceX 的關聯交易都需要極其嚴格的審查，以確保對 Tesla 股東公平。可以預見，這些公司間的商業安排將是有史以來受到最嚴密審視的關聯交易之一。但商業邏輯的強度，使得某種形式的整合幾乎是必然的。

---

## 對當前投資熱潮的警訊

這個發展方向對當前的資料中心和電力投資熱潮提出了嚴肅的問題。目前，大量資本正在湧入地面資料中心建設、電力基礎設施、天然氣渦輪機、甚至核能項目。這些投資的回收期通常以十年甚至二十年計。如果太空資料中心在五到六年內開始大規模部署，這些投資的長期回報將面臨挑戰。

這不是說地面資料中心會立即過時。訓練超大規模模型仍然需要集中的算力，而太空資料中心的規模擴張需要時間。推論服務的遷移會更快，但訓練服務可能會在地面保留更久。短期內，電力和資料中心投資仍然是 AI 供應鏈的關鍵瓶頸，相關投資仍有其價值。

但長期投資者需要思考一個問題：如果太空真的是資料中心的最優地點，那麼地面資料中心的長期價值應該如何定價？這不是一個容易回答的問題，因為技術發展路徑存在不確定性。但忽略這個可能性，把地面基礎設施視為永久性資產，可能是一個代價高昂的錯誤。

---

## 電力約束的短期意涵

在太空資料中心成為現實之前，電力仍然是地面資料中心的關鍵約束。有趣的是，這種約束對某些玩家來說反而是好消息。

當電力是約束因素時，運算設備的價格變得相對不重要。如果你能取得的電力是固定的，那麼決定你產出的就是每瓦特能產生多少 Token。在這個邏輯下，能效最高的運算技術將享有巨大的定價權。你可以把 GPU 賣得更貴，因為客戶關心的不是設備價格，而是每瓦特的產出。這解釋了 Nvidia 為什麼能夠維持如此高的毛利率——在電力受限的環境中，他們的技術領先直接轉化為定價權。

至於短期的電力解決方案，核能在美國的前景有限。環保法規、審批流程、鄰避效應，使得新建核電廠幾乎不可能在合理的時間框架內完成。一個半開玩笑但又真實的例子是：一種稀有螞蟻的棲息地，就可以完全阻止一座核電廠的建設。人類福祉在美國的監管體系中，有時似乎排在其他考量之後。

實際可行的解決方案是天然氣和太陽能。美國因為頁岩氣革命，擁有豐富的天然氣供應。這就是為什麼德州 Abilene 成為資料中心建設的熱點——它位於一個大型天然氣盆地的中心。天然氣發電機組可以相對快速地部署，為資料中心提供穩定的電力來源。系統正在回應需求：Caterpillar 宣布將在未來幾年內把燃氣輪機產能提高 75%。

---

## 一個更大的模式

太空資料中心的邏輯，是一個更大模式的一部分。無論 AI 發展遇到什麼瓶頸，似乎總能找到突破口。硬體升級停滯？Reasoning 模型填補空白。電力供應受限？太空資料中心的可能性正在浮現。稀土供應被中國掌控？替代供應鏈和新提煉技術正在加速發展。

這種「AI 需要什麼就得到什麼」的模式令人印象深刻。公眾對核能的態度在短短兩三年內發生了戲劇性的轉變，而這個轉變恰好發生在 AI 對電力的需求開始爆發的時刻。這是巧合，還是某種深層的技術與社會動力學在運作？

從投資角度看，這個模式提供了一種思考框架：不要低估 AI 發展突破障礙的能力。歷史上的每一個「AI 不可能做到 X」的論斷，最終都被證明是錯誤的，只是時間問題。太空資料中心聽起來像科幻，但從第一原則分析，它的邏輯是嚴謹的。在每一個維度上——電力、冷卻、網路——太空都優於地球。剩下的只是工程和商業執行的問題。

SpaceX 正在解決發射成本問題。Starlink 已經證明了大規模衛星部署的可行性。直連手機的衛星通訊已經實現。所有的技術拼圖正在到位。問題不是「是否可能」，而是「什麼時候」。對於願意看得更遠的投資者來說，這或許是當前最重要的長期趨勢之一。

---

🎧 **收聽本集完整訪談**：
- [Invest Like the Best EP.451 - Gavin Baker](https://podwise.ai/dashboard/episodes/6327964)

---

*本文為 AINEXT 系列報導「Gavin Baker 談 AI 產業」第二篇。下一篇將分析 OpenAI、Anthropic、Google、XAI 四大前沿實驗室的競爭格局。*
