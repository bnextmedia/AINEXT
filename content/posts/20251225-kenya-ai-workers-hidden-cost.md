---
title: "每小時 2 美元的 AI 夢：肯亞標註員揭露矽谷的隱藏人力成本"
date: 2025-12-25T12:00:00+08:00
description: "當我們讚嘆 AI 的神奇時，很少人知道背後有一支龐大的人類大軍正在訓練這些模型。在肯亞，數學系畢業生每小時賺 2 美元，整天看著暴力和色情內容，為 Meta 和 OpenAI 標註資料。60 Minutes 深入調查這個被稱為「矽谷薩凡納」的地方，揭露 AI 產業光鮮背後的血淚故事。"
tags: ["AI 產業", "肯亞", "資料標註", "勞工權益", "60 Minutes"]
categories: ["AI 產業"]
source_url: "https://www.youtube.com/watch?v=KpOcUrPdx-4"
source_name: "60 Minutes"
draft: false
---

> 本文整理自 CBS《60 Minutes》2025 年播出的 AI 專題報導。
> 🎧 收聽連結：[YouTube](https://www.youtube.com/watch?v=KpOcUrPdx-4)

「你在教機器人如何像人類一樣思考、像人類一樣做事。」

Naphtali Wambalo 坐在肯亞奈洛比的某處，向 60 Minutes 記者解釋他的工作。他是大學畢業生，主修數學，有兩個孩子要養。在一個年輕人失業率高達 67% 的國家，他很高興終於找到了一份工作——而且是在新興的人工智慧領域。

他的工作內容是：每天盯著螢幕八小時，在圖片和影片上畫框框、貼標籤，教 AI 演算法辨識物件。

「你會標註家具，說『這是電視、這是微波爐』，這樣你就在教 AI 辨識這些東西。」

「還有一個是標註人臉和膚色。如果看起來像這樣，這是白人；如果看起來像這樣，這是黑人、這是亞洲人。」

時薪：2 美元。

## 「現代奴隸制」

這是一個很少被說出來的事實：AI 不會自己變聰明。

在 ChatGPT 能回答你的問題之前，在自駕車能辨識行人之前，在 AI 能診斷疾病之前，需要有人類先「教」它們。人類標註汽車和行人，教自駕車不要撞上去。人類圈出異常區域，教 AI 辨識疾病。

這些人被稱為「人類迴圈」（Humans in the Loop）。這是一支全球數百萬人的大軍，為 Meta、OpenAI、Microsoft、Google 分類、標註、篩選海量資料。

這是苦工。需要準確，需要快。為了壓低成本，這些工作被外包到非洲等地——那裡有大量受過教育、卻找不到工作的年輕人。

「老實說，這就像現代奴隸制，因為這是廉價勞動力。」肯亞民權運動者 Nerima Wako-Ojiwa 這樣說。

「等等，現代奴隸制？」記者驚訝地問。

「廉價勞動力，」她重複，「這些大型美國科技公司來這裡，把這些工作宣傳成通往未來的門票。但實際上，這是剝削。」

## 矽谷薩凡納的真相

為了吸引科技巨頭，肯亞政府積極招商。總統 Ruto 大力推動 AI 機會，提供財務優惠，加上原本就寬鬆的勞工法規。肯亞被宣傳為「矽谷薩凡納」——精通科技、數位連結發達。

但這些工人並非直接受僱於大公司。Meta、OpenAI 等透過外包公司——大多也是美國企業——來僱用他們。

「有一個中間人？」記者問。

「對，他們僱用、他們付錢。他們雇了數千人。他們在保護那些 Facebook 們，不讓它們的名字和這些工作扯上關係。」

「我們談的可是地球上最富有的公司。」

「對，但他們付給人們花生米。」

根據 60 Minutes 取得的文件，OpenAI 同意為每位工人每小時支付給外包公司 Sama 12.50 美元。但工人實際拿到的只有 2 美元。Sama 表示這對當地來說是公平的薪資。

「兩美元一小時在肯亞算低、中等，還是可以接受的薪水？」記者問 Naphtali。

「對我來說，我是月光族。我什麼都沒存下來，因為不夠。」

「這是一種侮辱嗎？」

「當然是。」

「那你為什麼接受這份工作？」

「我有家人要養。與其待在家裡，不如至少有事可做。」

## 看暴力色情內容的心理創傷

薪水低還不是最糟的。這些工人說，工作內容本身讓他們受到了傷害。

Naphtali 被分配去訓練 AI 辨識並過濾色情、仇恨言論和極端暴力內容。這意味著他必須一天八小時、一週四十小時，篩選網路上最惡劣的內容。

「我看過人被屠殺、人和動物發生性行為、人虐待兒童——身體上、性方面——人自殺。基本上...」

「整天都在看？」

「是的，整天，八小時一天，一週四十小時。」

工人們說他們被廣告欺騙了。招聘廣告寫的是「客服專員，協助客戶社群，同理心地解決問題」。

「我被告知我要做翻譯工作，」另一位工人說，「但實際上我在審查非常圖像化、非常令人不安的內容。我在看被肢解的屍體、無人機攻擊的受害者。每次談到這些，我還是會有閃回。」

「你們有誰因為這份工作變成不同的人嗎？」記者問。

「有，我現在很難和人交談。我發現哭比說話容易。你會不斷把自己和人隔離。你不想和別人社交。只有你自己。」

「我以前很享受婚姻，尤其是臥室裡的事。但這份工作之後，我討厭性。」Naphtali 說。

「你討厭性？」

「在這份工作中看了無數次那些性行為、色情內容之後，我討厭性。」

## 「他們知道我們受損了，但他們不在乎」

Sama 表示有提供心理健康諮詢，由「完全合格的專業人士」提供。但工人們說這遠遠不夠。

「我們要精神科醫生。我們要心理學家——合格的、真正了解我們經歷什麼、知道如何幫助我們應對的人。創傷專家。」

「你認為大公司，Facebook、ChatGPT，他們知道這對工人的影響嗎？」

「這是他們的職責要知道。」

「他們知道。因為他們就是提供這些工作的人。」

Naphtali 和另外近 200 名工人正在起訴 Sama 和 Meta，控告不合理的工作條件導致精神疾病。

「精神科醫生證明了我們真的病了。我們幾個月前接受了精神評估，證明我們都病了，徹底地病了。」

「他們知道我們受損了，但他們不在乎。我們是人。只因為我們是黑人，只因為我們現在很脆弱，不代表他們有權這樣剝削我們。」

Sama 已經終止了那些專案。Meta 和 OpenAI 表示他們致力於安全的工作條件，包括公平薪資和心理健康諮詢。

## 另一種剝削：做了工作卻拿不到錢

還有另一家美國 AI 訓練公司 Scale AI 在肯亞經營一個叫 Remotasks 的網站。工人在線上註冊帳號，按任務計酬，遠端工作。

問題是，有時候公司根本不付錢。

「在發薪日的前一天，他們關閉帳號，說『你違反了我們的政策』。」

「他們說你違反政策，然後不付你做過的工作的錢？」

「對。」

「這種情況常見嗎？做了工作卻拿不到錢？」

「很常見。而且你沒有申訴管道。你根本沒辦法抱怨。」

公司表示「所有符合社群準則的工作都已付款」。但去年，當工人開始公開抱怨後，Remotasks 突然關閉了在肯亞的所有業務。

## 「當我們開始要求保護，他們就搬到鄰國去了」

「這裡沒有勞工法嗎？」記者問。

「我們的勞工法有 20 年歷史了。它沒有涵蓋數位勞動。我確實認為我們的勞工法需要承認這一點，但不只是肯亞。因為當我們開始推動工人保護時，很多這些公司就關門搬到鄰國去了。」

「這很容易理解你們被困住了。肯亞被困住了。他們太需要工作了，所以害怕如果抱怨，這些公司就不來了。」

「對，這就是他們一直對我們說的。看到這麼多美國公司在這裡做錯事，真的很糟糕。他們在做他們不會在自己國家做的事，那為什麼要在這裡做？」

---

這是一個關於不平等的故事。

當我們讚嘆 AI 能寫詩、能畫畫、能和我們聊天時，很少人會想到背後的事。有一群人，在全球最貧窮的地方，用最便宜的價格，做著最髒、最累、最傷心理的工作。

AI 不會自己變聰明。它需要人類來教。問題是：教的人得到公平的對待了嗎？

在肯亞，答案是否定的。

每小時 2 美元。每天八小時的暴力和色情。沒有足夠的心理支援。隨時可能被解僱或拿不到錢。

這是「矽谷薩凡納」的真相。這是 AI 產業光鮮背後的隱藏成本。

而這些成本，不是由那些市值數兆美元的科技巨頭承擔——是由 Naphtali 這樣的人承擔。一個數學系畢業生，只是想養活他的兩個孩子。
