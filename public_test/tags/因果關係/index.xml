<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>因果關係 on AINEXT</title>
    <link>https://bnextmedia.github.io/AINEXT/tags/%E5%9B%A0%E6%9E%9C%E9%97%9C%E4%BF%82/</link>
    <description>Recent content in 因果關係 on AINEXT</description>
    <generator>Hugo</generator>
    <language>zh-TW</language>
    <lastBuildDate>Thu, 25 Dec 2025 15:30:00 +0800</lastBuildDate>
    <atom:link href="https://bnextmedia.github.io/AINEXT/tags/%E5%9B%A0%E6%9E%9C%E9%97%9C%E4%BF%82/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>通往 AGI 的路，可能需要重新發明電腦</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251225-unconventional-ai-agi-causality/</link>
      <pubDate>Thu, 25 Dec 2025 15:30:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251225-unconventional-ai-agi-causality/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 NeurIPS 2024 期間的訪談。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/wZ4DT20OHXE&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;「目前的 AI 系統有智慧嗎？有。它們是 AGI 嗎？還差得遠。」&lt;/p&gt;&#xA;&lt;p&gt;Naveen Rao 說這話的時候，不是在貶低現有的大型語言模型。他承認它們非常有用、非常強大。但「有用」和「通用智慧」是兩回事。「它們還是會犯很蠢的錯誤。跟它們互動，不像在跟一個人工作。我相信大多數人都有這種感覺。」&lt;/p&gt;&#xA;&lt;p&gt;問題是：缺了什麼？&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;因果關係的缺失&#34;&gt;因果關係的缺失&lt;/h2&gt;&#xA;&lt;p&gt;Rao 認為，目前 AI 系統最關鍵的缺失是「因果理解」。&lt;/p&gt;&#xA;&lt;p&gt;這不是說 Transformer 完全不懂因果。它們從大量文本中學到了很多關於世界的知識，包括事件之間的先後順序。但那是「統計相關」，不是「因果機制」。模型知道「下雨」和「地面濕」常常一起出現，但它不像人類那樣直觀地理解「雨水落下導致地面變濕」這個因果鏈。&lt;/p&gt;&#xA;&lt;p&gt;「小孩子某種程度上天生就理解因果，」Rao 說。「這就是為什麼我們能移動四肢——我知道如果我送出某個指令給我的手臂，它會做某件事。」嬰兒花很多時間做看似無意義的動作，但那其實是在建立因果模型：我做這個動作，會發生那件事。這種理解似乎是「內建」的，不完全是後天學習的結果。&lt;/p&gt;&#xA;&lt;p&gt;Transformer 沒有身體，沒有與物理世界互動的經驗，它所有的「知識」都來自文字描述。文字可以傳達很多東西，但有些東西很難用文字描述——重力的感覺、觸碰東西的觸感、移動時平衡的維持。這些「身體性」的知識，可能是因果理解的基礎。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;數位計算的根本限制&#34;&gt;數位計算的根本限制&lt;/h2&gt;&#xA;&lt;p&gt;Rao 更進一步提出一個激進的假設：數位計算本身可能就不適合理解因果。&lt;/p&gt;&#xA;&lt;p&gt;數位計算沒有真正的「時間」概念。程式可以暫停、可以倒轉、可以快轉。時間只是一個變數，你用數字去模擬它。但真實世界的時間是連續的、不可逆的、有方向的。「動態系統意味著時間，」Rao 解釋。「而且，時間在真實世界中是有因果性的——先發生的事影響後發生的事。我們在數位計算中沒有這個概念。」&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
