---
title: "sam altman openai strategy"
date: 2025-12-23T00:53:32+08:00
description: "> 本文整理自《Big Technology Podcast》2024 年 12 月 18 日播出的單集，主持人 Alex Kantrowitz 專訪 OpenAI CEO Sam Altman。 > 收聽連結：[Apple Podcast](https://podcasts.apple.com/"
tags: ["AI"]
categories: ["AI"]
draft: false
---


> 本文整理自《Big Technology Podcast》2024 年 12 月 18 日播出的單集，主持人 Alex Kantrowitz 專訪 OpenAI CEO Sam Altman。
> 收聽連結：[Apple Podcast](https://podcasts.apple.com/in/podcast/sam-altman-how-openai-wins-ai-buildout-logic-ipo-in-2026/id1522960417?i=1000741901091)

---

## Code Red 的真相：OpenAI 怎麼看待競爭

OpenAI 總部最近進入了「Code Red」狀態。這個消息傳出後，外界紛紛解讀為 OpenAI 陷入了生存危機——Gemini 3 來勢洶洶，DeepSeek 也在攻城掠地，ChatGPT 的領先地位看起來岌岌可危。

但 Sam Altman 在訪談中給了一個完全不同的詮釋。在他眼中，Code Red 是一個「相對低風險、會經常發生的事情」。這不是恐慌，而是一套標準作業程序：當潛在的競爭威脅出現時，快速行動、保持警覺。他用了一個傳染病防治的比喻來解釋這套邏輯——疫情剛開始時採取的每一個行動，效益都遠大於之後的補救措施。多數人在初期不夠積極，到後期才開始恐慌。OpenAI 的策略正好相反：在威脅還只是「潛在」的時候就當真，而不是等它成為「確定」的問題。

這次由 Gemini 3 觸發的 Code Red，到目前為止並沒有造成 Altman 擔心的那種衝擊。但這個過程並非毫無收穫——它迫使 OpenAI 審視自己產品策略中的弱點，並且快速補強。在 Code Red 期間，OpenAI 發布了全新的圖像生成模型（這是消費者長期想要的功能），也推出了 GPT-5.2，這個模型的市場反應極好，成長速度飛快。Altman 預估這個 Code Red 狀態大約會持續六到八週，之後會回歸正常節奏。但他預期未來每年可能會有一到兩次類似的警戒狀態，這已經變成 OpenAI 確保自己保持競爭力的常規機制。

這種心態其實值得細想。在多數企業的文化中，「Code Red」是要盡量避免的災難。但 Altman 把它重新定義成一種「戰略性的偏執」——不是因為真的在輸，而是為了確保自己不會開始輸。

---

## 策略一：模型不會完全商品化，前沿仍有巨大價值

當被問到 AI 模型是否會走向「商品化」——也就是說，當各家模型對一般使用者來說感覺差不多時，OpenAI 的優勢是否會消失？Altman 給了一個有點出乎意料的回答：商品化「不太是正確的思考框架」。

他的論點是這樣的：沒錯，對於日常的聊天使用，未來可能會有很多模型都能達到夠好的水準。但 AI 的經濟價值並不平均分佈在所有使用場景上。真正創造最大價值的，是那些位於「前沿」的模型——能夠做到其他模型做不到的事情的那一個。比如科學發現、比如解決企業最棘手的技術問題、比如協助複雜的研究工作。這些任務對模型能力的要求極高，而這正是 OpenAI 押注的領域。

Altman 對 GPT-5.2 的定位就體現了這個策略。他很驕傲地說，這是目前全世界最強的推理模型，也是科學家們認為最能幫助他們推進研究的工具。同時，企業客戶也反映 GPT-5.2 在各種商業任務上的表現是最好的。這是一個「前沿模型」應該達到的位置：不只是在某一個維度上領先，而是在多個關鍵維度上同時領先。

這個策略的風險在於：如果其他公司（比如 Google）開發出同樣強大的前沿模型，而且有更好的分發管道，OpenAI 會怎麼辦？Altman 承認 Google 仍然是巨大的威脅。他甚至說了一句很直白的話：如果 Google 在 2023 年真的認真起來對付我們，我們會非常慘。但他同時也指出 Google 的結構性劣勢——它有科技業史上最偉大的商業模式（搜尋廣告），這讓它很難真正擁抱會顛覆這個模式的創新。把 AI 硬塞進網頁搜尋的框架裡，Altman 認為效果不會好；真正能贏的，是那些從頭以 AI 為核心重新設計整個體驗的產品。

---

## 策略二：產品與個人化是真正的護城河

如果說模型是基礎建設，產品就是蓋在上面的房子。而 Altman 認為，真正能讓使用者留下來的，往往不是模型本身有多強，而是產品帶給他們的整體體驗。

這裡面最關鍵的一個詞是「個人化」。Altman 觀察到，ChatGPT 的記憶功能雖然還很原始（他用了「GPT-2 時代的記憶」來形容），但已經展現出驚人的黏著度。使用者喜歡這個模型慢慢認識他們，記住他們的偏好，理解他們的脈絡。這種體驗一旦建立起來，要換到另一個從零開始的服務，心理門檻就會變得很高。

他舉了一個有趣的比喻：研究顯示，多數人一輩子只會選一次牙膏品牌，然後就一直買下去。AI 助理可能也有類似的效應——使用者會經歷一個「決定性的體驗」，然後就定下來了。Altman 說，很多人對 ChatGPT 產生強烈黏著的契機，是一次健康相關的查詢。他們把血液檢驗報告或症狀輸入 ChatGPT，得到了有用的分析，發現了自己沒有意識到的問題，去看醫生後真的得到了診斷和治療。這種「它可能救了我一命」的體驗，會讓使用者對這個服務產生完全不同層次的信任和依賴。

除了記憶功能，OpenAI 還在打造其他的產品護城河。最近推出的瀏覽器功能是一個例子。AI 裝置計畫則是更長遠的佈局——Altman 認為，現有的手機和電腦形態並不是為 AI 時代設計的，未來的運算裝置應該更主動、更理解使用者的完整生活脈絡，而不是被動地等待指令。這些都是試圖在產品層面建立競爭對手難以複製的優勢。

在企業市場，個人化則以另一種形式呈現。企業會把自己的資料連接到 AI 平台上，讓 AI 理解這間公司的運作方式、專業術語、內部流程。這種深度整合一旦建立，要遷移到另一個平台的成本就會非常高。Altman 透露 OpenAI 已經有超過一百萬的企業用戶，而且今年 API 業務的成長速度甚至超過了 ChatGPT 消費者業務。這個數字顯示企業對 OpenAI 的依賴正在快速加深。

---

## 策略三：1.4 兆美元的基礎設施賭注

OpenAI 承諾在未來投入 1.4 兆美元建設基礎設施。這個數字大到讓很多人懷疑：你們真的知道這些運算能力要拿來做什麼嗎？

Altman 的回答很直接：知道，而且現在就已經供不應求了。他說 OpenAI 目前處於嚴重的「運算受限」狀態，如果明天運算能力能翻倍，營收也會跟著翻倍。這不是猜測，是根據他們實際看到的需求推算的。每一次把 AI 服務的成本降低，使用量就會跟著暴增。這個模式到目前為止從未失效過。

但 1.4 兆美元還是很多錢。Altman 解釋，這筆錢會在很長一段時間內陸續投入，不是一次性支出。他甚至說「希望可以花得更快」，但建造資料中心、部署能源、採購晶片、打造系統和網路，每一個環節都需要大量時間。從一年前到現在，OpenAI 的運算能力大約成長了三倍。他預期明年會再翻三倍，後年可能也是。營收的成長速度比運算能力還快一些，但兩者大致呈正相關。

更有趣的是 Altman 對這些運算能力用途的想像。他最興奮的應用是「科學發現」。在他的世界觀裡，科學發現是讓人類整體生活變得更好的「最高位元」。如果 AI 和大量運算可以加速科學發現的速度——找到新的治療方法、理解新的物理現象、開發新的材料——這將是改變人類命運等級的影響。他提到 GPT-5.2 發布才五天，Twitter 上就出現了數學家們串聯討論的現象：這是第一個讓他們覺得真的有用的 AI 模型，它開始能夠協助做一些小的證明、發現一些小的新東西。這只是開始，但在 Altman 看來，這條「曲線剛剛離開 X 軸」就已經是重大信號了。

另一個例子是 Sora 的 Android 應用程式——這個 app 是用 Codex 開發的，不到一個月就完成了。OpenAI 的員工可以不受限制地使用 Codex，他們吃了大量的 token，但換來的是開發速度的巨大提升。這種「用 AI 開發 AI 產品」的循環，會讓 OpenAI 在產品迭代速度上也享有優勢。

---

## 當 AGI 悄悄過去，下一個目標是什麼

訪談的最後，Alex Kantrowitz 問了一個尖銳的問題：Altman 曾說 GPT-5 在幾乎所有方面都比人類聰明。這難道不就是 AGI（通用人工智慧）嗎？如果不是，這個詞是不是已經沒意義了？

Altman 的回答值得細想。他說，這些模型在「原始運算能力」上確實非常強大——IQ 測試跑出來是 147 或 151 或其他高得嚇人的數字。它們在很多專業領域的表現已經讓專家們刮目相看。但它們還缺少一個關鍵能力：今天不會的事情，明天自己去學會。一個幼兒可以做到這一點——今天摔倒，明天走得更穩；今天不懂一個概念，聽過解釋之後就記住了。目前的 AI 模型還做不到這種持續學習。

但接下來，Altman 說了一句很值得玩味的話：「我們對 AGI 定義得太模糊了。」有些人認為現在的模型已經是 AGI，有些人認為還差得遠。這種分歧意味著這個詞本身可能不太有用。他的建議是：我們承認 AGI 這個階段可能已經「咻地過去了」，雖然沒有改變世界那麼多（長期來看會），但那個模糊的過渡期可能就這樣發生了。

如果 AGI 不再是目標，什麼才是？Altman 提出了一個「超級智慧」的候選定義：當一個系統可以比任何人類（即使那個人類有 AI 輔助）更好地擔任美國總統、大公司的 CEO、或主持大型科學實驗室時，那就是超級智慧。這個定義的巧妙之處在於，它不是問「AI 是否比人聰明」，而是問「AI 是否能執行人類最複雜的判斷性工作」。Altman 說這還很遙遠，但他想趁這次機會把定義說清楚，避免重蹈 AGI 的覆轍。

他用了一個西洋棋的例子來解釋可能的演進路徑。深藍打敗人類的時候，曾經有一段時期，人類加上 AI 一起下棋可以贏過純 AI。但後來，人類的參與反而開始拖累 AI 的表現——最強的西洋棋已經是純 AI 獨自運作，人類只會妨礙它。AI 執行高層領導工作，可能也會經歷類似的過程：先是工具，然後是夥伴，最後可能是獨立的決策者。而人類的角色，會轉變成像董事會一樣的「治理層」——設定目標、評估表現、必要時換人。

這是一個很大的想像，但 Altman 用一種出奇平靜的語氣在談論它。他說自己每天都在想如何讓 AI 接管 OpenAI 的各種功能，甚至包括 CEO 這個位置。他不覺得這有什麼好抗拒的——他不想成為那個堅持「手工製作比較好」的人。

---

## 結語

Sam Altman 在這次訪談中展現的，不只是一套商業策略，而是一種對 AI 發展的整體世界觀。在他的敘事裡，OpenAI 不只是在賣軟體，而是在鋪設人類智能延伸的基礎設施。前沿模型的競爭、產品體驗的黏著度、運算能力的規模，這三件事情是互相增強的：最好的模型需要最多的運算，最好的產品需要最好的模型，而最黏的使用者會願意付費支撐這整個循環。

這個願景是否會實現？沒有人能確定。但至少，Altman 正在按這個劇本執行。而整個 AI 產業，不管願不願意，都被拉進了這個敘事裡。
