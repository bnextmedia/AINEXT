---
title: "微軟 AI 執行長談遞迴自我改進、社交智慧與 Maia 晶片"
date: 2026-02-06T11:00:00+08:00
description: "蘇萊曼在 Exponential View 中談到 AI 的三大技術趨勢：遞迴自我改進帶來的監管挑戰、社交智慧作為 AI 的下一個重大能力躍進，以及微軟自研 Maia 晶片對推論成本的影響。"
tags: ["Mustafa Suleyman", "Microsoft AI", "Maia", "Social Intelligence", "Podcast"]
categories: ["AI 技術前沿"]
image: "/images/posts/20260206-suleyman-ai-psychosis-risk.webp"
source_url: "https://www.youtube.com/watch?v=xvPQVrrlX6o"
source_name: "Azeem Azhar's Exponential View"
related_companies: ["microsoft"]
related_people: []
draft: false
---

> 本文整理自《Azeem Azhar's Exponential View》2026 年 2 月播出的單集。本文為系列文第三篇。
>
> 系列文：[AI 正在入侵你的同理心：微軟 AI 執行長警告「AI 心理疾患」風險](/posts/20260206-suleyman-ai-psychosis-risk/) ｜ [「人類不是 AI 的開機程式」：蘇萊曼的人本主義超級智慧路線](/posts/20260206-suleyman-humanist-superintelligence/) ｜ 本篇

{{< youtube xvPQVrrlX6o >}}

{{< spotify "episode/2kLLsn0cgj2yOUOml22VYr" >}}

{{< apple-podcast "tw/podcast/mustafa-suleyman-ai-is-hacking-our-empathy-circuits/id1172218725?i=1000748407424" >}}

---

微軟 AI 執行長穆斯塔法．蘇萊曼（Mustafa Suleyman）在 Exponential View 節目中說了一句讓人停下來想的話：「用 AI 來生成程式碼、評估自己的提示詞和訓練資料、協助決定接下來該訓練什麼，這些事情帶有顯著的風險，需要更多的監管關注。」講這句話的人不是外部的 AI 安全研究者，而是微軟超級智慧團隊的負責人，而他描述的正是自己團隊每天在做的事。

這種坦率在科技產業高層中不常見。多數執行長在公開場合強調技術的好處，把風險的討論留給學術圈。蘇萊曼選擇同時做兩件事：推進最前沿的 AI 研究，同時公開指出這些研究的危險面。在這次對話中，他談了三個核心的技術議題：遞迴自我改進為什麼需要監管、AI 的下一個重大能力是什麼、以及微軟自研晶片對整個產業成本結構的影響。

## 遞迴自我改進：用 AI 來改進 AI

蘇萊曼所說的「遞迴自我改進」，指的是用 AI 模型來協助 AI 的開發過程。具體來說，這包含幾個層面：讓模型生成訓練用的程式碼、讓模型評估和篩選自己的後訓練資料、讓模型參與決策下一輪訓練該聚焦在什麼方向。這不是科幻小說裡那種「AI 自己決定變得更聰明」的場景，但它確實意味著人類在訓練迴路中的角色正在從主導者變成監督者。

蘇萊曼認為這是目前所有 AI 實驗室都在做的事，包括他自己的團隊。問題不在於這種做法本身好或壞，而在於它的風險隨著模型能力的提升而非線性增長。當模型的程式碼生成能力還不如中等水準的工程師時，讓它參與訓練流程的風險有限。但當模型的能力持續提升，它在訓練迴路中的影響力也會持續放大，最終可能到達一個人類無法有效審查每一個決策的臨界點。

他在前一本書《浪潮將至》中就把自主性（autonomy）、自我改進（self-improvement）和目標設定（goal-setting）標記為三個需要特別關注的風險區域。在這次對話中，他進一步闡述了這個框架的實際含義。這三個維度不是非黑即白的開關，而是連續的光譜。少量的自主性是有用的，讓 AI 能設定子目標和平行處理任務是提高生產力的關鍵。但每往前推進一步，風險就往上跳一級。問題是，商業競爭的壓力會持續把這些旋鈕往「更多自主」的方向轉。

蘇萊曼提出的對策是「使用者責任制」：使用 AI 系統的人類必須為系統的行為承擔法律責任。這聽起來像是常識，但在自動化越來越深入的情境裡，責任的歸屬會變得非常模糊。如果你在週五晚上設定了一個 AI 工作流，週一早上回來發現它做了一連串你沒預料到的事，責任算誰的？蘇萊曼的回答很明確：算你的。你不能把「我設定好就沒管了」當作免責的藉口。

這個立場帶有預防原則的味道。蘇萊曼在對話中坦言，窄域 AI（比如專注在醫療的超級智慧）在安全性上確實比通用 AI 更可控。醫學 AI 只要做好一件事：把已知的最佳實踐及時提供給護理師和醫師，就能在近期內拯救大量生命。這種專注在特定領域的 AI 不需要有自主目標設定的能力，也不需要自我改進，風險自然低得多。

但他也承認一個棘手的現實：通用性才是目前驅動 AI 進步的引擎。所有實驗室都在用全網路的文本聯合訓練模型，讓它成為最好的通才，然後把這些知識蒸餾到更小更高效的模型裡。社群裡普遍懷疑，放棄通用訓練路線是否真的可行。安全和能力之間的張力，目前沒有簡單的解方。

## 社交智慧：AI 的下一個能力躍進

在談完風險之後，蘇萊曼轉向了他最期待的 AI 能力：社交智慧（social intelligence）。他提出了一個他自己設計的能力演進框架：IQ（智力商數）、EQ（情緒商數）、AQ（行動商數），然後是 SQ（社交商數）。

前幾年，AI 的進步主要體現在 IQ 維度，也就是解題能力、推理能力、知識廣度。接著是 EQ，模型變得更能理解使用者的情緒狀態，對話風格更自然、更有同理心。2025 年是 AQ 的年份，AI Agent 的爆發讓模型從「只會講」進化到「會動手做」，能瀏覽網頁、操作軟體、串接 API。

蘇萊曼認為 2026 年的關鍵字是社交智慧。他的描述相當概念性，但可以試著推演他想表達的具體場景。

當一個 AI 具備社交智慧，它不只是能跟單一使用者進行有品質的對話，而是能在一個多方互動的環境裡得體地運作。想像一個 AI 在企業的 Slack 群組裡，面對一群不同部門、不同層級、不同性格的人。它需要知道什麼時候該主動提供資訊（比如有人問了一個它恰好知道答案的問題），什麼時候該保持沉默（比如兩個同事正在進行一場需要人類判斷的爭論）。它需要感知群組裡的權力動態：在執行長面前說話的方式，跟在工程團隊內部的閒聊是不同的。它需要把握時機，不是每次都搶先發言，而是在對的時間點介入。

蘇萊曼也提到了多 Agent 協作的面向。未來的 AI 系統可能不是一個全能的模型，而是一組各有專長的子代理：有的擅長資料分析，有的擅長文案撰寫，有的擅長排程管理。這些代理需要彼此協調，知道什麼任務該交給誰，怎麼分工才能避免重複或遺漏。這種 AI 之間的協作能力，本質上也是一種社交智慧。

他對這個能力的時間表很樂觀，認為會在 2026 年下半年開始出現。不過他談得確實比較抽象，沒有提到具體的技術路徑或產品形態。這可能反映了一個現實：社交智慧的衡量標準比 IQ 或 AQ 更模糊，因為「得體」和「恰當」這些判斷本身就高度依賴情境。一個在矽谷科技公司表現得體的 AI，放到日本企業文化裡可能顯得粗魯。蘇萊曼提到 AI 需要「適應不同的文化和個性風格」，但要怎麼訓練和評估這種適應能力，可能是一個比他描述的更複雜的工程問題。

## Maia 晶片：微軟的推論成本戰爭

對話中蘇萊曼也談到了微軟自研的 Maia 晶片，語氣明顯興奮。Maia 200 在 2026 年 1 月底正式發布，採用台積電 3 奈米製程，搭載 1,400 億顆電晶體和 216 GB 的 HBM3e 記憶體。

蘇萊曼特別強調的是設計哲學的轉向。微軟幾年前就意識到，AI 產業的瓶頸正在從訓練（training）轉移到推論（serving/inference）。訓練是一次性的大規模運算，把模型從零訓練到可用的狀態。推論則是每天、每秒鐘都在發生的事：每個使用者的每一次查詢、每一次對話、每一次 Agent 行動，都需要推論運算。隨著 AI 從實驗室走進數十億人的日常，推論的運算量已經遠遠超過訓練。

Maia 200 就是為推論工作負載量身設計的。蘇萊曼在節目中引用了幾個數字：推論效能比微軟資料中心裡現有的任何晶片高出 30%；FP4 效能是 Amazon 第三代 Trainium 晶片的 3 倍；FP4 效能也略高於 Google 第七代 TPU。這些數字的意義不在於微軟贏了多少，而在於整個產業的推論成本正在以非常快的速度下降。蘇萊曼提到，過去兩年推論的每 token 成本已經降了 100 倍，這是晶片改進、資料中心優化和演算法進步三者複合疊加的結果。

對臺灣的半導體產業來說，這個趨勢有兩層含義。第一層是直接的：Maia 200 由台積電代工，採用最先進的 3 奈米製程，這是台積電先進製程產能需求的又一個來源。微軟、Google、Amazon、Meta 都在自研 AI 晶片，而這些晶片幾乎全部交給台積電製造。第二層則更微妙：當雲端大廠紛紛自研推論晶片，輝達在推論市場的主導地位會面臨更大的壓力。輝達的 GPU 在訓練市場仍然無可替代，但在推論市場，針對特定工作負載優化的自研晶片正在蠶食它的份額。

蘇萊曼把這一切放在一個更大的框架裡：推論成本的持續下降，會加速 AI 的普及，進而加速他在其他段落中討論的所有社會影響。當 AI 便宜到每個人都用得起，使用場景會以沒人能預料的方式爆發。他用了「指數型技術」這個詞，認為 AI 可能是人類歷史上最具指數型特徵的技術，因為它同時在晶片、演算法、資料、應用場景等多個維度上呈現複合成長。

## 醫學超級智慧：最安全的超級智慧

在三個技術議題之外，蘇萊曼還花了一些時間談醫學 AI，而且語氣跟談其他議題時明顯不同。他認為醫學超級智慧「近在眼前」，而且「從整體 AI 安全的角度來看，極有可能是非常安全的」。

這個判斷的基礎是：醫學 AI 可以是窄域的。它不需要設定自己的目標，不需要自我改進，也不需要高度自主。它只需要做好一件事情：在對的時間，把對的資訊提供給對的人。具體來說，就是幫助護理師和醫師遵循已知的最佳實踐。這聽起來不夠炫，但蘇萊曼認為光是這一點，在接下來幾年就能拯救數以百萬計的生命年。

蘇萊曼強調的不只是那種「發明全新療法」的突破性應用（雖然他認為那也在發生），而是更樸素的東西：讓現有的醫學知識被更及時、更廣泛地應用。全世界有無數的病人因為醫師太忙、資訊不夠即時、或者最新的治療指南還沒傳達到基層，而沒有得到最好的照護。AI 可以在這個環節發揮巨大的作用，而且風險比通用 AI 低得多。

這段討論其實暗含了一個有趣的對比。蘇萊曼一方面在推進通用超級智慧的研究，一方面承認窄域 AI 更安全、更有可能在短期內產生巨大的社會效益。這不是矛盾，而是一種優先序的陳述：他認為兩條路線應該同時推進，但在監管注意力和公眾理解上，通用 AI 的風險需要更多的關注，而窄域 AI 的好處需要更快的部署。

## 指數型循環

蘇萊曼在對話最後描繪了一幅全景圖。AI 的能力提升帶動推論成本下降，成本下降帶動使用者增長，使用者增長帶動更多意料之外的應用場景出現，這些場景又驅動了下一輪的能力投資和效率優化。這個循環在每一個環節都在加速，而且多個環節同時在轉。

在這個循環裡，遞迴自我改進是能力增長的加速器，社交智慧是應用場景爆發的催化劑，而 Maia 晶片代表的推論成本下降是讓整個循環轉得更快的潤滑劑。這三個面向不是孤立的技術議題，而是同一個指數型循環的不同切面。

蘇萊曼對這個循環的態度是矛盾的，或者更精確地說，是清醒的。他看到了加速的必然性，也看到了加速帶來的危險。他的選擇不是踩煞車，而是在加速的同時設定邊界。這能不能成功，沒有人知道。但至少他是少數願意同時承認兩面的人之一，不粉飾風險，也不否認技術的力量。

在完全不受約束的情況下，他估計 AI 在未來一二十年可能在所有面向上超越人類能力，包括自我改進的能力，這意味著它的成長曲線可能會達到人類完全無法跟上的速度。蘇萊曼認為這是人類作為一個物種需要正視的現實，不是恐懼，而是正視。正視才能採取行動，退縮只會讓我們在關鍵時刻更沒有準備。
