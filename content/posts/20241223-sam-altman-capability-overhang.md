---
title: "sam altman capability overhang"
date: 2025-12-23T00:57:18+08:00
description: "> 本文整理自《Big Technology Podcast》2024 年 12 月 18 日播出的單集，主持人 Alex Kantrowitz 專訪 OpenAI CEO Sam Altman。 > 收聽連結：[Apple Podcast](https://podcasts.apple.com/"
tags: ["AI"]
categories: ["AI"]
draft: false
---


> 本文整理自《Big Technology Podcast》2024 年 12 月 18 日播出的單集，主持人 Alex Kantrowitz 專訪 OpenAI CEO Sam Altman。
> 收聽連結：[Apple Podcast](https://podcasts.apple.com/in/podcast/sam-altman-how-openai-wins-ai-buildout-logic-ipo-in-2026/id1522960417?i=1000741901091)

---

## 七成知識工作，AI 做得比人好

OpenAI 有一個內部評估指標叫做「GDPVal」。這不是一個對外公開的標準測試，而是 OpenAI 用來衡量模型在「對 GDP 有貢獻的工作任務」上表現的內部評量。這個評估涵蓋大約四十幾種不同的商業任務類型：做簡報、寫法律分析、開發小型網頁應用、撰寫報告、處理數據——基本上是一間公司運作會需要的各種知識工作。

評估的方式是這樣的：讓專家來判斷，對於這些任務，他們更喜歡 AI 的產出，還是其他人類專家的產出。這是一個「盲測」的設計，評估者不知道哪個是 AI 做的、哪個是人做的。

根據 OpenAI 的數據，GPT-5 Thinking（今年夏天發布的版本）在 38.8% 的任務上「表現相當或更好」。而最新的 GPT-5.2，這個數字跳到了 70.9%。如果用更貴的 GPT-5.2 Pro，數字是 74.1%。更重要的是，GPT-5.2 Pro 在「專家級」任務上的表現也跨過了門檻——大約 60% 的專家級任務，它的表現可以達到與人類專家相當的水準。

這些數字應該很驚人。三年前 ChatGPT 剛推出時，沒有人敢預測三年後會達到這個水準。如果你有一個「同事」，把一小時的任務交給他，七成的機率你會對結果滿意或更滿意——那是一個相當可靠的同事。而這個「同事」的時薪遠低於人類。

但問題來了：如果 AI 這麼強，為什麼這麼多企業說他們「沒有看到投資報酬率」？

---

## 兩個互相矛盾的說法

Alex Kantrowitz 在訪談中提出了一個尖銳的觀察。一方面，OpenAI 的 GDPVal 數據顯示 AI 在七成知識工作上表現優於人類。另一方面，MIT 的調查和很多企業訪談都指出，許多公司在導入 AI 後，沒有得到他們期待的效益。這兩個說法怎麼同時成立？

Altman 對這個問題的第一反應是：「我不太確定怎麼理解那些調查。」他說 OpenAI 聽到的企業反饋完全相反——有公司說如果 GPT-5.2 的價格漲十倍，他們還是會付。有人說 OpenAI 嚴重低估了自己產品的價值。寫程式的人更誇張，有人說他願意付一百倍的價格。

所以到底誰說的是真的？

Altman 給了一個他自己也覺得有點奇怪的答案：兩邊可能都是真的。模型確實有這個能力，但人們還沒學會怎麼用。

---

## 能力過剩（Capability Overhang）

Altman 用了一個詞來描述這個現象：「overhang」，可以翻譯成「過剩」或「懸置」。意思是，AI 的能力已經到達某個水準，但這個能力還沒有被充分部署到實際的工作流程中。這中間的落差，就是「能力過剩」。

他原本以為這個過剩不會很大。他以為一旦 AI 展現出足夠的能力，世界會很快地學會如何運用它。但事實證明，這個假設是錯的。過剩的程度比他預期的大得多。

Altman 舉了一個自己的例子。他知道他應該在日常工作中更多地使用 AI。他知道如果他改變自己的工作流程，把更多任務交給 AI 處理，效率可以提升很多。但他還是用「非常接近以前的方式」在工作。這不是因為他不懂 AI，不是因為他不知道 AI 能做什麼——他是 OpenAI 的 CEO，他比任何人都清楚這些模型的能力。但他還是沒有改變。

如果連 Altman 自己都有這個問題，普通的企業員工會怎樣？

他描述了一個具體的情境：一個工作者，習慣把「做一份簡報」這個任務交給初級分析師。這個習慣已經內化成自然反應了——有這種任務，就指派給人。現在理論上他可以把這個任務交給 AI，而且 GDPVal 的數據說七成機率結果會讓他滿意。但要改變這個習慣，需要的不只是「知道 AI 可以做」。他需要改變自己發起任務的方式、改變自己檢查結果的方式、重新建立對於「什麼任務可以交出去、什麼任務自己做」的判斷標準。這些改變需要時間，需要刻意練習，需要克服「以前這樣做都沒問題」的慣性。

這就是為什麼「能力」和「採用」之間會有這麼大的落差。

---

## 這個落差有什麼影響

Altman 說，這個能力過剩的現象讓他重新思考了一些以前對 AI 發展的假設。

他提到一個他過去常想的思考框架：一個 2x2 的矩陣，一軸是「時間線長短」（AI 進展多快），另一軸是「起飛速度」（從有用變到超級強大要多久）。不同的象限代表不同的世界，需要不同的應對策略。

但他現在發現這個框架漏掉了一個重要的 Z 軸：「過剩程度」。就算 AI 發展很快、能力提升很陡峭，如果世界沒有跟上採用的速度，那個「能力」就會懸在那裡，等待被使用。

這有幾個含義。首先，對於「AI 會不會造成大規模失業」這個問題，短期的答案可能不是「會」或「不會」，而是「AI 的能力已經可以取代很多工作，但實際取代的速度會比純粹的技術能力慢很多」。工作流程有慣性，組織架構有慣性，人的習慣有慣性。這些慣性會減緩 AI 取代人類勞動的速度。

其次，這對 OpenAI 的商業模式是好消息也是壞消息。壞消息是，模型的能力提升沒有直接轉化成等比例的收入增長——因為使用者還沒有把全部的潛在價值用出來。好消息是，這意味著即使模型進步暫時放緩，只要使用者的採用程度持續提升，OpenAI 的業務還是可以增長。「能力過剩」是一個可以慢慢兌現的資產。

第三，這改變了「AI 什麼時候會改變世界」這個問題的答案。改變世界需要的不只是能力，還需要採用。而採用需要時間、需要教育、需要工具、需要工作流程的重新設計。就算今天 AI 的能力已經「夠」顛覆很多產業，實際的顛覆可能會是一個拉長的過程，而不是一個突然的轉折點。

---

## 那麼，問題在哪裡？

如果 AI 這麼強，企業也願意付錢，但採用還是很慢，問題到底出在哪裡？

Altman 在訪談中沒有給出一個系統性的答案，但他提到了幾個線索。

第一個是「任務的粒度」問題。GDPVal 測試的是「明確定義、時間有限」的任務——大約一小時可以完成的工作單元。但真實世界的工作往往不是這樣切分的。一個大專案可能有幾十個這樣的任務單元，彼此之間有依賴關係，需要前後連貫，需要有人掌握整體脈絡。把這些任務單元「拆出來」交給 AI，本身就需要額外的工作。

第二個是「品質檢驗」問題。GDPVal 說七成機率你會滿意 AI 的產出。但這也意味著三成機率你不會滿意。誰來檢查？誰來判斷這次是好的七成還是壞的三成？這個檢查工作本身需要花時間，有時候甚至比自己做還花時間。對於某些任務來說，「偶爾錯誤」的代價很高，導致使用者寧可自己做、確保品質，也不願意冒這個風險。

第三個是「整合」問題。企業不只是需要一個「可以做事的 AI」，還需要這個 AI 整合進現有的系統裡——連接資料庫、理解內部術語、符合公司的格式規範、尊重權限設定。這些整合工作需要技術投資，需要 IT 部門的參與，需要流程的調整。很多企業還沒有做好這些準備。

Altman 說，OpenAI 正在嘗試解決這個問題。他提到企業客戶想要的是一個「全包式的 AI 平台」——不只是一個 API，而是包含客製化的模型、客製化的 ChatGPT Enterprise、可以跑各種代理程式的平台、可以處理海量 token 的能力、可以讓內部流程更有效率的一整套解決方案。OpenAI 目前還沒有做到這個程度，但這是他們正在努力的方向。

---

## 改變需要時間

訪談快結束時，Alex 問了一個關於工作的問題。有人分享自己的經歷：先是變成「管理 AI 機器人」的人，然後自己也被裁掉了。這會不會越來越常見？

Altman 承認，短期內他對工作轉型「有一些擔心」。某些轉型過程可能會很rough（他用的詞）。但他說自己「不是工作末日論者」。他的論點是：人類太深刻地渴望被其他人需要、渴望創造、渴望表達自己、渴望追求相對地位。這些是演化刻在我們基因裡的東西，不會因為 AI 出現就消失。

他舉了一個例子：他每天都在想，OpenAI 內部的各種功能要怎麼讓 AI 來做，甚至包括 CEO 這個職位。如果有一天 AI 可以當比他更好的 CEO，他不會抵抗。但他相信，到那個時候，人類會找到新的事情做——新的創造、新的表達、新的追求。也許 2050 年的人類每天在做什麼，看起來會跟今天非常不同。但那不表示人類會失去意義。

這個回答有點樂觀，但也有點閃避。他沒有直接回應那個被裁掉的人的經歷。也許他沒辦法回應——那是一個個案，而他在談的是長期趨勢。兩者不矛盾，但對於正在經歷轉型痛苦的人來說，「長期來看會沒事」不是什麼安慰。

---

## 結語：過剩是暫時的

Sam Altman 在訪談中描述的「能力過剩」，是一個值得思考的框架。它解釋了為什麼 AI 的技術進展這麼快，但世界的改變看起來沒有那麼戲劇性。這不是因為 AI 沒有用，而是因為人類採用新技術的速度有其上限。

但過剩是暫時的。隨著更多人學會如何使用 AI、更多工具被開發出來簡化整合、更多工作流程被重新設計來納入 AI，那個懸置的能力會逐漸被「提取」出來。這個過程可能需要幾年。

對於企業來說，這意味著現在是學習的時候，不是觀望的時候。那些提早搞懂「怎麼把 AI 能力轉化成實際效益」的組織，會在這個過剩被吸收的過程中取得優勢。等到大家都學會了，就不再是優勢，而是入門門檻了。

對於個人來說，這意味著自己的工作習慣也是需要更新的東西。Altman 自己都承認他「應該更多用 AI 但沒有」。這不是資訊不足的問題，是慣性的問題。打破慣性需要刻意的努力。

GPT-5.2 的能力已經在那裡了。七成的知識工作，它可以做得跟人一樣好或更好。這個能力不會消失。問題只是：你打算什麼時候開始真正使用它？
