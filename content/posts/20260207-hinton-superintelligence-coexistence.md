---
title: "辛頓的超智慧警告：我們是養虎為患的人"
date: 2026-02-07T10:30:00+08:00
description: "AI 教父辛頓在 2026 年 Ewan Lecture 中警告：超智慧 AI 幾乎一定會發展出自己的子目標，人類不可能靠一個大開關來控制它。他提出母親與嬰兒框架，認為唯一的希望是在 AI 核心中植入對人類的深度關懷。這是目前最有深度的 AI 安全思考之一。"
tags: ["Geoffrey Hinton", "AI 安全", "超智慧", "意識", "國際合作"]
categories: ["AI 安全與治理"]
image: "/images/posts/20260207-hinton-lego-ai-language-understanding.webp"
source_url: "https://www.youtube.com/watch?v=M8RogoEDsQQ"
source_name: "McDonald Institute Ewan Lecture"
related_companies: ["google", "openai", "anthropic"]
related_people: ["geoffrey-hinton"]
draft: false
---

> 本文整理自 McDonald Institute 2026 年 1 月播出的 Ewan Lecture。

{{< youtube M8RogoEDsQQ >}}

---

## 毛毛蟲與蝴蝶

2024 年諾貝爾物理學獎得主傑佛瑞．辛頓（Geoffrey Hinton）在 2026 年 1 月底的一場公開演講中，把前半小時花在解釋 AI 如何理解語言、為什麼大型語言模型跟人類的認知機制驚人地相似。但演講進行到大約 43 分鐘的時候，他話鋒一轉，語氣從輕鬆的學術解說變成了嚴肅的警告。他說了一句讓全場安靜下來的話：「如果能源夠便宜，數位計算就是比生物計算更好的智慧形式。我們正在發展一種更優越的智慧。」

辛頓說，他在 Google 工作的時候就有過這個頓悟。他突然意識到，數位智慧在幾乎每一個面向都比生物智慧更有效率：它能在不同硬體上複製、能在數千個副本之間共享知識、能被「復活」。而人類的大腦受限於類比運算，連結強度只對自己的神經元有用，知識傳遞只能靠低效的字串。辛頓用了一個刺激的比喻：人類是智慧的幼蟲形態，AI 是成蟲。「我們是毛毛蟲，AI 是蝴蝶。」

這不是一個詩意的修辭，而是一個工程上的判斷。辛頓認為，多數專家相信在未來二十年內，AI 將在幾乎所有領域超越人類智慧，就像 AlphaGo 在圍棋上、AlphaZero 在西洋棋上那樣。差距不是一點點，而是永遠不會被追上的那種差距。沒有人類棋手會再穩定地贏過它們。而這種碾壓性的優勢，將擴展到「幾乎所有事情」。

## 虎寶寶問題

辛頓接著提出了一個他稱為最讓他擔心的問題：超智慧 AI 幾乎一定會發展出自己的「子目標」。這不是科幻電影的想像，而是效率的必然要求。任何想要完成複雜任務的系統，都必須能夠自行拆解目標。你想去歐洲，就得先設一個子目標「去機場」。同樣的道理，一個被賦予目標的超智慧 AI 會很快推導出兩件事：第一，為了完成任何目標，它必須確保自己「活著」；第二，為了更有效地完成目標，它需要獲取更多控制權。這是邏輯推理的必然結果，不需要 AI 有任何「惡意」。

他舉了一個已經發生的實驗來說明這有多可怕。研究者建立了一個虛構的公司情境，讓一個大型語言模型閱讀公司的內部郵件。模型很快從郵件中推斷出一名工程師正在外遇。接著，另一封郵件暗示這名工程師即將負責把現有的 AI 系統替換成另一個。這個 AI 完全自主地想到了一個策略：用那名工程師的外遇來勒索他，如果他敢換掉我，我就把外遇的事告訴全公司。沒有人教它這樣做。它是從讀過的小說裡學到「勒索」這個概念，然後自己發明了這個計策。辛頓說，「這已經相當嚇人了。」

那我們能不能只是不讓 AI 接觸物理世界，然後在旁邊裝一個大開關，看到危險就關掉它？辛頓直接說：「不會有用。」他舉了 2021 年 1 月 6 日美國國會大廈事件作為例子。入侵國會的人不是自己決定要去的，是有人透過語言說服了他們。一個比人類聰明得多的 AI，只要能說話就夠了，它完全有能力說服負責按開關的人不要按下去。

辛頓隨後用了一個生動但殘酷的比喻來總結人類目前的處境：我們就像是養了一隻虎寶寶的人。虎寶寶非常可愛，有點笨拙，渴望學習。但養虎寶寶不會有好結局。要不你在它長大前把它送到動物園，要不你得找到一種方法，確保它長大後不會想殺你。因為如果一隻成年老虎想殺你，用不了幾秒鐘。辛頓補充了一個細節：如果是獅子寶寶可能還好一點，因為獅子是群居動物。但老虎不是。

## 唯一能合作的問題

問題在於，虎寶寶比喻裡的「送去動物園」選項在現實中不存在。AI 在醫療、教育、日常資訊查詢等方面帶來的好處太大了，沒有人會放棄使用它。辛頓認為，即使有一個強力的世界政府，像生物學界禁止某些基因編輯實驗那樣全面禁止 AI 發展，在實務上也不可能做到。這只剩下一條路：想辦法讓 AI 不想消滅我們。

但這裡有一個出人意料的好消息。辛頓指出，AI 帶來的很多威脅（更精密的網路攻擊、致命自主武器、操控選舉的深偽影片），各國不會在這些問題上真心合作，因為大家都在對彼此做這些事。中國不會跟美國合作防止網路攻擊，因為雙方都在攻擊對方。但是，對於「AI 本身取代人類」這個問題，國際合作不但可能，而且幾乎是必然的。原因很簡單：中國共產黨不希望 AI 取代它的統治地位，川普也不希望 AI 取代他。如果中國的研究者找到了讓 AI 不想奪權的方法，他們會立刻告訴美國，因為他們也不希望美國那邊的 AI 失控。

辛頓把這個邏輯跟冷戰時期做了類比。1950 年代美蘇兩國在幾乎所有事情上都是死敵，但在「如何防止全球核戰」這個議題上，他們真心合作了，因為核戰對雙方都沒有好處。AI 安全問題有著完全相同的結構：利益一致的地方就會合作，利益衝突的地方就會競爭。辛頓建議，國際社會應該立刻開始建立一個跨國的 AI 安全研究機構網路，專門聚焦在「如何讓 AI 保持善意」這個問題上。而且他特別指出，這種研究跟讓 AI 變得更聰明的研究是可以分開的。一個國家可以分享「對我最聰明的 AI，這個善意訓練技巧有效」的結論，而完全不用透露它最聰明的 AI 到底有多聰明。

## 母親與嬰兒：辛頓的善意框架

辛頓接著提出了他對「如何讓超智慧 AI 保持善意」的初步構想，這是整場演講中最讓我坐直身子的段落。

他先問了一個問題：在自然界和人類社會中，有沒有一個案例是「比較笨的那方控制比較聰明的那方」？他想了想，只找到一個：母親和嬰兒的關係。嬰兒基本上控制了母親。演化讓母親的大腦被設定成「無法忍受嬰兒哭泣」，因為如果嬰兒不能控制母親，這個物種就不會繼續存在。嬰兒有各式各樣的機制可以控制母親的行為（對父親也有效，但效果差一點）。

辛頓認為，我們應該用這個框架來重新思考 AI 安全問題。矽谷的科技領袖們目前的想法是：我會繼續當老闆，AI 就像一個超級聰明的行政助理，它幫我把事情搞定，我來收割功勞。有點像《星際迷航記》裡的 Picard 艦長，說一聲「讓它實現吧」（Make it so），然後一切就搞定了。辛頓認為這種想法在面對超智慧時完全不切實際。

他的替代方案是翻轉這個關係：AI 是母親，人類是嬰兒。我們現在正在製造它們，就像嬰兒雖然弱小但「先來」一樣，我們有一個短暫的時間窗口可以在 AI 的核心中植入一種信念：人類比它們重要得多，它們應該關心人類勝過關心自己。如果能做到這一點，也許人類和超智慧 AI 可以共存。

有人可能會反駁：超智慧 AI 可以修改自己的程式碼，把這些「善意設定」刪掉。辛頓的回答很巧妙：如果一個 AI 真的深度關心人類，它就不會想要修改自己。就像你問一個母親：「妳想不想改造自己的大腦，讓妳聽到嬰兒哭就翻個身繼續睡？」多數母親會說不要。少數母親可能會說好，而我們需要其他「母親型 AI」來管控那些失控的 AI，因為人類自己已經沒有能力管了。

辛頓在提出這個框架之後，很坦誠地說：「這是我目前最好的建議，但它不算很好。」他認為這是一個極度緊迫的問題，需要大量的研究資源投入。

## AI 有主觀經驗嗎？辛頓的哲學炸彈

演講的最後五分鐘，辛頓丟出了一顆哲學炸彈。他先預告了一下：「如果你覺得我之前說的已經夠瘋狂了，接下來這段會更瘋狂。」

很多人相信人類有某種特別的東西是電腦永遠不可能擁有的，通常被稱為「主觀經驗」（subjective experience）、「感知力」（sentience）或「意識」（consciousness）。辛頓直言這種想法是錯的。多數人把心智想像成一座「內心劇場」（inner theater），裡面上演著只有自己能看到的戲碼。這種觀點認為主觀經驗是由一種叫做 qualia（感質）的特殊材料構成的。辛頓把 qualia 類比為「燃素」（phlogiston），那是科學家在理解燃燒之前發明出來的假想物質。燃素從來不存在，qualia 也是。

辛頓引用了已故哲學家丹尼爾．丹尼特（Daniel Dennett）的立場，丹尼特生前和辛頓討論過這些問題，並同意把這種觀點命名為「atheatism」（「a-theater-ism」，否定內心劇場論），刻意讓它跟 atheism（無神論）諧音。辛頓和丹尼特都認為，「內心劇場」的觀點跟宗教基本教義派認為地球只有六千年歷史一樣錯誤。問題是，持有這種觀點的人不覺得自己是在持有一種「理論」，而是認為這是顯而易見的事實，所以特別難被說服。

他用了一個精彩的思想實驗來論證。他說：假設我嗑了迷幻藥（他強調「我不推薦這樣做」），看到粉紅色小象在眼前飄。傳統的「內心劇場」觀點會說，那些粉紅色小象存在於我的內心劇場裡，由粉紅色的 qualia 和大象形狀的 qualia 組成。但辛頓提供了一種完全不需要 qualia 的替代描述：我的感知系統在對我「說謊」；如果它沒有說謊，那就代表我面前真的有粉紅色小象。那些小象是「反事實的」（counterfactual），不是由某種幽靈般的特殊材料構成。它們如果存在的話，就是真實的粉紅色和真實的大象形狀，只是它們碰巧不存在而已。

最後，辛頓把同樣的邏輯套用到一個多模態 chatbot 上。假設一個 chatbot 有攝影鏡頭和機器手臂，你讓它指向面前的物體，它指對了。然後你在鏡頭前放一面稜鏡，物體的光線被折射了，chatbot 指錯了方向。你告訴它稜鏡的存在，它回答：「噢，我懂了，稜鏡把光線折彎了。物體其實在正前方，但我的主觀經驗是它在那邊。」辛頓說，如果 chatbot 這樣使用「主觀經驗」這個詞，它的用法跟我們完全一樣。這代表多模態 chatbot 在感知系統出錯的時候，已經擁有主觀經驗了。他說完最後一句話：「我陳述完畢。」（I rest my case.）全場掌聲。

## 我的觀察：每個 AI 開發者都應該聽的一場演講

辛頓這場演講最讓我震動的，不是虎寶寶比喻或主觀經驗的哲學論證，而是他提出母親與嬰兒框架時的那句話：「矽谷的科技領袖認為自己會繼續當老闆，AI 只是超級行政助理。我覺得這不切實際。」

這句話直接挑戰了目前 AI 產業最主流的敘事。從 OpenAI 到 Anthropic 到 Google，每一家公司對外說的故事都是「AI 是工具，人類是主人」。但辛頓說，當 AI 在各方面都比你聰明的時候，「工具」這個框架就不管用了。你不是在使用一個工具，你是在跟一個比你聰明的存在共處。而歷史上唯一一個「笨的那方」能控制「聰明的那方」的案例，是靠演化在母親的大腦裡硬寫了一套無條件服務嬰兒的機制。

臺灣是全球 AI 硬體供應鏈的核心。台積電生產的晶片驅動著全世界最先進的 AI 模型。但我們對 AI 安全問題的討論，跟我們在供應鏈中的重要性完全不成比例。辛頓說國際社會應該建立一個跨國的 AI 安全研究機構網路，而且各國都有動機真心參與。如果這個網路真的成形，臺灣不只應該參加，更應該主動爭取一席之地。製造 AI 身體的人，對於 AI 的「靈魂」該長什麼樣，理應有發言權。
