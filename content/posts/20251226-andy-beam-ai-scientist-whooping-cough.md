---
title: "那年被誤診的男孩，現在要讓 AI 自己做實驗"
date: 2025-12-26T10:00:00+08:00
description: "Andy Beam 小學六年級時得了百日咳，小兒科醫師卻診斷為鼻竇炎。這次誤診讓他看見醫療的認知盲點，最終成為哈佛教授、醫療 AI 先驅。2024 年他離開學界，加入 Lila Sciences 擔任技術長，目標是打造能自己提出假說、自己做實驗的 AI 系統。這是他的故事，也是 AI 科學研究的下一章。"
tags: ["Andy Beam", "Lila Sciences", "醫療 AI", "Scaling Laws", "AI 科學研究", "Podcast"]
categories: ["AI 產業動態"]
source_url: "https://podcasts.apple.com/tw/podcast/can-ai-accelerate-science-dr-andy-beam-on-ais-next-frontier/id1657518313?i=1000717523879"
source_name: "NEJM AI Grand Rounds"
draft: false
---

> 本文整理自《NEJM AI Grand Rounds》2025 年 7 月播出的單集。

{{< apple-podcast "tw/podcast/can-ai-accelerate-science-dr-andy-beam-on-ais-next-frontier/id1657518313?i=1000717523879" >}}

---

那年夏天，一個剛從太空營回來的六年級男孩開始像狗一樣咳嗽。那聲音太奇怪了，他媽媽從沒聽過。幾天後的某個晚上，他咳到窒息、咳到嘔吐。隔天在小兒科診所，同樣的發作當場發生——劇烈咳嗽、支氣管痙攣、嘔吐。醫師的診斷是：鼻竇炎。

這個男孩叫 Andy Beam。那次誤診改變了他的人生軌跡。

## 誤診背後的認知盲點

Beam 的母親知道這不是鼻竇炎。但她不知道是什麼，直到某天半夜醒來，想起小時候坐在外公車上的記憶。她的母親當時發生了同樣的事——在路邊咳到嘔吐。那是百日咳。

第二天，母親打電話給小兒科醫師，問能不能是百日咳。醫師說：「有意思，我們剛接到 CDC 的電話，說附近有幾個確診案例。」檢查結果證實，Beam 確實得了百日咳。他父親的牙科診所因此關閉了幾週，CDC 人員來到他們家做全面調查。

這件事讓 Beam 看見了一件重要的事：醫師不是神。那位小兒科醫師不是不專業，而是他執業多年，從來沒見過百日咳。這個疾病在美國幾乎已經根絕，它不在醫師的「記憶庫」裡。如果你用貝氏定理來看，Beam 的症狀幾乎百分之百指向百日咳——但醫師腦中的「近因偏誤」讓他完全看不見這個選項。

這種認知偏誤是人類的共同弱點。醫師會累、會忘記、會被最近看過的病例影響判斷。Beam 當時還只是個孩子，但這個經驗在他腦中種下了一顆種子：電腦不會累，電腦可以讀完整個網路，電腦有完美的記憶。如果診斷是一種模式識別，電腦遲早會比人類做得更好。

## 從改機 Xbox 到訓練神經網路

Beam 從小就是工程宅。幼兒園的「自由學習站」制度讓他整年都待在樂高區，結果幼兒園結束時還不會寫自己的名字。高中時他在社區大學修了 QBasic 程式課，從此確定自己要走電腦科學這條路。大學時期，他靠改機 Xbox 賺零用錢——在主機板上焊兩個點，就能刷 BIOS，把 Xbox 變成通用電腦。宿舍裡堆滿等待改機的 Xbox，一台收 50 美元。

真正的轉折點是大四那年的 AI 課程。Russell 和 Norvig 那本綠色封面的教科書《人工智慧：現代方法》讓他大開眼界。課程談到西修斯之船、意識的本質，也談到 A* 搜尋和定理證明。這是他見過最有趣的學科，結合了哲學思辨和實用技術。他決定投入 AI 領域，然後開始回想：AI 能做什麼最有影響力的事？

百日咳的記憶浮現了。答案是醫療。

接下來的十幾年，Beam 沿著這條路一路走。他在北卡州大讀完統計碩士和生物資訊博士，研究貝葉斯神經網路。那是 GPU 運算剛起步的年代，沒有自動微分工具，他得手寫 CUDA 核心、手算反向傳播。2014 年他到哈佛做博士後，第一天就跟老闆 Zak Kohane 說：「我們需要更多 GPU。」Kohane 問為什麼，Beam 說：「神經網路會改變一切。」

他說對了。

## 讓電腦通過醫師執照考試

在博士後期間，Beam 開始嘗試一件當時聽起來像科幻小說的事：訓練神經網路通過美國醫師執照考試（USMLE）的 Step 1。他的太太 Kristyn 是兒科醫師，剛考完這些試，Beam 想：如果我要讓電腦學會醫學，最直接的方式就是讓它做醫師做的事。

USMLE Step 1 是個好的評估標準。它有明確的正確答案、標準化的題目、大量的人類表現數據可供比較。Beam 用 LSTM 訓練模型，讓它從網路上整理的資料學習。那些早期模型能答對大約 40% 的題目——以當時的標準來看已經是最好的成績之一。更有趣的是，模型會展示「逐字推理」的過程：當你輸入「1 歲病人，發燒四天，草莓舌」，模型對川崎症的信心值會在「草莓舌」出現的瞬間飆高。

但那些模型太小、資料太少，天花板很低。Beam 從這個經驗學到的教訓是：你應該永遠在最通用的問題上工作。他以為 USMLE 已經夠通用了，結果更通用的問題是「預測下一個 token」。當 GPT-3 和 GPT-4 問世，它們直接就能解決這些醫學問題——那只是它們的「副產品」。現在已經沒有人會對 LLM 通過醫師執照考試感到驚訝了。

## 但 LLM 不夠

2019 年 Beam 成為哈佛公衛學院的助理教授。他組建實驗室，研究因果推論和 AI 的結合，也做新生兒醫學的應用研究。他的團隊發現一種預防早產的藥物可能根本沒效，FDA 後來撤銷了這個藥的上市許可，還引用了他們的論文作為關鍵證據。

學術生涯看起來一帆風順。但 2024 年初，Beam 在育嬰假期間開始反思。第二個孩子出生了，沒有疫情、沒有同時創業，生活終於平靜下來，他有時間想一個問題：我真正想做的事，在學界還做得了嗎？

答案是：很難。

不是學術界不好。是前沿 AI 研究需要的資源，已經超出學術界能提供的範圍。2019 年 Beam 開始教授工作時，GPT-3 還沒出現，用學校的 GPU 叢集做頂尖研究還是可能的。到了 2024 年，這已經很難成立。訓練一個前沿模型需要數千張 GPU、數億美元的投資。Power law 是殘酷的——要獲得同樣的進步，你需要把算力再擴大一個數量級。

更重要的是，Beam 開始看見 LLM 的根本限制。這些模型是人類知識的絕佳索引，能用模糊的方式檢索人類創造過的一切。但從因果推論的角度來看，它們本質上還是一堆觀察性資料。它們最多只能告訴你：哪些假說和現有資料相容。要從一堆假說中挑出正確的那個，你要嘛做很強的假設（像因果推論那樣），要嘛就是去做實驗。

科學文獻不是事實的記錄，而是一場辯論的紀錄。研究者有動機發表對自己假說最有利的版本，有動機淡化不一致的發現。你不可能光靠讀論文就推導出 2050 年的科學會是什麼樣子。你需要一步一步做實驗，驗證、推翻、修正。

這就是 Beam 決定離開哈佛，加入 Lila Sciences 擔任技術長的原因。

## 讓 AI 自己做實驗

Lila Sciences 的願景聽起來很瘋狂：打造一個能自己提出假說、自己設計實驗、自己執行實驗、然後根據結果更新認知的 AI 系統。這不只是「用 AI 加速科學」，而是讓 AI 成為科學家本身。

公司有兩大部門。一半專注於可規模化的實驗平台，另一半專注於 AI。實驗平台的核心是一套自動化系統：96 孔或 384 孔的實驗板透過磁懸浮，在一條軌道上高速移動。軌道旁邊是各種實驗設備，機器手臂會把板子從軌道上拿起來、放進設備、做完實驗再放回去，然後板子移動到下一站。

Beam 用一個比喻來描述這套系統：它就像一台新型電腦。那條軌道就是 PCI 匯流排，每個實驗設備就是插在匯流排上的裝置。他們不只是要建幾個這樣的工作站，而是要建整棟大樓的工作站，讓實驗能夠大規模並行。當你把這個「實驗叢集」和傳統的 GPU 叢集配對，你就得到了一種全新的運算範式。

這是 Beam 所謂的「新 Scaling Law」。現有的 pre-training 已經開始飽和——每一代模型需要的算力都是上一代的十倍，但改進幅度越來越小。推理模型（像 OpenAI 的 O 系列）證明了 test-time compute 是另一個有效的方向。但在科學領域，有一類問題是推理解決不了的：需要大自然當驗證者的問題。你可以讓模型推理很久，但最後你還是得做實驗才能知道答案。

Lila 的目標就是打造這個「大自然驗證器」，讓模型能夠生成假說、測試假說、然後從結果中學習。這就像 AlphaGo 需要自己跟自己下棋來生成訓練資料，科學 AI 也需要自己做實驗來生成新的 token。

## 真實世界的困難

當然，在真實世界做事比在數位世界難多了。那些實驗板裡面有液體，液體會晃動，晃動會讓板子的位置產生偏移。機器手臂要拿板子時，它可能不在預期的位置。像這樣的邊緣案例有成千上萬個，每個都要解決。

更根本的挑戰是：現有的所有實驗室自動化設備，都是為人類設計的。為什麼實驗台在那個高度？因為人要站著操作。為什麼設備之間有走道？因為人要走過去。當你想打造一個完全沒有人類參與的實驗室，你必須從頭重新思考一切。

Beam 說，這是他現在最大的挑戰。AI 的部分他相對有把握——訓練大規模模型很難，但那是一個已知的困難。實驗平台的部分是一個未知的困難，因為從來沒有人做過「為 AI 設計的實驗室」。

## 對醫療 AI 的預測

在節目的最後，主持人問 Beam 對醫療 AI 未來的預測。他的回答很有意思。

首先，他認為診斷問題「已經解決了」。正確估計「給定症狀下各種疾病的機率」這件事，LLM 已經做得夠好。那個讓他童年被誤診的問題，電腦已經能處理了——即使是最早期用 LSTM 訓練的小模型，也能正確識別百日咳。

接下來 1-3 年最大的突破會是「通用電腦操作」。OpenAI 的 Operator、Claude 的 Computer Use，這些讓 AI 能可靠地使用滑鼠鍵盤的工具，會解決醫療 AI 剩下 90% 的問題。因為一旦 AI 能坐在工作站前、開醫囑、打電話、操作 Epic 系統，它就能做大部分醫護人員的行政工作。這大概還需要一兩個數量級的算力提升，但應該在一年內就能實現。

更遠的未來——五到十年——則需要新的測量設備。現在電子病歷能捕捉到的病人生理資訊，分辨率大概就像 1940 年代的黑白電視。我們真正需要的是 100 呎大的 8K 螢幕那種分辨率。非侵入式的全面生理特徵測量、可穿戴設備、新型感測器，這些都還沒有。AI 加速科學研究，會間接讓醫療變好，但確切的路徑還不清楚。

## 給臨床醫師的建議

最後一個問題是：臨床醫師該怎麼跟上 AI 的發展？

Beam 的答案很直接：挑一個前沿模型，每天都用它。花 20 美元訂閱 ChatGPT 或 Claude，然後把它用在你生活中的各種任務。要做墨西哥捲餅？問它食譜。要規劃假期？問它建議。要做簡報的圖？用它生成。

沒有任何單一的課程能讓你跟上這個領域，因為技術變化太快了。但當你每天都在用這些工具，你會自然地建立起直覺：它能做什麼、不能做什麼、什麼時候會產生幻覺、什麼時候可以信任。這種「民俗理解」比讀任何論文都有用。

不需要去讀 Attention Is All You Need，不需要懂 RLHF 的細節。你需要的是實際操作的肌肉記憶。

---

那年被誤診的男孩，現在四十多歲了。他花了二十年證明電腦能通過醫師執照考試，然後發現這只是副產品。現在他在打造的東西更有野心：一個能自己做科學的 AI。

如果成功，這會改變的不只是醫療，而是人類獲取知識的方式。但 Beam 很清楚這有多難。他在節目中引用了一個比喻：我們對 Scaling Laws 的理解，就像古埃及人對太陽的理解——我們能精確測量，但不知道它為什麼運作。

也許這就是他離開學界的原因。有些問題，你只能靠建造來回答。
