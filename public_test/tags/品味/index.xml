<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>品味 on AINEXT</title>
    <link>https://bnextmedia.github.io/AINEXT/tags/%E5%93%81%E5%91%B3/</link>
    <description>Recent content in 品味 on AINEXT</description>
    <generator>Hugo</generator>
    <language>zh-TW</language>
    <lastBuildDate>Wed, 24 Dec 2025 01:52:00 +0800</lastBuildDate>
    <atom:link href="https://bnextmedia.github.io/AINEXT/tags/%E5%93%81%E5%91%B3/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>為什麼 Claude 寫程式碼這麼強？訓練 AI 的內幕人士揭露答案</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251224-surge-ai-why-claude-is-better/</link>
      <pubDate>Wed, 24 Dec 2025 01:52:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251224-surge-ai-why-claude-is-better/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Lenny&amp;rsquo;s Podcast 與 Surge AI 創辦人 Edwin Chen 的訪談。&#xA;收聽連結：&lt;a href=&#34;https://www.youtube.com/watch?v=dduQeaqmpnI&#34;&gt;YouTube&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;過去一年多，有個現象讓很多人困惑：Claude 在寫程式和寫作上，為什麼能領先其他模型這麼久？&lt;/p&gt;&#xA;&lt;p&gt;幾乎所有 AI 程式開發工具——Cursor、Windsurf、各種 coding agent——都把 Claude 當作首選模型。不是因為行銷，是因為它實際用起來就是比較好。這很奇怪，因為考慮到程式碼能力的經濟價值有多大，你會預期其他實驗室會很快追上來。OpenAI 的資源更多，Google 的資料更多，為什麼 Anthropic 一家相對小的公司能在這麼重要的能力上保持優勢？&lt;/p&gt;&#xA;&lt;p&gt;Edwin Chen 是 Surge AI 的創辦人，這家公司為所有主要 AI 實驗室提供訓練資料。四年內做到 10 億美元營收，靠的就是對「什麼讓 AI 變好」有獨到的理解。最近一次訪談中，他分享了一個不常被討論的答案：taste（品味）。&lt;/p&gt;&#xA;&lt;h2 id=&#34;不只是更多資料這麼簡單&#34;&gt;不只是「更多資料」這麼簡單&lt;/h2&gt;&#xA;&lt;p&gt;很多人以為 AI 模型的差異就是資料量的差異。誰有更多資料，誰就會更強。但 Edwin 認為這完全搞錯了問題的本質。&lt;/p&gt;&#xA;&lt;p&gt;「人們不理解的是，所有前沿實驗室在訓練模型時，面對的選擇幾乎是無限多的。」他解釋道。你要用純人類資料嗎？蒐集資料的方式是什麼？你要求產出資料的人具體創造什麼內容？在程式碼領域，你更在乎前端還是後端？如果是前端，你更在乎視覺設計，還是執行效率，還是純粹的正確性？要混入多少合成資料？要針對哪些 benchmark 優化？&lt;/p&gt;&#xA;&lt;p&gt;這些決策不是工程問題，而是品味問題。就像問「什麼是好的視覺設計」，不同人會有不同答案。有人在乎極簡主義，有人喜歡 3D 動畫效果，有人偏好復古風格。這些偏好會滲透到訓練資料的每一個選擇中，最終塑造出模型的「性格」。&lt;/p&gt;&#xA;&lt;p&gt;Edwin 用一個精準的說法來描述這件事：「後訓練（post-training）幾乎是一門藝術，不純粹是科學。當你決定要打造什麼樣的模型、它擅長什麼，這裡面有品味和精緻度（sophistication）的概念。」&lt;/p&gt;&#xA;&lt;h2 id=&#34;諾貝爾獎等級的詩-vs-勾選清單&#34;&gt;諾貝爾獎等級的詩 vs 勾選清單&lt;/h2&gt;&#xA;&lt;p&gt;為了說明「品味」如何影響資料品質，Edwin 舉了一個例子。&lt;/p&gt;&#xA;&lt;p&gt;假設你要訓練模型寫一首關於月亮的八行詩。什麼叫「好」？如果你不深入思考品質，檢查方式會是：這是詩嗎？有八行嗎？提到月亮嗎？這些條件都符合，那就是好詩。&lt;/p&gt;&#xA;&lt;p&gt;「但這跟我們要的完全不同。」Edwin 說。「我們要的是諾貝爾獎等級的詩。這首詩獨特嗎？有細膩的意象嗎？會讓你驚喜、觸動你的心嗎？會教你一些關於月光本質的事情嗎？會玩弄你的情緒、讓你思考嗎？」&lt;/p&gt;&#xA;&lt;p&gt;這就是差別所在。某些公司，你問他們什麼是好詩，他們會機械式地檢查一堆條件。符合指令，就是好詩。但那不是好詩。有品味和精緻度的實驗室會意識到，品質無法簡化成一組固定的勾選清單，他們會去考慮那些隱晦的、微妙的特質。&lt;/p&gt;&#xA;&lt;p&gt;這種思維差異會體現在一切地方。當你在選擇程式碼訓練資料時，你是要能跑的程式碼，還是優雅的程式碼？你是要符合規格的程式碼，還是考慮到邊界情況、有好的錯誤處理、註解清楚、結構乾淨的程式碼？這些選擇會累積，最終決定模型的水準。&lt;/p&gt;&#xA;&lt;h2 id=&#34;anthropic-做對了什麼&#34;&gt;Anthropic 做對了什麼&lt;/h2&gt;&#xA;&lt;p&gt;被問到哪家實驗室做得最好時，Edwin 明確表示他對 Anthropic 的印象最深刻。&lt;/p&gt;&#xA;&lt;p&gt;「我一直覺得 Anthropic 對於他們在乎什麼、不在乎什麼，以及他們希望模型如何表現，有非常有原則的看法。」他說。這種「有原則」（principled）是關鍵詞——它意味著 Anthropic 不是隨波逐流，不是看到什麼 benchmark 熱門就往那個方向優化，而是有一套清晰的價值觀來指導決策。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
