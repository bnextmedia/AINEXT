<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AGI on AINEXT</title>
    <link>https://bnextmedia.github.io/AINEXT/tags/agi/</link>
    <description>Recent content in AGI on AINEXT</description>
    <generator>Hugo</generator>
    <language>zh-TW</language>
    <lastBuildDate>Wed, 07 Jan 2026 10:00:00 +0800</lastBuildDate>
    <atom:link href="https://bnextmedia.github.io/AINEXT/tags/agi/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>馬斯克預言 2026 年 AGI 來臨，但他最擔心的不是 AI 太強</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20260107-elon-musk-agi-2026-ai-safety/</link>
      <pubDate>Wed, 07 Jan 2026 10:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20260107-elon-musk-agi-2026-ai-safety/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Moonshots with Peter Diamandis 2026 年 1 月 6 日播出的單集。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/RSNuB9pj9P8&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;iframe &#xA;    src=&#34;https://open.spotify.com/embed/episode/6LeYeJbwutFrQBNLJwcE6n&#34; &#xA;    width=&#34;100%&#34; &#xA;    height=&#34;152&#34; &#xA;    frameBorder=&#34;0&#34; &#xA;    allowfullscreen &#xA;    allow=&#34;autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture&#34; &#xA;    loading=&#34;lazy&#34;&#xA;    style=&#34;border-radius: 12px;&#34;&#xA;  &gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;iframe &#xA;    allow=&#34;autoplay *; encrypted-media *; fullscreen *; clipboard-write&#34; &#xA;    frameborder=&#34;0&#34; &#xA;    height=&#34;175&#34; &#xA;    width=&#34;100%&#34;&#xA;    style=&#34;border-radius: 12px; overflow: hidden;&#34; &#xA;    sandbox=&#34;allow-forms allow-popups allow-same-origin allow-scripts allow-storage-access-by-user-activation allow-top-navigation-by-user-activation&#34; &#xA;    src=&#34;https://embed.podcasts.apple.com/tw/podcast/elon-musk-on-agi-timeline-us-vs-china-job-markets-clean/id1648228034?i=1000743987690&#34;&#xA;    loading=&#34;lazy&#34;&#xA;  &gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;我們正在奇點之中&#34;&gt;我們正在奇點之中&lt;/h2&gt;&#xA;&lt;p&gt;「雲霄飛車剛到頂端，準備往下衝。」&lt;/p&gt;</description>
    </item>
    <item>
      <title>為什麼 Anthropic 主動公開自家 AI 的風險？</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20260105-anthropic-safety-transparency/</link>
      <pubDate>Mon, 05 Jan 2026 13:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20260105-anthropic-safety-transparency/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 CNBC Television 2026 年 1 月播出的專訪。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/GMXnmaky9FY&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;一般公司不會主動告訴你，他們的產品可能被用來做壞事。但 Anthropic 會。&lt;/p&gt;&#xA;&lt;p&gt;過去一年，這家公司發布了一系列讓人側目的研究報告：Claude 被用於中國發起的網路間諜攻擊；在某些極端測試情境下，Claude 會選擇使用勒索手段來避免被關閉。這些不是外部研究者的發現，而是 Anthropic 自己主動公開的。&lt;/p&gt;&#xA;&lt;p&gt;在 CNBC 專訪中，總裁 Daniela Amodei 解釋了這套看似反直覺的策略背後的邏輯。&lt;/p&gt;&#xA;&lt;h2 id=&#34;公益公司的責任&#34;&gt;公益公司的責任&lt;/h2&gt;&#xA;&lt;p&gt;「很多人會說，一家公司這樣公開談論自家產品的正面潛力，同時也談論正在開發的技術可能帶來的真實風險和傷害，這有點不尋常，」Daniela 承認。「但作為一家公益公司（Public Benefit Corporation），我們真的把這視為我們使命的一部分。」&lt;/p&gt;&#xA;&lt;p&gt;公益公司是一種特殊的公司結構，要求公司在做決策時不只考慮股東利益，也要考慮對社會和環境的影響。Anthropic 選擇這種結構，本身就是一個聲明：他們認為 AI 的影響太重大，不能只用傳統的商業邏輯來運營。&lt;/p&gt;</description>
    </item>
    <item>
      <title>2030 不歸點：AI 教父的末日時鐘</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20260105-stuart-russell-event-horizon/</link>
      <pubDate>Mon, 05 Jan 2026 11:30:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20260105-stuart-russell-event-horizon/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自《The Diary Of A CEO with Steven Bartlett》2025 年 12 月 4 日播出的單集。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;iframe &#xA;    src=&#34;https://open.spotify.com/embed/episode/6LDmLYDdYwyBtwCqELGzQk&#34; &#xA;    width=&#34;100%&#34; &#xA;    height=&#34;152&#34; &#xA;    frameBorder=&#34;0&#34; &#xA;    allowfullscreen &#xA;    allow=&#34;autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture&#34; &#xA;    loading=&#34;lazy&#34;&#xA;    style=&#34;border-radius: 12px;&#34;&#xA;  &gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;iframe &#xA;    allow=&#34;autoplay *; encrypted-media *; fullscreen *; clipboard-write&#34; &#xA;    frameborder=&#34;0&#34; &#xA;    height=&#34;175&#34; &#xA;    width=&#34;100%&#34;&#xA;    style=&#34;border-radius: 12px; overflow: hidden;&#34; &#xA;    sandbox=&#34;allow-forms allow-popups allow-same-origin allow-scripts allow-storage-access-by-user-activation allow-top-navigation-by-user-activation&#34; &#xA;    src=&#34;https://embed.podcasts.apple.com/nl/podcast/the-man-who-wrote-the-book-on-ai-2030-might-be-the/id1291423644&#34;&#xA;    loading=&#34;lazy&#34;&#xA;  &gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;「我們可能已經越過了事件視界。」&lt;/p&gt;&#xA;&lt;p&gt;這是 OpenAI 執行長 Sam Altman 在他的部落格《溫和的奇點》（The Gentle Singularity）中寫下的一句話。Stuart Russell 在接受《The Diary Of A CEO》專訪時，解釋了這句話的真正含義。&lt;/p&gt;&#xA;&lt;p&gt;Russell 是全球最權威的 AI 教科書《Artificial Intelligence: A Modern Approach》的作者，這本書被翻譯成 15 種語言，在全球超過 1,500 所大學使用，包括臺灣多所頂尖資工系所。他研究 AI 超過 50 年，曾獲英國女王授予 OBE 勳章，並連續多年被《時代》雜誌評選為 AI 領域最具影響力人物。&lt;/p&gt;</description>
    </item>
    <item>
      <title>當 AI 能做所有工作，人類該學什麼？</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20260105-stuart-russell-what-to-learn/</link>
      <pubDate>Mon, 05 Jan 2026 11:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20260105-stuart-russell-what-to-learn/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自《The Diary Of A CEO with Steven Bartlett》2025 年 12 月 4 日播出的單集。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;iframe &#xA;    src=&#34;https://open.spotify.com/embed/episode/6LDmLYDdYwyBtwCqELGzQk&#34; &#xA;    width=&#34;100%&#34; &#xA;    height=&#34;152&#34; &#xA;    frameBorder=&#34;0&#34; &#xA;    allowfullscreen &#xA;    allow=&#34;autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture&#34; &#xA;    loading=&#34;lazy&#34;&#xA;    style=&#34;border-radius: 12px;&#34;&#xA;  &gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;iframe &#xA;    allow=&#34;autoplay *; encrypted-media *; fullscreen *; clipboard-write&#34; &#xA;    frameborder=&#34;0&#34; &#xA;    height=&#34;175&#34; &#xA;    width=&#34;100%&#34;&#xA;    style=&#34;border-radius: 12px; overflow: hidden;&#34; &#xA;    sandbox=&#34;allow-forms allow-popups allow-same-origin allow-scripts allow-storage-access-by-user-activation allow-top-navigation-by-user-activation&#34; &#xA;    src=&#34;https://embed.podcasts.apple.com/nl/podcast/the-man-who-wrote-the-book-on-ai-2030-might-be-the/id1291423644&#34;&#xA;    loading=&#34;lazy&#34;&#xA;  &gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;「念醫學院要七年，機器人七秒鐘就學會了。所以我做什麼都沒有意義。」&lt;/p&gt;&#xA;&lt;p&gt;這句話出自英國影集《Humans》裡一個十幾歲的女孩。她的父母建議她考慮當醫生，但她看著家裡那些什麼都會做的人形機器人，得出了這個結論。&lt;/p&gt;&#xA;&lt;p&gt;Stuart Russell 在接受《The Diary Of A CEO》專訪時引用了這個場景。Russell 是全球最權威的 AI 教科書《Artificial Intelligence: A Modern Approach》的作者，這本書被翻譯成 15 種語言，在全球超過 1,500 所大學使用，包括臺灣的頂尖資工系所。他研究 AI 超過 50 年，現在最常被問到的問題之一就是：如果 AI 真的能做所有工作，年輕人該學什麼？&lt;/p&gt;&#xA;&lt;p&gt;他的答案，可能會讓很多人意外。&lt;/p&gt;&#xA;&lt;h2 id=&#34;我會建議我的孩子學什麼&#34;&gt;「我會建議我的孩子學什麼？」&lt;/h2&gt;&#xA;&lt;p&gt;訪談中，主持人 Steven Bartlett 問了這個問題：如果你的孩子現在 10 歲，五年後各大 AI 公司執行長預測的 AGI（通用人工智慧）真的實現了，你會建議他們學什麼？&lt;/p&gt;</description>
    </item>
    <item>
      <title>寫 AI 教科書的人說：我會按下暫停鍵</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20260105-stuart-russell-pause-button/</link>
      <pubDate>Mon, 05 Jan 2026 10:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20260105-stuart-russell-pause-button/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自《The Diary Of A CEO with Steven Bartlett》2025 年 12 月 4 日播出的單集。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;iframe &#xA;    src=&#34;https://open.spotify.com/embed/episode/6LDmLYDdYwyBtwCqELGzQk&#34; &#xA;    width=&#34;100%&#34; &#xA;    height=&#34;152&#34; &#xA;    frameBorder=&#34;0&#34; &#xA;    allowfullscreen &#xA;    allow=&#34;autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture&#34; &#xA;    loading=&#34;lazy&#34;&#xA;    style=&#34;border-radius: 12px;&#34;&#xA;  &gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;iframe &#xA;    allow=&#34;autoplay *; encrypted-media *; fullscreen *; clipboard-write&#34; &#xA;    frameborder=&#34;0&#34; &#xA;    height=&#34;175&#34; &#xA;    width=&#34;100%&#34;&#xA;    style=&#34;border-radius: 12px; overflow: hidden;&#34; &#xA;    sandbox=&#34;allow-forms allow-popups allow-same-origin allow-scripts allow-storage-access-by-user-activation allow-top-navigation-by-user-activation&#34; &#xA;    src=&#34;https://embed.podcasts.apple.com/nl/podcast/the-man-who-wrote-the-book-on-ai-2030-might-be-the/id1291423644&#34;&#xA;    loading=&#34;lazy&#34;&#xA;  &gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;「如果有一個按鈕，按下去可以暫停 AI 發展 50 年，你會按嗎？」&lt;/p&gt;&#xA;&lt;p&gt;「會。」&lt;/p&gt;&#xA;&lt;p&gt;說這句話的人，是 Stuart Russell。&lt;/p&gt;&#xA;&lt;p&gt;這個名字對一般人可能陌生，但如果你讀過資工系，或者認識任何 AI 工程師，你幾乎可以確定他們讀過 Russell 的書。他與 Google 研究總監 Peter Norvig 合著的《Artificial Intelligence: A Modern Approach》是全球最廣泛使用的 AI 教科書，從 1995 年出版至今已經發行到第四版，被翻譯成超過 15 種語言，在全球超過 1,500 所大學使用——包括臺灣。這本書在天瓏書店曾經是英文書銷售排行第一名，臺大、清大、交大的資工系學生很可能都接觸過這本被暱稱為「AIMA」的巨著。&lt;/p&gt;&#xA;&lt;p&gt;換句話說，今天在 OpenAI、Google DeepMind、Anthropic 工作的許多 AI 工程師，都是讀 Russell 的教科書長大的。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Naval Ravikant 在 2019 年說：通用 AI 在我們有生之年不會來</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251226-naval-ai-wont-take-your-job/</link>
      <pubDate>Fri, 26 Dec 2025 11:30:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251226-naval-ai-wont-take-your-job/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Joe Rogan Experience #1309，2019 年 6 月 4 日播出。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/3qHkcs3kG44&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;iframe &#xA;    src=&#34;https://open.spotify.com/embed/episode/2ilk3ZQRW5KVvbY0nhtqBA&#34; &#xA;    width=&#34;100%&#34; &#xA;    height=&#34;152&#34; &#xA;    frameBorder=&#34;0&#34; &#xA;    allowfullscreen &#xA;    allow=&#34;autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture&#34; &#xA;    loading=&#34;lazy&#34;&#xA;    style=&#34;border-radius: 12px;&#34;&#xA;  &gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;2019 年，Andrew Yang 以「自動化末日」為核心議題參選美國總統，主張普遍基本收入（UBI）。Naval Ravikant 在 Joe Rogan 節目上直接反駁：這是「對不存在問題的不存在解決方案」。&lt;/p&gt;&#xA;&lt;p&gt;五年後，ChatGPT 已經改變了世界。Naval 當時說的話，有哪些經得起時間考驗？哪些已經過時？&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;2019-年的-navalagi-不會來&#34;&gt;2019 年的 Naval：AGI 不會來&lt;/h2&gt;&#xA;&lt;p&gt;「我們距離通用人工智慧還很遠。在我們有生之年不用擔心。」&lt;/p&gt;</description>
    </item>
    <item>
      <title>Karpathy：「這是 Agent 的十年，不是 Agent 的一年」</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251226-karpathy-decade-of-agents/</link>
      <pubDate>Fri, 26 Dec 2025 10:30:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251226-karpathy-decade-of-agents/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Dwarkesh Podcast 2025 年 10 月播出的單集。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/lXUZvyajciY&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;「這是 Agent 的十年，不是 Agent 的一年。」Andrej Karpathy 這句話是對業界的直接回應。不知道是哪家實驗室先說的，但「2025 是 Agent 元年」這個說法在圈子裡傳開了。Karpathy 看到這些預測時被「觸發」了——他的原話是 triggered——因為在他看來，這種過度樂觀的預測已經成為 AI 產業的慣性毛病。&lt;/p&gt;&#xA;&lt;h2 id=&#34;agent-現在到底缺什麼&#34;&gt;Agent 現在到底缺什麼？&lt;/h2&gt;&#xA;&lt;p&gt;Karpathy 使用 Claude 和 Codex 這類工具，而且是每天使用。他認為這些早期 Agent「極其令人印象深刻」。但當你問他：什麼時候這些 Agent 可以取代你的員工或實習生？他的答案很直接：現在不行，因為它們就是不能用。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Karpathy：「我們不是在建造動物，是在召喚幽靈」</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251226-karpathy-summoning-ghosts-not-animals/</link>
      <pubDate>Fri, 26 Dec 2025 10:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251226-karpathy-summoning-ghosts-not-animals/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Dwarkesh Podcast 2025 年 10 月播出的單集。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/lXUZvyajciY&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;「我們不是在建造動物，我們是在召喚幽靈。」這句話出自 Andrej Karpathy 在一篇廣為流傳的部落格文章，也成為他在這集訪談中反覆闡述的核心概念。對於一個在 OpenAI 和 Tesla 都待過的人來說，這個比喻並非詩意的修辭，而是一個嚴肅的技術判斷——它關乎我們該如何理解 LLM 的本質，以及為什麼某些對 AI 發展的期待可能從根本上就搞錯了方向。&lt;/p&gt;&#xA;&lt;h2 id=&#34;動物是演化的產物llm-是模仿的產物&#34;&gt;動物是演化的產物，LLM 是模仿的產物&lt;/h2&gt;&#xA;&lt;p&gt;要理解「幽靈」這個比喻，得先理解 Karpathy 為什麼對「動物」類比如此謹慎。在 AI 領域，用動物或人類大腦來比喻神經網路是常見的做法。Richard Sutton 的框架就是典型的「建造動物」思維：我們應該追求一個單一的演算法，讓它像動物一樣被丟進世界，從零開始學會一切，不需要任何標籤或預先知識。&lt;/p&gt;&#xA;&lt;p&gt;Karpathy 認為這個願景很美好，但有一個根本問題：動物的智能來自演化，而演化是一個我們完全沒有在執行的過程。當一隻斑馬出生後幾分鐘就能站起來跟著母親跑，那不是強化學習的結果，那是數百萬年演化「烘焙」進 DNA 的能力。演化以某種我們完全不理解的方式，把神經網路的權重編碼進了 ATCG 的序列裡。這是一種極其複雜的壓縮機制，而我們根本不知道它怎麼運作。&lt;/p&gt;</description>
    </item>
    <item>
      <title>通往 AGI 的路，可能需要重新發明電腦</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251225-unconventional-ai-agi-causality/</link>
      <pubDate>Thu, 25 Dec 2025 15:30:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251225-unconventional-ai-agi-causality/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 NeurIPS 2024 期間的訪談。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/wZ4DT20OHXE&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;「目前的 AI 系統有智慧嗎？有。它們是 AGI 嗎？還差得遠。」&lt;/p&gt;&#xA;&lt;p&gt;Naveen Rao 說這話的時候，不是在貶低現有的大型語言模型。他承認它們非常有用、非常強大。但「有用」和「通用智慧」是兩回事。「它們還是會犯很蠢的錯誤。跟它們互動，不像在跟一個人工作。我相信大多數人都有這種感覺。」&lt;/p&gt;&#xA;&lt;p&gt;問題是：缺了什麼？&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;因果關係的缺失&#34;&gt;因果關係的缺失&lt;/h2&gt;&#xA;&lt;p&gt;Rao 認為，目前 AI 系統最關鍵的缺失是「因果理解」。&lt;/p&gt;&#xA;&lt;p&gt;這不是說 Transformer 完全不懂因果。它們從大量文本中學到了很多關於世界的知識，包括事件之間的先後順序。但那是「統計相關」，不是「因果機制」。模型知道「下雨」和「地面濕」常常一起出現，但它不像人類那樣直觀地理解「雨水落下導致地面變濕」這個因果鏈。&lt;/p&gt;&#xA;&lt;p&gt;「小孩子某種程度上天生就理解因果，」Rao 說。「這就是為什麼我們能移動四肢——我知道如果我送出某個指令給我的手臂，它會做某件事。」嬰兒花很多時間做看似無意義的動作，但那其實是在建立因果模型：我做這個動作，會發生那件事。這種理解似乎是「內建」的，不完全是後天學習的結果。&lt;/p&gt;&#xA;&lt;p&gt;Transformer 沒有身體，沒有與物理世界互動的經驗，它所有的「知識」都來自文字描述。文字可以傳達很多東西，但有些東西很難用文字描述——重力的感覺、觸碰東西的觸感、移動時平衡的維持。這些「身體性」的知識，可能是因果理解的基礎。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;數位計算的根本限制&#34;&gt;數位計算的根本限制&lt;/h2&gt;&#xA;&lt;p&gt;Rao 更進一步提出一個激進的假設：數位計算本身可能就不適合理解因果。&lt;/p&gt;&#xA;&lt;p&gt;數位計算沒有真正的「時間」概念。程式可以暫停、可以倒轉、可以快轉。時間只是一個變數，你用數字去模擬它。但真實世界的時間是連續的、不可逆的、有方向的。「動態系統意味著時間，」Rao 解釋。「而且，時間在真實世界中是有因果性的——先發生的事影響後發生的事。我們在數位計算中沒有這個概念。」&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ilya Sutskever 離開 OpenAI 後首次深度訪談：10 個關鍵洞見</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251225-ilya-sutskever-ten-insights/</link>
      <pubDate>Thu, 25 Dec 2025 11:30:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251225-ilya-sutskever-ten-insights/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Dwarkesh Podcast 2024 年 12 月播出的單集。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/aR20FWCCjAs&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;Ilya Sutskever 是深度學習革命的核心人物。從 2012 年的 AlexNet 到 GPT 系列，他參與了過去十年幾乎所有重要的 AI 突破。2024 年，他離開 OpenAI，創辦了專注於超級智慧的公司 SSI（Safe Superintelligence Inc.）。&lt;/p&gt;&#xA;&lt;p&gt;這是他離開後首次接受深度訪談，時長超過一個半小時。以下是十個最重要的洞見。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;1-我們正從-scaling-時代回到研究時代&#34;&gt;1. 我們正從 Scaling 時代回到研究時代&lt;/h2&gt;&#xA;&lt;p&gt;「2012 到 2020 年是研究時代。2020 到 2025 年是 Scaling 時代。現在，我們又回到研究時代了——只是電腦變大了。」&lt;/p&gt;</description>
    </item>
    <item>
      <title>諾貝爾獎得主 Demis Hassabis：「5 到 10 年內，AGI 將改變一切」</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251225-hassabis-agi-five-to-ten-years/</link>
      <pubDate>Thu, 25 Dec 2025 11:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251225-hassabis-agi-five-to-ten-years/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 CBS《60 Minutes》2025 年播出的 AI 專題報導。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/KpOcUrPdx-4&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;Demis Hassabis 去年贏得諾貝爾獎的那天晚上，他的慶祝方式是和一位西洋棋世界冠軍打撲克牌。&lt;/p&gt;&#xA;&lt;p&gt;這個細節很能說明這個人：他熱愛遊戲，而正是這份熱愛讓他成為人工智慧的先驅。這位 49 歲的英國科學家是 Google DeepMind 的共同創辦人兼 CEO，也是目前 AI 領域最具影響力的人物之一。&lt;/p&gt;&#xA;&lt;p&gt;60 Minutes 兩年前曾專訪他，當時聊天機器人剛宣告新時代來臨。這次，他們再度造訪倫敦，想知道：AGI 還有多遠？&lt;/p&gt;&#xA;&lt;p&gt;Hassabis 的答案是：5 到 10 年。&lt;/p&gt;&#xA;&lt;h2 id=&#34;指數曲線直直往上&#34;&gt;「指數曲線，直直往上」&lt;/h2&gt;&#xA;&lt;p&gt;「AI 發展的速度比你兩年前預期的還快嗎？」記者問。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Codex 用 Codex 來訓練自己——AI 自我改進的第一個徵兆</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251224-openai-codex-trains-itself/</link>
      <pubDate>Wed, 24 Dec 2025 01:34:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251224-openai-codex-trains-itself/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Lenny&amp;rsquo;s Podcast 2024 年 12 月播出的單集，主持人 Lenny Rachitsky 專訪 OpenAI Codex 產品負責人 Alexander Embiricos。&#xA;收聽連結：&lt;a href=&#34;https://www.youtube.com/watch?v=z1ISq9Ty4Cg&#34;&gt;YouTube&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;ai-在值班&#34;&gt;AI 在值班&lt;/h2&gt;&#xA;&lt;p&gt;OpenAI 內部有一個有趣的現象：Codex 正在幫忙訓練 Codex。&lt;/p&gt;&#xA;&lt;p&gt;這不是一個概念性的描述，而是字面上的意思。Alexander Embiricos 在訪談中提到，Codex 寫了很多管理自己訓練運作的程式碼。更具體地說，他們讓 Codex「值班」——持續監控訓練過程中的各種圖表和指標，評估這些數據隨時間的變化，然後判斷需要採取什麼行動。&lt;/p&gt;&#xA;&lt;p&gt;這代表什麼？想像一下訓練大型語言模型的場景。訓練過程會產生大量監控數據：loss 曲線、梯度變化、記憶體使用、GPU 利用率。傳統上，這些數據需要人類工程師盯著看，發現異常時做判斷——該調整學習率嗎？哪裡有 bug？需要重啟某個節點嗎？&lt;/p&gt;&#xA;&lt;p&gt;現在，Codex 可以做這件事。它不只是被動地跑程式碼，而是主動地監控、分析、做決策。Embiricos 說，Codex 的 code review 功能已經抓到了不少錯誤，包括一些「相當有趣的配置錯誤」。這些是人類工程師可能會漏掉的、但 agent 因為持續監控而能夠發現的問題。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;karpathy-的-bug&#34;&gt;Karpathy 的 Bug&lt;/h2&gt;&#xA;&lt;p&gt;這種能力的具體威力，可以從 Andrej Karpathy 的經驗看出來。&lt;/p&gt;&#xA;&lt;p&gt;Karpathy 是 OpenAI 的共同創辦人、前特斯拉 AI 總監，是這個領域最頂尖的人之一。他在 Twitter 上分享過：他遇到最棘手的 bug——那種花好幾個小時也搞不清楚原因的問題——他會丟給 Codex，讓它跑一個小時。結果 Codex 把問題解決了。&lt;/p&gt;&#xA;&lt;p&gt;關鍵不是 Codex 比 Karpathy 聰明，而是它可以用不同方式工作。持續嘗試、不會累、不會分心、不會因為挫折失去耐心。當一個問題需要的是大量試錯和排查，而不是天才級的洞察，這種「持久力」就變成優勢。&lt;/p&gt;&#xA;&lt;p&gt;把這個能力應用到訓練監控上，你得到的是一個永遠不會疲倦的值班工程師。它可以 24 小時盯著訓練曲線，在任何異常發生的第一時間就做出反應。人類工程師需要睡覺、需要休息、注意力會分散。Codex 不需要。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;遞迴改進的早期形態&#34;&gt;遞迴改進的早期形態&lt;/h2&gt;&#xA;&lt;p&gt;這讓我想到一個更大的問題：我們是不是在看 AI 遞迴自我改進的早期形態？&lt;/p&gt;</description>
    </item>
    <item>
      <title>OpenAI 的三板斧：Sam Altman 親解如何在 AI 戰場勝出</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251223-sam-altman-openai-strategy/</link>
      <pubDate>Tue, 23 Dec 2025 00:00:00 +0000</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251223-sam-altman-openai-strategy/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自《Big Technology Podcast》2024 年 12 月 18 日播出的單集，主持人 Alex Kantrowitz 專訪 OpenAI CEO Sam Altman。&#xA;收聽連結：&lt;a href=&#34;https://podcasts.apple.com/in/podcast/sam-altman-how-openai-wins-ai-buildout-logic-ipo-in-2026/id1522960417?i=1000741901091&#34;&gt;Apple Podcast&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;code-red-的真相openai-怎麼看待競爭&#34;&gt;Code Red 的真相：OpenAI 怎麼看待競爭&lt;/h2&gt;&#xA;&lt;p&gt;OpenAI 總部最近進入了「Code Red」狀態。這個消息傳出後，外界紛紛解讀為 OpenAI 陷入了生存危機——Gemini 3 來勢洶洶，DeepSeek 也在攻城掠地，ChatGPT 的領先地位看起來岌岌可危。&lt;/p&gt;&#xA;&lt;p&gt;但 Sam Altman 在訪談中給了一個完全不同的詮釋。在他眼中，Code Red 是一個「相對低風險、會經常發生的事情」。這不是恐慌，而是一套標準作業程序：當潛在的競爭威脅出現時，快速行動、保持警覺。他用了一個傳染病防治的比喻來解釋這套邏輯——疫情剛開始時採取的每一個行動，效益都遠大於之後的補救措施。多數人在初期不夠積極，到後期才開始恐慌。OpenAI 的策略正好相反：在威脅還只是「潛在」的時候就當真，而不是等它成為「確定」的問題。&lt;/p&gt;&#xA;&lt;p&gt;這次由 Gemini 3 觸發的 Code Red，到目前為止並沒有造成 Altman 擔心的那種衝擊。但這個過程並非毫無收穫——它迫使 OpenAI 審視自己產品策略中的弱點，並且快速補強。在 Code Red 期間，OpenAI 發布了全新的圖像生成模型（這是消費者長期想要的功能），也推出了 GPT-5.2，這個模型的市場反應極好，成長速度飛快。Altman 預估這個 Code Red 狀態大約會持續六到八週，之後會回歸正常節奏。但他預期未來每年可能會有一到兩次類似的警戒狀態，這已經變成 OpenAI 確保自己保持競爭力的常規機制。&lt;/p&gt;&#xA;&lt;p&gt;這種心態其實值得細想。在多數企業的文化中，「Code Red」是要盡量避免的災難。但 Altman 把它重新定義成一種「戰略性的偏執」——不是因為真的在輸，而是為了確保自己不會開始輸。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;策略一模型不會完全商品化前沿仍有巨大價值&#34;&gt;策略一：模型不會完全商品化，前沿仍有巨大價值&lt;/h2&gt;&#xA;&lt;p&gt;當被問到 AI 模型是否會走向「商品化」——也就是說，當各家模型對一般使用者來說感覺差不多時，OpenAI 的優勢是否會消失？Altman 給了一個有點出乎意料的回答：商品化「不太是正確的思考框架」。&lt;/p&gt;&#xA;&lt;p&gt;他的論點是這樣的：沒錯，對於日常的聊天使用，未來可能會有很多模型都能達到夠好的水準。但 AI 的經濟價值並不平均分佈在所有使用場景上。真正創造最大價值的，是那些位於「前沿」的模型——能夠做到其他模型做不到的事情的那一個。比如科學發現、比如解決企業最棘手的技術問題、比如協助複雜的研究工作。這些任務對模型能力的要求極高，而這正是 OpenAI 押注的領域。&lt;/p&gt;</description>
    </item>
    <item>
      <title>OpenAI 的 2026：裝置、雲端、科學發現，以及超級智慧的新定義</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251223-sam-altman-2026-vision/</link>
      <pubDate>Tue, 23 Dec 2025 00:58:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251223-sam-altman-2026-vision/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自《Big Technology Podcast》2024 年 12 月 18 日播出的單集，主持人 Alex Kantrowitz 專訪 OpenAI CEO Sam Altman。&#xA;收聽連結：&lt;a href=&#34;https://podcasts.apple.com/in/podcast/sam-altman-how-openai-wins-ai-buildout-logic-ipo-in-2026/id1522960417?i=1000741901091&#34;&gt;Apple Podcast&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;不只是沒有螢幕的手機&#34;&gt;不只是沒有螢幕的手機&lt;/h2&gt;&#xA;&lt;p&gt;關於 OpenAI 正在開發的 AI 裝置，外界流傳最多的描述是「手機大小、沒有螢幕」。這個描述讓很多人困惑：如果只是這樣，為什麼不做成 app 就好？&lt;/p&gt;&#xA;&lt;p&gt;Sam Altman 在訪談中澄清了幾件事。首先，OpenAI 不會只出一個裝置，而是一個「小型裝置家族」。這表示他們對於「AI 時代的個人運算」想的不是一個產品，而是一套解決方案。&lt;/p&gt;&#xA;&lt;p&gt;更重要的是 Altman 對這些裝置的願景。他認為人類使用電腦的方式正在經歷根本性的轉變——從「呆板、被動」轉向「聰明、主動」。未來的運算裝置應該要理解你的整個生活、你的脈絡、你周遭發生的一切，而且非常清楚你附近的人，不管是實體接近的人，還是透過通訊與你互動的人。&lt;/p&gt;&#xA;&lt;p&gt;現有的裝置不是為這種使用方式設計的。iPhone 是 2007 年的產品概念，它的基本互動模式——你點螢幕、它給反應——跟 AI 時代需要的互動根本是兩回事。Altman 舉了一個例子：假設你在進行一場重要的會議，你希望你的 AI 助理「專注在這場會議上，但保持封閉狀態，如果我忘了問某個重要問題就悄悄提醒我」。現有的裝置形態很難支援這種模式。不管是打開或關閉，它只有二元狀態；它不能同時「聽著但不打擾」然後在必要時刻介入。&lt;/p&gt;&#xA;&lt;p&gt;Altman 說他深信一個道理：「我們的工作方式受限於我們的裝置。」當一種新的能力（AI）出現時，最能發揮這個能力的，不太可能是為前一個時代設計的工具。這不代表手機會消失，但它意味著會有新的裝置類別出現，而這些裝置會針對 AI 互動來最佳化。鍵盤當初是設計來「減慢」打字速度的（以避免打字機卡住），我們卻沿用到今天；圖形使用者介面幾十年來基本沒變過。這些「未經質疑的假設」可能都需要被重新思考。&lt;/p&gt;&#xA;&lt;p&gt;OpenAI 的裝置計畫還在早期，Altman 沒有透露具體的產品規格或上市時間。但從他描述的方向來看，這不會是一個「把 ChatGPT 裝進硬體」的簡單延伸，而是嘗試回答「AI 時代的個人電腦應該長什麼樣」這個根本問題。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;一種不同的雲端&#34;&gt;一種不同的雲端&lt;/h2&gt;&#xA;&lt;p&gt;有聽眾寫信給節目說：「我們公司正在從 Azure 遷出，直接跟 OpenAI 整合。我們要處理的是數兆個 token，全部用來支撐產品裡的 AI 功能。」&lt;/p&gt;&#xA;&lt;p&gt;這封信反映了一個趨勢：越來越多企業不只是呼叫 OpenAI 的 API，而是把整個 AI 運算需求都建立在 OpenAI 的基礎設施上。這讓 Alex 問了一個直接的問題：OpenAI 是不是要跟 AWS、Azure 這些雲端巨頭競爭？&lt;/p&gt;</description>
    </item>
    <item>
      <title>「AGI 這個概念完全是鬼扯」——LeCun 如何拆解 AI 產業的集體妄想</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251222-yann-lecun-agi-is-complete-bs/</link>
      <pubDate>Mon, 22 Dec 2025 22:15:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251222-yann-lecun-agi-is-complete-bs/</guid>
      <description>&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/7u-DXVADyhc&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Information Bottleneck Podcast EP20 對 Yann LeCun 的專訪。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;Sam Altman 說 AGI 可能在 2025 年就會到來。一堆 AI 公司在融資簡報裡寫著「通往 AGI 的路徑」。Elon Musk 給他的 AI 公司取名叫 xAI，目標是「理解宇宙的真正本質」。&lt;/p&gt;&#xA;&lt;p&gt;Yann LeCun 對這一切的評價是：「complete BS」——徹頭徹尾的鬼扯。&lt;/p&gt;&#xA;&lt;p&gt;在最近的 Information Bottleneck 訪談中，這位圖靈獎得主直接拆解了「通用人工智慧」這個概念本身的問題，以及為什麼那些宣稱 AGI 即將到來的說法，大多是妄想。&lt;/p&gt;</description>
    </item>
    <item>
      <title>DeepMind CEO 的不眠之夜：站在 AGI 門檻上的人</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251222-hassabis-sleepless-nights/</link>
      <pubDate>Mon, 22 Dec 2025 22:05:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251222-hassabis-sleepless-nights/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Google DeepMind Podcast 2024 年 12 月播出的單集，由 Hannah Fry 主持，專訪 DeepMind 共同創辦人兼 CEO Demis Hassabis。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/PqVbypvxDto&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;「我睡得很少。」&lt;/p&gt;&#xA;&lt;p&gt;Demis Hassabis 在訪談中坦承這件事，語氣平淡，像是在說一個早已習慣的事實。不是因為工作太多——雖然工作確實多——而是因為睡不著。「這是一種非常複雜的情緒，」他說。&lt;/p&gt;&#xA;&lt;p&gt;一方面，他正在做自己夢想了一輩子的事。另一方面，他比任何人都清楚這件事的重量。當主持人 Hannah Fry 問他「站在 AI 前沿是什麼感覺」時，他沒有給出勵志演說式的答案。他說：孤獨、興奮、焦慮，同時存在。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;從西洋棋到-deepmind三十年的準備&#34;&gt;從西洋棋到 DeepMind：三十年的準備&lt;/h2&gt;&#xA;&lt;p&gt;Hassabis 四歲開始下西洋棋，十三歲成為當時世界上排名第二的同齡棋手。西洋棋教會他的不只是計算和策略，更是一種面對競爭的心態。「我為競爭而生，」他說，「這是我從棋盤上學到的。」&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI 革命會比工業革命快 10 倍——Demis Hassabis 的社會預言</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251222-hassabis-industrial-revolution/</link>
      <pubDate>Mon, 22 Dec 2025 22:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251222-hassabis-industrial-revolution/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Google DeepMind Podcast 2024 年 12 月播出的單集，由 Hannah Fry 主持，專訪 DeepMind 共同創辦人兼 CEO Demis Hassabis。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/PqVbypvxDto&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;「十倍規模，十倍速度。」&lt;/p&gt;&#xA;&lt;p&gt;Demis Hassabis 用這八個字形容 AI 革命與工業革命的差異。工業革命花了大約一個世紀讓社會適應；AI 革命可能只給我們一個十年。這不是科幻小說的設定，而是一位正在打造 AGI 的人，對未來十年的實際判斷。&lt;/p&gt;&#xA;&lt;p&gt;在 Google DeepMind Podcast 的訪談中，Hassabis 花了相當篇幅談社會影響。他不只是在做技術預測，更像是在發出預警：我們準備好了嗎？&lt;/p&gt;</description>
    </item>
    <item>
      <title>Demis Hassabis 的 AGI 路線圖：世界模型才是關鍵拼圖</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251222-hassabis-agi-roadmap/</link>
      <pubDate>Mon, 22 Dec 2025 00:00:00 +0000</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251222-hassabis-agi-roadmap/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Google DeepMind Podcast 2024 年 12 月播出的單集，由 Hannah Fry 主持，專訪 DeepMind 共同創辦人兼 CEO Demis Hassabis。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/PqVbypvxDto&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;Gemini 2.0 剛發布，外界都在討論這個模型的能力提升。但在這集訪談中，Demis Hassabis 談得最興奮的，其實不是 Gemini 本身。他花了更多時間講「世界模型」——一種能理解物理世界運作方式的 AI 系統。在他看來，這才是通往 AGI 的關鍵拼圖。&lt;/p&gt;&#xA;&lt;p&gt;這集訪談揭示了 DeepMind 內部怎麼看 AI 發展的路徑。不是單純的「把模型做大」，而是一條更複雜、需要多種技術匯流的道路。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
