---
title: "AI 的數學能力可能永遠是鋸齒狀的：一位數學家的清醒診斷"
date: 2026-01-30T09:00:00+08:00
description: "多倫多大學數學教授 Daniel Litt 在 Epoch AI 的 Podcast 中，深入剖析 AI 在數學領域的真實能力。他指出 AI 在不同數學子領域的表現落差極大，基準測試測的是知識而非推理，而 AI 對數學最大的貢獻是降低嘗試的邊際成本。"
tags: ["Daniel Litt", "Epoch AI", "FrontierMath", "AI 數學", "Podcast"]
categories: ["AI 技術前沿"]
source_url: "https://www.youtube.com/watch?v=jFJku8sxLWY"
source_name: "Epoch After Hours"
draft: false
---

> 本文整理自 Epoch After Hours 2026 年 1 月 29 日發布的單集。

{{< youtube jFJku8sxLWY >}}

{{< spotify "episode/1brOmv2FYLzH6TdEZacZ3S" >}}

{{< apple-podcast "tw/podcast/ai-math-capabilities-could-be-jagged-for-a-long/id1790976895?i=1000747213829" >}}

---

## 一位你該認識的數學家

如果你有在追蹤 AI 與科學研究的交叉議題，Daniel Litt 這個名字值得記住。他是多倫多大學的數學教授，專攻代數幾何與數論，也就是研究方程式的幾何形狀，以及整數之間的深層規律。這些聽起來離日常很遠，但他的研究水準是頂尖的：他在數學界最高等級的期刊 *Annals of Mathematics* 發表過論文，2024 年拿到 Sloan 研究獎，2026 年獲選美國數學學會 Fellow。用白話講，他是全世界幾百個真正站在數學前沿的人之一。

但讓他在 AI 圈出名的不只是學術成就。Litt 在 X（前 Twitter）上有超過五萬追蹤者，是目前 AI 與數學辯論中最受關注的專業數學家。他不是那種一口否定 AI 的學院派，也不是動輒宣布「AI 要取代數學家」的樂觀派。他的立場很精確：承認 AI 的進步，但用第一手經驗指出哪裡真的厲害、哪裡只是看起來厲害。

讓他的觀點特別有分量的另一個原因是，他在多倫多大學。這所學校是深度學習的發源地，Geoffrey Hinton 在這裡待了將近四十年，Ilya Sutskever 在這裡讀博士，整個現代 AI 革命可以說從這棟校園開始。Litt 身處 AI 研究的絕對震央，每天和 AI 研究者共用同一間大學，卻做著最純粹的數學。這種位置讓他既理解 AI 的真實進展，又不會被矽谷的樂觀敘事帶著走。

這集 Podcast 是 Epoch AI 的「After Hours」節目，由 Epoch 的研究員 Greg Burnham 和 Anson Ho 主持。Epoch AI 是一間專門研究 AI 進展速度的非營利機構，他們做出了 FrontierMath 這個數學基準測試，集結了六十多位數學家（包括 Fields Medal 得主陶哲軒）出題。Litt 本人也為 FrontierMath 貢獻過題目，而且親眼看到 OpenAI 的 o3 模型解出了他的題。所以當他談 AI 的數學能力時，不是在抽象推測，而是有第一手的觀察。

## AI 做得到的數學，大概就是 IMO 等級

先從 AI 目前做得到什麼說起。Litt 給了一個很具體的定位：現在的前沿 AI 模型，大約能做到國際數學奧林匹克（IMO）中低難度的題目。這相當於一個非常厲害的高中生或大學生，花幾個小時能解出來的問題。所有的前沿模型基本上都能在最近一屆 IMO 拿到金牌，這確實令人印象深刻。

但 Litt 隨即指出，IMO 題目和真正的數學研究之間有一道很深的鴻溝。IMO 是一個非常受限的環境：有限的技巧、有限的時間、有明確答案的問題。而數學研究完全不是這回事。你不知道問題有沒有解，不知道該用什麼工具，甚至不知道自己在找什麼。這種差距，比大多數人想像的大得多。

他預測，在接下來一年內，AI 可能會開始解決一些「中等有趣」的數學猜想，也就是曾經有人正式提出、至少有人花了幾小時思考過的問題。事實上，他認為最近已經開始看到這樣的例子了。但他用了一個很精準的詞來形容這些成就：「Oh, that's cool」，就是「噢，不錯。」然後人生繼續。不是劃時代的突破，而是一個值得記錄的進展。

## 「鋸齒邊界」：AI 在數學裡的能力分布極度不均

這集 Podcast 最核心的概念是「jagged frontier」，也就是鋸齒狀的能力邊界。AI 不是在所有數學領域都同樣強或同樣弱，它的能力分布是極度不均勻的。

Litt 舉了自己的親身經驗。在他的專業領域代數幾何和數論裡，AI 模型的表現相當差。你問它一個代數幾何的問題，它做的事情基本上是去記憶中找一個最接近的結果，然後嘗試往前多推一兩步。這跟真正的「解題」差距很大。但如果你問它一個組合數學的問題，或者讓它證明一個不等式，它的表現就好得多，甚至超越他本人。

為什麼會這樣？Litt 認為有兩個主要原因。第一是訓練資料。有些數學領域的資料比較容易生成，網路上也有比較多的相關內容，模型自然在這些領域比較強。第二是工具親和性。有些數學問題可以透過寫程式來輔助解決，比如找反例或驗證不等式。AI 天生擅長寫程式，所以在這些領域佔優勢。但代數幾何研究中，「寫程式幫忙找三次曲面的中間 Jacobian 的反例」這種事，基本上不存在可以寫的程式。

更深層的原因是，數學研究是一個極高維度的技能。它不像 IMO 那樣有一套有限的已知技巧，而是需要各種完全不同的思維方式。Litt 指出，即使是頂尖數學家之間，能力的重疊也很有限。有些人擅長代數操作，有些人擅長幾何直覺，有些人根本沒有視覺想像力卻是傑出的幾何學家。目前只有三、四個前沿 AI 模型，它們的「思維方式」遠比人類數學家的多樣性要低得多。這在基準測試中已經反映出來了：不同模型能解的題目有很高的重疊度，而所有人類數學家加起來能解的題目範圍要大得多。

## 基準測試在測什麼？知識，不是推理

Litt 對 AI 數學基準測試提出了一個根本性的質疑。他認為，這些測試（包括他參與的 FrontierMath）主要測量的是「知識」，而不是「推理能力」。

他的邏輯是這樣的。當一個人類數學家解題時，人類的知識是很有限的。你可能有一個模糊的方向，然後在推導過程中發現自己需要某個中間結果。去發現這個中間結果的存在、去猜測它可能為真、然後去證明它，這整個過程需要大量的推理能力。但 AI 模型基本上「記住」了整個數學文獻。它已經知道那個中間結果存在，所以它需要的推理量遠遠少於人類。

換句話說，同一道題目，在人類身上測試的是推理能力，在 AI 身上測試的卻是知識量。一個人類如果能在 FrontierMath 上拿到 AI 目前的分數，他幾乎可以確定是一位非常成功的數學研究者。但 AI 拿到同樣的分數，卻沒有展現出對應的研究能力。這個落差恰恰說明了測試在測的東西不同。

Epoch AI 自己的分析也印證了這一點。他們測試 Gemini 2.5 DeepThink 的數學能力時，發現模型的分數和「背景知識難度」呈負相關，也就是說，需要越多專業背景知識的題目，模型表現越差。但分數和「創造力」評級之間沒有相關性。這意味著模型的瓶頸在於它有沒有看過相關的數學，而不是它能不能創造性地思考。

## AI 對數學最大的貢獻：降低嘗試的邊際成本

如果 AI 目前做不了真正的數學研究，那它到底幫了什麼忙？Litt 給出了一個非常清楚的框架：邊際成本。

數學研究中有大量「嘗試」的工作。你有一個猜想，想驗證一下，需要坐下來花幾天時間算一些例子。即使這些計算不需要多少創意，但它需要時間，而且你是個忙碌的人，手上還有其他更讓你興奮的研究。所以很多猜想就這樣擱著了，不是因為太難，而是因為嘗試的成本太高。

AI 把這個邊際成本壓得很低。現在 Litt 如果需要證明一個不等式，他的第一步是讓模型寫一些程式來探索整個空間的樣貌。如果想找一個滿足特定性質的代數簇，他可以讓模型開始亂試。這些嘗試不需要模型多聰明，只需要它能夠執行一些基本的數學操作然後回報結果。

他把這比作計算機對數學的影響。在 1960 到 1980 年代，電腦的出現讓數學家可以做以前不可能的搜尋。比如歐拉的冪次和猜想，第一個反例就是靠電腦暴力搜尋找到的。後來 Elkies 在 1988 年用一個巧妙的電腦搜尋解決了四次方的情形。AI 模型做的事情是同一條路線的延伸：以前你只能搜尋用程式可以完整表達的東西，現在你可以搜尋需要一點點人類判斷力的東西，因為模型可以提供那一點點判斷力。

但 Litt 特別強調，這些都是「摩擦力的降低」，不是「瓶頸的突破」。數學研究的真正瓶頸是「想出好的想法」，而大多數人一年只有幾個好想法。AI 目前對這個瓶頸幫助不大。

## 垃圾論文危機：當造假的邊際成本也降低了

邊際成本的降低是雙面刃。Litt 指出了一個令人擔憂的趨勢：AI 大幅降低了產出垃圾論文的成本。

他追蹤了一個很具體的現象。Hodge 猜想是六個未解的千禧年數學問題之一，因為光是理解問題的陳述就需要深厚的代數幾何背景，它長期以來「不受民科騷擾」。但 2025 年 9 月到 10 月，他注意到 arXiv 的代數幾何分類下，出現了大約 12 到 13 篇標題或摘要中帶有「Hodge Conjecture」的論文，來自大約六位不同的作者。除了一篇之外，全部是胡說八道。他無法「證明」這些是 AI 生成的，但從寫作風格來看，相當明顯。

以前要識別一篇民科論文只需要十秒鐘，因為文字本身就不通順。現在你可能需要花好幾分鐘，翻到論文中間才能發現某些陳述根本沒有意義。那篇他認為最認真偽裝的論文，引言寫得完全合理，還提出了相當戲劇性的宣稱，他得真正去讀中間的技術部分才確認是廢紙。

更令人擔心的場景是這樣的：一個認真的研究生，卡在證明中間的某個步驟，用 AI 模型生成了一段看起來合理但實際上有問題的證明。整篇論文 99% 可能是正確的，但那 1% 的錯誤讓整篇論文沒有價值。而這種錯誤非常難被審查者發現。數學界本來就有審稿危機，產出的論文數量遠超過能被仔細審查的量。AI 讓這個問題更加惡化。

Litt 用了一句話總結：「很多事情的關鍵在於邊際成本，而說謊和造假的邊際成本正在大幅下降。」

## 我的觀察：鋸齒邊界不只是數學的故事

Litt 描述的「jagged frontier」，其實是整個 AI 產業的隱喻，不只發生在數學領域。

想想你自己使用 AI 工具的經驗。有些任務 AI 做得令人驚嘆，比如翻譯一段技術文件、生成一段程式碼、整理會議紀錄。但另一些看似相近的任務，AI 卻會莫名其妙地失敗，比如理解一個微妙的文化梗、判斷一封客訴信背後的真正情緒、或者在一個你沒有明確指示的情境下做出合理的決策。能力的邊界不是一條平滑的線，而是鋸齒狀的：某個方向突出一大截，隔壁卻凹進去一大塊。

Litt 的「邊際成本」框架對台灣企業導入 AI 特別有啟發。很多企業在評估 AI 時，關注的是「AI 能不能取代某個職位」。但更實際的思路是：「AI 能不能降低某個嘗試的成本」。就像 AI 無法替 Litt 做數學研究，但可以讓他用很低的成本去試一些以前懶得試的東西。企業導入 AI 的最佳切入點，往往不是那些需要深度判斷力的核心決策，而是那些「其實不難但就是沒人有空去做」的嘗試性工作。降低嘗試的摩擦力，累積起來的效果可能比想像中大得多。
