<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI 科學研究 on AINEXT</title>
    <link>https://bnextmedia.github.io/AINEXT/tags/ai-%E7%A7%91%E5%AD%B8%E7%A0%94%E7%A9%B6/</link>
    <description>Recent content in AI 科學研究 on AINEXT</description>
    <generator>Hugo</generator>
    <language>zh-TW</language>
    <lastBuildDate>Fri, 26 Dec 2025 12:00:00 +0800</lastBuildDate>
    <atom:link href="https://bnextmedia.github.io/AINEXT/tags/ai-%E7%A7%91%E5%AD%B8%E7%A0%94%E7%A9%B6/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Scaling Law 的下一章：讓 AI 自己做實驗</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251226-new-scaling-law-ai-experiments-lila/</link>
      <pubDate>Fri, 26 Dec 2025 12:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251226-new-scaling-law-ai-experiments-lila/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自《NEJM AI Grand Rounds》2025 年 7 月播出的單集。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;iframe &#xA;    allow=&#34;autoplay *; encrypted-media *; fullscreen *; clipboard-write&#34; &#xA;    frameborder=&#34;0&#34; &#xA;    height=&#34;175&#34; &#xA;    width=&#34;100%&#34;&#xA;    style=&#34;border-radius: 12px; overflow: hidden;&#34; &#xA;    sandbox=&#34;allow-forms allow-popups allow-same-origin allow-scripts allow-storage-access-by-user-activation allow-top-navigation-by-user-activation&#34; &#xA;    src=&#34;https://embed.podcasts.apple.com/tw/podcast/can-ai-accelerate-science-dr-andy-beam-on-ais-next-frontier/id1657518313?i=1000717523879&#34;&#xA;    loading=&#34;lazy&#34;&#xA;  &gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;大型語言模型能通過美國醫師執照考試。這件事在 2020 年還是科幻小說，到了 2024 年已經沒有人會驚訝。但這裡有一個問題：通過考試是一回事，發現新藥是另一回事。&lt;/p&gt;&#xA;&lt;p&gt;LLM 能告訴你教科書裡寫了什麼，但它不能告訴你教科書還沒寫的東西。它能從現有文獻中找出最合理的假說，但它不能告訴你哪個假說是對的。要知道答案，你還是得做實驗。&lt;/p&gt;&#xA;&lt;p&gt;這是 Lila Sciences 技術長 Andy Beam 正在解決的問題。他的團隊正在打造一套系統，讓 AI 不只是讀論文，而是能自己設計實驗、自己執行、自己學習。這是他所謂的「新 Scaling Law」——當 pre-training 的邊際效益越來越低，下一個突破可能來自讓模型生成自己的訓練資料。&lt;/p&gt;&#xA;&lt;h2 id=&#34;pre-training-的極限&#34;&gt;Pre-training 的極限&lt;/h2&gt;&#xA;&lt;p&gt;先退一步，理解現在 AI 發展的瓶頸在哪。&lt;/p&gt;&#xA;&lt;p&gt;過去幾年 AI 的爆發式成長，靠的是一個經驗觀察：當你增加模型參數、訓練資料、和運算量，模型表現會以可預測的方式提升。這就是 Pre-training Scaling Law。OpenAI、Google、Anthropic 投入數十億美元建造超大規模運算叢集，都是基於這個定律會繼續成立的假設。&lt;/p&gt;&#xA;&lt;p&gt;但這個定律是 Power Law，指數關係。這意味著每一代要獲得同樣的進步，你需要把算力再擴大一個數量級——從一萬張 GPU 到十萬張，從十萬張到一百萬張。Meta 預計 2025 年底要部署 130 萬張 GPU，但即使如此，進步幅度可能也不會比以前更大。&lt;/p&gt;&#xA;&lt;p&gt;更麻煩的是，我們其實不知道這個定律為什麼會成立。Beam 用一個比喻來形容這種認知狀態：古埃及人能精確測量太陽的運行軌跡，精確到能把金字塔的東西軸對準春分點。但他們不懂軌道力學，不知道地球繞著太陽轉。我們對 Scaling Law 的理解，就處在類似的階段——精確測量，但缺乏根本性理解。&lt;/p&gt;</description>
    </item>
    <item>
      <title>那年被誤診的男孩，現在要讓 AI 自己做實驗</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251226-andy-beam-ai-scientist-whooping-cough/</link>
      <pubDate>Fri, 26 Dec 2025 10:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251226-andy-beam-ai-scientist-whooping-cough/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自《NEJM AI Grand Rounds》2025 年 7 月播出的單集。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;iframe &#xA;    allow=&#34;autoplay *; encrypted-media *; fullscreen *; clipboard-write&#34; &#xA;    frameborder=&#34;0&#34; &#xA;    height=&#34;175&#34; &#xA;    width=&#34;100%&#34;&#xA;    style=&#34;border-radius: 12px; overflow: hidden;&#34; &#xA;    sandbox=&#34;allow-forms allow-popups allow-same-origin allow-scripts allow-storage-access-by-user-activation allow-top-navigation-by-user-activation&#34; &#xA;    src=&#34;https://embed.podcasts.apple.com/tw/podcast/can-ai-accelerate-science-dr-andy-beam-on-ais-next-frontier/id1657518313?i=1000717523879&#34;&#xA;    loading=&#34;lazy&#34;&#xA;  &gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;那年夏天，一個剛從太空營回來的六年級男孩開始像狗一樣咳嗽。那聲音太奇怪了，他媽媽從沒聽過。幾天後的某個晚上，他咳到窒息、咳到嘔吐。隔天在小兒科診所，同樣的發作當場發生——劇烈咳嗽、支氣管痙攣、嘔吐。醫師的診斷是：鼻竇炎。&lt;/p&gt;&#xA;&lt;p&gt;這個男孩叫 Andy Beam。那次誤診改變了他的人生軌跡。&lt;/p&gt;&#xA;&lt;h2 id=&#34;誤診背後的認知盲點&#34;&gt;誤診背後的認知盲點&lt;/h2&gt;&#xA;&lt;p&gt;Beam 的母親知道這不是鼻竇炎。但她不知道是什麼，直到某天半夜醒來，想起小時候坐在外公車上的記憶。她的母親當時發生了同樣的事——在路邊咳到嘔吐。那是百日咳。&lt;/p&gt;&#xA;&lt;p&gt;第二天，母親打電話給小兒科醫師，問能不能是百日咳。醫師說：「有意思，我們剛接到 CDC 的電話，說附近有幾個確診案例。」檢查結果證實，Beam 確實得了百日咳。他父親的牙科診所因此關閉了幾週，CDC 人員來到他們家做全面調查。&lt;/p&gt;&#xA;&lt;p&gt;這件事讓 Beam 看見了一件重要的事：醫師不是神。那位小兒科醫師不是不專業，而是他執業多年，從來沒見過百日咳。這個疾病在美國幾乎已經根絕，它不在醫師的「記憶庫」裡。如果你用貝氏定理來看，Beam 的症狀幾乎百分之百指向百日咳——但醫師腦中的「近因偏誤」讓他完全看不見這個選項。&lt;/p&gt;&#xA;&lt;p&gt;這種認知偏誤是人類的共同弱點。醫師會累、會忘記、會被最近看過的病例影響判斷。Beam 當時還只是個孩子，但這個經驗在他腦中種下了一顆種子：電腦不會累，電腦可以讀完整個網路，電腦有完美的記憶。如果診斷是一種模式識別，電腦遲早會比人類做得更好。&lt;/p&gt;&#xA;&lt;h2 id=&#34;從改機-xbox-到訓練神經網路&#34;&gt;從改機 Xbox 到訓練神經網路&lt;/h2&gt;&#xA;&lt;p&gt;Beam 從小就是工程宅。幼兒園的「自由學習站」制度讓他整年都待在樂高區，結果幼兒園結束時還不會寫自己的名字。高中時他在社區大學修了 QBasic 程式課，從此確定自己要走電腦科學這條路。大學時期，他靠改機 Xbox 賺零用錢——在主機板上焊兩個點，就能刷 BIOS，把 Xbox 變成通用電腦。宿舍裡堆滿等待改機的 Xbox，一台收 50 美元。&lt;/p&gt;&#xA;&lt;p&gt;真正的轉折點是大四那年的 AI 課程。Russell 和 Norvig 那本綠色封面的教科書《人工智慧：現代方法》讓他大開眼界。課程談到西修斯之船、意識的本質，也談到 A* 搜尋和定理證明。這是他見過最有趣的學科，結合了哲學思辨和實用技術。他決定投入 AI 領域，然後開始回想：AI 能做什麼最有影響力的事？&lt;/p&gt;&#xA;&lt;p&gt;百日咳的記憶浮現了。答案是醫療。&lt;/p&gt;&#xA;&lt;p&gt;接下來的十幾年，Beam 沿著這條路一路走。他在北卡州大讀完統計碩士和生物資訊博士，研究貝葉斯神經網路。那是 GPU 運算剛起步的年代，沒有自動微分工具，他得手寫 CUDA 核心、手算反向傳播。2014 年他到哈佛做博士後，第一天就跟老闆 Zak Kohane 說：「我們需要更多 GPU。」Kohane 問為什麼，Beam 說：「神經網路會改變一切。」&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
