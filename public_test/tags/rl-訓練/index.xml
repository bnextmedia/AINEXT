<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>RL 訓練 on AINEXT</title>
    <link>https://bnextmedia.github.io/AINEXT/tags/rl-%E8%A8%93%E7%B7%B4/</link>
    <description>Recent content in RL 訓練 on AINEXT</description>
    <generator>Hugo</generator>
    <language>zh-TW</language>
    <lastBuildDate>Thu, 25 Dec 2025 10:30:00 +0800</lastBuildDate>
    <atom:link href="https://bnextmedia.github.io/AINEXT/tags/rl-%E8%A8%93%E7%B7%B4/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Ilya Sutskever：為什麼 AI 模型在測驗上很強，實際使用卻讓人抓狂？</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251225-ilya-sutskever-eval-vs-real-world/</link>
      <pubDate>Thu, 25 Dec 2025 10:30:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251225-ilya-sutskever-eval-vs-real-world/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Dwarkesh Podcast 2024 年 12 月播出的單集。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/aR20FWCCjAs&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;你有沒有遇過這種情況？&lt;/p&gt;&#xA;&lt;p&gt;你用 AI 寫程式，它很快生出一版。跑起來有 bug，你告訴它。它說：「天哪你說得對！讓我修一下。」然後製造了第二個 bug。你再告訴它，它又說：「天哪我怎麼會犯這種錯！」然後把第一個 bug 帶回來。你可以在這兩個 bug 之間無限循環。&lt;/p&gt;&#xA;&lt;p&gt;Ilya Sutskever 在訪談中描述了這個場景，然後問了一個尖銳的問題：「這怎麼可能？」&lt;/p&gt;&#xA;&lt;p&gt;一個模型能在各種困難的評測上拿高分，能解競程題目、能寫複雜程式，怎麼會在這種基本情境中卡住？&lt;/p&gt;&#xA;&lt;h2 id=&#34;這個矛盾有多嚴重&#34;&gt;這個矛盾有多嚴重？&lt;/h2&gt;&#xA;&lt;p&gt;Ilya 說，這是目前 AI 最讓人困惑的現象之一。&lt;/p&gt;&#xA;&lt;p&gt;「模型在評測上表現太好了。你看那些評測，會覺得『這真的很難耶』。但經濟影響卻遠遠落後。」&lt;/p&gt;&#xA;&lt;p&gt;他指的是，如果按照評測分數來看，這些模型應該已經能大幅提升生產力、改變工作方式。但實際上呢？大家確實在用，但還沒有看到那種「整個產業被翻轉」的效果。&lt;/p&gt;&#xA;&lt;p&gt;這個落差怎麼解釋？&lt;/p&gt;&#xA;&lt;h2 id=&#34;第一個解釋rl-訓練讓模型變成考試機器&#34;&gt;第一個解釋：RL 訓練讓模型變成考試機器&lt;/h2&gt;&#xA;&lt;p&gt;Ilya 提出的第一個解釋有點諷刺。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
