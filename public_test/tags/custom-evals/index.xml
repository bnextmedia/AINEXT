<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Custom Evals on AINEXT</title>
    <link>https://bnextmedia.github.io/AINEXT/tags/custom-evals/</link>
    <description>Recent content in Custom Evals on AINEXT</description>
    <generator>Hugo</generator>
    <language>zh-TW</language>
    <lastBuildDate>Thu, 25 Dec 2025 14:30:00 +0800</lastBuildDate>
    <atom:link href="https://bnextmedia.github.io/AINEXT/tags/custom-evals/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>AI 基準測試革命——為什麼通用評測無法告訴你 AI 能不能用在你的業務</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251225-ai-benchmarks-revolution-custom-evals/</link>
      <pubDate>Thu, 25 Dec 2025 14:30:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251225-ai-benchmarks-revolution-custom-evals/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Moonshots Podcast 2024 年 12 月播出的單集。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/7GFKB0oKd9A&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;每當 OpenAI、Anthropic 或 Google 發布新模型，科技媒體都會報導一串基準測試數字：HumanEval 編程能力提升 20%、GSM8K 數學推理進步 15%、MMLU 知識測試創新高。這些數字讓我們知道模型在「變強」，但它們回答不了一個關鍵問題：這個模型能不能用在我的業務上？&lt;/p&gt;&#xA;&lt;p&gt;「大部分公眾關注的焦點，到目前為止都放在大型公開基準上，比如編程能力測試，」Matt Fitzpatrick 在 Moonshots Podcast 上說。他曾在麥肯錫待了超過十年，領導 QuantumBlack Labs 的 AI 產品開發，現在是 Invisible Technologies 的 CEO。「這些基準對於衡量『模型整體上有沒有進步』很有用。但問題是，如果你是企業或小公司，你的基準不是寬泛的認知測試——而是特定任務的準確度，或者與人類表現的等效程度。」&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
