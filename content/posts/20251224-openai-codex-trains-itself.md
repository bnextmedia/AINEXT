---
title: "Codex 用 Codex 來訓練自己——AI 自我改進的第一個徵兆"
date: 2025-12-24T01:34:00+08:00
description: "OpenAI 內部正在發生一件有趣的事：Codex 正在幫忙訓練 Codex。這不是概念描述，而是字面上的意思——Codex 寫程式碼來監控自己的訓練過程、發現問題、做出決策。這是 AI 遞迴自我改進的早期形態嗎？"
tags: ["AI 自我改進", "OpenAI", "Codex", "AI 訓練", "AGI"]
categories: ["AI 產業"]
source_url: "https://www.youtube.com/watch?v=z1ISq9Ty4Cg"
source_name: "Lenny's Podcast"
draft: false
---

> 本文整理自 Lenny's Podcast 2024 年 12 月播出的單集，主持人 Lenny Rachitsky 專訪 OpenAI Codex 產品負責人 Alexander Embiricos。
> 收聽連結：[YouTube](https://www.youtube.com/watch?v=z1ISq9Ty4Cg)

---

## AI 在值班

OpenAI 內部有一個有趣的現象：Codex 正在幫忙訓練 Codex。

這不是一個概念性的描述，而是字面上的意思。Alexander Embiricos 在訪談中提到，Codex 寫了很多管理自己訓練運作的程式碼。更具體地說，他們讓 Codex「值班」——持續監控訓練過程中的各種圖表和指標，評估這些數據隨時間的變化，然後判斷需要採取什麼行動。

這代表什麼？想像一下訓練大型語言模型的場景。訓練過程會產生大量監控數據：loss 曲線、梯度變化、記憶體使用、GPU 利用率。傳統上，這些數據需要人類工程師盯著看，發現異常時做判斷——該調整學習率嗎？哪裡有 bug？需要重啟某個節點嗎？

現在，Codex 可以做這件事。它不只是被動地跑程式碼，而是主動地監控、分析、做決策。Embiricos 說，Codex 的 code review 功能已經抓到了不少錯誤，包括一些「相當有趣的配置錯誤」。這些是人類工程師可能會漏掉的、但 agent 因為持續監控而能夠發現的問題。

---

## Karpathy 的 Bug

這種能力的具體威力，可以從 Andrej Karpathy 的經驗看出來。

Karpathy 是 OpenAI 的共同創辦人、前特斯拉 AI 總監，是這個領域最頂尖的人之一。他在 Twitter 上分享過：他遇到最棘手的 bug——那種花好幾個小時也搞不清楚原因的問題——他會丟給 Codex，讓它跑一個小時。結果 Codex 把問題解決了。

關鍵不是 Codex 比 Karpathy 聰明，而是它可以用不同方式工作。持續嘗試、不會累、不會分心、不會因為挫折失去耐心。當一個問題需要的是大量試錯和排查，而不是天才級的洞察，這種「持久力」就變成優勢。

把這個能力應用到訓練監控上，你得到的是一個永遠不會疲倦的值班工程師。它可以 24 小時盯著訓練曲線，在任何異常發生的第一時間就做出反應。人類工程師需要睡覺、需要休息、注意力會分散。Codex 不需要。

---

## 遞迴改進的早期形態

這讓我想到一個更大的問題：我們是不是在看 AI 遞迴自我改進的早期形態？

「遞迴自我改進」是 AI 安全領域長期討論的概念。簡單說：AI 系統改進自己，變得更強之後又能更好地改進自己，形成加速的正向循環。這概念聽起來很科幻。有些人認為這是通往超級智慧的路徑，有些人認為這是需要非常謹慎對待的風險。

Codex 訓練 Codex 是不是這種遞迴改進？嚴格來說，還不是。目前的情況更像是 Codex 在做「輔助工作」——監控、debug、寫基礎設施程式碼——而不是直接改進自己的核心演算法。它沒有在調整自己的模型架構，沒有在改寫自己的訓練程式碼的核心邏輯。它是在處理週邊任務，讓人類研究員可以專注在更重要的決策上。

但這個區分可能比看起來更微妙。訓練一個好的模型，需要的不只是好的演算法，還需要穩定的基礎設施、可靠的監控、快速的問題排除。如果 Codex 讓這些「週邊任務」的效率提高十倍，那整個研發週期就會加快。研發週期加快，意味著更多的實驗、更快的迭代、更快地找到更好的方法。這是一種「間接」的自我改進，雖然不是直接改寫自己的權重，但效果可能同樣顯著。

---

## 還差什麼

如果這已經是遞迴改進的起點，為什麼我們還沒看到爆炸性的加速？

Embiricos 的分析指向一個關鍵限制：驗證。目前的 agent 可以做很多事，但驗證這些事情做對了沒有，還是需要人類。你讓 Codex 修一個 bug，它會給你一個修復方案，但你還是要自己看過、跑測試、確認沒有引入新問題。這個驗證環節，是目前整個流程的瓶頸。

為什麼驗證這麼難自動化？因為「對」的定義往往是模糊的、依賴上下文的、需要判斷的。一段程式碼可能在技術上沒有 bug，但不符合整體架構的設計原則。一個決策可能在短期內是對的，但長期來看有問題。這些判斷目前還是需要人類來做。

Embiricos 舉了一個有趣的例子。一個工程師在做 Atlas 專案（OpenAI 的瀏覽器）時，發現 Codex 沒辦法自己驗證它寫的程式碼。於是他做了一個巧妙的事：他提示 Codex「為什麼你不能驗證你的工作？去修好它」，然後讓這個過程循環跑。換句話說，他讓 Codex 去解決「讓 Codex 可以自我驗證」這個問題。

這是一個很元的解法。它展示了目前我們還需要人類在迴圈中，但也展示了人類可以把越來越多的工作——包括「讓 agent 更自主」這件工作本身——交給 agent 去做。

---

## 這對我們意味著什麼

看著 Codex 訓練 Codex，我有幾個想法。

第一，遞迴改進不會是一個「某天突然發生」的事件，而是一個漸進的過程。我們可能已經在這個過程的早期了，只是它發生得夠慢，以至於不會引起恐慌。這可能是好事——給我們時間適應、制定規範、建立安全措施。

第二，「AI 改進 AI」的能力會成為 AI 公司之間競爭的關鍵差異。如果 OpenAI 的 Codex 能夠顯著加速 OpenAI 的研發，而競爭對手沒有類似的工具，這個差距會隨著時間擴大。這可能解釋了為什麼 AI 公司這麼重視 coding agent——這不只是一個產品線，而是一個戰略資產。

第三，對於個人來說，理解這個趨勢可能比學會用特定工具更重要。工具會一直變，但「AI 輔助 AI 開發」這個方向不會變。如果你的工作跟 AI 開發相關，思考怎麼讓 AI 幫你做更多事，可能比埋頭苦幹更有槓桿效應。

Codex 訓練 Codex。這句話在兩年前聽起來像科幻，現在是 OpenAI 的日常運作。兩年後呢？
