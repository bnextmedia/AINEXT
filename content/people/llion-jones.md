---
# === 基本資訊 ===
title: "里昂・瓊斯 Llion Jones"
slug: "llion-jones"
name_zh: "里昂・瓊斯"
name_en: "Llion Jones"
name_full_en: "Llion Jones"

# === 照片 ===
photo: "/images/people/llion-jones.jpg"
photo_alt: "Llion Jones"
photo_credit: "Sakana AI"
photo_source: ""

# === 基本背景 ===
nationality: "英國（威爾斯）"
birth_year: 1985
birth_place: "英國威爾斯"
death_year: null
residence: "日本東京"

# === 現職 ===
current_position: "共同創辦人與技術長"
current_organization: "Sakana AI"
current_org_slug: "sakana-ai"

# === 簡介 ===
description_short: "Transformer 論文共同作者，Sakana AI 共同創辦人"
description_long: |
  Llion Jones 是「Attention Is All You Need」論文的共同作者，曾在 Google Research 東京工作超過十年。2023 年，他離開 Google，與 David Ha 共同創立 Sakana AI——一家位於東京的 AI 新創公司，專注於探索 Transformer 以外的新架構。諷刺的是，這位 Transformer 的發明者公開表示自己已經「受夠了 Transformer」，正在尋找下一個突破。

# === 人物分類 ===
person_type: ["科學家", "創辦人", "CTO"]
importance_level: "B"
importance_reason: "Transformer 共同作者，在 Google 最後一位離開，現在探索下一代 AI 架構"

# === AI 領域專長 ===
ai_domains: ["深度學習", "自然語言處理", "Transformer", "神經架構搜索"]
ai_impact_areas: ["LLM", "新架構研究", "AI 創新"]

# === 關鍵貢獻（白話解釋）===
key_contributions:
  - title: "Transformer 架構"
    description: "作為 Google Research 東京的研究員參與開發 Transformer 架構"
    impact_on_llm: "所有現代 LLM 的技術基礎"
    impact_on_other: "改變 AI 領域的發展方向"
    year: 2017
  - title: "Sakana AI"
    description: "創立專注於探索新 AI 架構的研究型新創公司"
    impact_on_llm: "挑戰 Transformer 的主導地位，探索替代方案"
    impact_on_other: "推動 AI 基礎研究的多元化"
    year: 2023

# === 代表作品 ===
representative_works:
  - title: "Attention Is All You Need"
    type: "論文"
    year: 2017
    description: "提出 Transformer 架構，被引用超過 17 萬次"
    url: "https://arxiv.org/abs/1706.03762"
  - title: "Sakana AI"
    type: "公司"
    year: 2023
    description: "探索新 AI 架構的研究型新創公司"
    url: "https://sakana.ai/"

# === 獲獎紀錄 ===
awards:
  - name: "NEC C&C Prize"
    year: 2024
    issuer: "NEC C&C Foundation"
    category: "computer_science"
    significance: "表彰 Transformer 團隊的開創性貢獻"

# === 學歷 ===
education:
  - institution: "伯明罕大學"
    institution_en: "University of Birmingham"
    degree: "人工智慧與電腦科學學士"
    field: "人工智慧與電腦科學"
    years: "2003-2006"
  - institution: "伯明罕大學"
    institution_en: "University of Birmingham"
    degree: "進階電腦科學碩士"
    field: "電腦科學"
    years: "2006-2007"

# === 職業經歷 ===
career_history:
  - organization: "Sakana AI"
    organization_en: "Sakana AI"
    position: "共同創辦人與技術長"
    years: "2023-現在"
    org_slug: "sakana-ai"
    description: "探索 Transformer 以外的新 AI 架構"
  - organization: "Google Research 東京"
    organization_en: "Google Research Tokyo"
    position: "研究科學家"
    years: "2011-2023"
    org_slug: "google"
    description: "從事大規模機器學習、NLP 研究超過十年"

# === 師承與門生 ===
mentors: []
notable_students: []

# === 重要論文 ===
publications:
  - title: "Attention Is All You Need"
    year: 2017
    venue: "NeurIPS"
    coauthors: ["Ashish Vaswani", "Noam Shazeer", "et al."]
    citations: 173000
    significance: "Transformer 原始論文"
  - title: "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
    year: 2020
    venue: "ICLR"
    coauthors: ["Alexey Dosovitskiy", "et al."]
    citations: 40000
    significance: "Vision Transformer (ViT)，將 Transformer 應用於影像"

# === 創立或參與的組織 ===
founded_companies:
  - name: "Sakana AI"
    year: 2023
    role: "共同創辦人與技術長"
    outcome: "獲得 Lux Capital、Khosla Ventures、NVIDIA 投資，募資超過 2 億美元"
    company_slug: "sakana-ai"

# === 重要言論 ===
notable_quotes:
  - quote: "我已經受夠了 Transformer。"
    context: "解釋為什麼要探索新架構"
    date: "2024"
    source: "TED AI"
  - quote: "我們需要跳脫漸進式改進 Transformer 的思維，尋找真正的新方向。"
    context: "在 TED AI 舊金山的演講"
    date: "2024"
    source: ""

# === 對 AI 發展的立場 ===
ai_safety_stance: "neutral"
ai_development_view: |
  Jones 認為 AI 領域過度依賴 Transformer 架構，需要更多基礎研究來探索替代方案。他在 Sakana AI 的工作專注於「自然啟發」的計算範式——從生物系統中學習，尋找比 Transformer 更高效、更通用的架構。

# === 相關人物 ===
related_people:
  - slug: "ashish-vaswani"
    relation: "Transformer 論文共同作者"
  - slug: "noam-shazeer"
    relation: "Transformer 論文共同作者"
  - slug: "david-ha"
    relation: "Sakana AI 共同創辦人與執行長"

# === 相關公司 ===
related_companies:
  - slug: "sakana-ai"
    relation: "創辦人與技術長"
  - slug: "google"
    relation: "前研究科學家（12 年）"

# === 社群連結 ===
social:
  personal_website: ""
  twitter: ""
  linkedin: "https://www.linkedin.com/in/llion-jones-9ab3064b/"
  github: ""
  google_scholar: ""
  wikipedia: ""

# === 延伸資源 ===
resources:
  - title: "Sakana AI 官網"
    url: "https://sakana.ai/"
    type: "official"
  - title: "CNBC 報導"
    url: "https://www.cnbc.com/2023/08/17/transformer-co-author-llion-jones-leaves-google-for-startup-sakana-ai.html"
    type: "article"

# === 標籤 ===
tags: ["Transformer", "Sakana AI", "日本", "新架構", "Google Research", "威爾斯"]

# === 元資料 ===
data_sources: ["LinkedIn", "CNBC", "Sakana AI"]
last_updated: "2026-01-26"
update_notes: "初始建檔"
draft: false
---

## 一句話認識他

**Llion Jones 是 Transformer 的發明者之一，但他現在公開表示「受夠了 Transformer」，創立 Sakana AI 尋找下一個 AI 架構突破。**

---

## 為什麼重要？

在「Transformer 八人幫」中，Llion Jones 是最後一個離開 Google 的人。他在 Google Research 東京工作了超過 12 年，見證了 Transformer 從一個想法變成改變世界的技術。

但他對此感到矛盾。

2024 年，在 TED AI 舊金山的演講中，Jones 說了一句讓人意外的話：「我已經受夠了 Transformer。」

這位 Transformer 的發明者認為，AI 領域現在過度依賴這個架構。所有人都在做同樣的事——把 Transformer 做得更大、更快、更便宜。但很少有人在問：有沒有更好的方法？

2023 年，Jones 離開 Google，與 David Ha（前 Google Brain 研究員）在東京創立 Sakana AI。公司的名字來自日文「魚」——象徵魚群如何用簡單規則形成複雜行為，就像集體智慧。

Sakana AI 的目標是探索 Transformer 以外的新架構，從自然界和生物系統中尋找靈感。他們已經獲得 Lux Capital、Khosla Ventures、NVIDIA 等頂級投資者超過 2 億美元的資金。

這是一個大膽的賭注：如果下一個 AI 突破不是來自更大的 Transformer，而是來自完全不同的東西呢？

---

## 關鍵貢獻

### 1. Transformer 架構（2017）

Jones 是「Attention Is All You Need」論文的八位共同作者之一。在 Google Research 東京，他專注於大規模機器學習和自然語言處理研究。

### 2. Vision Transformer（2020）

Jones 也是「An Image is Worth 16x16 Words」論文的共同作者。這篇論文將 Transformer 應用於圖像識別，創造了 Vision Transformer（ViT），證明 Transformer 不只能處理文字，也能處理影像。

### 3. Sakana AI：尋找下一個突破

2023 年創立的 Sakana AI 專注於探索新的 AI 架構。公司的研究方向包括：
- 自然啟發的計算範式
- 神經架構搜索
- 更高效的模型設計

---

## 人生軌跡

### 威爾斯到東京

Jones 來自英國威爾斯，在伯明罕大學完成人工智慧與電腦科學的學士和碩士學位。

2011 年，他加入 Google，後來轉到 Google Research 東京分部。在那裡，他專注於大規模機器學習和自然語言處理研究。

### Transformer 與其後（2017-2023）

2017 年，Jones 參與發表 Transformer 論文。這篇論文改變了整個 AI 領域，但 Jones 後來反思，這也讓研究變得過於單一——所有人都在做 Transformer 的變體。

在 Google 的最後幾年，Jones 開始思考：下一個突破會是什麼？

### Sakana AI（2023-現在）

2023 年 8 月，Jones 成為八位 Transformer 作者中最後一個離開 Google 的人。他與 David Ha 在東京創立 Sakana AI。

選擇東京有幾個原因：
- Jones 已經在東京工作多年
- 日本有獨特的 AI 研究傳統
- 遠離矽谷的喧囂，可以專注於長期研究

---

## 觀點與立場

### 「受夠了 Transformer」

Jones 的立場很明確：AI 領域需要更多基礎研究，而不只是把 Transformer 做得更大。他認為現在的研究太過漸進式——大家都在做同樣的事，競爭誰能訓練更大的模型。

他在 TED AI 的演講中呼籲 AI 社群「跳脫漸進式改進的思維，尋找真正的新方向」。

### 自然啟發的 AI

Sakana AI 的研究方向是從自然界尋找靈感。公司的名字「Sakana」（魚）就象徵這種理念——魚群用簡單規則形成複雜行為，這可能是設計 AI 系統的新方式。

---

## 延伸閱讀

### 推薦報導

- **CNBC**："Transformer co-author Llion Jones leaves Google for startup Sakana AI"
- **TED AI 演講**：Jones 談為什麼需要超越 Transformer

---

## 相關人物

- **[Ashish Vaswani](/people/ashish-vaswani/)**：Transformer 論文第一作者
- **[Noam Shazeer](/people/noam-shazeer/)**：Transformer 共同作者
- **David Ha**：Sakana AI 共同創辦人與執行長
