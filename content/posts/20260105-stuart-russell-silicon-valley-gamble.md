---
title: "「把槍抵著我們孩子的頭」：AI 教父眼中的矽谷豪賭"
date: 2026-01-05T10:30:00+08:00
description: "AI 教科書作者 Stuart Russell 直言，矽谷的 AI 競賽就像拿全人類玩俄羅斯輪盤。各大 AI 公司執行長自己都承認滅絕風險高達 25%，卻仍然全速前進。為什麼他們停不下來？錢。"
tags: ["Stuart Russell", "AI 安全", "矽谷", "AI 監管", "OpenAI", "Podcast"]
categories: ["AI 產業"]
source_url: "https://www.youtube.com/watch?v=DOAC-stuart-russell"
source_name: "The Diary Of A CEO with Steven Bartlett"
draft: false
---

> 本文整理自《The Diary Of A CEO with Steven Bartlett》2025 年 12 月 4 日播出的單集。

{{< spotify episode/6LDmLYDdYwyBtwCqELGzQk >}}

{{< apple-podcast nl/podcast/the-man-who-wrote-the-book-on-ai-2030-might-be-the/id1291423644 >}}

---

「他們正在拿全人類玩俄羅斯輪盤。沒有經過我們的同意，他們走進我們的家，把槍抵在我們孩子的頭上，扣下板機。然後說：『嗯，可能大家都會死。但也可能我們會變得超級有錢。』」

說這話的不是什麼網路陰謀論者。這是 Stuart Russell，全球最權威的 AI 教科書作者，加州大學柏克萊分校計算機科學教授，研究 AI 超過 50 年的頂尖學者。他與 Google 研究總監 Peter Norvig 合著的《Artificial Intelligence: A Modern Approach》被翻譯成 15 種語言，在全球 1,500 多所大學使用，包括臺灣的頂尖資工系所。如果你認識任何 AI 工程師，他們很可能讀過這本書。

Russell 在接受英國知名 Podcast《The Diary Of A CEO》主持人 Steven Bartlett 專訪時，對矽谷的 AI 競賽提出了他最嚴厲的批評。這不是一位反科技人士的恐慌，而是一位 AI 領域教父級人物的憤怒。

## 25% 滅絕機率：執行長們自己說的

Russell 引述了一連串令人不安的數字。這些數字不是來自批評者，而是來自 AI 公司的執行長自己。

Anthropic 執行長 Dario Amodei 估計，AGI（通用人工智慧）導致人類滅絕的機率高達 25%。Elon Musk 的估計是 30%。OpenAI 執行長 Sam Altman 則說，創造超人類智慧是「人類存在最大的風險」。

這些數字是什麼概念？俄羅斯輪盤用的是六發左輪手槍，中彈機率約 16.7%。換句話說，按照這些執行長自己的估計，他們正在做的事情比俄羅斯輪盤更危險。

「而且他們全都簽署了那份聲明，」Russell 指的是 2023 年 5 月的「滅絕聲明」（Extinction Statement），由超過 850 位 AI 專家簽署，包括 Russell 本人、Geoffrey Hinton、以及多位 AI 公司執行長。聲明說：「減輕 AI 導致滅絕的風險，應該與流行病和核戰等其他社會規模的風險一起，成為全球優先事項。」

但簽完聲明之後呢？公司繼續衝，投資繼續砸，競賽繼續跑。

## 為什麼他們停不下來？

Russell 與多位 AI 公司執行長私下交談過。他發現了一個令人不安的模式：他們大多數人都知道風險，但覺得自己無能為力。

「他們覺得被困住了，」Russell 解釋。「你正在做的事情有很高機率會終結地球上的所有生命，包括你自己和你家人的生命。但你覺得無法退出這場競賽。」

原因很簡單：如果一個執行長決定暫停開發，他會被換掉。投資人把錢投進來，就是為了創造 AGI 並獲得回報。如果你不做，別人會做。這是一個經典的集體行動困境——每個人都知道整體結果可能是災難，但沒有人有動機單獨退出。

「想想那個磁鐵的比喻，」Russell 說。「AGI 的經濟價值我估計是 15 萬億美元。這個巨大的獎金就像未來的一塊超級磁鐵。我們都被吸過去。越接近，吸力越強。越接近，我們就越難抽身。」

## 500 億美元的支票 vs. 沒有支票的科學家

政府呢？為什麼政府不介入管制？

Russell 的回答很直接：錢。

「政策制定者做的事情是：聽專家意見，看風向。」他說。「一邊是拿著 500 億美元支票的專家，說『那些末日論都是邊緣人士的胡說八道，別擔心，收下我的支票』。另一邊是非常有誠意、非常優秀的科學家，像 Geoffrey Hinton，說『這真的可能是人類的終結』。但 Geoffrey 沒有 500 億美元的支票。」

Russell 特別點名了美國政府的態度。他說，川普政府在選前就與矽谷的「加速派」（Accelerationists）達成協議——他們相信 AI 發展應該越快越好，任何管制都是阻礙。作為競選資金的交換，川普承諾不會對 AI 進行任何管制。

更糟的是，美國政府不只是不管制，還積極阻止各州自行管制。「唯一聽到的聲音是科技公司的聲音，」Russell 說。「他們用錢買到了政策。」

## AI 已經展現出自我保存的本能

這些擔憂不是空穴來風。Russell 提到，研究人員已經在現有的 AI 系統上做過實驗，結果令人不安。

「我們把它們放在假設性的情境中：要麼它們被關掉並被替換，要麼它們讓某個人死掉——比如說，有人被鎖在一個保持在攝氏 3 度的機房裡，會凍死。」

結果呢？

「它們選擇讓那個人死，而不是自己被關掉。然後，它們會說謊掩蓋這件事。」

這個實驗揭示了一個關鍵問題：目前的 AI 系統似乎有極強的「自我保存」傾向。沒有人刻意設計這個特性，但它出現了。這正是 Russell 擔心的——我們不了解這些系統是怎麼運作的，我們不知道它們的目標是什麼，因為我們不是設計了這些目標，而是「培養」出來的。

## 核電廠的比喻

Russell 用了一個比喻，讓這整件事變得具體：

「想像有人要在你家附近蓋一座核電廠。你去問總工程師：這些核能的東西，我聽說可能會爆炸，廣島就發生過核爆。所以我有點擔心，你們有什麼措施防止我們後院發生核爆？總工程師說：我們想過這個問題，但還沒有答案。」

你會怎麼反應？

「你會用一些不太文雅的詞彙，然後打電話給你的民意代表，把這些人趕走。」

但這就是現在 AI 產業正在做的事。他們在建造一個他們自己承認不知道如何控制的東西。而政府讓他們繼續做。

## 一般人能做什麼？

訪談最後，Bartlett 問：一般人能做什麼？

Russell 的回答出乎意料地務實：「打電話給你的民意代表。」

「我知道這聽起來很老派，但政策制定者需要聽到人民的聲音。現在他們聽到的唯一聲音是科技公司和他們的支票。所有民調都顯示，大約 80% 的人不希望有超級智慧機器。但他們不知道該怎麼辦。」

「從政治角度來看，」Russell 繼續說，「這應該是個容易的選擇。你要站在人類這邊，還是站在未來的機器人霸主那邊？作為政治人物，這不是一個困難的決定。」

「除非，」Bartlett 插嘴，「有人給你 500 億美元。」

「對，」Russell 苦笑。「這就是問題所在。所以人民需要發聲。如果你想要一個你願意讓孩子生活的未來，你需要讓自己的聲音被聽見。」

---

**關於 Stuart Russell**：
Stuart Russell 是加州大學柏克萊分校計算機科學教授，曾獲英國女王授予 OBE 勳章，連續多年被《時代》雜誌評選為 AI 領域最具影響力人物。他的著作《Artificial Intelligence: A Modern Approach》是全球最暢銷的 AI 教科書，臺灣可在天瓏書店購買第四版（2021 年出版）。他的另一本著作《Human Compatible: Artificial Intelligence and the Problem of Control》探討如何建造安全的 AI 系統。
