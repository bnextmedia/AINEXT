---
title: "AI 教父與 Google 首席科學家首度同台：從臥室裡的 AlexNet 到 Gemini 的誕生"
date: 2026-01-24T10:00:00+08:00
description: "Geoffrey Hinton 與 Jeff Dean 在 NeurIPS 2024 的對談，揭露了現代 AI 發展史上許多不為人知的故事——AlexNet 在學生臥室裡訓練、64 歲的 Hinton 成為 Google 實習生、在賭場舉行的收購拍賣，以及 Google 為何讓 ChatGPT 搶得先機。"
tags: ["Geoffrey Hinton", "Jeff Dean", "Google", "AlexNet", "Gemini", "TPU", "Transformer", "NeurIPS", "Podcast"]
categories: ["領袖思維"]
source_url: "https://www.youtube.com/watch?v=ue9MWfvMylE"
source_name: "Radical Talks"
draft: false
---

> 本文整理自 Radical Ventures 於 NeurIPS 2024 大會錄製的特別節目，由 Radical Ventures 創辦合夥人 Jordan Jacobs 主持。

{{< youtube ue9MWfvMylE >}}

{{< spotify "episode/2zM1FkXwxspjK1OlX7wMSU" >}}

{{< apple-podcast "tw/podcast/the-collaboration-that-built-modern-ai/id1524902736?i=1000741723764" >}}

---

如果要用一場對話來理解現代 AI 是怎麼走到今天的，大概沒有比這場更適合的了。

2024 年 12 月，在聖地牙哥舉辦的 NeurIPS 大會上，兩位塑造了這個時代的人物罕見地同台：Geoffrey Hinton，諾貝爾獎與圖靈獎得主，被稱為「AI 教父」的神經網路先驅；以及 Jeff Dean，Google 首席科學家、Gemini 團隊的共同負責人，也是過去二十年來最具影響力的系統工程師之一。

這不是一場充滿術語的技術演講，而是兩位老朋友的閒聊。他們回憶起第一次見面的餐廳名字、開玩笑說 Hinton 64 歲當 Google 實習生的窘境、還有那場在賭場樓上舉行的收購拍賣。在這些看似輕鬆的故事背後，藏著現代 AI 發展最關鍵的轉折點。

## 一切始於一間臥室

2012 年，深度學習還是個邊緣領域。當時多數電腦視覺研究者相信手工設計的特徵才是正途，神經網路被視為上個世紀的遺物。然後 AlexNet 出現了，在 ImageNet 競賽中以巨大的差距擊敗所有傳統方法，這個結果震驚了整個學術界。

但很少人知道，這個改變歷史的模型是在哪裡訓練的。

Hinton 在對談中揭露了這個細節：訓練 AlexNet 的電腦是兩張 GPU 顯卡，放在他的學生 Alex Krizhevsky 的臥室裡，而那間臥室在 Alex 父母的家中。Hinton 笑著說，他們付了顯卡的錢，但電費是 Alex 的父母出的，這當然是為了幫多倫多大學省錢。

這個畫面本身就是一個時代的縮影：改變世界的技術，不一定需要龐大的資源，而是需要正確的想法、正確的時機，以及願意嘗試的人。

故事還有前傳。在 AlexNet 之前，Hinton 實驗室的 Vlad Ni 就已經用 NVIDIA 的 GPU 來辨識航拍影像中的道路，並且證明了一個當時仍有爭議的問題：多層神經網路確實比單層的好，而且每加一層就更好。這項研究申請政府的「策略型補助」續約時，有位審查委員寫道：這項研究不可能有任何產業影響。

Hinton 說他很想知道那位審查委員是誰，因為他想告訴對方，這個「不可能有產業影響」的技術，貢獻了去年美國股市 80% 的成長。

## 64 歲的實習生

AlexNet 成功後，各大科技公司都想挖角 Hinton 的團隊。但 Hinton 早在 2012 年夏天就已經和 Google Brain 團隊建立了連結，而那段經歷本身就充滿了戲劇性。

當時 Andrew Ng 想專心發展 Coursera，需要有人接替他在 Google Brain 的顧問角色，於是推薦了 Hinton。問題是，短期訪問學者需要待滿六個月才能拿到正式身份，而 Hinton 只能待一個夏天。Google 的人資系統需要一個分類才能發門禁卡，最後唯一符合的選項是：實習生。

於是，64 歲的 Hinton 成了 Google 的實習生。

他回憶起第一天報到的場景：一個大教室裡坐滿了來自印度理工學院和清華大學的年輕學生，每個人都在筆電前操作。講師說「用你的 LDAP 和 OTP 登入」，Hinton 舉手問：什麼是 LDAP？什麼是 OTP？教室裡有四個助教在幫忙，十分鐘後，其中一個被指派專門服務他。那些年輕學生都在看這個顯然什麼都不懂、年紀是他們三倍的老人。

午餐時間，Hinton 正在排隊，一位他以前教過的大學生認出他喊了聲「Hinton 教授」，其他人這才恍然大悟。

在那個夏天，Hinton 第一次見到 Jeff Dean。他們約在帕羅奧圖一家叫 Tamarine 的越南餐廳，兩人一見如故。Hinton 說，從那之後他們一直相處愉快，「直到現在」——這句話引來現場笑聲。

## 賭場裡的收購拍賣

AlexNet 在 ImageNet 競賽奪冠後，所有大公司都想買下 Hinton 的團隊。Hinton 和他的學生 Ilya Sutskever、Alex Krizhevsky 決定成立一家公司叫 DNN Research，理由很務實：他們注意到公司付薪水的預算和做收購的預算是兩回事，後者通常大十倍，所以不如讓自己變成一個「收購標的」。

然後他們辦了一場拍賣。

那年的 NeurIPS（當時還叫 NIPS）在南太浩湖的一家賭場舉辦。Hinton 說，賭場一樓是吃角子老虎機和二十一點的賭桌，每次有人贏了一萬美元，鈴聲就會響起。而他們在樓上的房間裡進行拍賣，每次出價要加一百萬美元。

這場拍賣有個內幕：Hinton 早就決定 Google 必須贏，因為那年夏天在 Brain 團隊的經歷太愉快了。所以當拍賣進行到最後只剩兩家，而且看起來「錯誤的那家」可能會贏的時候，他們直接宣布拍賣結束。

為什麼選 Google 而不是另一個出價者百度？Hinton 的理由很直接：他當時沒辦法搭飛機（背部問題），永遠去不了北京，而且他覺得自己永遠搞不懂中國人在想什麼。在 Google，他知道會很開心。

## 「更大的模型、更多的資料、更多的算力」

Jeff Dean 加入這個故事的方式，同樣充滿了偶然。

2011 年左右，他在 Google 的茶水間撞見剛開始每週來一天的 Andrew Ng。Dean 問他在做什麼，Ng 說還不太確定，但在史丹佛，他的學生開始用神經網路得到不錯的結果。

Dean 自從大學畢業論文之後就沒有特別關注神經網路，但他一直記得這是個有用的抽象概念，感覺是「對的方向」。他當場提議：我們在 Google 有很多電腦，何不訓練真正巨大的神經網路看看？

當時 Google 的資料中心沒有 GPU，只有大量的 CPU 機器。Dean 建了一套軟體框架，可以把神經網路的運算切分到數千台機器上。他們最終訓練了一個比當時任何人都大 50 倍的模型，用 16,000 個 CPU 核心，在一千萬張隨機的 YouTube 影格上做無監督學習。

在那個過程中，他們觀察到一個現象：模型越大，效果越好。資料越多，效果越好。算力越多，效果越好。他們沒有把這叫做「Scaling Laws」，但他們有一句口號：「更大的模型、更多的資料、更多的算力。」

這意味著當 AlexNet 的結果出來時，Google 是少數不感到驚訝的組織之一。因為他們自己早就在 ImageNet 22K 的分類任務上看到了類似的進步。

## 2 million would do

Hinton 加入 Google 後，對企業資源的感受截然不同於學術界。

他記得有一次團隊的運算資源用完了。在大學，這種情況意味著要寫好幾年的補助申請。但他看到 Jeff Dean 拿起電話，他只聽到 Dean 這邊的對話，對方顯然在問需要多少錢。Dean 說：「嗯，兩百萬應該夠了。」

就這樣。

那時候的 Brain 團隊大約只有二十個人，全部擠在一間比會議室還小的辦公室裡。Hinton 說，那個時期的每個人回想起來都會說：那真是太好玩了。一切都是新的，我們不知道會走到哪裡，但每件事都在進步。

在那段時間，Hinton 做了兩件事。一件是 Capsules，他花了很多年研究，Jeff Dean 和 Ilya Sutskever 都勸他放棄，但這只讓他更堅持。他自嘲說，這是「用極大的決心做錯誤的事情會發生什麼」的最佳示範。

另一件是 Distillation（知識蒸餾），把大模型的知識壓縮到小模型裡。這篇論文在 2014 年被 NeurIPS 拒稿，審稿人說：蒸餾出來的學生模型又沒有比老師模型好，有什麼意義？

Hinton 說，後來這個技術變得非常有用，「你可以去問 DeepSeek」。

## Transformer：並沒有覺得特別重要

2017 年，Google Brain 發表了〈Attention Is All You Need〉，提出 Transformer 架構。今天回頭看，這篇論文是 ChatGPT、Gemini、Claude 等所有大型語言模型的基礎。但在當時，它只是眾多突破中的一個。

Dean 解釋了 Transformer 的技術脈絡。在那之前，他們用 LSTM 做序列到序列的學習，已經在機器翻譯等任務上取得很好的成績。但 LSTM 有兩個問題：一是每個時間步驟都依賴前一個步驟，沒辦法平行運算；二是要把所有資訊壓縮到一個固定大小的向量裡，資訊會「糊掉」。

Transformer 的核心想法是：不要壓縮，把所有狀態都存起來，需要的時候再用注意力機制去查。這樣既可以平行運算，又能清楚地參照之前的所有資訊。

第一篇 Transformer 論文就顯示，達到相同品質只需要十分之一到百分之一的運算量，或者用相同的運算量可以達到更高的品質。這顯然是大事。但 Dean 說，他當時並沒有覺得它比其他突破更重要，像是序列到序列模型、混合專家模型，每一個都很重要。他甚至說：「我現在也不確定它真的比其他的更重要。我們用它，是因為它很有用，僅此而已。」

Hinton 則坦承，他一開始沒有太注意 Transformer，因為它不符合生物可行性。大腦不可能儲存所有神經活動向量的副本，所以他覺得這不是大腦在做的事，就沒有深究。後來他發現可以用 fast weights 和聯想記憶來近似，但怎麼做穿越時間的反向傳播來學習，到現在還是個問題。

## 八萬人早就在用的聊天機器人

2022 年 11 月，ChatGPT 發布，舉世震驚。外界都在問：Google 的反應是什麼？是「紅色警戒」嗎？

Dean 說，他不會用「紅色警戒」這個詞。他寫了一份一頁的備忘錄，大意是：我們有點蠢。

Google 內部其實早就有一個聊天機器人，而且在 COVID 期間就開始使用。那是在大家都在家工作的時候開發的，內部有大約八萬名員工在用，回饋非常正面，大家都覺得很有用。

那為什麼沒有先發布？

Dean 說，問題出在認知框架。從搜尋的角度看，Google 最重視的是準確性和事實性。而那時候的語言模型有幻覺問題，會編造不存在的事情。如果你用搜尋的標準來看，這是不可接受的。

但他們沒有意識到，聊天機器人有很多用途跟搜尋無關：幫我寫一封信給獸醫談我生病的狗、幫我摘要這篇論文、幫我寫程式碼。這些任務不需要百分之百的事實準確性。

還有一個歷史教訓讓 Google 格外謹慎。Hinton 提醒說，在 ChatGPT 之前，微軟曾經發布過一個聊天機器人 Tay，結果它開始吐出仇恨言論，因為微軟讓它做線上學習，從使用者的互動中即時更新。那次事件嚇到了所有人。

Dean 說，ChatGPT 出來後，他很快就寫了那份備忘錄。內容是：我們不應該分散資源。Google 內部有原本的 DeepMind 團隊、Brain 團隊，還有 Google Research 的幾個不同計畫，各自在做文字模型和多模態模型。這意味著研究想法分散、算力也分散，這不合理。我們應該合併成一個團隊，集中資源，打造世界上最好的多模態模型。

這就是 Gemini 的起源。

## 走廊裡攔截財務長

Google 在 AI 領域的另一個關鍵優勢是 TPU。這個自主研發的機器學習專用晶片，讓 Google 不需要完全依賴 NVIDIA。

TPU 的起源是 2013 年，Dean 做了一個簡單的計算。當時他們在語音辨識上取得了很大的進步，模型品質好很多，但運算需求也高很多。如果這個更好的語音辨識要部署給使用者呢？

Dean 算了一下：假設一億人每天對著手機講三分鐘話，用 CPU 來跑這個模型需要多少運算？答案是：要把 Google 的電腦數量加倍。這在成本上可能勉強可行，但在時間上不可能。

他有個直覺：神經網路的運算很單純，只有幾種操作，而且對精度的要求不高。降低精度只是增加雜訊，而神經網路本來就喜歡雜訊。如果為神經網路專門設計硬體，應該可以獲得巨大的效能提升。

他在走廊上攔住了當時的財務長 Patrick Pichette，說服他投資五千萬美元來部署這些晶片，當時甚至還不完全確定要怎麼用。結果 TPU 被用在語音、視覺、翻譯等各種任務上，第一代 TPU 的論文顯示，效能比同期的 CPU 或 GPU 快 15 到 30 倍，每瓦效能高 30 到 80 倍。

這篇論文後來成為電腦架構頂級會議 ISCA 有史以來被引用最多的論文。

Dean 特別強調軟硬體協同設計的重要性。晶片開發需要兩到六年的時間，所以硬體設計師必須預測這個快速變化的領域在那麼遠的未來會走向何方。如果機器學習研究者和硬體團隊在同一個組織裡，可以一起討論哪些現在還不是主流但看起來有希望的方向，這就像是獲得了一個看向未來的更清晰的透鏡。

Google 甚至用強化學習來做晶片設計中的佈局和繞線，這個技術已經用在三代 TPU 上，不僅提高了晶片品質，也加快了開發速度。

## 「要麼幸福永遠，要麼全部死亡」

對談的最後，主持人問了一個大問題：二十年後，AI 會對世界產生什麼影響？

Hinton 的回答是一個他想像中的書名：「如果有人建造出它，我們要麼從此幸福快樂地生活，要麼全部死亡。」

他說，二十年後會發生什麼，沒有人知道。很清楚的是，很多工作會消失，但不清楚會不會有新工作來取代。這不是 AI 的問題，這是政治制度的問題。如果生產力大幅提升，財富要怎麼分配？至少在美國，目前的政府似乎不是處理這個問題的理想配置。

Dean 的看法比較樂觀，或者說更聚焦在正面的可能性。他去年和一群共同作者研究了 AI 可能帶來的影響，包括醫療、教育、創作新媒體，也包括就業衝擊、假訊息、地緣政治。他最興奮的是 AI 能夠加速科學發現，在不同領域之間建立人類個體難以察覺的連結。

Hinton 接著這個話題說了一個重要的觀點：這些大型模型把海量的知識壓縮到有限的參數裡，而壓縮的過程必然需要找出看似不同的知識之間的共通性。這意味著模型可能已經發現了希臘文學和量子力學之間的某種類比，而沒有人同時是這兩個領域的專家。

很多人說大型語言模型只是在「複述」訓練資料，沒有真正的創造力。Hinton 說這是胡說。他相信這些模型會非常擅長發現遙遠的類比，正是因為它們在做這種大規模的壓縮。

那麼哪個領域會被 AI 改變最多？Dean 和 Hinton 都認為是醫療和教育。

Hinton 解釋說，這兩個領域有一個特性：需求是彈性的。如果醫生的效率提高十倍，不是只需要十分之一的醫生，而是每個人都能獲得十倍的醫療照護。教育也一樣。我們知道私人家教的效果遠比課堂教學好，而幾年之內，AI 就會達到私人家教的水準，然後超越它，因為 AI 見過一百萬個學生。

這意味著每個人都能獲得以前只有特權階級才負擔得起的個人化教育。

## 我的觀察：框架的詛咒

這場對談最讓我震撼的，不是那些傳奇故事，而是 Jeff Dean 對「為什麼 Google 沒有先發布 ChatGPT」的坦白。

Google 內部有八萬人在用聊天機器人，回饋非常正面。他們有模型、有資料、有算力、有人才。但他們沒有發布，因為「從搜尋的角度看，幻覺是不可接受的」。

這是一個認知框架的問題，而不是技術能力的問題。

Google 的搜尋業務建立在「準確性」這個核心價值上。當你用這個框架去評估語言模型，你看到的是它的缺陷：它會編造不存在的引用、會自信地說出錯誤的事實。這些在搜尋的標準下都是致命傷。

但 OpenAI 沒有搜尋業務。他們看到的是：這個東西很有用，人們會想用它，我們先發布再說。

這讓我想到 Clayton Christensen 在《創新的兩難》裡描述的經典困境：既有的成功往往是創新的最大障礙。不是因為你沒有能力，而是因為你的評估標準被現有業務形塑了。

Dean 說他們「用搜尋的透鏡」看聊天機器人，所以沒看到它在搜尋以外的價值——幫忙寫信、摘要文章、當程式設計助手。這些事情不需要百分之百準確，八成準確就已經非常有用。

這個教訓對所有在位者都適用。當你評估一項新技術時，你用什麼標準？那個標準是從哪裡來的？它是否來自你現有的成功模式？如果是，你可能正在用錯誤的透鏡看未來。

Hinton 和 Dean 的對談還透露了另一件事：Google 最終的反應是打破組織藩籬。Gemini 的誕生不是因為發明了什麼新技術，而是因為 Dean 寫了一份備忘錄說「我們不應該分散資源」，然後把 DeepMind、Brain、和 Google Research 的團隊合併成一個。

換句話說，Google 的問題從來不是缺乏技術或人才，而是組織結構讓這些資源無法集中。這也是大公司常見的困境：各個團隊各自為政，每個都有自己的計畫和目標，結果在面對需要全力以赴的競爭時反而分身乏術。

這場對談最後以 Hinton 的警告作結。他說沒有人知道二十年後會發生什麼，可能很好，也可能很糟。但有一件事是確定的：這不是 AI 的問題，而是我們人類社會要怎麼應對的問題。

生產力即將大幅提升，財富要怎麼分配？工作會消失，人們要怎麼找到意義？這些問題的答案不在技術裡，而在政治、經濟、社會制度裡。

AI 教父和 Google 首席科學家聊了一個多小時，最後的結論是：技術我們大概能搞定，但人類社會能不能跟上，還很難說。
