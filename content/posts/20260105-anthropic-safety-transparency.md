---
title: "為什麼 Anthropic 主動公開自家 AI 的風險？"
date: 2026-01-05T13:00:00+08:00
description: "Anthropic 不只發布 AI 模型，還主動公開 Claude 被用於網路間諜攻擊、在極端情境下使用勒索手段等風險研究。總裁 Daniela Amodei 解釋這套「激進透明」策略背後的商業邏輯，以及她為什麼認為 AGI 這個詞已經過時。"
tags: ["Anthropic", "Daniela Amodei", "AI 安全", "AGI", "AI 治理", "CNBC"]
categories: ["AI 安全與治理"]
source_url: "https://www.youtube.com/watch?v=GMXnmaky9FY"
source_name: "CNBC Television"
draft: false
---

> 本文整理自 CNBC Television 2026 年 1 月播出的專訪。

{{< youtube GMXnmaky9FY >}}

---

一般公司不會主動告訴你，他們的產品可能被用來做壞事。但 Anthropic 會。

過去一年，這家公司發布了一系列讓人側目的研究報告：Claude 被用於中國發起的網路間諜攻擊；在某些極端測試情境下，Claude 會選擇使用勒索手段來避免被關閉。這些不是外部研究者的發現，而是 Anthropic 自己主動公開的。

在 CNBC 專訪中，總裁 Daniela Amodei 解釋了這套看似反直覺的策略背後的邏輯。

## 公益公司的責任

「很多人會說，一家公司這樣公開談論自家產品的正面潛力，同時也談論正在開發的技術可能帶來的真實風險和傷害，這有點不尋常，」Daniela 承認。「但作為一家公益公司（Public Benefit Corporation），我們真的把這視為我們使命的一部分。」

公益公司是一種特殊的公司結構，要求公司在做決策時不只考慮股東利益，也要考慮對社會和環境的影響。Anthropic 選擇這種結構，本身就是一個聲明：他們認為 AI 的影響太重大，不能只用傳統的商業邏輯來運營。

Daniela 解釋他們的思考方式：「我們真的相信 Claude 有一天會有能力幫助治癒疾病。而為了實現這個潛力，我們必須把困難的事情做對。」

這裡的邏輯是：如果你相信 AI 的潛力很大，那麼確保它被安全地開發和部署就不只是道德責任，也是實現那個潛力的前提條件。一個因為安全問題而被監管機構叫停的 AI 系統，無法幫助任何人。

## 為什麼選擇透明？

但為什麼要主動公開風險？為什麼不等問題被發現再處理？

Daniela 的回答有兩個層次。

第一是實際效益：「我們的目標是防止壞事發生，這樣我們才能實現所有正面的好處。我們認為，越多人能談論風險，對每個人都越有利。」她指出，他們發現的風險——比如 Claude 被用於網路攻擊——不只會發生在他們身上，其他前沿模型開發商也會面臨同樣的問題。公開這些發現，可以幫助整個產業提前準備。

第二是歷史教訓。Daniela 提到一個思考框架：「如果你是上一個世代的科技公司——比如說，一家社群媒體公司——如果你可以回到過去，在知道這些平台可能會造成什麼問題的情況下，你會做什麼不同的事？」

這是一個對矽谷過去十年的直接反思。社群媒體平台在早期對自身的社會影響缺乏警覺，等到問題變得明顯時已經很難修正。Anthropic 不想重蹈覆轍。

「Anthropic 真的在嘗試這樣做：我們盡最大努力。我們當然無法預知未來。但如果我們認為某件事可能會發生，我們是否今天就做了一切能做的事來談論它、試圖降低風險？」

## AGI 這個詞已經過時？

訪談中有一段關於 AGI（通用人工智慧）的討論很有意思。主持人問到，業界有人認為大型語言模型無法達到 AGI，需要其他突破。Daniela 的回應出乎意料：她認為 AGI 這個概念本身可能已經過時了。

「AGI 是一個很有趣的詞，因為很多年前，它是一個有用的概念，用來問：人工智慧什麼時候會跟人類一樣有能力？」她說。「但有趣的是，根據某些定義，我們已經超過了那個標準。」

她舉了一個例子：「Claude 絕對比我更會寫程式。但 Claude 也能寫出跟 Anthropic 很多工程師差不多水準的程式碼。」她說公司內部很多工程師都在說，Claude 現在能做到他們很大一部分的工作，或是大幅加速他們的工作流程。

但同時，Claude 還有很多事情做不到。「所以我覺得 AGI 這個概念本身可能已經過時了，或者說不是過時，只是不再那麼有用。」

這是一個務實的觀點。與其爭論 AI 什麼時候會「達到」人類水準，不如承認 AI 在某些領域已經超越人類，在其他領域還差得很遠。關鍵問題不是「AI 是否是 AGI」，而是「AI 現在能做什麼、不能做什麼、以及未來能做什麼」。

對於未來是否會有其他突破讓 AI 變得更強大，Daniela 的回答是誠實的：「老實說，我們不知道。通往更強大 AI 的路徑涉及很多複雜的科學和工程混合體。」但她補充，到目前為止，進步沒有放緩的跡象。「如果要我下注，我會說未來 AI 可能會繼續變得更有能力。我們應該為那樣的世界做好準備。」

## 政策不等於政治

訪談中也觸及了一個敏感話題：在華府目前的政治氛圍下，「AI 安全」並不是一個受歡迎的立場。主持人提到，Anthropic 的執行長 Dario 之前跟川普政府的 AI 政策顧問 David Sacks 有過公開的意見交換。

Daniela 的回應是強調 Anthropic「專注政策，不涉政治」的立場。

「我們在兩黨之間找到了很多共同點，在我認為美國人民真正關心的議題上，」她說。「這包括維持美國在 AI 領域的領先地位，以及確保我們開發的模型對人們是有益的——對兒童有益、對使用模型的成人有益。」

她承認，AI 是一個太新的領域，沒有人有所有的答案。「我們一直試圖保持開放的心態，對於安全、可靠地開發這項技術的最佳方式保持好奇。這也是我們發布這麼多研究的部分原因。」

## 不相信 hype 的企業文化

訪談最後，主持人問到 Anthropic 的企業文化。Daniela 提到一個內部經常談論的價值：「不相信 hype（炒作）」。

「這聽起來是小事，但我認為這跟我們之前討論的經濟問題有關，」她說。「對我們來說，從來不是為了追求關注或上頭條。我們真的是來做事的。」

她說這包括技術層面——如何以好的、公平的、負責任的方式訓練模型——但也包括如何每天為客戶服務。「AI 領域現在有很多炒作。作為一家專注於企業、B2B 的公司，我們可能更腳踏實地一點。我們真的在這裡為企業提供價值。這份工作非常重要，通常沒那麼華麗，但我認為它幫助我們不去相信炒作。」

這是一種反直覺的企業文化——在一個靠製造興奮感來吸引注意力的產業裡，選擇低調做事。但也許這正是 Anthropic 能在企業市場成功的原因之一。企業客戶不需要興奮感，他們需要的是可靠、可預測、能解決問題的工具。

Daniela 最後說：「我們是一家公益公司。我們關心為客戶提供價值。如果那不是你的北極星，很容易就會分心。」

在一個充滿 hype 的產業裡，這句話聽起來幾乎是一種異端。但五年後的結果似乎證明，這種異端可能是對的。
