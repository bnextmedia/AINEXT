---
title: "不要當末日派，也別盲目樂觀：Amodei 的「外科手術式監管」主張"
date: 2026-01-28T09:30:00+08:00
description: "AI 安全圈長期被末日派和加速派撕裂。Anthropic 執行長 Dario Amodei 試圖走第三條路：他批評末日論的「類宗教語言」，同時主張透明度立法優先於限制性法規。他提出分層監管框架，從加州 SB 53 到紐約 RAISE Act，試圖在不扼殺創新的前提下建立安全防線。"
tags: ["Dario Amodei", "Anthropic", "AI 監管", "SB 53", "RAISE Act", "AI 安全"]
categories: ["AI 安全與治理"]
source_url: "https://www.darioamodei.com/essay/the-adolescence-of-technology"
source_name: "Dario Amodei 個人網站"
image: "/images/posts/20260128-dario-amodei-regulation.jpg"
draft: false
---

> 本文整理自 Anthropic 執行長 Dario Amodei 於 2026 年 1 月發表的長文[《科技的青春期》（The Adolescence of Technology）](https://www.darioamodei.com/essay/the-adolescence-of-technology)。本篇為系列共五篇的第四篇，聚焦 Amodei 的監管哲學：他如何在末日派和加速派之間走出第三條路，以及他主張的「透明度優先」分層監管架構。強烈建議讀者閱讀原文全文。

---

## 被兩個極端撕裂的 AI 安全圈

如果你在過去三年關注過 AI 安全的辯論，你大概會認為這場辯論只有兩個陣營。

一邊是末日派。以 Eliezer Yudkowsky 為代表，他們認為超級智慧 AI 的出現幾乎必然導致人類滅亡。他們使用的語言帶有強烈的末世色彩——「存亡風險」、「最後的發明」、「人類物種的終結」。在 2023 到 2024 年的高峰期，這個陣營的聲量極大，催生了各種公開信、暫停呼籲和聳動的社群媒體帳號。

另一邊是加速派。以 Marc Andreessen 等人為代表，他們認為 AI 是人類史上最偉大的發明，任何監管都會扼殺創新、讓美國落後於中國。在他們看來，末日派的恐慌不只是錯誤的，更是危險的——因為它會催生過度監管，而過度監管才是真正的威脅。

Dario Amodei 在他的萬字長文中明確拒絕了這兩個陣營。而且他不是用「兩邊都有道理」的和稀泥方式，而是具體指出了兩邊各自的問題。

## 他對末日派的批評：語氣錯了

Amodei 對末日派的批評不是「你們說的不對」，而是「你們說的方式搞砸了一切」。

他指出 2023 到 2024 年的 AI 安全高峰期產生了三個負面效果。第一，出現了大量「聳動的社群媒體帳號」，用類似宗教的語言描述 AI 風險。第二，這些帳號和倡議者在沒有充分證據的情況下，呼籲採取極端行動——包括全面暫停 AI 開發。第三，也是最嚴重的，這種過度的末日敘事不可避免地觸發了反彈和文化極化。

結果就是：本來應該是嚴肅的技術安全討論，變成了一場文化戰爭。「你擔心 AI 安全」被貼上「你是末日派、你反科技、你想讓中國贏」的標籤。而「你不擔心 AI 安全」則被貼上「你是加速派、你只在乎利潤、你不在乎人類存亡」的標籤。中間地帶被擠壓殆盡。

Amodei 認為正確的態度是：冷靜、基於事實、承認不確定性。他在文中反覆強調——「這篇文章裡的任何內容都不代表確定性，甚至不代表高機率。」他不是說風險不存在，而是說我們應該用工程師排除故障的態度來面對風險，而不是用傳教士警告末日的態度。

## 透明度優先，限制其次

Amodei 的監管框架建立在一個核心原則上：先看清楚，再動手。

他稱之為「外科手術式監管」——介入要精準、負擔要最小、要隨時注意意外後果和反效果。而他認為，在目前的階段，最重要的不是限制 AI 公司能做什麼，而是要求它們公開說明自己在做什麼。

他具體支持的兩個立法是加州 SB 53 和紐約 RAISE Act。這兩個法案的共同特點是以「透明度」為核心，而非「禁令」為核心。它們要求前沿 AI 公司公開揭露模型的能力、已知的風險、安全測試的結果，以及防護措施的具體內容。但它們不禁止任何特定的研究方向或商業應用。

Amodei 的邏輯是分層的。他把監管想像成一個階梯：

第一階是透明度。要求公司公開資訊，讓社會——包括研究者、政策制定者和公眾——有足夠的資訊來判斷風險的嚴重程度。這是目前應該做的。

第二階是收集證據。在透明度的基礎上，系統性地評估各種風險是否正在成為現實。不是靠猜測，不是靠直覺，而是靠資料。

第三階才是限制性法規。只有在證據確實顯示某個風險正在「迫近且具體」的情況下，才實施更強的監管——而且這些監管必須是針對性的，不能是一刀切的。

他特別強調了一個設計細節：SB 53 和 RAISE Act 都包含小公司豁免條款。不太可能開發出前沿模型的小型公司和新創團隊，不需要承擔這些合規成本。這是為了避免監管成為大公司的競爭壁壘。

## Anthropic 自己在做什麼

Amodei 不只是在談「政府應該做什麼」，他也詳細描述了 Anthropic 在公司層級已經實施的安全措施。

最核心的是 Constitutional AI——一種用高層次的價值原則（而非具體規則）來訓練模型的方法。Amodei 的比喻是：與其告訴一個孩子「不准做 A、不准做 B、不准做 C」，不如培養他的判斷力和道德感，讓他自己在遇到新情境時做出正確決定。

在此基礎上，Anthropic 實施了多層防護。機械式可解釋性研究嘗試理解模型內部的運作邏輯——不是只看它輸出了什麼，而是看它「為什麼」輸出這個東西。預發布的對齊評估會在模型上線之前進行一系列壓力測試，包括測試模型是否能辨認出自己正在被測試（Sonnet 4.5 確實辨認出來了）。系統卡制度則要求公開揭露已知的問題行為和限制。

此外，Anthropic 還實施了專門針對生物武器的防護。在模型中部署了生物武器相關的分類器，會攔截可能被用於武器製造的查詢。Amodei 透露，這些分類器消耗了大約 5% 的推論運算成本——這是一個不小的數字，但他認為是必要的投資。

他也提到了 Responsible Scaling Policy（負責任擴展政策）和 AI Safety Level 3 保護措施。這些是 Anthropic 內部的自我約束框架，定義了在模型能力達到特定門檻時必須啟動的安全措施。

外部方面，Anthropic 接受 METR、NIST、英國 AISI 等第三方機構的評估，並且參與了 Frontier Model Forum 的產業協調。

## 為什麼「暫停 AI」行不通

Amodei 用了一段話直接回應了「暫停 AI 開發」的呼籲。他的論點是：暫停只會讓負責任的公司停下來，不會讓不負責任的公司和國家級行為者停下來。

這個論點的邏輯很直白。如果美國和歐洲的 AI 公司暫停開發，中國不會跟著暫停。軍事應用的研究不會暫停。黑市和地下實驗室不會暫停。結果就是：最有能力也最有意願實施安全措施的組織退出了競爭，而最不在乎安全的組織繼續前進。

他把這比喻成一個囚徒困境：每一方都有動機繼續開發，因為退出只會讓自己的處境變得更差。而打破囚徒困境的方式不是單方面停手，而是建立所有參與者都必須遵守的規則——也就是透過國際協調和立法來解決。

這也是為什麼他反對極端的監管提案。他擔心的不只是「扼殺創新」，更是「扼殺負責任的創新，同時對不負責任的參與者毫無影響」。

---

## 我的觀察

**「外科手術式監管」聽起來完美，但現實中的政府不會做外科手術。** Amodei 描繪的理想監管是精準的、基於證據的、最小負擔的。這在白板上畫起來很漂亮。但任何跟過一輪立法過程的人都知道，現實中的法規制定是緩慢的、粗糙的、被利益團體嚴重影響的。加州 SB 1047 的爭議就是最好的例子——原本是一個針對前沿模型的精準監管提案，最後在業界遊說和政治角力下面目全非。Amodei 的分層框架需要一個既精明又快速、還能抵抗遊說的政府來執行。但這種政府在任何民主國家都極其罕見。他的框架在理論上是所有方案中最好的，但在實踐上可能面臨最大的落差。讀者在評估這個方案時，不只要看「它設計得好不好」，更要問「它在現實的政治環境中能不能被正確執行」。

**他批評末日派的「語氣」，但他自己的文章也在製造緊迫感——只是用了不同的音調。** 在同一篇文章裡，Amodei 談了 AI 欺騙、生物武器、鏡像生命可能毀滅地球所有自然生命、極權 AI 帝國。他描述的風險嚴重程度，跟末日派其實沒有本質差異。差別在什麼？差別在他多了一句「但我們可以解決」，以及他始終用學術論文的冷靜語氣在講述這些可怕的事情。這不是矛盾，但讀者要清楚地意識到：語氣的冷靜不等於內容的溫和。一個穿白袍、語調平靜的醫生告訴你「你的腫瘤很嚴重但可以治療」，跟一個大喊「你快死了」的路人，傳達的資訊嚴重程度其實相差無幾。Amodei 是前者。你被他的語氣安撫了，不代表他說的事情不可怕。

**Anthropic 主動制定安全標準，然後遊說把它變成法律——這既是負責任，也是商業策略，讀者要同時看到兩面。** Anthropic 公開系統卡、接受第三方評估、實施 Constitutional AI、在分類器上投入 5% 的推論成本。這些都是真金白銀的投入，不是做做樣子。但換個角度看：當一家公司定義了一套安全標準，然後推動政府將這些標準寫入法律，它同時也在建立競爭壁壘。能負擔這些合規成本的公司，全球大概不超過五家。Amodei 設計了小公司豁免條款，試圖緩解這個問題，但開源社群和中型 AI 公司是否真的不受影響，還有待觀察。讀者不需要在「Anthropic 是真心做安全」和「Anthropic 在利用安全建立壁壘」之間二選一——因為兩件事完全可以同時為真。真正該問的問題是：如果 AI 安全的標準是由三五家最大的公司來定義的，那這些標準是否真的反映了公共利益，還是只反映了這幾家公司的利益？

---

### 本系列全部文章

本系列共五篇，整理自 Dario Amodei 的長文[《科技的青春期》（The Adolescence of Technology）](https://www.darioamodei.com/essay/the-adolescence-of-technology)：

1. [Anthropic 執行長萬字長文：人類正在經歷「文明的青春期」](/posts/20260128-dario-amodei-adolescence-of-technology-overview/)
2. [Amodei 直言：別把晶片和資料中心賣給中國，AI 極權是人類最大威脅](/posts/20260128-dario-amodei-ai-autocracy-geopolitics/)
3. [AI 取代白領不是危言聳聽：Amodei 預估一半初階白領工作將在數年內消失](/posts/20260128-dario-amodei-ai-economy-jobs/)
4. **本篇 →** 不要當末日派，也別盲目樂觀：Amodei 的「外科手術式監管」主張
5. [AI 正在加速開發下一代 AI：Amodei 描述的回饋循環為什麼讓人不安](/posts/20260128-dario-amodei-ai-feedback-loop/)
