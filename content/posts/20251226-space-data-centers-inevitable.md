---
title: "太空資料中心：為什麼「不信」等於不信運算會繼續成長"
date: 2025-12-26T11:00:00+08:00
description: "地球上的資料中心正面臨土地、水、電力三大限制。一位能源產業背景的研究者 Pranav Myana 認為，太空資料中心不是科幻，而是必然。他預測三年內，衛星上的 AI 推論成本將比地球更低。"
tags: ["太空資料中心", "SpaceX", "Starship", "AI 運算", "Pranav Myana", "Podcast"]
categories: ["科技趨勢"]
source_url: "https://www.youtube.com/watch?v=2gCZql8C0tk"
source_name: "TBPN"
draft: false
---

> 本文整理自 TBPN 2025 年 12 月 19 日播出的年終特別節目。

{{< youtube 2gCZql8C0tk >}}

{{< spotify "episode/1arhdqrFfjs9Dj3lt1qfoU" >}}

{{< apple-podcast "us/podcast/2025-in-review-cursor-acquires-graphite-tiktoks-%2450b/id1772360235" >}}

---

「如果你不相信太空資料中心，你就是不相信運算會繼續成長。」Pranav Myana 在 TBPN 的訪談中開門見山地說。這位能源產業背景的研究者，過去幾個月因為他的太空資料中心財務模型在科技圈引發討論。他的核心論點很簡單：地球上的資源是有限的，而太空的資源幾乎是無限的。

## 三大限制：土地、水、電力

理解太空資料中心的邏輯，要先理解地球資料中心正在面對的困境。Pranav 列出三個關鍵限制：土地、水、電力。這三者環環相扣，而且都在快速惡化。

電力是最直接的瓶頸。根據 Pranav 的說法，目前美國電網的互聯佇列（interconnection queue）裡，有超過 2,000 吉瓦（GW）的專案在等待審批——這個數字接近美國整體電網容量的兩倍。換句話說，想蓋資料中心的需求遠遠超過電網能承載的供給。而且這個問題不會自己解決，因為每一座新的資料中心都需要配套的變電站、輸電線路、甚至發電廠，這些基礎設施的建設週期以年計算。

更令人意外的是，很多 GPU 已經買了，卻用不了。Pranav 說，Google 和 Microsoft 手上有價值數億美元的 GPU「就放在那裡積灰塵」，因為沒有足夠的電力來運轉它們。這些晶片會折舊、會過時，但電力許可的審批流程不會因此加快。「AI 最大的威脅，」Pranav 說，「其實是縣政府許可辦公室那個叫 Doug 的人，他已經三週沒來上班了。」

水是另一個被低估的限制。現代資料中心需要大量的水來冷卻，尤其是當你把幾萬張 GPU 塞進同一個建築裡的時候。這在乾旱地區會引發社區反彈，在水資源豐富的地區則會遇到環保法規。土地限制同樣棘手——不是沒有空地，而是能同時滿足電力、水源、網路連接、且通過環評的空地越來越稀少。

## 太空的「優勢」：沒有這些限制

太空資料中心的吸引力，正是來自這些限制的解除。在太空中，太陽能是免費且充沛的——沒有大氣層遮蔽，沒有日夜週期（如果你的軌道設計得當），也沒有縣政府的許可流程。「我們的人類心智還沒進化到能理解太空有多大，」Pranav 說。當你開始用數學計算可用的資源時，太空的優勢變得非常明顯。

冷卻是一個常被提出的反對意見。在地球上，我們用空氣或水來帶走熱量。但太空是真空，沒有介質可以對流。Pranav 承認這是一個真實的工程挑戰，但他認為這是可解決的問題，而非根本性的限制。目前的設計思路是使用被動式散熱器（radiator）——基本上是一大片可以輻射熱量的表面。Starlink 衛星已經在用類似的設計，只是規模較小。

「熱的問題確實存在，」Pranav 說，「但物理學已經被解決了。剩下的是工程問題——電弧、電力電子、那些我們需要在太空中搞定的細節。這些問題一定會被解決。」

## 三年內成本低於地球？

Pranav 最大膽的預測是時間表。他引用 Elon Musk 最近的一則推文：在衛星上做本地化的 AI 推論，將在三年內成為生成 AI 位元流（bitstream）成本最低的方式。Pranav 說他正在獨立驗證這個說法，而他的初步結論是：這個時間表甚至可能更快。

這個論點的基礎是發射成本的學習曲線。1980 年代的太空梭時代，把一公斤物質送上軌道要 6 萬美元。SpaceX 的 Falcon 9 已經把這個數字降到約 1,500 美元。如果 Starship 成功並達到預期的複用率，成本還會再降一個數量級。「如果我們假設電腦會停留在 1980 年代的水準，」Pranav 說，「今天的電腦價格會是現在的一億倍。」同樣的學習曲線邏輯，應該也適用於太空發射。

當然，這個預測建立在幾個關鍵假設上。最重要的是 Starship 的成功與快速量產。如果 Starship 的發展停滯，或者複用率達不到預期，整個時間表就會延後。Pranav 承認他的模型假設 Starship 會成功，「如果你打賭 Starship 會失敗，那你也在打賭太空資料中心不會成真。」

## 推論先行，訓練更遠

一個重要的區分是：推論（inference）和訓練（training）是不同的工作負載。Pranav 認為推論會先上太空，因為它對延遲的容忍度相對較高，而且可以分散在許多小型衛星上。「如果你在北維吉尼亞，你離地面資料中心很近，延遲當然低。但對於全球 80% 不在北維吉尼亞、不在達拉斯的人來說，衛星網路的延遲可能反而更好。」

訓練則是另一回事。訓練大型模型需要數萬張 GPU 緊密協作，對網路頻寬和延遲的要求極高。這在太空中更難實現，至少在近期內是如此。但 Pranav 顯然也在思考這個問題——他提到正在建模「太空中的核融合資料中心」，並且已經在跟 Avalanche Fusion 的創辦人 Robin Langtry 討論這個方向。

## 光子運算：真正的未來？

訪談最後，Pranav 丟出了一個更大膽的想法：未來不只是 AI 軌道資料中心，而是「光學軌道資料中心」——用光子（photonics）取代電子來做運算。

光子運算的優勢在於矩陣乘法——這正是神經網路最吃運算的部分。光學元件天生就擅長這種運算，而且產生的熱量遠低於電子元件。「你可以想像電子在電路裡移動，就像把一個很重的箱子推過粗糙的地板，會有很多摩擦和熱量。光子通過波導移動時，幾乎不跟介質互動，熱的問題就小很多。」

這聽起來很科幻，但 Pranav 的態度是認真的。「光子運算現在非常早期，但這百分之百是未來。」

## Dyson Sphere 2100 年之前？

在訪談結束前，主持人問 Pranav：你接下來要建什麼模型？答案是 Dyson Sphere（戴森球）——一個環繞太陽、收集所有太陽能的巨型結構。「我還在試著把數學和物理算對，」Pranav 說，「但如果你問我的直覺——樂觀派的話——2100 年之前。」

這個回答被主持人敲了一記鑼。

---

太空資料中心的爭論，目前主要集中在時間表而非可行性。沒有人認為人類永遠不會在太空中建造大規模運算設施——問題只是這件事會發生在三年後、十年後、還是三十年後。Pranav 的觀點顯然站在激進的一端，他的模型也還需要更多驗證。

但他提出的核心邏輯很難反駁：如果你相信 AI 運算的需求會繼續指數成長，而地球的資源是有限的，那麼某個時間點，太空會變成唯一的選擇。唯一的問題是，這個「某個時間點」是什麼時候。

許可辦公室的 Doug 還沒回來上班。也許這就是答案的一部分。
