---
title: "80 年來首次，有人想重寫計算的底層架構"
date: 2025-12-25T14:30:00+08:00
description: "Unconventional AI 創辦人 Naveen Rao 正在嘗試一件「瘋狂」的事：用類比電路取代數位電路來執行 AI 運算。這不是漸進式改良，而是對計算本質的重新思考。"
tags: ["Unconventional AI", "Naveen Rao", "類比計算", "AI 晶片", "電腦架構"]
categories: ["科技趨勢"]
source_url: "https://www.youtube.com/watch?v=wZ4DT20OHXE"
source_name: "NeurIPS 2024 訪談"
draft: false
---

> 本文整理自 NeurIPS 2024 期間的訪談。

{{< youtube wZ4DT20OHXE >}}

---

1945 年，ENIAC 在賓州大學點亮。這台 30 噸重、佔據整個房間的機器，是現代數位計算的起點。從那之後的 80 年，我們基本上都在做同一件事：用 0 和 1 來表示一切，用邏輯閘來處理一切。處理器變快了、變小了、變省電了，但底層架構沒有根本性的改變。

現在有人想改變這件事。

---

## 數位計算的勝利與代價

要理解 Naveen Rao 在做的事，得先理解數位計算為什麼會贏。

1940 年代其實有兩種計算機在競爭。類比計算機用連續的物理量來代表數字——電壓、電流、旋轉角度。數位計算機則把一切離散化成 0 和 1。類比機器更直觀、更高效，但有一個致命傷：它無法規模化。

問題出在製造精度。當時的真空管特性會隨著溫度變化、隨著老化改變。如果你的計算依賴於電壓的精確值，這些微小的變異就會累積成嚴重的誤差。系統越大，誤差越難控制。數位計算繞過了這個問題：只要能可靠地區分「高」和「低」，中間的變異就不重要了。「我沒辦法精確描述中間的狀態，」Rao 解釋當年的困境，「但我可以說它是高還是低。」

這個選擇讓 ENIAC 得以用 18,000 個真空管構建出可用的計算機。之後的每一代技術——電晶體、積體電路、微處理器——都沿著同一條路前進。數位抽象成為計算的基礎語言，精確的數字運算成為一切應用的底層。這條路走了 80 年，從未被真正挑戰過。

---

## 「類比」不是落後，是不同

「類比」這個詞常被誤解成「落後」或「粗糙」。但它的本意是「類似於」——用一個物理系統來類比另一個物理系統。

風洞是經典的例子。如果你想知道空氣怎麼流過一架飛機，可以寫方程式、跑模擬、用超級電腦算流體力學。這是數位的方法。但工程師至今還是會造風洞，把縮小版的飛機模型放進去吹。讓真正的空氣流過真正的形狀，然後測量結果。為什麼？因為計算流體力學極其困難，數值解永遠有誤差，而且某些細節很難建模。真正的空氣「知道」自己該怎麼流動，你只需要問它。

這就是類比計算的本質：找到一個物理系統，讓它的行為「類似於」你想要計算的東西，然後讓物理自己給你答案。不是用數字去模擬現實，而是用現實來計算現實。

大腦是另一個存在證明。人腦的功耗約 20 瓦，貓腦只要 0.1 瓦。這些神經網路不是在「模擬」智慧，它們的物理結構本身就是智慧。神經元放電、化學物質擴散、突觸連結變化——這些物理過程直接構成了計算，沒有中間的抽象層。沒有記憶體和 CPU 之間的資料搬運，沒有數字表示法的精度損失，沒有 0 和 1 的編解碼開銷。

---

## 為什麼 AI 是類比的機會

Rao 的核心論點是：AI 可能是類比計算重新崛起的契機。

傳統的數位計算適合需要「精確」和「確定性」的任務。發射火箭需要精確計算軌道，金融系統需要精確追蹤每一分錢，密碼學需要確定性的演算法。這些場景，數位計算無可取代。

但神經網路不一樣。「神經網路本質上是一種隨機機器，」Rao 說。它不需要精確到小數點後第 16 位，它需要的是大量的平行運算和模式識別。訓練過程本身就充滿隨機性——隨機初始化、隨機抽樣、dropout。模型的「正確答案」從來就不是唯一的，而是一個機率分布。這種「天生模糊」的特性，恰好是類比電路擅長處理的。

更深層的問題是「時間」。數位計算沒有真正的時間概念——你用數字去「模擬」時間，把它當成一個變數來處理。但真實世界的時間是連續的、不可逆的、有因果性的。大腦的物理結構天生就嵌入了時間：訊號傳遞需要時間、突觸強化需要時間累積、記憶形成需要睡眠週期。這種「動態系統」的特性，可能無法被純粹的數字運算完全捕捉。

「動態系統意味著時間，」Rao 解釋。「在數位世界，我們沒有這個概念。我們用數字去模擬時間。」但如果你用物理過程本身來計算，時間就是內建的——電流流動需要時間、電容充放電需要時間、訊號在電路中傳播需要時間。這種「物理時間」可能比「模擬時間」更適合處理因果關係。

---

## Unconventional 的方法論

Rao 強調他們不是「晶片公司」，至少不是傳統意義上的。Unconventional 的前期工作更像是研究機構：搞清楚理論、建立數學框架、證明概念可行。

他們的起點是目前已知有效的 AI 架構。Transformer、擴散模型、流模型——這些東西已經證明能用，不該丟掉。但它們可以用不同的基板來實現。擴散模型和能量基礎模型特別有趣，因為它們本身就是用常微分方程來描述的，天生就有「動態」的特性。能不能找到一種物理系統，它的演化規律正好對應到這些方程式？如果可以，就能用物理本身來執行這些模型，而不是用數位電路去逐步計算。

「我們在尋找一種同構關係，」Rao 說，「在電路中找到能夠服務智慧的正確映射。」這不是把神經網路「翻譯」成電路圖那麼簡單，而是要找到物理和演算法之間更深層的對應。

實際建造會是混合訊號設計——既有類比也有數位。純類比系統太難控制，純數位系統又失去了效率優勢。他們需要的是在對的地方用對的技術。目標是五年內拿出可製造的原型，然後證明它能規模化。Rao 提到，他們的第一顆晶片可能會是「有史以來最大的類比晶片」——這本身就是一個工程挑戰。

---

## 40 年學術研究的收割期

類比 AI 晶片不是新概念。學術界研究這個方向超過 40 年了，為什麼現在才有機會商業化？

Rao 認為有三個關鍵變化。第一是製程技術。現代的 TSMC 能做到的精度，是 40 年前完全無法想像的。當年類比計算失敗的根本原因——製造變異導致的誤差——在奈米級製程下已經大幅改善。不是完全解決，但改善到可以應對。

第二是 AI 本身改變了賽局。過去沒有明確的「殺手應用」能夠撐起類比計算的商業價值。現在有了。AI 的算力需求如此龐大，能源成本如此高昂，任何能夠顯著提升效率的技術都有市場。這不是「也許有用」，而是「如果能用就是數十億美元的價值」。

第三是理論進展。過去四十年的學術研究累積了大量的存在證明：某些類比電路確實能執行神經網路運算、某些動態系統確實能實現學習、某些物理過程確實能模擬推理。這些零散的證據，現在需要被整合成可製造的產品。「偉大的工程就是利用別人造好的東西去做新的事，」Rao 說。學術界已經造好了很多零件，現在是組裝的時候。

---

## 如果成功會怎樣

如果 Unconventional 成功，影響遠超「省電」這個表面好處。

首先是 AI 的普及化。現在只有少數公司負擔得起訓練大型模型的電費。如果能效提升 10 倍、100 倍，AI 的進入門檻會大幅降低。更多玩家、更多實驗、更多創新——這是整個產業的加速。

其次是邊緣運算的突破。手機、汽車、機器人——這些設備無法接電線，電池容量有限。如果能在毫瓦級功耗下執行複雜的 AI 模型，應用場景會徹底改變。不是「雲端推論結果傳回來」，而是「在設備上即時處理」。

最後是對「計算」本身的重新定義。80 年來，我們把計算等同於數位計算。如果類比架構證明可行，可能會開啟一個新的範式——不同類型的問題用不同類型的基板來處理。數位處理精確計算，類比處理模式識別。就像人腦有不同區域負責不同功能，未來的計算系統可能也會是異質的。

「如果我們成功，世界不會忘記這件事，」Rao 說。「這會被寫進歷史書裡。」
