---
title: "寫 AI 教科書的人說：我會按下暫停鍵"
date: 2026-01-05T10:00:00+08:00
description: "Stuart Russell 是全球最暢銷 AI 教科書的作者，教出無數 AI 工程師。但這位 AI 領域的教父級人物，現在卻說如果有按鈕能暫停 AI 發展 50 年，他會按下去。這個矛盾背後，藏著他對人類存亡的深層憂慮。"
tags: ["Stuart Russell", "AI 安全", "AGI", "AI 監管", "Podcast"]
categories: ["AI 產業"]
source_url: "https://www.youtube.com/watch?v=DOAC-stuart-russell"
source_name: "The Diary Of A CEO with Steven Bartlett"
draft: false
---

> 本文整理自《The Diary Of A CEO with Steven Bartlett》2025 年 12 月 4 日播出的單集。

{{< spotify episode/6LDmLYDdYwyBtwCqELGzQk >}}

{{< apple-podcast nl/podcast/the-man-who-wrote-the-book-on-ai-2030-might-be-the/id1291423644 >}}

---

「如果有一個按鈕，按下去可以暫停 AI 發展 50 年，你會按嗎？」

「會。」

說這句話的人，是 Stuart Russell。

這個名字對一般人可能陌生，但如果你讀過資工系，或者認識任何 AI 工程師，你幾乎可以確定他們讀過 Russell 的書。他與 Google 研究總監 Peter Norvig 合著的《Artificial Intelligence: A Modern Approach》是全球最廣泛使用的 AI 教科書，從 1995 年出版至今已經發行到第四版，被翻譯成超過 15 種語言，在全球超過 1,500 所大學使用——包括臺灣。這本書在天瓏書店曾經是英文書銷售排行第一名，臺大、清大、交大的資工系學生很可能都接觸過這本被暱稱為「AIMA」的巨著。

換句話說，今天在 OpenAI、Google DeepMind、Anthropic 工作的許多 AI 工程師，都是讀 Russell 的教科書長大的。

而現在，這位 AI 領域的教父級人物，卻說他想按下暫停鍵。

## 這不是恐懼，是精算

在《The Diary Of A CEO》這集近兩小時的訪談中，主持人 Steven Bartlett 問了 Russell 一個尖銳的問題：「你對現在 AI 的發展方向感到困擾嗎？」

「困擾是太輕描淡寫了，」Russell 回答。「我感到震驚（appalled）。」

Russell 用了一個比喻：想像有人要在你家附近蓋一座核電廠。你去問總工程師：「你們有什麼措施防止核爆？」工程師說：「我們想過這個問題，但還沒有答案。」

你會怎麼反應？你會用一些不太文雅的詞彙表達你的憤怒，然後打電話給你的民意代表。

「這就是現在 AI 產業正在做的事，」Russell 說。「這些 AI 執行長們正在拿全人類玩俄羅斯輪盤——沒有經過我們的同意。他們走進我們的家，把槍抵在我們孩子的頭上，扣下板機，然後說：『嗯，可能大家都會死。但也可能我們會變得超級有錢。』」

這不是一位反科技人士的恐慌言論。這是一位用 50 年研究 AI 的頂尖學者，根據業界數據做出的判斷。根據 Russell 的引述，Anthropic 執行長 Dario Amodei 估計 AGI 導致人類滅絕的機率高達 25%。Elon Musk 的估計是 30%。OpenAI 執行長 Sam Altman 則說，創造超人類智慧是「人類存在最大的風險」。

這些數字是什麼概念？俄羅斯輪盤的中彈機率是六分之一，大約 16.7%。換句話說，這些 AI 公司的執行長認為，他們正在做的事情比俄羅斯輪盤更危險。

## 「猩猩困境」：為什麼智慧是最重要的

Russell 在訪談中提出一個他稱之為「猩猩困境」（The Gorilla Problem）的思想實驗。

幾百萬年前，人類這個物種從猩猩的演化線分支出來。現在，猩猩對自己的命運沒有任何發言權。如果人類決定讓猩猩滅絕，我們幾週內就可以做到。猩猩無法阻止我們，因為我們比他們聰明太多。

「智慧，」Russell 說，「是控制地球的最重要因素。」

這個類比的恐怖之處在於：如果我們創造出比人類更聰明的東西，我們就會變成猩猩。我們對自己的命運將失去發言權。

有些人會說：「那就把插頭拔掉啊。」Russell 對這種想法嗤之以鼻。「你以為一個超級智慧沒想過這一點嗎？它看過所有那些人類試圖拔插頭的電影。」

還有人說：「只要它沒有意識，就不會有危險。」Russell 認為這完全搞錯重點。「猩猩不會坐在那裡說：『唉，要是那些人類沒有意識就好了，一切都會沒事。』不會。讓猩猩滅絕的不是我們的意識，是我們的能力。」

他下了一個精準的結論：「我們該擔心的不是意識（consciousness），而是能力（competence）。」

## 為什麼他們停不下來

既然風險這麼高，為什麼這些公司不停下來？

Russell 說，他私下跟許多 AI 公司的執行長談過。令人震驚的是，他們大多數人都知道風險。他們並不是不了解情況，而是覺得自己被困住了。

「如果一個執行長決定說『我們不做這個了』，他會立刻被換掉，」Russell 解釋。「因為投資人投錢進來，就是為了創造 AGI 並獲得回報。如果你不做，別人會做。如果你停下來，你就出局了。」

這是一個集體行動的困境。每個參與者都知道整體結果可能是災難，但沒有人有動機單獨退出。這就像一群人一起衝向懸崖，每個人都知道懸崖在那裡，但沒有人願意第一個停下來，因為停下來就會被踩過去。

Russell 估計，明年（2026 年）全球投入 AGI 開發的預算將達到一兆美元。這是曼哈頓計畫（開發原子彈）預算的 50 倍。「這是人類歷史上規模最大的科技專案，而且沒有人在認真考慮安全問題。」

## 他的解方：不是更強的 AI，而是不同種類的 AI

訪談中最有建設性的部分，是 Russell 談到他認為可行的解決方案。

問題的核心在於：我們創造 AI 的方式錯了。目前的 AI 開發方式是「模仿學習」（imitation learning）——我們觀察人類的語言行為，然後讓機器盡可能地模仿。這樣創造出來的不是「工具」，而是「替代品」。

「我們正在創造的是模仿人類，」Russell 說。「所以當然它們會取代我們。它們不是工具。」

Russell 主張，我們應該創造一種根本不同的 AI——一種「唯一目標是實現人類想要的未來」的智慧。這種 AI 不會有自己的目標，而是會努力學習人類想要什麼，並幫助我們實現。

這聽起來很理想化，但 Russell 說這在數學上是可行的。問題是，這需要從頭開始的不同架構，而目前的公司都在瘋狂地往另一個方向跑。

## 「我願意用 50 年換安全」

訪談接近尾聲時，Bartlett 問了那個著名的「按鈕問題」：如果有一個按鈕可以永遠停止 AI 發展，你會按嗎？

Russell 猶豫了。「不是現在。我還覺得有一點希望能把事情導向正確的方向。」

「那如果是暫停 50 年呢？」

「會。我會按。」

他解釋：「我們需要時間回答兩個問題。第一，如何確保 AI 系統在數學上是安全的？第二，在一個 AI 可以做所有工作的世界裡，人類社會應該長什麼樣子？這兩個問題我們都還沒有答案。」

50 年聽起來很長。但 Russell 提醒：工業革命花了七、八十年才完成，過程中造成了巨大的社會動盪和苦難。AI 革命的規模可能是工業革命的十倍，但速度可能快十倍。如果我們沒有準備好，後果不堪設想。

訪談最後，Bartlett 問 Russell：一般人能做什麼？

「打電話給你的民意代表，」Russell 說。「政策制定者現在聽到的唯一聲音，是科技公司和他們 500 億美元的支票。如果你想要一個你願意讓孩子生活的未來，你需要讓自己的聲音被聽見。」

---

**延伸閱讀**：
- Stuart Russell 的著作《Human Compatible: Artificial Intelligence and the Problem of Control》（2019），中文版由商周出版
- 《Artificial Intelligence: A Modern Approach》第四版，臺灣可在天瓏書店購買
