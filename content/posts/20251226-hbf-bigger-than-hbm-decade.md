---
title: "十年後，HBF 會比 HBM 更重要：一場可能改變半導體版圖的技術革命"
date: 2025-12-26T11:30:00+08:00
description: "KAIST 金正鎬教授預測，HBF（高頻寬快閃記憶體）將在十年後超越 HBM 成為 AI 半導體的核心。他詳細解釋了 HBF 的技術原理、為什麼 AI 需要它、以及這對三星、SK 海力士、SanDisk 等記憶體廠商的戰略意義。"
tags: ["HBF", "HBM", "NAND Flash", "三星", "SK 海力士", "SanDisk", "金正鎬", "AI 半導體"]
categories: ["AI 產業"]
source_url: "https://www.youtube.com/watch?v=uJWZQb9rWUk"
source_name: "삼프로TV 언더스탠딩"
draft: false
---

> 本文整理自韓國財經節目《삼프로TV 언더스탠딩》2025 年 11 月播出的單集，來賓為 KAIST 電子及電機工程學部金正鎬教授。
> 🎬 YouTube：[連結](https://www.youtube.com/watch?v=uJWZQb9rWUk)

「HBM 這個詞，大家大概是一年前才開始聽到的。但這項技術從 2010 年就開始研發了，花了 15 年才變成今天的熱門話題。」

KAIST 電子及電機工程學部的金正鎬（Kim Jung-ho）教授在韓國財經節目中這樣說。作為 HBM 技術發展的早期參與者，他現在把目光投向了下一個十年：HBF（High Bandwidth Flash，高頻寬快閃記憶體）。

他的預測很明確：大約三年後，HBF 產品會開始量產；十年後，HBF 的市場規模會超過 HBM。到時候，這個你現在可能還沒聽過的名詞，會像今天的 HBM 一樣，成為半導體產業最熱門的關鍵字。

## 從 HBM 到 HBF：記憶體的下一個進化

要理解 HBF，首先要理解 HBM 解決了什麼問題。

傳統的電腦記憶體（DRAM）是平鋪在主機板上的，和處理器之間有一段距離。資料要從記憶體傳到處理器，得經過主機板上的線路，這條路既長又窄。當 AI 運算需要大量、快速地存取資料時，這條路就成了瓶頸。

HBM 的解決方案是：把 DRAM 晶片堆疊起來，像蓋大樓一樣一層一層往上疊，然後直接放在 GPU 旁邊。這樣做有兩個好處：第一，堆疊後的容量更大；第二，距離更近，資料傳輸更快。這就是為什麼 HBM 叫做「高頻寬記憶體」——它的資料傳輸頻寬遠超傳統 DRAM。

但 HBM 有一個根本限制：它的基底材料是 DRAM。DRAM 的特性是讀寫速度快，但儲存密度相對較低。以目前最先進的 HBM 產品來說，堆疊 12 層，總容量大約是 36GB；堆疊更多層可以到 48GB 或更高，但物理極限擺在那裡。當 AI 模型越來越大，需要儲存的「知識」越來越多時，HBM 的容量就不夠用了。

HBF 的概念就是：把 NAND Flash 也堆疊起來，放在 GPU 旁邊。NAND Flash 的儲存密度比 DRAM 高得多——同樣堆 16 層，HBF 的容量可以達到 HBM 的十倍左右。

## DRAM vs NAND Flash：兩種記憶體的本質差異

金教授在節目中用了兩個生動的比喻來解釋這兩種記憶體的差異。

DRAM 就像一個有門的水桶。你把水（資料）倒進去，門關起來就存住了。想讀資料的時候，把門打開，看看裡面有沒有水就知道了。這個過程很快，而且門可以反覆開關無限次。但問題是，這個水桶會漏水。放久了，水會慢慢流失，所以系統要定期「補水」（這叫做 Refresh）。而且水桶本身體積比較大，單位面積能放的水桶數量有限。

NAND Flash 則像一個監獄。資料進去之後，被高牆圍住，很難逃出來。這意味著斷電後資料還在，不需要補水。而且牢房可以做得很小，單位面積能關更多「犯人」（資料），儲存密度更高。但進出牢房很麻煩——要把資料寫進去，得用很高的「電壓」把犯人推過高牆（這是量子穿隧效應）；要清除資料，得來一次大規模「清場」。這個過程比較慢，而且每次進出都會對牆造成一點損傷。大約十萬次之後，牆就會破損，這個儲存單元就報廢了。

這就解釋了為什麼 HBM 和 HBF 會有不同的使用場景。HBM 適合那些需要頻繁讀寫的資料——就像你書桌上經常翻閱的參考書。HBF 則適合那些寫入一次、多次讀取的資料——就像圖書館裡的藏書，借閱頻繁但很少更新。

## AI 為什麼需要 HBF？

回到 AI 的場景。金教授把 AI 模型的運作比喻成「翻密碼本」：每次回答問題，AI 都要去查一本巨大的密碼本，找到對應的答案。這本密碼本就是模型的參數和 KV Cache。

關鍵在於：這本密碼本是「一次寫入、多次讀取」的。在模型訓練階段，密碼本會被寫入和更新。但一旦訓練完成，進入推論（inference）階段，密碼本基本上就固定了。每次使用者提問，AI 都是在讀取這本已經寫好的密碼本，而不是修改它。

這正好符合 NAND Flash 的特性：寫入次數有限，但讀取可以非常快速且頻繁。把密碼本存在 HBF 裡，既能獲得更大的容量（存更多知識），又不會因為頻繁寫入而損壞。

金教授進一步分析了 AI 發展的趨勢。目前的大型語言模型主要處理文字，密碼本的大小還算可控。但未來的 AI 會走向「多模態」——同時處理文字、圖片、影片、聲音。一張圖片的資料量是一段文字的上千倍，一段影片又是圖片的數十倍。當 AI 需要「理解」和「生成」影片時，密碼本的大小會爆炸式成長。

這時候，HBM 的容量就徹底不夠了。HBF 提供了一個解決方案：在 GPU 旁邊放一個容量大十倍的「大書庫」，用來存放那些龐大的多模態知識。

## 記憶體階層的重新設計

金教授在節目中展示了他對未來 AI 晶片架構的構想。這是一個四層的記憶體階層：

最頂層是 SRAM，直接嵌入在 GPU 內部，容量最小（不到 100MB）但速度最快。這是「書桌上攤開的那本書」。

第二層是 HBM，堆疊在 GPU 旁邊，容量約 100-200GB，速度次之。這是「書桌旁的小書架」。

第三層是 HBF，也堆疊在 GPU 旁邊，容量可達 1-2TB，速度比 HBM 慢但比遠端儲存快得多。這是「地下室的大書庫」。

第四層是網路儲存（SSD 陣列），容量幾乎無限，但需要通過網路傳輸，速度最慢。這是「城市裡的公共圖書館」。

在這個架構下，軟體會智慧地管理資料的放置：最常用的放 SRAM，次常用的放 HBM，不常改變但經常讀取的放 HBF，很少用的放遠端儲存。這就像一個有經驗的學者，知道把最常翻的書放在手邊，把整套百科全書放在地下室，只有需要冷門資料時才去圖書館。

## 競爭格局：誰會贏？

從技術角度來看，金教授認為有 HBM 經驗的公司會佔優勢。原因很直接：HBF 的核心挑戰和 HBM 類似——都是把記憶體晶片堆疊起來，然後用高速通道連接到 GPU。已經解決過這些問題的公司，不需要從零開始。

這意味著三星和 SK 海力士有先天優勢。它們不只有 HBM 的量產經驗，還同時擁有 NAND Flash 的技術。理論上，它們可以把 HBM 和 HBF 整合在同一個封裝裡，提供一站式解決方案。

但競爭不會這麼單純。SanDisk（剛從 Western Digital 分拆出來）是全球主要的 NAND Flash 製造商，它也有可能在 HBF 領域異軍突起。金教授提到，他兩週前才去美國和 SanDisk 進行了密集的技術交流。而 SanDisk 近期股價大漲，部分原因就是市場開始意識到 AI 對 NAND Flash 的需求在增加。

更有趣的是 NVIDIA 的角色。如果記憶體真的變成 AI 效能的決定性因素，NVIDIA 會不會直接收購一家記憶體公司？金教授認為這是一個合理的推測。NVIDIA 手上有足夠的現金和股票，買下 SanDisk 或 Micron 並不困難。這樣一來，NVIDIA 就能完全掌控從 GPU 到記憶體的整條供應鏈。

## 對韓國的戰略意義

金教授特別強調這對韓國半導體產業的意義。

目前，韓國在 DRAM 和 NAND Flash 市場都佔有領先地位。三星和 SK 海力士合計佔全球 HBM 市場超過 90%，NAND Flash 市場也佔約 50-60%。如果 HBF 成為下一個關鍵戰場，韓國有機會延續這個領先優勢。

但這需要及早投資。金教授回憶，2010 年代中期他開始倡導 HBM 投資時，有些公司猶豫不決，有些公司堅定執行。十年後的結果差異明顯。同樣的故事可能在 HBF 上重演——現在開始認真投入的公司，十年後會收穫成果。

他也提到一個更宏觀的視角：韓國一直想從「記憶體強國」升級為「系統半導體強國」。HBF 可能是一個橋樑。因為 HBF 不只是製造記憶體晶片，還涉及與 GPU 的協同設計、軟體最佳化、系統整合。這正好是韓國需要補強的領域。

金教授預計，2027 年左右會看到第一批 HBF 產品，2028 年開始商業化部署。他計畫在明年初舉辦 HBF 技術發表會，就像他之前為 HBM 做的那樣。如果歷史重演，這可能是一個改變半導體版圖的起點。

---

「Memory is hungry, Memory is foolish.」金教授在節目結尾引用了賈伯斯的名言，但把主詞換成了記憶體。在他看來，記憶體產業就像一個永遠餓著肚子、永遠不知滿足的巨獸。而這隻巨獸的下一餐，就是 HBF。
