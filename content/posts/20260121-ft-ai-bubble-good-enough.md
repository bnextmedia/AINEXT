---
title: "AI 不用比人強，「夠好就好」才是真正的威脅"
date: 2026-01-21T10:00:00+08:00
description: "《金融時報》記者圓桌討論 AI 泡沫，意外揭露一個殘酷現實：AI 不需要超越人類，只要「夠好又夠便宜」，企業就會選擇換掉你。創意產業首當其衝。"
tags: ["AI 泡沫", "金融時報", "創意產業", "勞動市場", "LLM", "Podcast"]
categories: ["AI 產業動態"]
source_url: "https://podcasts.apple.com/tw/podcast/tech-in-2026-inside-the-ai-bubble/id1169101860?i=1000745133717"
source_name: "FT Tech Tonic"
draft: false
---

> 本文整理自《金融時報》Tech Tonic 播客 2026 年 1 月播出的單集「Tech in 2026: Inside the AI bubble」。

{{< spotify "episode/7HcV208xC66wScYb1YjWho" >}}

{{< apple-podcast "tw/podcast/tech-in-2026-inside-the-ai-bubble/id1169101860?i=1000745133717" >}}

---

## 泡沫裡的清醒對話

當一家 AI 新創公司能在投資人連辦公室門都沒進去的情況下，募到 20 億美元——你就知道這個市場有多瘋狂。

《金融時報》的創投記者 George Hammond 分享了這個親眼見證的場景：OpenAI 前技術長 Mira Murati 創辦的 Thinking Machines Lab，投資人只能坐在門廳的小空間裡，什麼資訊都沒拿到，估值卻已經飆到 100 億美元。

這是泡沫嗎？矽谷創投的答案很坦白：「當然是泡沫，但泡沫很棒。」

他們的邏輯是：泡沫吸引人才、吸引資本、推動技術。十家投資的公司裡，九家會失敗，但只要有一家爆發性成功，就值得了。

但《金融時報》這場圓桌討論，真正有意思的不是泡沫會不會破，而是一個更實際的問題：**AI 到底會怎麼改變工作？**

## 放射科醫師還在，而且還缺人

2016 年，「AI 教父」Geoffrey Hinton 在一場會議上說：別再訓練放射科醫師了，AI 讀片已經比人類準確。

十年過去了，結果呢？放射科醫師不但沒減少，反而比以前更多，而且業界還在喊人手不足。

《金融時報》專欄作家 Sarah O'Connor 解釋：AI 確實能在某些影像上抓到人類可能漏掉的微小病灶，但放射科醫師的工作遠不只是「看圖」。而且 AI 在訓練資料充足的領域表現優異，但在資料不足的地方，仍然不如人類。

同樣的故事也發生在律師身上。幾年前大家擔心初級律師會被 AI 取代，結果呢？初級律師的薪水不降反升——經濟學家會告訴你，這代表需求根本沒有下降。

為什麼？因為這些行業對「準確性」的要求極高，而 LLM 有一個無法根除的問題：它會出錯，而且你無法預測它什麼時候會出錯。

AI 記者 Melissa Heikkilä 直言：「這是統計學和數學的現實，LLM 永遠會有某種程度的錯誤率。這不是能修好的 bug，而是技術的本質。」

## 但創意產業不一樣

這裡就是殘酷的分界線。

在醫療、法律、新聞這些行業，AI 的不可靠性形成了一道天花板。但在另一些行業——廣告、行銷、文案——「夠好就好」是完全可以接受的標準。

Sarah O'Connor 的預測很直接：「創意產業可能會開始看到更多的勞動市場衝擊。不是因為 AI 比最優秀的人類專業者更好，而是因為在很多應用場景裡，『夠好』就是夠好了。」

對於想削減成本的企業來說，這是一個太容易的選擇。

而且這種「夠好就好」的思維已經在蔓延。George Hammond 觀察到：AI 進入職場後，最明顯的效果不是取代工作，而是讓更多人能產出更多「平庸的東西」。社群媒體上已經被 AI 生成的低品質內容淹沒。

## 比失業更糟的事

還有一個很少人討論的面向：AI 可能讓沒被取代的工作變得更糟。

一位企業執行長告訴《金融時報》記者：當 AI 處理掉所有簡單的客服問題後，剩下的全是最棘手、最難搞的案例。原本那些讓工作日「還過得去」的輕鬆任務都消失了，留下來的只有憤怒的客戶和複雜的爭議。

這份工作本來就不是最有成就感的，現在變得更糟，薪水卻沒有變高。

Sarah O'Connor 指出，這其實是自動化歷史上一再出現的模式：技術淘汰某些人，同時讓留下來的人工作強度增加。

## 被綁架的風險

另一個被低估的風險：依賴 AI 服務供應商。

那些裁掉人力、全面導入 OpenAI 模型的企業，現在面臨幾個問題：

- 如果 OpenAI 漲價怎麼辦？
- 如果他們更新模型，導致你的系統全部壞掉怎麼辦？
- 如果你已經裁掉所有員工，卻發現自己被供應商綁住了？

這已經發生過。當 OpenAI 推出新模型時，一群重度使用者抱怨 AI 的「個性」變了，太過諂媚，公司被迫回滾。

你建立在別人模型上的一切，隨時可能因為對方的一次更新而崩潰。

## 2026 的預測

節目最後，三位記者各自給出預測：

**Melissa Heikkilä（AI 記者）**：「我希望 AI 變得無聊。無聊代表可靠，可靠才是我們對技術的期待。」

**George Hammond（創投記者）**：「我預期某家大型 AI 實驗室會出事。可能是競爭壓力、獲利問題、倫理爭議，或是版權官司。」

**Sarah O'Connor（勞動市場專欄作家）**：「我希望 AI 能幫我報帳和回信。但我擔心我們會在創意產業看到明確的衝擊——不是因為 AI 比人類好，而是因為有些公司會決定：它比較便宜。」

---

這場對話最清醒的地方在於：它沒有陷入「AI 萬能」或「AI 是騙局」的二元對立。

真正的問題不是 AI 能不能超越人類，而是在哪些領域，「夠好就好」會成為新標準——而你剛好在那個領域。
