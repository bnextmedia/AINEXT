---
title: "從資料標註到「養育人類的孩子」——AI 訓練的真相"
date: 2025-12-24
description: "Surge AI 創辦人 Edwin Chen 深度訪談：為什麼 AI 訓練不是「標註貓照片」？諾貝爾獎等級的詩如何定義品質、RL 環境如何模擬真實世界，以及為什麼人類在 AI 訓練中不會消失。"
tags: ["AI 訓練", "Surge AI", "RLHF", "資料標註", "Edwin Chen"]
categories: ["AI 產業"]
source_url: "https://www.youtube.com/watch?v=dduQeaqmpnI"
source_name: "Lenny's Podcast"
draft: false
---

> 本文整理自 Lenny's Podcast 與 Surge AI 創辦人 Edwin Chen 的訪談。
> 🎧 收聽連結：[YouTube](https://www.youtube.com/watch?v=dduQeaqmpnI)

---

說到 AI 訓練，很多人腦中浮現的畫面是：一群人坐在電腦前，在貓的照片上標註「這是貓」，在狗的照片周圍畫框框。這種工作聽起來很無聊、很機械、很容易被取代。

Edwin Chen 是 Surge AI 的創辦人，這家公司為所有主要 AI 實驗室提供訓練資料。他討厭「資料標註」這個詞。

「資料標註讓人想到這種簡單工作——標註貓的照片、畫 bounding box。我們做的完全不同。」他說。「我覺得我們做的事情更像是養育孩子。養小孩不只是餵他吃東西。你在教他價值觀、創造力、什麼是美、無數關於什麼讓一個人變好的微妙事情。我們對 AI 做的就是這件事。」

這個比喻不是誇張。如果你仔細理解現代 AI 是怎麼訓練出來的，你會發現這確實比「標註」複雜得多。

## 不只是「教會模型答案」

每一個你用過的大型語言模型——ChatGPT、Claude、Gemini——都經歷過一個叫「後訓練」（post-training）的階段。這個階段發生在模型已經從網路上學會大量文字知識之後。

預訓練只讓模型學會「預測下一個字」。你給它一個句子的開頭，它能猜出後面會接什麼。但這不代表它知道什麼樣的回答是好的。它可能給你一個在網路上常見的回答，但那個回答可能是錯的、有害的、或者根本沒用。

後訓練的目的是教會模型分辨品質。方法有很多種：SFT（監督微調）讓模型學習高品質的對話範例；RLHF（人類回饋強化學習）讓人類評估模型的回答，模型學習產生更受歡迎的回答；rubrics 和 verifiers 是各種評估和檢驗機制。

這些方法都需要人類參與。你需要有人產出高品質的範例，需要有人評估模型的回答，需要有人設計評估標準。這就是 Surge AI 在做的事。

## 諾貝爾獎等級的詩

Edwin 用一個例子來說明「品質」在這裡是什麼意思。

假設你要訓練模型寫一首關於月亮的八行詩。什麼叫「好」？如果你不深入思考，你會這樣檢查：這是詩嗎？有八行嗎？提到月亮嗎？符合這些條件，就是好詩。

「但這跟我們要的完全不同。」Edwin 說。「我們要的是諾貝爾獎等級的詩。這首詩獨特嗎？有細膩的意象嗎？會讓你驚喜、觸動你的心嗎？會教你一些關於月光本質的事情嗎？它可能是一首關於水面月光的俳句，可能用了內韻和格律，寫月亮的方式有一千種，每一種都能教你不同的東西——關於語言、意象、人類表達的可能性。」

這種品質很難測量。它非常主觀、複雜、豐富。但這就是 Surge 試圖達到的標準。

為了做到這點，他們建立了複雜的系統。每個工作者都有數千個信號被追蹤——他們的背景、專業領域、打字模式、回答品質。Surge 會用這些信號訓練自己的模型，預測哪些人擅長哪些任務，哪些資料真的能讓模型變得更好。

「我們最終會知道你擅長寫詩、還是擅長寫論文、還是擅長寫技術文件。」Edwin 解釋。「這就像 Google 搜尋用無數信號來判斷網頁品質——我們對我們的工作者和產出的資料做同樣的事。」

## RL 環境：模擬真實世界

AI 訓練正在進入一個新階段，Edwin 稱之為「RL 環境」（強化學習環境）。

「RL 環境本質上是真實世界的模擬。」他解釋。「想像你在建造一個有完整宇宙的電玩遊戲。每個角色都有真實的故事，每個企業都有可以呼叫的工具和資料，各種實體彼此互動。」

舉個例子：你可能建造一個模擬的新創公司世界，裡面有 Gmail 郵件、Slack 訊息、Jira ticket、GitHub PR、整個程式碼庫。然後突然間，AWS 掛了、Slack 也掛了。模型，你該怎麼辦？

模型必須在這個模擬環境中找出問題、採取行動、解決問題。這跟以前那種「給一個問題、寫一個答案」的訓練方式完全不同。模型需要跟各種工具互動，需要處理混亂的真實世界資訊，需要在一連串步驟中做出正確的決策——而且第 1 步的決定會影響第 50 步的情況。

「這些環境真的展現出模型在端到端真實世界任務上有多弱。」Edwin 觀察。「你有這些模型，在單獨的 benchmark 上看起來很聰明——單步驟工具呼叫很好、單步驟指令遵從很好。但把它們丟進這些混亂的世界，有令人困惑的 Slack 訊息、從沒見過的工具，需要執行正確的動作、修改資料庫、在更長的時間跨度上互動，它們就會以各種瘋狂的方式失敗。」

## 人類不會消失

有個很多人會問的問題：AI 會不會很快就能自己訓練自己，不再需要人類？

Edwin 的回答很直接：「這要到 AGI 才會發生。從定義上來說，如果我們還沒達到 AGI，就代表模型還有東西可以向人類學習。所以我不認為這會很快發生。」

他對 AGI 的時間線估計也比較保守。「人們沒意識到，從 80% 的表現到 90%，到 99%，到 99.9%，每一步的難度差異有多大。」他說。「我可能會猜，在未來一兩年內，模型會自動化一個普通 L6 軟體工程師 80% 的工作。但要到 90% 可能還要幾年，到 99% 又要幾年。所以我覺得我們離 AGI 還有大約十年或幾十年。」

這意味著在可預見的未來，訓練 AI 仍然需要大量人類專家的參與。不只是標註貓照片的人，而是各領域的頂尖專家——物理學家、詩人、程式設計師、律師、醫生——他們的專業知識和判斷力，是讓 AI 變得更好的關鍵。

## 一千種學習方式

Edwin 有一個更深層的信念：訓練 AI 需要模仿人類學習的各種方式。

「想想怎麼成為一個偉大的作家。你不是靠背一堆文法規則變好的。你讀好書，你練習寫作，你從老師和讀者那裡得到回饋，你注意什麼有效什麼沒效，你透過接觸傑作和糟糕的作品來培養品味。你在這個無盡的練習和反思循環中學習。」

每一種學習方式都不一樣。SFT 是一種，RLHF 是一種，rubrics 是一種，RL 環境又是一種。它們不是互相取代，而是互相補充——就像一個人成長過程中，閱讀、練習、得到回饋、觀察他人，都是必要的學習方式。

「我真的認為，我們需要建造一套產品，反映人類學習的千百種不同方式。」Edwin 說。這就是為什麼 Surge 不只做一件事，而是不斷開發新的產品線來配合 AI 訓練方法的演進。

## 養育人類的孩子

訪談的最後，Edwin 回到了那個比喻。

「很多人以為資料標註是很簡單的工作——標註貓照片、畫框框。我一直很討厭『資料標註』這個詞，因為它呈現的是一個非常簡化的畫面。」

「我覺得我們做的事情更像是養育孩子。養小孩不只是餵他吃東西。你在教他價值觀、創造力、什麼是美、無數關於什麼讓一個人變好的微妙事情。這就是我們對 AI 做的事。」

「所以我經常把我們做的事情想成——這是人類的未來，或者說，我們在養育人類的孩子。」

---

*這個視角改變了我們理解 AI 訓練的方式。這不是一個會被自動化取代的機械工作，而是一個需要人類判斷力、專業知識、甚至「品味」的複雜過程。至少在接下來十年或更久，我們需要的是能夠教導 AI「什麼是好」的人——不是能畫框框的人，而是知道什麼是諾貝爾獎等級詩歌的人。*
