<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Scaling Laws on AINEXT</title>
    <link>https://bnextmedia.github.io/AINEXT/tags/scaling-laws/</link>
    <description>Recent content in Scaling Laws on AINEXT</description>
    <generator>Hugo</generator>
    <language>zh-TW</language>
    <lastBuildDate>Mon, 05 Jan 2026 11:30:00 +0800</lastBuildDate>
    <atom:link href="https://bnextmedia.github.io/AINEXT/tags/scaling-laws/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>2030 不歸點：AI 教父的末日時鐘</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20260105-stuart-russell-event-horizon/</link>
      <pubDate>Mon, 05 Jan 2026 11:30:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20260105-stuart-russell-event-horizon/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自《The Diary Of A CEO with Steven Bartlett》2025 年 12 月 4 日播出的單集。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;iframe &#xA;    src=&#34;https://open.spotify.com/embed/episode/6LDmLYDdYwyBtwCqELGzQk&#34; &#xA;    width=&#34;100%&#34; &#xA;    height=&#34;152&#34; &#xA;    frameBorder=&#34;0&#34; &#xA;    allowfullscreen &#xA;    allow=&#34;autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture&#34; &#xA;    loading=&#34;lazy&#34;&#xA;    style=&#34;border-radius: 12px;&#34;&#xA;  &gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;iframe &#xA;    allow=&#34;autoplay *; encrypted-media *; fullscreen *; clipboard-write&#34; &#xA;    frameborder=&#34;0&#34; &#xA;    height=&#34;175&#34; &#xA;    width=&#34;100%&#34;&#xA;    style=&#34;border-radius: 12px; overflow: hidden;&#34; &#xA;    sandbox=&#34;allow-forms allow-popups allow-same-origin allow-scripts allow-storage-access-by-user-activation allow-top-navigation-by-user-activation&#34; &#xA;    src=&#34;https://embed.podcasts.apple.com/nl/podcast/the-man-who-wrote-the-book-on-ai-2030-might-be-the/id1291423644&#34;&#xA;    loading=&#34;lazy&#34;&#xA;  &gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;「我們可能已經越過了事件視界。」&lt;/p&gt;&#xA;&lt;p&gt;這是 OpenAI 執行長 Sam Altman 在他的部落格《溫和的奇點》（The Gentle Singularity）中寫下的一句話。Stuart Russell 在接受《The Diary Of A CEO》專訪時，解釋了這句話的真正含義。&lt;/p&gt;&#xA;&lt;p&gt;Russell 是全球最權威的 AI 教科書《Artificial Intelligence: A Modern Approach》的作者，這本書被翻譯成 15 種語言，在全球超過 1,500 所大學使用，包括臺灣多所頂尖資工系所。他研究 AI 超過 50 年，曾獲英國女王授予 OBE 勳章，並連續多年被《時代》雜誌評選為 AI 領域最具影響力人物。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Anthropic 只花對手十分之一的錢，為什麼還能贏？</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20260105-anthropic-efficiency-strategy/</link>
      <pubDate>Mon, 05 Jan 2026 10:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20260105-anthropic-efficiency-strategy/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 CNBC Television 2026 年 1 月播出的專訪。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/GMXnmaky9FY&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;一千億美元對上一兆四千億美元。這是 Anthropic 與 OpenAI 目前在算力投資承諾上的差距——將近十四倍。但如果你問業界人士，哪家公司的模型在過去兩年最常被認為是「最強」，答案經常是 Anthropic 的 Claude。這個數字與結果之間的落差，正是 Anthropic 總裁 Daniela Amodei 在 CNBC 專訪中最想解釋的事。&lt;/p&gt;&#xA;&lt;h2 id=&#34;用更少資源做更多事&#34;&gt;用更少資源做更多事&lt;/h2&gt;&#xA;&lt;p&gt;Daniela Amodei 是 Anthropic 的共同創辦人暨總裁，負責公司營運、業務發展與客戶關係。她的哥哥 Dario Amodei 是執行長，專注於技術願景。在這場訪談中，Daniela 坦承 Anthropic 的算力資源「一直只有競爭對手的一小部分」，但她認為這反而成為公司的核心優勢。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Neolab 爭議：沒有百億美元，AI 新創還能怎麼贏？</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251226-neolab-ai-startup-without-scale/</link>
      <pubDate>Fri, 26 Dec 2025 12:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251226-neolab-ai-startup-without-scale/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 TBPN Podcast 2025 年 12 月播出的單集。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/DRZatti6mVM&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;iframe &#xA;    src=&#34;https://open.spotify.com/embed/episode/6IaZ6BSNKkQQy6y4mmGQVN&#34; &#xA;    width=&#34;100%&#34; &#xA;    height=&#34;152&#34; &#xA;    frameBorder=&#34;0&#34; &#xA;    allowfullscreen &#xA;    allow=&#34;autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture&#34; &#xA;    loading=&#34;lazy&#34;&#xA;    style=&#34;border-radius: 12px;&#34;&#xA;  &gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;iframe &#xA;    allow=&#34;autoplay *; encrypted-media *; fullscreen *; clipboard-write&#34; &#xA;    frameborder=&#34;0&#34; &#xA;    height=&#34;175&#34; &#xA;    width=&#34;100%&#34;&#xA;    style=&#34;border-radius: 12px; overflow: hidden;&#34; &#xA;    sandbox=&#34;allow-forms allow-popups allow-same-origin allow-scripts allow-storage-access-by-user-activation allow-top-navigation-by-user-activation&#34; &#xA;    src=&#34;https://embed.podcasts.apple.com/us/podcast/amazon-x-openai-fords-ev-reality-check-kushner-drops/id1772360235?i=1000741755977&#34;&#xA;    loading=&#34;lazy&#34;&#xA;  &gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;「Scale is all you need。」這句話在 AI 圈幾乎成了信條。OpenAI、Anthropic、Google DeepMind 這些頂尖實驗室，都在瘋狂擴大運算規模，動輒燒掉數十億甚至上百億美元。Scaling Laws 的信仰者認為，只要持續加大模型參數、增加訓練資料、堆疊更多運算，AI 的能力就會持續提升。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Scaling Law 的下一章：讓 AI 自己做實驗</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251226-new-scaling-law-ai-experiments-lila/</link>
      <pubDate>Fri, 26 Dec 2025 12:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251226-new-scaling-law-ai-experiments-lila/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自《NEJM AI Grand Rounds》2025 年 7 月播出的單集。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;iframe &#xA;    allow=&#34;autoplay *; encrypted-media *; fullscreen *; clipboard-write&#34; &#xA;    frameborder=&#34;0&#34; &#xA;    height=&#34;175&#34; &#xA;    width=&#34;100%&#34;&#xA;    style=&#34;border-radius: 12px; overflow: hidden;&#34; &#xA;    sandbox=&#34;allow-forms allow-popups allow-same-origin allow-scripts allow-storage-access-by-user-activation allow-top-navigation-by-user-activation&#34; &#xA;    src=&#34;https://embed.podcasts.apple.com/tw/podcast/can-ai-accelerate-science-dr-andy-beam-on-ais-next-frontier/id1657518313?i=1000717523879&#34;&#xA;    loading=&#34;lazy&#34;&#xA;  &gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;大型語言模型能通過美國醫師執照考試。這件事在 2020 年還是科幻小說，到了 2024 年已經沒有人會驚訝。但這裡有一個問題：通過考試是一回事，發現新藥是另一回事。&lt;/p&gt;&#xA;&lt;p&gt;LLM 能告訴你教科書裡寫了什麼，但它不能告訴你教科書還沒寫的東西。它能從現有文獻中找出最合理的假說，但它不能告訴你哪個假說是對的。要知道答案，你還是得做實驗。&lt;/p&gt;&#xA;&lt;p&gt;這是 Lila Sciences 技術長 Andy Beam 正在解決的問題。他的團隊正在打造一套系統，讓 AI 不只是讀論文，而是能自己設計實驗、自己執行、自己學習。這是他所謂的「新 Scaling Law」——當 pre-training 的邊際效益越來越低，下一個突破可能來自讓模型生成自己的訓練資料。&lt;/p&gt;&#xA;&lt;h2 id=&#34;pre-training-的極限&#34;&gt;Pre-training 的極限&lt;/h2&gt;&#xA;&lt;p&gt;先退一步，理解現在 AI 發展的瓶頸在哪。&lt;/p&gt;&#xA;&lt;p&gt;過去幾年 AI 的爆發式成長，靠的是一個經驗觀察：當你增加模型參數、訓練資料、和運算量，模型表現會以可預測的方式提升。這就是 Pre-training Scaling Law。OpenAI、Google、Anthropic 投入數十億美元建造超大規模運算叢集，都是基於這個定律會繼續成立的假設。&lt;/p&gt;&#xA;&lt;p&gt;但這個定律是 Power Law，指數關係。這意味著每一代要獲得同樣的進步，你需要把算力再擴大一個數量級——從一萬張 GPU 到十萬張，從十萬張到一百萬張。Meta 預計 2025 年底要部署 130 萬張 GPU，但即使如此，進步幅度可能也不會比以前更大。&lt;/p&gt;&#xA;&lt;p&gt;更麻煩的是，我們其實不知道這個定律為什麼會成立。Beam 用一個比喻來形容這種認知狀態：古埃及人能精確測量太陽的運行軌跡，精確到能把金字塔的東西軸對準春分點。但他們不懂軌道力學，不知道地球繞著太陽轉。我們對 Scaling Law 的理解，就處在類似的階段——精確測量，但缺乏根本性理解。&lt;/p&gt;</description>
    </item>
    <item>
      <title>那年被誤診的男孩，現在要讓 AI 自己做實驗</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251226-andy-beam-ai-scientist-whooping-cough/</link>
      <pubDate>Fri, 26 Dec 2025 10:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251226-andy-beam-ai-scientist-whooping-cough/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自《NEJM AI Grand Rounds》2025 年 7 月播出的單集。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;iframe &#xA;    allow=&#34;autoplay *; encrypted-media *; fullscreen *; clipboard-write&#34; &#xA;    frameborder=&#34;0&#34; &#xA;    height=&#34;175&#34; &#xA;    width=&#34;100%&#34;&#xA;    style=&#34;border-radius: 12px; overflow: hidden;&#34; &#xA;    sandbox=&#34;allow-forms allow-popups allow-same-origin allow-scripts allow-storage-access-by-user-activation allow-top-navigation-by-user-activation&#34; &#xA;    src=&#34;https://embed.podcasts.apple.com/tw/podcast/can-ai-accelerate-science-dr-andy-beam-on-ais-next-frontier/id1657518313?i=1000717523879&#34;&#xA;    loading=&#34;lazy&#34;&#xA;  &gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;那年夏天，一個剛從太空營回來的六年級男孩開始像狗一樣咳嗽。那聲音太奇怪了，他媽媽從沒聽過。幾天後的某個晚上，他咳到窒息、咳到嘔吐。隔天在小兒科診所，同樣的發作當場發生——劇烈咳嗽、支氣管痙攣、嘔吐。醫師的診斷是：鼻竇炎。&lt;/p&gt;&#xA;&lt;p&gt;這個男孩叫 Andy Beam。那次誤診改變了他的人生軌跡。&lt;/p&gt;&#xA;&lt;h2 id=&#34;誤診背後的認知盲點&#34;&gt;誤診背後的認知盲點&lt;/h2&gt;&#xA;&lt;p&gt;Beam 的母親知道這不是鼻竇炎。但她不知道是什麼，直到某天半夜醒來，想起小時候坐在外公車上的記憶。她的母親當時發生了同樣的事——在路邊咳到嘔吐。那是百日咳。&lt;/p&gt;&#xA;&lt;p&gt;第二天，母親打電話給小兒科醫師，問能不能是百日咳。醫師說：「有意思，我們剛接到 CDC 的電話，說附近有幾個確診案例。」檢查結果證實，Beam 確實得了百日咳。他父親的牙科診所因此關閉了幾週，CDC 人員來到他們家做全面調查。&lt;/p&gt;&#xA;&lt;p&gt;這件事讓 Beam 看見了一件重要的事：醫師不是神。那位小兒科醫師不是不專業，而是他執業多年，從來沒見過百日咳。這個疾病在美國幾乎已經根絕，它不在醫師的「記憶庫」裡。如果你用貝氏定理來看，Beam 的症狀幾乎百分之百指向百日咳——但醫師腦中的「近因偏誤」讓他完全看不見這個選項。&lt;/p&gt;&#xA;&lt;p&gt;這種認知偏誤是人類的共同弱點。醫師會累、會忘記、會被最近看過的病例影響判斷。Beam 當時還只是個孩子，但這個經驗在他腦中種下了一顆種子：電腦不會累，電腦可以讀完整個網路，電腦有完美的記憶。如果診斷是一種模式識別，電腦遲早會比人類做得更好。&lt;/p&gt;&#xA;&lt;h2 id=&#34;從改機-xbox-到訓練神經網路&#34;&gt;從改機 Xbox 到訓練神經網路&lt;/h2&gt;&#xA;&lt;p&gt;Beam 從小就是工程宅。幼兒園的「自由學習站」制度讓他整年都待在樂高區，結果幼兒園結束時還不會寫自己的名字。高中時他在社區大學修了 QBasic 程式課，從此確定自己要走電腦科學這條路。大學時期，他靠改機 Xbox 賺零用錢——在主機板上焊兩個點，就能刷 BIOS，把 Xbox 變成通用電腦。宿舍裡堆滿等待改機的 Xbox，一台收 50 美元。&lt;/p&gt;&#xA;&lt;p&gt;真正的轉折點是大四那年的 AI 課程。Russell 和 Norvig 那本綠色封面的教科書《人工智慧：現代方法》讓他大開眼界。課程談到西修斯之船、意識的本質，也談到 A* 搜尋和定理證明。這是他見過最有趣的學科，結合了哲學思辨和實用技術。他決定投入 AI 領域，然後開始回想：AI 能做什麼最有影響力的事？&lt;/p&gt;&#xA;&lt;p&gt;百日咳的記憶浮現了。答案是醫療。&lt;/p&gt;&#xA;&lt;p&gt;接下來的十幾年，Beam 沿著這條路一路走。他在北卡州大讀完統計碩士和生物資訊博士，研究貝葉斯神經網路。那是 GPU 運算剛起步的年代，沒有自動微分工具，他得手寫 CUDA 核心、手算反向傳播。2014 年他到哈佛做博士後，第一天就跟老闆 Zak Kohane 說：「我們需要更多 GPU。」Kohane 問為什麼，Beam 說：「神經網路會改變一切。」&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ilya Sutskever：我們正從 Scaling 時代，進入研究時代</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251225-ilya-sutskever-age-of-research/</link>
      <pubDate>Thu, 25 Dec 2025 10:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251225-ilya-sutskever-age-of-research/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Dwarkesh Podcast 2024 年 12 月播出的單集。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/aR20FWCCjAs&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;「2012 到 2020 年，是研究時代。2020 到 2025 年，是 Scaling 時代。現在，我們又回到研究時代了——只是電腦變大了。」&lt;/p&gt;&#xA;&lt;p&gt;這是 Ilya Sutskever 在離開 OpenAI 後首次深度訪談中說的話。Ilya 是深度學習革命的核心人物之一，從 AlexNet 到 GPT-3，他參與了幾乎所有重要的突破。他現在創辦了 SSI（Safe Superintelligence Inc.），專注於超級智慧的研究。&lt;/p&gt;&#xA;&lt;p&gt;當這樣一個人說「Scaling 時代結束了」，值得認真聽。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Scaling Laws 沒死，但遊戲規則變了——Gemini 3 研究負責人的第一手觀察</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251223-gemini3-scaling-laws-not-dead/</link>
      <pubDate>Tue, 23 Dec 2025 00:55:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251223-gemini3-scaling-laws-not-dead/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自《The MAD Podcast with Matt Turck》2025 年 12 月 18 日播出的單集，訪談來賓為 Google DeepMind Gemini 3 預訓練負責人 Sebastian Bourgeaud。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/cNGDAqFXvew&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;這些討論對我來說很奇怪&#34;&gt;「這些討論對我來說很奇怪」&lt;/h2&gt;&#xA;&lt;p&gt;2024 年底到 2025 年初，科技圈瀰漫著一種焦慮：Scaling Laws 是不是到頂了？預訓練是不是撞牆了？各種「AI 泡沫即將破滅」的論調甚囂塵上。&lt;/p&gt;&#xA;&lt;p&gt;Sebastian Bourgeaud 對這些討論感到困惑。作為 Google DeepMind Gemini 3 預訓練的負責人，他每天都在與這些模型的極限搏鬥，而他的經驗告訴他完全不同的故事。「這些討論對我來說一直很奇怪，因為我的經驗不是這樣的，」他說。&lt;/p&gt;</description>
    </item>
    <item>
      <title>「我們走得比我預期的還要前面」——Gemini 3 預訓練負責人談 AI 真實進展</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251223-gemini3-ahead-of-expectations/</link>
      <pubDate>Tue, 23 Dec 2025 00:53:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251223-gemini3-ahead-of-expectations/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自《The MAD Podcast with Matt Turck》2025 年 12 月 18 日播出的單集，訪談來賓為 Google DeepMind Gemini 3 預訓練負責人 Sebastian Bourgeaud。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/cNGDAqFXvew&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;一個圈內人的坦誠&#34;&gt;一個圈內人的坦誠&lt;/h2&gt;&#xA;&lt;p&gt;Sebastian Bourgeaud 是 Google DeepMind 負責 Gemini 3 預訓練的核心研究者，帶領著一支約 150 到 200 人的團隊。當主持人 Matt Turck 問他，作為一個如此深入 AI 核心的研究者，對於當前的 AI 進展是否感到驚訝時，他給了一個坦誠的答案：「如果對自己誠實的話，我認為我們走得比我預期的還要前面。」&lt;/p&gt;</description>
    </item>
    <item>
      <title>Reasoning 如何拯救 AI：一場你不知道的 18 個月危機</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251222-reasoning-saved-ai-scaling-laws/</link>
      <pubDate>Mon, 22 Dec 2025 21:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251222-reasoning-saved-ai-scaling-laws/</guid>
      <description>&lt;p&gt;如果不是 Reasoning 模型的出現，AI 的進展可能在 2024 年就停滯了。這個說法聽起來驚人，但背後有著嚴謹的技術邏輯——而且這個故事鮮為人知。&lt;/p&gt;&#xA;&lt;p&gt;Gavin Baker 是 Atreides 投資公司創辦人，曾任 Fidelity 科技基金經理人，長期追蹤 AI 與半導體產業。2024 年 12 月，他接受知名投資 Podcast《Invest Like the Best》主持人 Patrick O&amp;rsquo;Shaughnessy 專訪，深入剖析了 AI 產業的競爭格局、技術演進與投資邏輯。在這場近兩小時的對談中，他揭露了一個公開市場投資人普遍忽略的事實：基於預訓練規模定律的邏輯，2024 和 2025 年的 AI 進展「理論上不應該發生」。這個看似矛盾的陳述，需要從 Scaling Laws 的本質說起。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;scaling-laws我們精確測量卻不理解的神秘法則&#34;&gt;Scaling Laws：我們精確測量卻不理解的神秘法則&lt;/h2&gt;&#xA;&lt;p&gt;要理解 Reasoning 為什麼「拯救」了 AI，首先要理解什麼是 Scaling Laws（規模定律）。這個概念是當前 AI 發展的核心驅動力，但它的本質卻帶有一種令人不安的神秘性。&lt;/p&gt;&#xA;&lt;p&gt;Pre-training Scaling Laws（預訓練規模定律）並非像牛頓力學那樣的物理定律，而是一個「經驗觀察」。研究人員發現，當你增加模型的參數量、訓練資料量、以及運算量時，模型的表現會以一種可預測的方式提升。這個觀察已經被精確測量並持續驗證了很長時間，成為各大 AI 實驗室投入數十億美元建設超大規模運算叢集的理論基礎。然而，沒有人真正知道這個定律為什麼會成立。&lt;/p&gt;&#xA;&lt;p&gt;Baker 用了一個精妙的比喻來描述這種認知落差。古埃及人可以精確測量太陽的運行軌跡，精確到能夠把金字塔的東西軸完美對準春分點，巨石陣的建造者同樣展現了對太陽週期的精確掌握。但他們完全不懂軌道力學，不知道地球繞著太陽轉，不知道為什麼太陽會東升西落、為什麼會有四季變化。他們的神話中，太陽是由神駕著戰車拉過天空。當代 AI 研究者對 Scaling Laws 的理解，與古人對太陽的理解處於類似的階段：精確測量，但缺乏根本性的理解。&lt;/p&gt;&#xA;&lt;p&gt;這種認知狀態帶來了一個實際問題：既然我們不知道 Scaling Laws 為什麼會成立，我們也無法確定它什麼時候會停止成立。每一次新模型的訓練，都是對這個經驗定律的又一次驗證。這就是為什麼 2024 年底 Google 發布 Gemini 3 時，業界如此關注——它證明了預訓練規模定律在又一個數量級上依然有效。這個確認對於整個產業的信心至關重要，因為目前所有的大規模資本支出，都是基於這個定律會繼續成立的假設。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;blackwell-延遲科技史上最複雜的產品轉換&#34;&gt;Blackwell 延遲：科技史上最複雜的產品轉換&lt;/h2&gt;&#xA;&lt;p&gt;2024 年，Nvidia 的新一代晶片 Blackwell 遭遇了嚴重的產品延遲。這不是普通的供應鏈問題或良率挑戰，而是科技史上「最複雜的產品轉換」之一。理解這次延遲的嚴重性，需要先理解從 Hopper 到 Blackwell 究竟改變了什麼。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
