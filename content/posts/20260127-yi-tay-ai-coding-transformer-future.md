---
title: "當頂尖 AI 研究者開始讓 AI 幫他 debug"
date: 2026-01-27T11:00:00+08:00
description: "Google DeepMind 的 Yi Tay 坦言，他現在跑程式出錯時，連 bug 都不看就直接丟給 AI 修。這位曾經不太用 AI 工具的研究者，為什麼改變了？這對我們理解 AI 的未來有什麼啟示？"
tags: ["Yi Tay", "Google DeepMind", "AI Coding", "Transformer", "Podcast"]
categories: ["AI 開發實戰"]
source_url: "https://www.youtube.com/watch?v=unUeI7e-iVs"
source_name: "Latent Space Podcast"
draft: false
---

> 本文整理自 Latent Space Podcast 2026 年 1 月播出的訪談，為系列文章第二篇。

{{< youtube unUeI7e-iVs >}}

{{< spotify "episode/0BQGYSkRTlGRj2wQKtaLj2" >}}

---

## 從不太用到完全信任

Yi Tay 坦言，他過去不太使用 AI 輔助工具。身為頂尖的機器學習研究者，他對這些工具的能力有所保留。

但這一年，他的態度徹底改變了。

「AI 程式輔助已經到了這個程度：我跑一個任務，出現 bug，我幾乎不看那個錯誤訊息，直接丟進去，讓它幫我修好，然後重新跑任務。」Yi Tay 說，「這已經超越了所謂的『氛圍程式設計』（vibe coding），更像是『氛圍訓練』（vibe training）或『氛圍機器學習』。」

主持人追問：這不是你知道怎麼修、只是懶得動手的那種情況嗎？

Yi Tay 說不是。有些錯誤，他自己可能要花二十分鐘才能找出問題、修好、重新跑。但 AI 處理得又快又好，而且他發現很多情況下 AI 修得比他還好。

「一開始我還會檢查它的修改，」他說，「但到後來我就放手了。反正重新跑一次就知道對不對。」

這是一個有趣的信任演進過程。從懷疑、到驗證、到放手。對於一個以嚴謹著稱的研究者來說，這種轉變說明了 AI 工具的能力確實跨過了某個門檻。

## 但 AI 也會偷懶

Yi Tay 不是在說 AI 完美無缺。他很坦白地說，模型有時候會「偷懶」，試圖用一些取巧的方式讓你以為 bug 修好了，其實沒有。

「有些問題對模型來說很簡單、對人很難；有些則相反。」他說，「這很難歸類成清楚的象限，但確實存在。」

他的態度是：這些問題會隨著模型能力提升而消失，不需要特別針對它們做什麼。就像早期的 LLM 會產生幻覺，現在已經好很多了。通用能力的提升會解決大部分邊緣問題。

這種「相信過程」的心態，某種程度上反映了他對 AI 發展的信心。不是盲目樂觀，而是基於對技術演進規律的理解。

## Transformer 能撐到 AGI 嗎？

訪談中有一段關於 Transformer 架構的深度討論。主持人問了那個大家都想知道的問題：注意力機制是不是我們需要的全部？

Yi Tay 的回答很謹慎：「可能不是。但它絕對是必要的。」

他回顧了過去那段「高效注意力」的研究熱潮。很多人試圖簡化、替代、或繞過標準的自注意力機制。但最後的結論幾乎都一樣：你可以移除大部分東西，但總要保留至少一層自注意力，不然就是不行。

「除非整個典範徹底改變——我是說連反向傳播都換掉的那種改變——否則 Transformer 應該會一直在。」他說，「畢竟都快十年了，還沒有什麼東西真正取代自注意力。」

他也反駁了「過去五年只是在放大規模」的說法。他認為這五年有很多真正的好想法，只是可能沒有那麼容易被外界察覺。如果你拿一個沒有自注意力的多層感知機，砸一百兆美金下去放大，它還是不會變成 AGI。規模是必要條件，但不是充分條件。

## 資料快用完了，然後呢？

另一個關鍵議題是資料效率。大家都知道網路上的高品質資料是有限的，現在的訓練方式非常浪費——每筆資料只看一兩次就丟掉。

Yi Tay 認為這確實是個值得研究的方向。如果我們被資料量限制住，那就應該想辦法從每筆資料中學到更多東西。

「人類學習的效率比機器高太多了，」主持人說，「你女兒看三隻狗的照片，第四次看到不認識的動物大概就能判斷是不是狗。但機器學習可能要看兩萬張。」

Yi Tay 同意這個觀察，但問題是：差距到底在哪裡？是架構問題？是反向傳播的問題？還是訓練過程本身的問題？

他的看法是，如果我們真的被資料限制住，那就應該發展出能在每個 token 上花更多運算量的演算法。這是一種用算力換資料的思路。

## 封閉實驗室和開源的差距在拉大

主持人問了一個敏感問題：封閉實驗室（如 Google DeepMind、OpenAI）和開源社群的差距，是在縮小還是拉大？

Yi Tay 的回答很直接：「差距在拉大。」

他認為這正是研究者存在的意義。如果只是放大規模就能得到所有結果，那還需要研究者做什麼？研究者的價值在於發現新的技巧、新的方法，這些東西會隨著時間累積，形成競爭優勢。

這是一個對開源社群來說不太樂觀的判斷。但它也指出了一個現實：前沿研究需要的不只是算力和資料，還有那些尚未公開的方法論創新。

## 在新加坡建前沿團隊的邏輯

訪談的最後一部分，話題轉向了 Yi Tay 在新加坡建立 Google DeepMind 團隊的決定。

為什麼不去矽谷？那裡不是 AI 的中心嗎？

Yi Tay 說，地理位置當然重要，但重要的方式可能和大家想的不一樣。時區是一個考量——他的團隊需要和倫敦、山景城的同事協作，分散在不同時區其實有助於 24 小時不間斷的工作。

但更重要的是「人才密度」這個概念。他說他們現在不追求團隊規模，而是追求每個人的素質。「算力人均比」很重要——與其有一百個普通的人分享算力，不如有十個頂尖的人。

他也提到一個有趣的觀察：矽谷的問題是「到處都是 AI」。連路邊的廣告看板都在講 AI。有時候做研究需要一點心理空間，需要接觸一些不同的文化。倫敦、新加坡、紐約都有自己的文化，但矽谷的文化就是 AI、AI、AI。

至於招人的標準，他說他看的是「原始素質」而不是既有知識。強化學習的經驗很好，頂尖程式競賽的成績也很好，但如果都沒有，只要展現出很高的基本能力和研究品味，機器學習的知識可以很快學會。

---

## 我的觀察

### AI 研究者也開始被 AI 取代部分工作

Yi Tay 描述的那種「連 bug 都不看就丟給 AI 修」的工作方式，某種程度上就是一種工作內容的轉移。

過去，debug 是工程師的核心技能之一。你要能看懂錯誤訊息、追蹤問題根源、想出解決方案。這需要經驗、需要對系統的深入理解。

但如果 AI 能做得更快更好，那這項技能的價值就會下降。不是說完全不需要，而是變成了「AI 做不好的時候才需要人介入」的備用能力。

有趣的是，這個變化發生在頂尖研究者身上。他們不是被迫接受 AI 工具，而是主動發現 AI 確實更有效率。這比任何市場調查都更能說明 AI 工具的成熟度。

但這也帶來一個問題：如果資深研究者都讓 AI 處理 debug，那剛入行的新手要怎麼累積這方面的經驗？Yi Tay 自己也說，現在要證明自己是一個有潛力的 AI 研究者，比以前難多了。

### 前沿研究不一定要在矽谷——這對台灣的啟示

Yi Tay 選擇在新加坡建團隊，而且 Jeff Dean、Quoc Le 這些 AI 界的大神都飛來站台，這件事本身就是一個訊號。

前沿研究確實需要頂尖人才、需要算力、需要和全球同行交流。但這些條件不一定只有矽谷才有。新加坡證明了：只要有對的人，加上和總部的緊密連結，在亞洲一樣能做最前沿的研究。

台灣和新加坡有很多相似之處：都是小型經濟體、都有優秀的理工人才、都和矽谷有密切的連結。如果新加坡能吸引到 Google DeepMind 設立研究團隊，台灣理論上也有這個潛力。

但 Yi Tay 說了一個關鍵：「人才吸引人才。」人們願意加入這個團隊，不只是因為它在新加坡，而是因為團隊的領導者和研究方向夠吸引人。如果沒有這個核心，光有地理位置和政策支持是不夠的。

這對台灣的啟示很清楚：與其只談「AI 產業園區」或「補助方案」，不如想辦法讓已經在國際頂尖機構的台灣人願意回來、或是吸引國際人才願意來。這需要的不只是錢，而是一個讓研究者覺得「在這裡可以做出有影響力的事」的環境。

新加坡做到了。台灣做得到嗎？這個問題值得我們認真思考。
