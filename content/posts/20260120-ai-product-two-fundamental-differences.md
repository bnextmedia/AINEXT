---
title: "AI 產品開發的兩大根本差異：非確定性與代理控制權衡"
date: 2026-01-20T11:00:00+08:00
description: "為什麼 AI 產品開發和傳統軟體完全不同？OpenAI Codex 負責人 Kiriti Badam 與 AI 顧問 Aishwarya Reganti 這對夫妻檔，用 Booking.com vs ChatGPT 的對比，解釋 AI 產品的兩個根本性挑戰。"
tags: ["OpenAI", "AI 產品", "非確定性", "Agent", "Kiriti Badam", "Aishwarya Reganti"]
categories: ["AI 產業"]
source_url: "https://www.youtube.com/watch?v=z7T1pCxgvlA"
source_name: "Lenny's Podcast"
draft: false
---

> 本文整理自 Lenny's Podcast 2026 年 1 月播出的單集，為系列第二篇。

{{< youtube z7T1pCxgvlA >}}

---

## 來賓背景

這集的兩位來賓是夫妻，也是 AI 產品領域最有實戰經驗的組合之一：

- **Kiriti Badam**：OpenAI Codex 產品負責人，曾在 Google 和 Kumo 打造 AI/ML 基礎設施
- **Aishwarya Reganti**：前 Alexa、Microsoft AI 研究員，現為企業 AI 轉型顧問，發表過 35+ 篇論文

兩人合計參與 50+ AI 產品部署，從 Amazon 到新創公司都有。他們在 Maven 開設的 AI 產品課程是平台上評價最高的課程。

對臺灣讀者來說，Kiriti 正在打造全球最前沿的 coding agent，而 Aishwarya 則是協助傳統企業 AI 轉型的實戰專家。他們的觀點結合了「技術前沿」與「落地實踐」兩個視角。

---

## 第一個差異：非確定性

Aishwarya 指出，很多人忽略了 AI 產品與傳統軟體的第一個根本差異：**非確定性（Non-determinism）**。

### 傳統軟體：可預測的流程

想像你用 Booking.com 訂旅館。你有一個意圖（在舊金山住兩晚），產品設計了一連串按鈕、選項、表單，讓你一步步完成這個意圖。每次流程都一樣，結果可預測。

### AI 產品：雙重不確定性

但 AI 產品完全不同。使用者用自然語言表達意圖，而同一個意圖可以有無數種說法。這是**輸入端的不確定性**。

同時，LLM 是機率性的 API，對 prompt 的微小變化很敏感，而且本質上是黑盒子。這是**輸出端的不確定性**。

你既不知道使用者會怎麼跟你的產品互動，也不知道 LLM 會怎麼回應。輸入、輸出、處理過程——三者你都無法完全掌握。

### 這是缺點，也是優點

Aishwarya 補充：這其實也是 AI 最美的地方。人類天生更習慣用說話來溝通，而不是點按鈕。AI 產品的使用門檻因此大幅降低——你可以像跟人說話一樣自然地表達需求。

但問題是：你的後端系統是確定性的，你想達成確定性的結果，卻要透過非確定性的技術來完成。這就是挑戰所在。

---

## 第二個差異：代理-控制權衡

Kiriti 指出第二個差異：**代理-控制權衡（Agency-Control Trade-off）**。

### 什麼是代理-控制權衡？

每次你讓 AI 系統擁有更多自主決策能力（agency），你就放棄了一些控制權（control）。

很多人只想著打造全自動的 agent——可以自己做決定、自己完成工作。但 Kiriti 強調：**在給予 AI 更多自主權之前，它必須先贏得你的信任。**

### 為什麼這很重要？

UC Berkeley 的 Matei Zaharia 團隊（也是 Databricks 的人）做過一項調查：約 74-75% 的企業表示，**可靠性是他們最大的問題**。這也是為什麼他們不敢把 AI 產品部署給終端客戶——他們就是不放心。

這導致了一個現象：目前大多數企業 AI 產品都是「提升生產力」的工具（低自主性），而不是「端到端替代工作流程」的 agent（高自主性）。

---

## 實際案例：從低代理到高代理

Kiriti 用客服 agent 舉例，說明如何逐步增加 AI 的自主性：

| 版本 | 功能 | 代理程度 | 控制程度 |
|------|------|---------|---------|
| V1 | 分類並路由工單到正確部門 | 低 | 高 |
| V2 | 根據 SOP 產生回覆草稿，人工審核後送出 | 中 | 中 |
| V3 | 端到端解決工單，包括退款、提交功能需求等 | 高 | 低 |

### 為什麼不直接做 V3？

因為你會被問題淹沒。Aishwarya 分享他們曾經為一個客戶做全自動客服 agent，結果問題多到修不完，最後只能關掉產品。Air Canada 也發生過類似事件——agent 幻覺出一個不存在的退款政策，公司被迫照做。

### V1 看起來簡單，其實不簡單

光是「路由」這件事，在企業環境就可能極度複雜。Aishwarya 舉例：她遇過零售公司的產品分類系統，「鞋子」底下同時有「女鞋」和「男鞋」，但另一個地方又有「for women」和「for men」的分類，而且根本沒整合。人類客服知道哪些是過時的死節點，但 AI 沒有這個脈絡。

---

## 更多案例：coding assistant 與 marketing assistant

主持人 Lenny 補充了兩個例子：

**Coding Assistant**
- V1：建議 inline completion 和樣板程式碼
- V2：產生較大區塊（測試、重構），由人類審核
- V3：自動套用修改、開 PR

**Marketing Assistant**
- V1：草擬 email 或社群貼文
- V2：建立多步驟行銷活動並執行
- V3：自動上線、A/B 測試、跨渠道優化

重點都一樣：**從低代理開始，隨著信任建立，逐步增加自主性。**

---

## 關鍵心態：Problem First

Aishwarya 強調一個被低估的原則：**Problem First（問題優先）**。

在 AI 快速發展的時代，很容易陷入一個陷阱：一直想著解決方案的複雜性，卻忘了你到底要解決什麼問題。

當你從小規模、低自主性開始，你會被迫思考：「我到底要解決什麼問題？」這反而是好事。

---

## 小結

AI 產品開發與傳統軟體的兩大根本差異：

1. **非確定性**：輸入和輸出都無法完全預測
2. **代理-控制權衡**：自主性越高，風險越大，必須逐步建立信任

理解這兩點，是避免 AI 產品失敗的第一步。

---

*本系列共四篇。下一篇將介紹 CCCD 框架——持續校準、持續開發的具體方法論。*
