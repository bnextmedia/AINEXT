---
title: "前 OpenAI 研究員：AGI 還缺兩塊拼圖，2026-2029 年可能達成"
date: 2026-01-26T11:00:00+08:00
description: "Jerry Tworek 主導了 OpenAI 的推理模型開發，親眼見證 Q-Star 第一次展現能力的時刻。他認為目前的模型離 AGI 還有距離，關鍵缺口是架構創新和持續學習。他也分享了對研究文化的看法：好的研究環境比明星研究員更重要。"
tags: ["Jerry Tworek", "OpenAI", "AGI", "Transformer", "持續學習", "強化學習", "Podcast"]
categories: ["AI 技術前沿"]
source_url: "https://www.youtube.com/watch?v=VaCq4u5c78U"
source_name: "Core Memory Podcast"
draft: false
---

> 本文整理自 Core Memory Podcast 於 2026 年 1 月播出的訪談。

{{< youtube VaCq4u5c78U >}}

{{< spotify "episode/5Q0sraaXJyKuO6CEdJPQgs" >}}

{{< apple-podcast "tw/podcast/he-left-openai-to-think-bigger-ep-53-jerry-tworek/id1789397163?i=1000746040747" >}}

---

Jerry Tworek 是少數親眼見證 Q-Star 誕生的人。

兩年前，當這個後來被稱為 Strawberry、最終以 O1 之名問世的推理模型第一次展現能力時，他就在房間裡。那是什麼感覺？

「你坐在一個房間裡，看著一個有意義的新技術出現。如果你不會感到一點害怕、一點擔心、有那麼一個『這會對世界造成什麼後果』的時刻，我覺得你沒有認真對待你的工作。」Tworek 說。

但即使親手打造了這些推理模型，他仍然認為：現在的模型還不是 AGI。要達到那個里程碑，還缺兩塊關鍵的拼圖。

## Transformer 不會是最後一個架構

Tworek 認為 AI 領域有兩個被嚴重低估、資源投入不足的研究方向。第一個是架構創新。

「我覺得我們對 Transformer 架構有點太執著了。」他說，「這是一個很棒的架構，被非常徹底地探索過，人們也很難在 Transformer 上做出更好的局部改進。有一些改進是成功的，像是稀疏性（Sparsity）非常成功，各種讓 attention 更便宜的方法也蠻成功的。但 Transformer 會是做所有機器學習的最後一個架構嗎？很明顯不是。」

他承認 Transformer 的作者們做了了不起的工作，定義了接下來十年的機器學習版圖。但他相信還有更多可能性，還有其他訓練大型模型的方式，可能看起來有點像 Transformer，也可能完全不像。

「這是一個我想解決的問題。如果沒有別人做，我會捲起袖子自己來。」

## 持續學習：AGI 的最後幾塊能力拼圖之一

第二個被低估的方向是持續學習（Continual Learning）。

「這是一個比較熱門的問題，但我不覺得有人做得很好。」Tworek 說，「我們人類就是這樣運作的。我們沒有一個單獨的『學習模式』和『回答問題模式』，所有事情都是連續發生的。我認為我們的模型也應該更像這樣。」

他認為，持續學習可能是「在我們能有意義地稱呼我們的模型為 AGI 之前，最後幾個重要的能力元素之一」。如果模型不能從它看到的資料中學習，它們仍然感覺有點受限、有點笨。

這個觀點呼應了 Ilya Sutskever 在 NeurIPS 提出的「預訓練時代可能結束」的說法。但 Tworek 的看法更細緻：不是說預訓練沒用了，而是預訓練不是唯一改進模型的方式，其他方式可能更快。

「Scaling 預訓練在很多事情上改進模型的速度非常慢。它確實有用，模型確實會變好，但可能還有更多。」

## 強化學習改變了一切，但還不夠

Tworek 的職業生涯有一大部分在推動強化學習的 scaling。這正是推理模型背後的關鍵技術。

在推理模型出現之前，業界的主流做法是不斷 scale 預訓練。每一季訓練一個更大的模型，用更多算力、更多資料，模型就會更好。「這條路走得很順，進步沒有停下來的跡象。」

但 Tworek 和他的團隊相信還有其他可能。他們證明了在語言模型上 scaling 強化學習，用跟預訓練差不多規模的算力，可以教會模型那些光靠預訓練永遠學不會的東西。

「這就是為什麼我們今天有那些很棒的 agent，能夠自動化工作、解決那些只靠預訓練模型需要花天文數字算力和資料才能做到的問題。」他說，「你發明新的 scaling 方式，就能得到全新的能力。」

但強化學習也不是終點。Tworek 坦承，一年半前他曾經堅信「只要 scale RL，就會得到 AGI」，但現在他必須修正這個看法。有些事情你只有到了下一個階段才看得到。

## 電玩遊戲與世界模型

訪談中，Tworek 提到一個有趣的研究方向：用電玩遊戲訓練 AI。

這不是新想法。OpenAI 早期做過 Dota，DeepMind 做過 AlphaGo 和 StarCraft。但這個方向後來有點退流行，被 ChatGPT 時代的語言模型熱潮蓋過了。

Tworek 認為電玩遊戲仍然是訓練智慧非常有趣的環境，原因很簡單：遊戲是為了讓人類大腦覺得有趣而設計的。

「遊戲必須有趣、引人入勝、不能重複。它們非常針對人類智慧量身打造，包含很多問題解決、資源分配、如何贏得各種遊戲的元素。這正是你想要你的 agent 做的事。」

但早期在遊戲上做強化學習有一個明顯問題：那些模型沒有世界知識。它們是從頭開始訓練，只為了玩那個遊戲，不理解我們的世界，沒有比「對像素做反應」更高層次的概念。

現在不一樣了。經過多年的預訓練 scaling，我們已經訓練出了對周遭世界有很好理解的模型。「整個推理模型的魔法，就是在預訓練建立的堅實基礎上，蓋起強化學習的塔。」

下一步是什麼？Tworek 認為是把世界模型和強化學習結合起來。「當有人成功在一個訓練得很好的世界模型上做強化學習，那會是一個非常令人開心的時刻。」

## AGI 時間表：2026-2029

主持人問 Tworek 對 AGI 時間表的看法。他的回答很謹慎，但也很具體。

「如果你把今天的模型拿給十年前的人看，他們可能已經會稱之為 AGI 了。」他說，「所以我不覺得談論 AGI 是什麼遙不可及或瘋狂的事了。但至少以我的定義，現在的模型還不是 AGI，因為持續學習還沒有以任何方式整合進我們的模型。」

他也提到多模態感知的問題：如果模型很會理解文字、很會寫程式，但看不到外面的世界、不能好好理解影片，我們能稱它們為 AGI 嗎？

「有很多問題我會稱之為達到那個文明里程碑的必要步驟。」他說，「有一陣子我在想，如果我們真的很努力、把所有事情都做好，也許 2026 年至少會是我們達成真正好的持續學習和真正通用的強化學習的一年。」

他的時間表仍在調整，但他不認為這個想法是瘋狂的：也許 2026，也許 2027，也許 2028，也許 2029。「我不認為會比那更久。但還有工作要做，而人們正在努力。」

## 「零到一」vs「一到一百」

訪談中有一段關於研究哲學的討論特別值得注意。

Tworek 觀察到，很多研究者喜歡做「零到一」的工作：創造一個全新的想法，證明它有點用，然後發表。學術界有大量這樣的研究。

但他認為更重要的是「一到一百」：把那些已經被證明有點用、但還沒有人認真投入的想法，想辦法讓它們在大規模訓練頂尖模型時穩定運作，並且跟其他技術結合。

「概念驗證很酷，但要用某個特定技術訓練出世界上最強的模型之一，需要非常多特定的工作。如果你做不好，可能要花好幾年；如果你有好的方法，可能只要幾個月。」

他認為這是學術研究最需要的東西。也是他未來想做更多的事。

## 研究文化比明星研究員更重要

OpenAI 這幾年有很多重要人物離開，業界也常常把 AI 看成一個「明星驅動」的領域。但 Tworek 的看法不太一樣。

「我覺得兩件事可以同時為真。」他說，「很多時候，確實是非常小的一群人產生了巨大的影響，推動了一整套突破性的成果，然後傳播到整個產業。我在 OpenAI 看過這種事一再發生。」

「但同時，每當我看到人在公司之間跳槽，我很少看到這對公司產生那麼大的影響。我真的認為，一家公司的身份認同、一家公司的運作方式，才是真正的研究引擎，而不是某個特定的研究員在不在。」

他觀察到，那些頻繁換公司的研究員，通常在新公司的生產力沒有那麼高，即使他們過去做過很棒的工作。「他們可能需要時間適應，或者現在沒有特別新鮮的想法。」

真正重要的是什麼？「創造一種個人責任感的氛圍、能夠探索事物的氛圍、讓人能做出偉大事情的環境。我認為可以建立很多能做出偉大事情的團隊，不管是這一組特定的人還是另一組特定的人。」

「我真的認為，好的研究結構、好的研究文化、好的合作，比某個特定的人在不在你的團隊重要得多。」

## 「跑少一點實驗，多想一點」

Tworek 分享了他常對團隊說的一句話：「跑少一點實驗，多想一點。」

這聽起來有點違反直覺。在一個強調快速迭代的領域，不是應該盡可能多跑實驗嗎？

但他的觀點是：很多時候，研究瓶頸不是算力不夠，而是缺乏專注。如果你同時做三個專案，每個專案都只分到三分之一的注意力和資源。如果你只做一個專案，它的進展會快得多。

「有時候，就是那幾個小時，什麼都不跑，只是更仔細地分析資料，就能帶來突破，比跑更多東西更有用。」

這也是為什麼他認為 OpenAI 現在很難做真正不一樣的事：當你必須同時維持市場領先地位，不能讓 Gemini 下一季有更好的模型，你就很難把整家公司的資源集中在一個瘋狂的新方向上。

「這需要一種特定類型的人，願意嘗試這樣的事。」他說，「我想我就是那種風險容忍度最高的人之一。」

## 我的觀察

聽完 Tworek 對技術的看法，有幾件事讓我印象深刻。

**第一，持續學習的產品意涵比我們想像的大。**

如果模型真的能從它看到的資料中即時學習，會改變什麼？最明顯的是個人化助理：你的 AI 助理會記得你說過的每一件事、你的偏好、你的工作方式，而且會隨著時間越來越了解你，不需要你每次都重新解釋。

對企業來說，這可能意味著真正的知識管理革命。現在的企業知識庫是死的，資料放進去就沒人看。但如果 AI 能夠持續從公司的對話、文件、決策中學習，那就是一個真正活的、會成長的組織記憶。

這也是為什麼 Tworek 把持續學習列為 AGI 的必要條件之一。一個不會學習的系統，不管多聰明，都感覺受限。

**第二，「一到一百」的工作被嚴重低估了。**

學術界和業界常常把光環給「零到一」的人：第一個提出想法的人、第一個發論文的人。但 Tworek 指出，真正讓技術變得有用的，是那些把想法從概念驗證變成大規模可用的人。

這在 AI 領域特別明顯。一篇論文證明某個方法有點用，跟用那個方法訓練出世界頂尖的模型，是完全不同層次的工作。後者需要大量的工程、調參、跟其他技術整合，而且通常沒有論文可以發。

我覺得這對台灣的 AI 人才培育有啟示。我們不缺聰明人、不缺會寫論文的人，但我們可能缺的是那種願意花時間把東西做到真正能用的人。這種工作沒那麼光鮮，但可能更有價值。

**第三，研究文化是可以刻意建立的。**

Tworek 說研究文化比明星研究員更重要，這聽起來像是老生常談，但他提供了具體的內容：個人責任感、能夠探索的空間、讓人做出偉大事情的環境。

這意味著，一個組織如果想要有好的研究產出，花錢挖人可能不是最有效的方式。更重要的是建立對的文化：讓人敢冒險、讓人能專注、讓人對自己的工作有責任感。

當然，這比挖人難多了。文化是慢慢養出來的，不是錢能買到的。但如果 Tworek 的觀察是對的，那些只會花錢挖人的組織，可能永遠追不上那些認真經營文化的組織。

這也許解釋了為什麼 Anthropic 能在資源劣勢下做出 Claude Code 這樣被開發者喜愛的產品。他們可能有某種 OpenAI 和 Google 都複製不來的東西。
