---
title: "通往 AGI 的路上，我們更可能先遇到什麼？"
date: 2026-02-02T13:00:00+08:00
description: "Sebastian Raschka 與 Nathan Lambert 在 Lex Fridman Podcast 討論 AGI 的定義之爭、AI 對 GDP 的真實影響、知識民主化的被低估力量，以及百年後回看今天，什麼才是真正的突破。三人的結論出奇一致：與其預測 AGI 什麼時候到來，不如好好用手上已經非常強大的工具。"
tags: ["AGI", "AI 經濟影響", "Lex Fridman", "Sebastian Raschka", "Nathan Lambert"]
categories: ["AI 技術前沿"]
image: "/images/posts/20260202-road-to-agi-amplification-not-revolution.webp"
source_url: "https://www.youtube.com/watch?v=EV7WhVT270Q"
source_name: "Lex Fridman Podcast"
related_companies: ["openai", "anthropic", "nvidia", "google-deepmind"]
related_people: ["lex-fridman", "jensen-huang"]
draft: false
---

> 本文整理自 Lex Fridman Podcast 2026 年 2 月播出的第 490 集。

{{< youtube EV7WhVT270Q >}}

{{< spotify "episode/4UBPQG2Z7s70DpRVD5kMbC" >}}

{{< apple-podcast "tw/podcast/490-state-of-ai-in-2026-llms-coding-scaling-laws/id1434243584?i=1000747523558" >}}

---

## AGI 到底是什麼？這個問題本身就是問題

Lex Fridman Podcast 第 490 集的最後三分之一，三位對談者從技術細節退後一步，開始聊一個更大的問題：AGI（通用人工智慧）到底距離我們多遠？但在回答「多遠」之前，他們先卡在了「什麼是 AGI」這個更基本的問題上。

Nathan Lambert 是艾倫人工智慧研究所（AI2）的後訓練團隊負責人，著有 *Reinforcement Learning from Human Feedback* 一書。他說業界大致有個共識：AGI 是一個能完成「大多數數位經濟工作」的系統，類似一個可以取代任何遠端工作者的 AI。OpenAI 的定義也差不多：能完成足夠數量有經濟價值的任務。但 Nathan 對這些定義不太買帳，因為它們太容易跟「意義追尋」和「準宗教式敘事」纏在一起。

Sebastian Raschka 是 Lightning AI 的資深研究工程師，也是 *Build a Large Language Model (From Scratch)* 的作者。他的懷疑更直接。AI 正在各個垂直領域變得越來越專精，金融、法律、製藥公司都在開發自己的專門模型。「但如果我們又在專業化了，這算 AGI 嗎？我們是不是只是在做跟以前一樣的事，只是規模更大、更精緻？」

Lex Fridman 提到另一個框架：AI 2027 報告中定義的「超人類程式設計師」里程碑。報告認為，一旦 AI 能完全自動化程式設計，後續的 AI 研究自動化和 ASI（超級人工智慧）會迅速跟進。最初預測是 2027-28 年，現在已經推遲到 2031 年。Lex 自己的預測比 2031 還要更晚。

## 「放大而非典範轉移」可能是最誠實的判斷

Sebastian 在這場討論中提出了一個框架，可能是整集近五小時對話中最清醒的判斷：AI 目前帶來的是「放大」（amplification），不是「典範轉移」（paradigm shift）。

「前沿實驗室仍然在衝刺下一個更好的模型，而且我看不到他們會減速。但真正讓使用者感受到差異的進步，越來越多來自模型周邊的改善，而不是模型本身。Context 的工程設計、inference scaling 的優化、工具整合的完善。」他的判斷是：大型實驗室會繼續推進 pre-training 的規模，但更多小型實驗室和應用開發者會在模型周邊做出創新。結果不會是一個戲劇性的「AGI 到來」時刻，而是持續的、逐漸加速的放大效應。

Nathan 大致同意，但措辭更謹慎。他認為 AGI 和 ASI 的門檻「不太有用」，因為真正發生的事情比這些標籤暗示的更複雜、更混亂。模型在某些能力上已經超越人類，在另一些能力上仍然很笨拙。這種「鋸齒狀」（jagged）的能力分布會持續很長時間。「你不會有一天早上醒來發現 AGI 到了。你會看到 Claude Code 變得更好了、某個特定領域的模型突然能做之前做不到的事、某個新創公司用 AI 發現了一個新藥物分子。這些事情加在一起，就是 AGI 正在發生。」

過去一年 AINEXT 整理了不少 AI 領袖觀點，Sebastian 的「放大而非典範轉移」可能最接近多數實際在做研究的人的感受。奧特曼說 AGI 今年就來，哈薩比斯畫了清晰的路線圖，卡普警告 AGI 風險。但 Sebastian 更接地氣：進步是真實的、持續的、可以預見會加速，但它是「更好的工具」而不是「全新的物種」。這個區別很重要。它決定了你面對 AI 的心態：恐懼，還是學習怎麼用。

## 如果今年就高原期了呢？

Lex 在這段討論中刻意扮演「悲觀的提問者」。他描繪了一個場景：AI 在 2026 年的實際經濟影響其實很有限。程式碼方面，能蓋出漂亮的網站、提供不錯的自動補全、幫你理解 codebase，但本質上就是一個很好的助手。研究方面，能幫數學家做一些推導。生活方面，幫你購物、幫你學習。「Clippy 的加強版，就這樣。Computer use 被證明極其困難。訓練和推理的成本都高得嚇人。這個可能性有多大？」

Nathan 的回答很務實。一般的 ChatGPT 使用者（八億人中的大多數）可能不會從 AI 進步中得到太多額外好處，但特定族群會獲益巨大。他舉了 RLVR 在科學領域的應用：已經有數億美元融資的新創公司在建造「AI + 濕實驗室」系統，讓語言模型提出假說，再到真實實驗室中驗證。「我不確定這些公司是提早了六個月還是八年，你無法判斷。但如果其中一個成功了，那會是非常不同於 ChatGPT 的突破。」

Sebastian 從另一個角度補充：即使「通用系統」的進步放緩了，垂直領域的 AI 應用仍然有巨大空間。金融、法律、製藥這些資源豐富的行業，會願意砸重金客製化模型。「但問題是，如果每家公司都用同一個 ChatGPT，競爭優勢在哪？這就是為什麼專業化和私有資料的價值會越來越高。」

## 知識民主化：被嚴重低估的影響

討論到 AI 的經濟影響時，Lex 提出一個他認為「幾乎沒有人在談」的觀點：AI 最大的影響可能不是自動化工作，而是讓全世界所有人都能取用人類知識。

「從 Google 搜尋到 LLM，差距是巨大的。我現在可以問 LLM 任何事情，得到一個答案，而且幻覺越來越少。這意味著理解我自己的人生、規劃職涯、解決身邊的問題、學習人類歷史上的任何知識。而且不只在美國，全世界都一樣。想想全世界的孩子都能透過 AI 學習任何東西，對整個文明的影響是什麼？」

Sebastian 同意，但做了一個重要區分。像數學這種有成熟教科書的領域，LLM 的主要價值不是「教你新東西」（好的教科書做得更好），而是無限量生成個人化的練習題和解答。但對於沒有好資訊來源的領域就不同了。他舉了一個日常例子：你要去迪士尼樂園，需要搞清楚哪天買哪個園區的票最划算。「這方面沒有教科書，網路上只有零散且充滿廣告的資訊。LLM 可以根據你的具體限制條件，即時生成一個完全客製化的方案。」

Nathan 聽完後潑了一盆冷水：「嗯，目前是這樣。因為這些服務被嚴重補貼。廣告一定會來。」

這句話很冷，但很重要。如果 AI 的知識民主化效應真有 Lex 說的那麼強大，廣告模式的引入就不是小事了。當你問 AI 推薦跑鞋，Nike 出現在第一位，那是巧合嗎？

## NVIDIA 與 Jensen Huang：這個時代的關鍵人物

三人花了一段時間討論輝達（NVIDIA）在 AI 生態中的角色。Nathan 對黃仁勳（Jensen Huang）評價很高。他認為輝達的核心護城河不是 GPU 晶片本身，而是整個 CUDA 生態系。但更關鍵的是組織文化：「所有人都說這家公司高度圍繞 Jensen 運作，他在營運層面的投入程度和多數大公司 CEO 完全不同。只要這種文化持續，我會對他們保持樂觀。」他把 Jensen 比作賈伯斯時代的蘋果。

Sebastian 提供了歷史視角。他讀博士時就在用輝達的 Tesla GPU 做生物物理模擬，那是十五年前的事。「CUDA 生態系花了二十年建立起來，這才是真正的護城河，不是晶片。」但他也指出，現在有了 LLM，也許複製 CUDA 會變得更容易。

Nathan 補充了一個微妙的觀察：輝達的命運跟 AI 擴散的速度正相關。「只要 AI 進步的步調還在加速，輝達的平台作為最靈活的選項就會被需要。但如果出現停滯期，客戶就會有時間開發自己的專用晶片。」Google 已經有 TPU、Amazon 在做 Trainium、微軟也在嘗試自研晶片。輝達的優勢能存在，前提是 AI 發展速度快到客戶沒時間做替代方案。

## 百年後回看今天：什麼才是真正的突破

Lex 問了一個有意思的問題：一百年後的歷史學家回顧我們的時代，會把什麼標記為導致奇點的關鍵突破？

Sebastian 的回答意外地簡單：「算力。不是 AI，不是神經網路，就是算力這個大概念。」他類比工業革命中的引擎：你記得的是蒸汽機，不是某一個特定型號的鍋爐。我們現在只是在更好地利用電腦，一百年後，人們記住的會是算力本身。

Nathan 大致同意，但補了一點：網路（連結人與人的能力）可能和算力同樣重要。「AI 系統未來會以多 agent 的方式運作，不同的 AI 管理不同的任務，它們之間需要溝通。這完全依賴網路和資訊的自由流通。」

Lex 追問：「神經網路本身會被記住嗎？」Sebastian 認為不太會。從根本上說，神經網路只是一種特別適合大規模平行計算的演算法，一百年後可能只被歸類為「一種演算法」。Nathan 認為「深度學習」這個詞可能會留下來，但「Transformer」這個特定架構到時候大概早已被其他東西取代。

## 太空運算農場與散熱問題

這段關於未來的腦力激盪中，Lex 提出一個聽起來像科幻小說的想法：繞著地球運行的太空運算農場，靠太陽能供電。Nathan 沒有嘲笑，而是認真分析了工程可行性：「太空中有大量的太陽能和空間，但問題是散熱。太空中沒有空氣帶走熱量，你接收了所有太陽輻射，卻沒有散熱機制。但如果工程意志夠強，散熱問題是可以解決的。」

這段看似天馬行空的討論，其實觸及一個嚴肅議題：如果 Bitter Lesson（Richard Sutton 的著名論述：更多計算總是贏過更聰明的演算法）在未來一百年仍然成立，人類對算力的需求將無上限增長。Nathan 在這裡做了精確的補充：「即使在算力充沛的世界裡，那些 scaling 曲線斜率更陡的方法照樣會贏。」換句話說，Bitter Lesson 不是「算力就是一切」，而是「同等算力下，利用效率更高的方法永遠有優勢」。演算法創新在任何未來都不會變得不重要。

## 人類的代理權不會被取代

對談最後，三人都回到了一個聽起來「老派」但可能比任何技術預測都重要的議題：人類的代理權（agency）和社群（community）。

Nathan 的觀點特別有意思，因為他在整場對話中一直偏向「AI 進步很快」那一邊。但談到未來一百年時，他突然變得很人文。「人類的生物本質不會在一百年內改變。人們需要代理權，需要能與身邊的人一起做事，需要能為自己的生命賦予意義。UBI（全民基本收入）解決不了代理權的問題。」

Sebastian 把這個觀點延伸到創作領域。他坦言自己很難讀明顯由 AI 生成的文字，即使裡面有很好的資訊。「就像你去博物館看一幅真跡，跟看一張完美的數位複製品，感受完全不同。手工藝、寫作、面對面的對話，這些東西的價值不會消失，只是占比可能會改變。」

Nathan 預測未來幾年會出現更多 AI 生成的「slop」（垃圾內容），但他「希望社會被 slop 淹沒到一個程度之後會醒過來」，開始對真實的、實體的、人類創造的東西給予更高的溢價。

Lex 最後把討論帶到意識的議題。他認為 AI 是一面鏡子，迫使人類面對關於自身的根本問題：意識是什麼？什麼讓人類的心智如此特殊？Sebastian 的回答替整場對談做了漂亮的收尾：「讓我們和 AI 根本不同的是，我們決定自己要做什麼。AI 是工具，你告訴它做什麼，它就做什麼。它比榔頭強大得多，但你仍然是那個決定怎麼用它的人。」

## 最務實的啟示

對臺灣讀者來說，這場近五小時的對談最實用的一句話，或許是 Nathan 在節目前半段說的：「我們手上已有的工具就已經非常強大了。」

一年前沒有 Claude Code，沒有真正的推理模型。今天這些工具已經能從零重建一個像 Slack 這樣的軟體。而且目前模型的失敗模式都是很笨的錯誤，技術上看是可以修的。可預見的改善空間還非常大。

與其焦慮 AGI 什麼時候來、會不會搶走工作，不如把注意力放在眼前。你有沒有真正花時間搞懂 Claude Code 能做什麼？你的公司有沒有認真評估哪些工作流可以交給 AI agent？Sebastian 說得好：這不是一場革命，是一場持續的放大。放大器已經擺在你面前了。

![封面圖](/images/posts/20260202-road-to-agi-amplification-not-revolution.webp)
