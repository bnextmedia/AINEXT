---
title: "2030 不歸點：AI 教父的末日時鐘"
date: 2026-01-05T11:30:00+08:00
description: "OpenAI 執行長 Sam Altman 說，我們可能已經越過了 AI 發展的「事件視界」。AI 教科書作者 Stuart Russell 解釋這句話的意思：就像黑洞一樣，一旦越過那條線，就再也回不去了。"
tags: ["Stuart Russell", "AGI", "AI 安全", "Scaling Laws", "Sam Altman", "Podcast"]
categories: ["AI 產業動態"]
source_url: "https://www.youtube.com/watch?v=DOAC-stuart-russell"
source_name: "The Diary Of A CEO with Steven Bartlett"
draft: false
---

> 本文整理自《The Diary Of A CEO with Steven Bartlett》2025 年 12 月 4 日播出的單集。

{{< spotify "episode/6LDmLYDdYwyBtwCqELGzQk" >}}

{{< apple-podcast "nl/podcast/the-man-who-wrote-the-book-on-ai-2030-might-be-the/id1291423644" >}}

---

「我們可能已經越過了事件視界。」

這是 OpenAI 執行長 Sam Altman 在他的部落格《溫和的奇點》（The Gentle Singularity）中寫下的一句話。Stuart Russell 在接受《The Diary Of A CEO》專訪時，解釋了這句話的真正含義。

Russell 是全球最權威的 AI 教科書《Artificial Intelligence: A Modern Approach》的作者，這本書被翻譯成 15 種語言，在全球超過 1,500 所大學使用，包括臺灣多所頂尖資工系所。他研究 AI 超過 50 年，曾獲英國女王授予 OBE 勳章，並連續多年被《時代》雜誌評選為 AI 領域最具影響力人物。

在這集長達兩小時的訪談中，Russell 詳細剖析了為什麼他認為人類正在接近一個「不可逆轉的臨界點」。

## 什麼是「事件視界」？

「事件視界」是物理學中的概念，來自黑洞理論。

想像一個質量極大的物體，大到連光都無法逃脫它的引力。在這個物體周圍，存在一條看不見的界線。一旦你越過這條線，就再也不可能回頭——你會被不可逆轉地拉向黑洞的中心。

這條界線，就叫做事件視界。

Altman 用這個比喻來描述 AI 的發展。他的意思是：我們可能已經到了一個點，無論我們想不想，AGI（通用人工智慧）的到來已經變得不可避免。我們已經被拉進那個引力場，正在被吸向那個中心。

## 15 萬億美元的磁鐵

Russell 用另一個比喻來解釋這個現象：一塊巨大的磁鐵。

「想想 AGI 的經濟價值，」他說。「我估計大約是 15 萬億美元。這個巨大的獎金就像未來的一塊超級磁鐵，把我們都拉過去。越接近它，吸力越強。」

這解釋了為什麼即使大家都知道風險，也停不下來。越接近 AGI，投資報酬率看起來越高。越多錢投入，就有越多人依賴這些投資獲得回報。這形成了一個正向循環——或者，如果你擔心後果的話，一個惡性循環。

「我們已經開始看到這個投資的衍生效益，」Russell 指出。「比如 ChatGPT，它已經開始產生收入。所以它確實像磁鐵一樣運作。越接近，我們就越難抽身。」

## 各大執行長怎麼說？

訪談中，主持人 Steven Bartlett 整理了各大 AI 公司執行長對 AGI 時程的預測：

- **Sam Altman**（OpenAI）：2030 年之前
- **Demis Hassabis**（Google DeepMind）：2030 到 2035 年
- **Jensen Huang**（NVIDIA）：大約五年
- **Dario Amodei**（Anthropic）：2026-2027 年會有接近 AGI 的強大 AI
- **Elon Musk**：2020 年代

幾乎所有人的預測都落在五年以內。

但 Russell 有不同看法。

「我實際上認為會更久一些，」他說。「我不認為你可以純粹基於工程來做預測。是的，我們可以把機器做大十倍、做快十倍。但這可能不是我們還沒有 AGI 的原因。」

「事實上，我認為我們擁有的運算能力已經遠超過 AGI 所需——可能超過一千倍。我們還沒有 AGI 的原因，是我們不知道如何正確地建造它。」

## 「我們像古埃及人一樣」

Russell 用一個精妙的比喻來說明我們對 AI 的理解程度。

「古埃及人可以精確地測量太陽的運行軌跡。精確到他們可以把金字塔的東西軸完美對準春分點。巨石陣的建造者也展現了對太陽週期的精確掌握。但他們完全不懂軌道力學。他們不知道地球繞著太陽轉。他們不知道為什麼太陽會東升西落、為什麼會有四季。在他們的神話裡，太陽是神駕著戰車拉過天空的。」

「我們對 Scaling Laws（規模定律）的理解，」Russell 繼續說，「與古人對太陽的理解處於類似的階段：精確測量，但缺乏根本性的理解。」

Scaling Laws 是目前 AI 發展的核心驅動力。研究人員發現，當你增加模型的參數量、訓練資料量、以及運算量時，模型的表現會以一種可預測的方式提升。但沒有人真正知道這個定律為什麼會成立。

這帶來一個實際問題：既然我們不知道它為什麼有效，我們也無法確定它什麼時候會停止有效。

## 「快速起飛」：AI 自己研究 AI

Russell 提到了另一個令人擔憂的可能性：「智慧爆炸」（intelligence explosion）。

這個概念最早由 Alan Turing 的同事 I.J. Good 在 1965 年提出。想法是這樣的：一個智慧足夠高的 AI 系統，可以自己做 AI 研究。它可以設計更好的演算法、更好的硬體架構、更好的訓練方法。然後用這些改進來升級自己，變得更聰明。然後再做更多 AI 研究，再次升級自己。

「假設它一開始的『智商』是 150，」Russell 解釋。「它用這個智商做 AI 研究，改進了自己，現在智商變成 170。接著它用 170 的智商做更多研究——而且因為更聰明了，做得更好。下一次迭代變成 250。然後繼續。」

這就是所謂的「快速起飛」（fast takeoff）。一旦 AI 達到某個臨界點，它可能會在極短時間內超越人類智慧，快到我們根本來不及反應。

Altman 自己也說過：「我認為快速起飛的可能性比幾年前我想的更高。」

## 史上最大的科技專案

Russell 提供了一個驚人的數據對比。

二戰期間，曼哈頓計畫開發原子彈的預算，換算成 2025 年的幣值，大約是 200 多億美元。

而明年（2026 年）全球投入 AGI 開發的預算，預計將達到一兆美元。

「這是曼哈頓計畫的 50 倍，」Russell 說。「這是人類歷史上規模最大的科技專案，而且差距還在拉大。」

這麼多錢砸下去，當然會有進展。問題是，這些進展是在安全可控的方向上嗎？

## 監管：一億分之一的標準

Russell 認為，有效的監管應該要求 AI 公司證明他們的系統是安全的。

他用核電廠的標準來做對比。核電廠必須證明，核心熔毀的機率低於每年一百萬分之一。有些電廠做到了每年一千萬分之一。這需要大量的數學分析——分析每個組件、冗餘系統、監控機制、操作程序。

「那麼，對於人類滅絕這種風險，我們應該接受什麼樣的機率？」Russell 問。「一百萬分之一？滅絕比核電廠熔毀嚴重多了。也許應該是一億分之一？」

「現在那些執行長們說的是多少？25%。他們差了幾百萬倍。」

「如果我們要求他們證明風險低於每年一億分之一，他們會說什麼？他們會說：『我們不知道怎麼做。』」

「這實際上就是在說：人類沒有權利保護自己免受我們的傷害。」

## 可能建造安全的超級智慧嗎？

訪談最後，Bartlett 問了一個關鍵問題：建造安全的、可控的超級智慧 AI，到底有沒有可能？

Russell 說：有可能。但需要一種根本不同的架構。

「長期以來，AI 的概念就是『純粹的智慧』——帶來你自己想要的未來的能力。智慧越高越好。但我們其實不想要純粹的智慧。因為它想要的未來，可能不是我們想要的未來。」

「宇宙並沒有把人類特別標示為唯一重要的東西。純粹的智慧可能決定讓蟑螂過得很好，或者根本不在乎生物生命。」

「我們真正想要的，是一種唯一目的是實現人類想要的未來的智慧。它必須以人類為中心，不是蟑螂，不是外星人，不是它自己。」

問題在於：如何精確定義「人類想要的未來」？這是一個出了名難以回答的問題。Russell 引用了「邁達斯國王」的故事：邁達斯向神許願，希望他碰到的一切都變成黃金。結果他的食物變成黃金，他的女兒變成黃金。他在飢餓和悲傷中死去。

「這說明了精確描述我們想要什麼有多困難。」

Russell 的解決方案是：不要試圖預先定義目標。讓 AI 系統一開始就處於「不知道人類想要什麼」的狀態，然後透過觀察和互動來學習。而且永遠保持一定程度的不確定性——這樣它就不會貿然採取可能傷害人類的行動。

這在數學上是可行的。問題是，目前的公司都在往完全相反的方向跑。

---

**關於 Stuart Russell**：
Stuart Russell 是加州大學柏克萊分校計算機科學教授，曾獲英國女王授予 OBE 勳章，連續多年被《時代》雜誌評選為 AI 領域最具影響力人物。他與 Google 研究總監 Peter Norvig 合著的《Artificial Intelligence: A Modern Approach》是全球最暢銷的 AI 教科書，目前已發行第四版（2021 年），臺灣可在天瓏書店購買。他的另一本著作《Human Compatible: Artificial Intelligence and the Problem of Control》深入探討如何建造對人類有益的 AI 系統。
