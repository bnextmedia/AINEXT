---
title: "GPT-4o 引用論文有九成是捏造的：Nature 新研究揭露學術 AI 的致命弱點"
date: 2026-02-06T10:00:00+08:00
description: "華盛頓大學與 AI2 團隊在 Nature 發表研究，揭露 GPT-4o 在引用科學文獻時有 78-90% 的幻覺率——那些論文根本不存在。他們打造的開源系統 OpenScholar 透過檢索增強架構將幻覺率降至 0%，且在專家評測中勝過人類撰寫的文獻回顧。"
tags: ["OpenScholar", "RAG", "引用幻覺", "Nature", "AI2"]
categories: ["AI 技術前沿"]
source_url: "https://www.nature.com/articles/s41586-025-10072-4"
source_name: "Nature"
related_companies: ["ai2"]
related_people: []
image: "/images/posts/20260206-openscholar-citation-hallucination.webp"
draft: false
---

![封面圖](/images/posts/20260206-openscholar-citation-hallucination.webp)

> 本文整理自華盛頓大學與艾倫人工智慧研究所（AI2）團隊 2026 年 2 月發表於 *Nature* 的研究論文。本文為 OpenScholar 系列第一篇，聚焦引用幻覺問題。系列其他文章：[小模型為什麼能贏](/posts/20260206-openscholar-small-model-beats-gpt4o/)、[AI vs 人類專家評測](/posts/20260206-openscholar-ai-vs-human-experts/)。

---

## 你用 ChatGPT 查過論文引用嗎？

如果你是研究生、學者、或任何需要查閱科學文獻的人，你大概做過這件事：把一個研究問題丟給 ChatGPT，請它幫你整理相關文獻、列出參考資料。它回答得頭頭是道，引用格式完整，作者名、期刊名、年份一應俱全。看起來非常專業。

但你有沒有真的去查過那些引用？大多數人沒有。我們傾向於信任 AI 產出的東西，尤其當它的格式看起來無懈可擊的時候。而這正是問題所在。

華盛頓大學與艾倫人工智慧研究所（AI2）的研究團隊做了這件事。他們系統性地測試了 GPT-4o 在回答科學問題時引用文獻的準確度，結果令人震驚：在電腦科學領域，GPT-4o 引用的論文有 78.7% 是捏造的，那些論文根本不存在。在生物醫學領域更慘，幻覺率高達 94.8%。連 2025 年 8 月才發布的 GPT-5，論文標題的幻覺率仍然有 39%。這個問題不分模型——Meta 的 Llama 3.1 系列同樣嚴重。換句話說，你用 AI 查到的十條引用裡，可能只有一兩條是真的。這是一個結構性的問題，不是偶發的小錯。

## 為什麼大型語言模型會捏造引用？

這些模型明明「讀過」大量論文，為什麼還會編出根本不存在的文獻？原因其實很直覺：大型語言模型的本質是一個「補全」機器。當你問它一個學術問題並要求附上引用，它做的事情不是去資料庫裡搜尋，而是根據訓練時見過的大量文字模式，「產生」一段看起來像引用的文字。它學到了學術引用長什麼樣子——作者名通常是 Smith et al.、年份放在括號裡、期刊名用斜體——所以它能生成格式完美但內容虛構的引用。

這個問題的嚴重性遠超出「不方便」的程度。學術引用是整個科學知識體系的信任基礎。一篇論文的可信度，很大一部分來自它引用了哪些先前研究、這些研究是否支持它的論點。當 AI 系統性地產生假引用，而使用者又不加驗證地採用，它動搖的是科學溝通的基本誠信。尤其在生物醫學領域，一個虛構的臨床試驗引用，可能影響實際的治療決策。

更麻煩的是，這些捏造的引用極難辨識。模型不會隨便瞎編，它產生的假論文標題通常聽起來非常合理——它可能組合了真實存在的作者名和一個真實存在的研究方向，產生一篇「應該存在但其實不存在」的論文。你必須逐一去 Google Scholar 或 PubMed 搜尋才能發現問題，這幾乎抵消了用 AI 查文獻的效率優勢。

## OpenScholar：讓 AI 先查再答的架構

面對這個問題，華盛頓大學的 Akari Asai 和 Hannaneh Hajishirzi 帶領的團隊採取了一個很不同的策略：他們不試圖「教模型不要說謊」，而是直接改變 AI 回答學術問題的方式。他們打造的系統叫做 OpenScholar，核心思路很簡單——別讓模型從記憶中「生成」引用，讓它先去真實的論文資料庫裡搜尋，找到真正存在的論文之後，再根據這些論文來回答問題。

這個思路在技術上叫做「檢索增強生成」（Retrieval-Augmented Generation, RAG），概念並不新。但 OpenScholar 把這個概念做到了一個新的高度。團隊建立了一個包含 4,500 萬篇開放取用論文的資料庫，預先計算了 2.36 億個段落的嵌入向量。靠著這個龐大的索引，模型可以在幾秒內找到相關段落。這是目前公開的最大科學文獻檢索資料庫。

其次是檢索的精細度。OpenScholar 不只是簡單地搜尋一次。它用了三層檢索管線：第一層是一個 1.1 億參數的雙編碼器，快速從 2.36 億個段落中篩出前 70 個候選；第二層同時使用 Semantic Scholar API 做關鍵字搜尋和 You.com 的學術搜尋做補充；第三層用一個 3.4 億參數的交叉編碼器重新排序，挑出最終使用的段落。這種多管齊下的方式確保了既不會漏掉重要的文獻，也不會被單一檢索方式的盲點所限制。

但最巧妙的設計是 OpenScholar 的「自我回饋」機制。模型產生初稿後，會自己審視回答內容，產生最多三條改進建議。這些建議是具體的，比如「這個論點缺少支持證據」或「需要補充更新的研究」。然後系統會根據這些建議進行新一輪的檢索，補充遺漏的文獻，修訂回答。最後還有一個引用驗證步驟，逐一確認每個引用是否真實存在、是否支持其所附著的論述。整個過程就像一個認真的研究助理：先查資料、寫初稿、自我檢查、補充修正、最後確認每個引用都站得住腳。

## 結果：0% 幻覺率，成本只要 0.003 美元

效果呢？在研究團隊設計的 ScholarQABench 基準測試上——這是首個跨學科的科學文獻綜述評測，涵蓋電腦科學、物理學、神經科學和生物醫學四個領域，由博士級專家花平均 56 分鐘撰寫每題的標準答案——OpenScholar-8B（基於 Meta 的 Llama 3.1 8B 微調）的引用幻覺率是 0%。不是「很低」，是零。

和其他系統比較一下。PaperQA2 是另一個學術文獻 AI 系統，每個問題的處理成本是 0.3 到 2.3 美元。OpenScholar-8B 的成本是每個問題 0.003 美元——便宜了兩到三個數量級。即使是搭配 GPT-4o 的版本（OpenScholar-GPT-4o），成本也只有每個問題 0.05 美元。在正確性方面，OpenScholar-8B 比 GPT-4o 高出 6.1 個百分點，比 PaperQA2 高出 5.5 個百分點。

但最有說服力的數據來自人類專家的評估。研究團隊邀請了 16 位博士級學者，針對 108 個問題，把 OpenScholar 的回答和人類專家撰寫的答案放在一起比較（評審不知道哪個是 AI 寫的）。結果，專家們有 70% 的時間偏好 OpenScholar-GPT-4o 的回答，51% 的時間偏好 OpenScholar-8B 的回答。相較之下，沒有檢索增強的 GPT-4o 只有 31% 的偏好率——甚至輸給人類專家。換句話說，加了正確的檢索架構之後，同一個 GPT-4o 從「不如人類」變成了「大幅勝過人類」。

專家們偏好 OpenScholar 的主要原因是覆蓋面。AI 能在幾秒內掃描數千萬篇論文，找出人類專家可能漏掉的相關研究。OpenScholar-GPT-4o 產生的回答平均長度是人類專家答案的 2.4 倍，引用的論文數量也更多。在學術文獻回顧這個任務上，AI 的廣度優勢是人類很難匹敵的。

## 這篇論文真正重要的，不是「AI 很強」

這篇 Nature 論文引起廣泛報導。Times Higher Education 下的標題是「新聊天機器人在文獻回顧上超越博士生」，聽起來像是又一個「AI 取代人類」的故事。但我覺得這篇研究真正重要的訊息在別處。

最直接的訊息是關於可信度。過去兩年，很多人把 ChatGPT 當成一個什麼都能做的工具，包括學術研究。這篇論文用硬數據告訴你：不行。至少在引用文獻這件事上，目前主流的大型語言模型是不及格的，它們系統性地產生虛假資訊。如果你正在寫論文，請不要直接採用 ChatGPT 給你的引用，除非你每一條都手動驗證過。

但更值得關注的是架構層面的啟示。OpenScholar 證明了一件事：AI 的可靠性不只取決於模型大小，更取決於系統架構。一個 80 億參數的模型搭配正確的檢索、排序和自我驗證機制，可以在專業任務上擊敗參數量可能超過十倍的通用模型。與其無限追求更大的模型，不如在特定領域把系統架構做對。

還有一點我特別在意：OpenScholar 的所有元件全部開源。模型、資料庫、訓練資料、評測基準，一個都不藏。這在 AI 研究日益封閉的趨勢下格外重要。自 2024 年底 OpenScholar 在 arXiv 上發布預印本以來，OpenAI、Google 等公司也陸續推出了類似的「深度研究」功能，大幅改善了引用準確度。但那些是黑盒子，你不知道它怎麼搜尋、怎麼排序、為什麼選了這篇論文而非那篇。OpenScholar 讓任何研究者都能檢視、複製和改進整個系統。對於科學研究來說，這種透明度本身就是一種價值。

OpenScholar 的公開示範系統自上線以來已經吸引超過 3 萬名使用者、處理近 9 萬次查詢。研究者對「可靠的 AI 文獻助手」有巨大的需求，這個數字就是最好的證明。問題一直都是同一個：AI 能不能做到不說謊？OpenScholar 給出了第一個令人信服的答案。
