---
title: "yc anthropic overtakes openai"
date: 2025-12-23T12:01:28+08:00
description: "> 本文整理自 YC 官方 Podcast《The Light Cone》2025 年 12 月播出的年度回顧單集。 > 🎧 收聽連結：[YouTube](https://www.youtube.com/watch?v=cqrJzG03ENE) --- ## 一個數據的翻轉 YC 每年都會在申請"
tags: ["AI"]
categories: ["AI"]
draft: false
---


> 本文整理自 YC 官方 Podcast《The Light Cone》2025 年 12 月播出的年度回顧單集。
> 🎧 收聽連結：[YouTube](https://www.youtube.com/watch?v=cqrJzG03ENE)

---

## 一個數據的翻轉

YC 每年都會在申請表上問創業者一個問題：你的技術堆疊用什麼模型？這個問題的答案，某種程度上反映了開發者社群對各家 LLM 的真實偏好——不是問你覺得哪家厲害，而是問你實際在用哪家。

Winter 26 批次的數據出來了，結果讓 YC 合夥人自己都嚇一跳：**Anthropic 首度超越 OpenAI，成為最多創業者選用的 API**。這在兩年前根本無法想像。Diana Hu 回憶，當 The Light Cone 這個 Podcast 剛開始做的時候，OpenAI 的市占率超過 90%。現在？被 Anthropic 超越了。

這不是一夜之間發生的翻轉。2024 年到 2025 年初，Anthropic 的佔比大約在 20-25% 徘徊，而 OpenAI 雖然持續下滑，但還是穩居第一。真正的「換代」發生在最近三到六個月。Diana 形容這是一個「曲棍球桿」式的成長——Anthropic 一路攀升到超過 52%。

---

## Gemini 的崛起也值得注意

另一個有趣的數字是 Google Gemini。去年這個時候，Gemini 在 YC 創業者中的使用率大約只有 2-3%，連個位數都勉強。但 Winter 26 的數據顯示，Gemini 已經爬升到 23%。

Harj Taggar 說他自己就是 Gemini 的愛用者。在 2.5 Pro 出來之前，他就已經把 Gemini 當成日常的主力工具。主要原因不是模型本身特別強，而是 Google 的 Grounding API——它能即時調用 Google 的搜尋索引，回答「今天發生了什麼」這類需要最新資訊的問題。他試過 Perplexity，快是快，但準確度不如 Gemini。

這反映了一個微妙的轉變：選模型不再只看「誰的 benchmark 分數高」，而是看「誰在我的使用場景下最可靠」。對 Harj 來說，那個場景是即時資訊查詢。對其他人，可能是程式碼生成、長文分析、或者多模態理解。

---

## 為什麼是 Anthropic？Coding 的溢出效應

那為什麼 Anthropic 能在這麼短時間內逆轉局勢？

Diana 的分析是：**Coding 能力**。這兩年 Vibe Coding 工具和 Coding Agent 大爆發，從 Cursor 到 Replit 到各種 AI 輔助開發工具，程式碼生成變成一個巨大的市場。而在這個領域，Claude 的表現被公認是最好的。

這不是偶然。Diana 提到她之前跟 Anthropic 共同創辦人 Tom Brown 的對話——他們內部的 eval（評估指標）就是刻意把 coding 能力當成北極星。你對什麼做最佳化，你就會在那個方向變強。Anthropic 選擇了 coding，然後贏了。

但更有趣的是一個「溢出效應」。Gary Tan 指出，大多數創業者用 LLM 做的事情其實不是寫程式。他們可能在做客服機器人、內容生成、資料分析。但因為他們自己每天用 Claude 寫程式，對 Claude 的「個性」和「品味」非常熟悉，所以在選擇產品要用的模型時，自然傾向選一個自己最了解的。這就像你每天用 iPhone，買新電腦時可能也會傾向買 Mac——不一定是因為 Mac 在那個用途上最好，而是因為你信任這個生態系。

---

## 模型套利時代：不再效忠單一家

另一個重要趨勢是：**創業者不再「效忠」單一模型公司了**。

Diana 跟幾家 Series B 等級的 AI 新創聊過。這些公司以前可能是 OpenAI 或 Anthropic 的死忠用戶，但現在他們都在建構一個「編排層」——一個抽象化的架構，讓他們可以根據任務類型，動態選擇最適合的模型。

一個具體的例子：有家新創用 Gemini 3 做 context engineering（整理、壓縮、結構化上下文資訊），然後把處理過的 context 餵給 OpenAI 的模型去執行任務。每當有新模型發布，他們就跑一輪自己的 eval，看看哪個模型在哪個環節表現最好，然後更新配置。

這個策略成立的前提是：你得有自己的 eval。這些公司做的是垂直領域的 AI agent，他們有領域專屬的資料集和評估標準。通用 benchmark 告訴你的是「這個模型整體有多強」，但垂直領域的 eval 告訴你的是「這個模型在我的任務上有多強」。兩者可能差很多。

Jared Friedman 用 Intel 和 AMD 的比喻：以前 PC 時代，每當有新架構發布，OEM 廠商就會評估要用哪家的晶片。現在 LLM 市場也進入類似的狀態——模型公司拼命提升性能，應用層公司則是坐享其成，挑最划算的用。

---

## 這對開發者意味著什麼？

如果你現在要選擇 LLM 來建構產品，YC 合夥人的觀察提供了幾個思考方向：

**第一，不要只看通用 benchmark。** 每家模型公司都會強調自己在某個 benchmark 上領先，但那不一定反映你的實際使用場景。建立自己的 eval，用自己的資料測試，才是最可靠的。

**第二，考慮建構模型抽象層。** 如果你的產品會長期發展，很可能會需要在不同模型之間切換。現在就設計一個能輕鬆換模型的架構，未來會省很多麻煩。

**第三，關注「品味」而非只看「能力」。** 不同模型有不同的「個性」——Gary 形容 OpenAI 像黑貓，有點傲嬌；Anthropic 像金毛獵犬，熱情友善；Gemini 則介於兩者之間。這種個性會影響使用者體驗，尤其是直接面對終端使用者的應用。

市場正在快速變化。兩年前 OpenAI 看起來不可撼動，現在已經被超越。兩年後？沒人知道。唯一確定的是，競爭對應用層開發者來說是好事——更多選擇、更低成本、更快的進步。
