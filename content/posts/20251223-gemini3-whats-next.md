---
title: "從 Gemini 3 看 AI 的下一步：長上下文、注意力機制與持續學習"
date: 2025-12-23T00:56:00+08:00
description: "Gemini 3 預訓練負責人 Sebastian Bourgeaud 分享接下來的技術方向：長上下文能力的效率提升、注意力機制的新發現、端對端可微分學習整合檢索功能、以及解決災難性遺忘的持續學習。AI 研究正從「優化模型」轉向「建構系統」。"
tags: ["Gemini", "長上下文", "注意力機制", "持續學習", "RAG"]
categories: ["AI 技術前沿"]
source_url: "https://www.youtube.com/watch?v=cNGDAqFXvew"
source_name: "The MAD Podcast with Matt Turck"
draft: false
---

> 本文整理自《The MAD Podcast with Matt Turck》2025 年 12 月 18 日播出的單集，訪談來賓為 Google DeepMind Gemini 3 預訓練負責人 Sebastian Bourgeaud。

{{< youtube cNGDAqFXvew >}}

---

## Gemini 3 之後，下一步是什麼

Gemini 3 的發布證明了預訓練 Scaling Laws 依然有效，也讓 Google DeepMind 在與 OpenAI、Anthropic 的競爭中重新站穩腳步。但對於站在研究前沿的人來說，更重要的問題是：接下來呢？

Sebastian Bourgeaud 是 Gemini 3 預訓練的負責人，當被問到接下來幾年會發生什麼時，他提到了幾個讓他興奮的技術方向。這些方向不是空泛的願景，而是他和團隊正在投入資源的具體研究領域。雖然他沒有透露太多細節——這畢竟是核心競爭力——但從他的描述中可以看出 AI 研究正在往哪個方向演進。

---

## 長上下文：從能力到效率

Bourgeaud 首先提到的是長上下文能力。Gemini 1.5 在這方面取得了顯著突破，能夠處理比之前更長的輸入。這種能力不只是技術指標的進步，它正在支撐一整類新的應用場景。

「我認為這真的在支撐今天各種 agent 和模型做複雜工作的能力，」他說。「當你在一個程式碼庫上工作時，你的上下文長度會持續增長。」想像一個 AI 程式助手需要理解整個專案的結構、追蹤多個檔案之間的依賴關係、記住之前討論過的設計決策——這一切都需要超長的上下文視窗。

但當前的長上下文能力還有很大的改進空間。首先是效率問題：處理超長輸入需要消耗大量運算資源，成本高昂。其次是上下文長度本身的限制：即使目前的限制已經很高，對於某些應用場景（比如分析一整本書、處理一整年的對話記錄）仍然不夠。

Bourgeaud 預期接下來一年會看到更多這方面的創新——既要讓長上下文更有效率，也要繼續擴展上下文長度的上限。這不是容易的問題。Transformer 架構的注意力機制在處理長序列時會遇到根本性的運算瓶頸，需要巧妙的工程和架構創新才能突破。

---

## 注意力機制的新發現

說到注意力機制，Bourgeaud 透露了一個有趣的訊息：他們最近在這個方向有了「非常有趣的發現」，將會影響未來幾個月的研究方向。

「在注意力方面，至少對我們來說，我們最近有一些非常有趣的發現，我認為這會形塑我們接下來幾個月很多的研究。我個人對此非常興奮。」

他沒有透露具體是什麼發現，這可能是 Google DeepMind 目前的競爭優勢之一。但這句話本身就很有意義：它暗示著即使在看似成熟的 Transformer 架構內部，仍然有重要的改進空間尚未被發現。

注意力機制是 Transformer 的核心。2017 年 Vaswani 等人發表「Attention Is All You Need」論文以來，這個架構已經主導了自然語言處理領域近八年。許多人假設這個架構已經被優化到極限，任何重大改進都必須來自全新的架構。但 Bourgeaud 的話暗示事實可能並非如此。

---

## 端對端可微分學習：把檢索融入訓練

另一個 Bourgeaud 提到的長期方向更加根本性：把檢索（retrieval）直接整合進模型的訓練過程。

目前的 RAG（檢索增強生成）系統是把檢索當成一個外部模組：先用一個獨立的系統找到相關文件，然後把這些文件塞進模型的上下文中。這種方法有效，但有點像是在正規教育之外偷偷夾帶小抄——檢索系統和生成模型各自為政，沒有真正整合。

Bourgeaud 認為長期的方向是讓整個系統「端對端可微分」——意思是，檢索的過程本身也成為可以被訓練優化的一部分，而不是一個固定的外掛模組。

「我認為長期的方向是端對端可微分的學習，把檢索和搜尋直接整合進訓練過程本身。」他說。這個方向的技術挑戰不小：如何讓一個離散的檢索過程（從資料庫中選擇特定文件）變成可以用梯度下降優化的連續過程？但如果能做到，模型就能學會自己決定什麼時候需要查資料、查什麼資料、以及如何利用查到的資訊。

Bourgeaud 之前在 DeepMind 的研究經歷與此相關。他參與過 Retro 計畫，這是一個早期嘗試把檢索能力內建到語言模型中的研究項目。那個計畫的經驗顯然影響了他對未來方向的判斷。

---

## 持續學習：模型如何跟上世界的變化

還有一個方向是持續學習（continual learning）。目前的大型語言模型有一個尷尬的限制：它們的知識截止於訓練數據的收集時間。訓練完成後，世界繼續變化，但模型的知識是靜態的。

這不只是一個學術問題。當使用者問一個關於最近事件的問題時，模型要嘛承認不知道，要嘛（更糟糕地）用過時的資訊胡說八道。目前的解決方案包括定期重新訓練、使用 RAG 補充即時資訊、或是微調模型加入新知識。但這些都是權宜之計。

理想的解決方案是讓模型能夠持續學習新資訊，而不會忘記已經學過的東西。這在機器學習中被稱為「災難性遺忘」（catastrophic forgetting）問題：神經網路在學習新任務時，往往會把舊任務的能力忘掉。解決這個問題需要在模型架構和訓練方法上進行根本性的創新。

Bourgeaud 沒有詳細討論這個方向的進展，但他把它列為讓他興奮的長期研究領域之一。這暗示著這可能是接下來幾代 Gemini 會重點投入的方向。

---

## 多模態：Gemini 的傳統優勢

Gemini 系列從一開始就以原生多模態聞名。「原生多模態」的意思是，處理文字、圖片、音訊、影片的不是幾個分開的模型拼接在一起，而是同一個神經網路。這種設計讓不同模態之間能夠更自然地互動和理解。

Bourgeaud 表示這是 DeepMind 歷來的強項，而且這個優勢仍在持續。「歷史上，DeepMind 在視覺和多模態方面一直非常非常強。這種情況今天依然如此，從人們使用模型的方式和 benchmark 結果都能看出來。」

多模態能力的提升不只是技術成就，它直接影響模型的實用性。當一個模型能真正「理解」圖片內容、能分析影片中發生的事、能聽懂音訊中的對話，它的應用範圍就會大幅擴展。這也是 Gemini 與某些競爭對手的差異化所在。

當然，多模態也帶來了額外的複雜性。Bourgeaud 承認這是一種「成本」：不同模態會以複雜的方式互相影響，讓研究變得更困難；圖像等模態的輸入尺寸通常也比純文字大，帶來更高的運算成本。但他認為這些成本被多模態帶來的好處所抵消。

---

## 從模型到系統的視角

綜合 Bourgeaud 提到的這些方向——長上下文、注意力機制、端對端學習、持續學習、多模態——有一個共同的主題：AI 研究正在從「優化一個模型」轉向「建構一個系統」。

純粹的模型能力（更高的 benchmark 分數、更大的參數量）當然重要，但不再是唯一的戰場。接下來的競爭會越來越圍繞著：模型如何與外部知識互動？如何處理超長的工作記憶？如何適應不斷變化的世界？如何同時處理多種形式的資訊？

這些問題的答案不會只來自單一的架構突破，而是需要在多個層面同時創新：模型架構、訓練方法、推理效率、系統整合。這也是為什麼 Bourgeaud 反覆強調「我們在建造的不只是模型，而是整個系統」。

對於關注 AI 發展的人來說，這些方向提供了一個路線圖，指出接下來幾年的進展可能從哪裡來。不是某個戲劇性的突破（雖然那也可能發生），而是在這些領域的持續累積，最終匯聚成新一代更強大、更實用的 AI 系統。
