---
title: "比 Transformer 更像人腦思考？Sakana AI 的 Continuous Thought Machine"
date: 2026-01-23T11:00:00+08:00
description: "Sakana AI 發表的 Continuous Thought Machine 獲得 NeurIPS 2025 Spotlight。這個受生物啟發的新架構，透過神經元同步化和自適應計算，展現出類似人類的推理行為。"
tags: ["Sakana AI", "Continuous Thought Machine", "CTM", "Llion Jones", "NeurIPS", "Podcast"]
categories: ["AI 技術前沿"]
source_url: "https://www.youtube.com/watch?v=DtePicx_kFY"
source_name: "Machine Learning Street Talk"
draft: false
---

> 本文整理自 Machine Learning Street Talk 2025 年 11 月播出的訪談。

{{< youtube DtePicx_kFY >}}

{{< spotify "episode/5zKGl6HNid03ExP7n5i4U8" >}}

{{< apple-podcast "tw/podcast/he-co-invented-the-transformer-now-continuous-thought/id1510472996?i=1000738009211" >}}

---

Sakana AI 的研究員 Luke Darlow 在 Podcast 中介紹了團隊最新的研究成果：Continuous Thought Machine（CTM），一個獲得 NeurIPS 2025 Spotlight 的新架構。

「你應該關注它，因為它有原生的自適應計算能力，」Darlow 說，「這是一種新的遞迴模型建構方式，使用更高層次的神經元概念和同步化作為表徵，讓我們能以更接近人類的方式解決問題。」

## 三個核心創新

CTM 建立在三個關鍵的設計理念上：

### 1. 內部思考維度

傳統神經網路一次性處理輸入、輸出答案。CTM 則有一個「內部思考維度」——模型可以在這個維度上進行序列性的計算。

Darlow 用迷宮解題來說明。傳統深度學習解迷宮很簡單：輸入迷宮圖片，輸出路徑圖。但如果要求模型像人一樣解題——「上、右、上、左...」一步步給出方向——問題就變得困難許多。

「當你用這種方式約束問題空間，要求機器學習系統像人一樣解題時，問題變得更有挑戰性，」Darlow 說，「這成了我們的『Hello World』問題。」

### 2. 神經元級模型

傳統神經網路的「神經元」是極度簡化的：一個 ReLU 函數，開或關。但生物神經元的運作複雜得多。

CTM 的做法是讓每個神經元本身成為一個小型模型。它不只接收當前輸入，還會參考自己過去的激活歷史，再產出一個輸出值。這在深度學習的可訓練性和生物真實性之間找到了一個平衡點。

### 3. 同步化表徵

這是 CTM 最獨特的設計。

傳統遞迴網路用「狀態向量」來表示模型在某個時間點的狀態。但 Darlow 問了一個哲學性的問題：一個想法（thought）真的能用某個瞬間的狀態來捕捉嗎？

「一個想法是存在於時間之上的東西，」他說。

CTM 的解法是測量神經元之間的「同步化程度」——兩個神經元的激活時間序列有多相關。如果系統有 D 個神經元，就有 D²/2 種配對關係。這讓表徵空間變得比單純的狀態向量豐富得多。

更進一步，CTM 用不同的時間尺度來衡量同步化：有些神經元配對只看「現在」是否同步放電，有些則看更長時間範圍的整體關聯。這呼應了生物大腦中不同腦波對應不同思考狀態的現象。

## 自適應計算：簡單問題快速解，複雜問題慢慢想

CTM 最令人驚豔的特性之一是「自適應計算時間」自然地從架構中湧現。

Darlow 解釋訓練方法：讓模型跑 50 步內部計算，然後找出兩個點——「哪一步表現最好」和「哪一步最確定」。損失函數只在這兩個點上計算。

結果是：簡單的 ImageNet 圖片，模型在一兩步內就給出答案；困難的圖片，模型會自然地使用更多「思考時間」。不需要額外的懲罰項或複雜的超參數調校，這個行為就自己出現了。

「這和 Alex Graves 之前的 Adaptive Computation Time 研究不同，」Transformer 共同發明人 Llion Jones 補充，「那篇論文需要大量的超參數調校，因為你必須平衡『用更多計算』和『懲罰計算量』兩個目標。CTM 的自適應計算是自然湧現的。」

更意外的收穫是：CTM 訓練完成後，模型校準（calibration）幾乎完美。

「大多數訓練夠久的模型都會校準不良——對某些錯誤答案過度自信，對某些正確答案又太不確定，」Darlow 說，「但 CTM 幾乎完美校準。如果它說有 90% 機率是貓，那真的有 90% 的時候是對的。這像是一個煙霧信號，暗示這可能是更好的做法。」

## 時間壓力下的跳躍式推理

研究團隊觀察到一個迷人的現象：當限制 CTM 的思考時間，但要求它解決長迷宮時，它發展出一種全新的策略。

「它不會從頭追蹤路徑，」Darlow 描述，「而是先跳到大概正確的位置，從那裡往回追蹤，然後再跳到前面，往回追蹤，像青蛙跳一樣。」

這種「跳躍式推理」是模型在時間壓力下自己發展出來的演算法，完全不是人為設計的。

「這告訴我們什麼？在時間受限的情況下，模型會學到什麼不同的演算法？這和人類在壓力下的思考方式有關係嗎？」Darlow 說，「有很多有趣的問題可以探索。」

另一個觀察：在訓練中期，模型會出現「試探、發現錯誤、回溯、嘗試另一條路」的行為。雖然最終訓練成熟後這個行為消失了（模型學會用注意力機制更有效率地探索），但這顯示 CTM 架構本身支援這種類人的推理過程。

## Sudoku Bench：GPT-5 只有 15% 正確率的推理基準

訪談中，Jones 還介紹了 Sakana AI 發布的另一項研究：Sudoku Bench。

這不是普通的數獨。這些是「變體數獨」——除了標準規則外，每題都有手工設計的獨特額外約束。有的題目會在描述中說「順帶一提，上面某個數字是錯的」，要求你先推理出哪裡有誤；有的題目在數獨上疊加迷宮，要求同時滿足兩種約束。

「目前最好的模型正確率大約 15%，而且只能解最簡單、最小的題目，」Jones 說，「我們會發布 GPT-5 的測試結果——有進步，但仍然無法解決人類能解的題目。」

更有價值的是資料集附帶的「思考軌跡」。研究團隊從 YouTube 頻道「Cracking the Cryptic」取得授權，擷取了數千小時專家解題的詳細推理過程。

「這些專家會說：『這看起來像奇偶性問題』或『我應該用路徑追蹤工具』，」Jones 解釋，「他們有一整套推理的樂高積木，會根據題目類型選擇對應的策略。這種『對推理進行推理』的能力，現在的 AI 還沒有。」

Jones 引用 Andrej Karpathy 的觀點：如果我們真的想要 AGI，需要的不是網路上所有的文字，而是人類寫下那些文字時腦中的「思考軌跡」。Sudoku Bench 正是這樣的資料集。

---

## 我的觀察

CTM 這類研究最珍貴的地方，不只是它可能帶來的技術突破，而是它示範了一種研究方法論。

Darlow 在訪談中反覆強調：CTM 的很多特性——自適應計算、完美校準、跳躍式推理——都不是設計目標，而是「自然湧現」的。團隊的做法是：先建構一個生物啟發的架構，然後觀察它會發展出什麼行為。

這和主流 AI 研究的路徑很不同。主流路徑是：定義一個明確目標（比如「提升 ImageNet 準確率」），然後設計方法去達成。CTM 團隊的路徑是：設計一個「感覺對」的架構，然後探索它能做什麼。

這種研究需要時間、需要容錯、需要對「還不知道會發現什麼」的探索保持開放。Jones 說他們花了八個月打磨這篇論文，期間完全不擔心被搶先——因為根本沒人在做類似的事。

某種程度上，這是一種奢侈。但也是必要的奢侈。

如果所有 AI 研究都在追趕 Transformer 的下一個百分點改進，如果所有資源都投入「已知有效」的方向，我們可能會在局部最優解上越陷越深。CTM 也許不會成為下一個 Transformer，但這種願意退一步、從基礎重新思考的研究，是產業保持突破可能性的必要投資。

八個月的探索性研究，換來一個 NeurIPS Spotlight 和一系列意料之外的發現。這筆帳，怎麼算都值得。
