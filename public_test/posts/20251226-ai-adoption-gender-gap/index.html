<!DOCTYPE html>
<html lang="en" >
  <head>
  <title>Ai 採用的性別落差：同一間公司、同一份工作，女性使用率少 10% | AINEXT</title>
  <meta charset='utf-8'>
  <meta name="viewport" content ="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">


<meta name="keywords" content="AINEXT">
<meta property="og:locale" content='en_US'>
<meta property="og:type" content="article">
<meta property="og:title" content="AI 採用的性別落差：同一間公司、同一份工作，女性使用率少 10%">
<meta property="og:description" content="
本文整理自《The Pie》2025 年 6 月播出的單集「AI, the Economy, and Public Policy」。


  ">
<meta property="og:url" content="https://bnextmedia.github.io/AINEXT/posts/20251226-ai-adoption-gender-gap/">
<meta property="og:image" content="https://bnextmedia.github.io/AINEXT/images/images/logo.png">
<link rel="canonical" href="https://bnextmedia.github.io/AINEXT/posts/20251226-ai-adoption-gender-gap/">

<link rel="apple-touch-icon" sizes="180x180" href='https://bnextmedia.github.io/AINEXT/apple-touch-icon.png'>
<link rel="icon" type="image/png" sizes="32x32" href='https://bnextmedia.github.io/AINEXT/favicon-32x32.png'>
<link rel="icon" type="image/png" sizes='16x16' href='https://bnextmedia.github.io/AINEXT/favicon-16x16.png'>
<link rel="manifest" href='https://bnextmedia.github.io/AINEXT/site.webmanifest'>

<link rel="stylesheet" href="https://bnextmedia.github.io/AINEXT/css/styles.648e60c6d86809f863ae1346848574b9c685732794e7851c7d3e557de9ddd293bc1c209f963d5041785c2fd4268470bdfde453a99f550b655d1b4f825eed4682.css" integrity="sha512-ZI5gxthoCfhjrhNGhIV0ucaFcyeU54UcfT5Vfend0pO8HCCflj1QQXhcL9QmhHC9/eRTqZ9VC2VdG0&#43;CXu1Ggg==">
</head>

  <body>
    <div class="nav-drop">
  <div class="nav-body">
      <a href="https://bnextmedia.github.io/AINEXT/" class="nav_item">首頁</a>
      <a href="https://bnextmedia.github.io/AINEXT/archives/" class="nav_item">文章列表</a>
    <div class="nav-close"></div><div class="color_mode">
  <label for="mode">Toggle Dark Mode</label>
  <input type="checkbox" class="color_choice" id="mode">
</div>

  </div>
</div>
<header class="nav">
  <nav class="nav-menu">
    <a href=https://bnextmedia.github.io/AINEXT/ class="nav-brand nav_item">
        <img src="https://bnextmedia.github.io/AINEXT/images/logo.png" alt="AINEXT " class="logo-light" width="130px" />
        <img src="https://bnextmedia.github.io/AINEXT/images/logo-dark.png" alt="AINEXT " class="logo-dark" width="130px" /></a>
    
    
    <div class="nav-links">
        <a href="https://bnextmedia.github.io/AINEXT/" class="nav-link">首頁</a>
        <a href="https://bnextmedia.github.io/AINEXT/archives/" class="nav-link">文章列表</a>
    </div>
    
    <div class="nav_bar-wrap">
      <div class="nav_bar"></div>
    </div>
  </nav>
</header>

<style>
 
.nav-links {
  display: flex;
  flex-direction: row;
  gap: 1.5rem;
  align-items: center;
  white-space: nowrap;
}

.nav-link {
  color: var(--text);
  text-decoration: none;
  font-size: 0.95rem;
  padding: 0.5rem 0;
  transition: color 0.2s ease;
}

.nav-link:hover {
  color: var(--theme);
}

 
@media (min-width: 768px) {
  .nav_bar-wrap {
    display: none;
  }
}

 
@media (max-width: 767px) {
  .nav-links {
    display: none;
  }
  
  .nav_bar-wrap {
    display: grid;
  }
}

 
.logo-dark {
  display: none;
}

html[data-mode="dark"] .logo-light {
  display: none;
}

html[data-mode="dark"] .logo-dark {
  display: block;
}

 
@media (prefers-color-scheme: dark) {
  html:not([data-mode="light"]) .logo-light {
    display: none;
  }
  
  html:not([data-mode="light"]) .logo-dark {
    display: block;
  }
}

 
.nav {
  position: relative !important;
  background: var(--bg);
  padding: 0.5rem 0;
  border-bottom: 1px solid var(--border);
}

.mt {
  margin-top: 2rem !important;
}

 
.post {
  padding-top: 1rem;
}

.post_date {
  margin-top: 0;
}

 
.archive {
  padding-top: 1rem;
}

.archive_title {
  margin-top: 0;
}
</style>


    <main>
      
  <div class="wrap mt post">
    <div><p class=post_date>26. December 2025</p>
      <h1 class="post_title">AI 採用的性別落差：同一間公司、同一份工作，女性使用率少 10%</h1>
      <div class="post_body">
        <div class="post_inner">
        
        
          <blockquote>
<p>本文整理自《The Pie》2025 年 6 月播出的單集「AI, the Economy, and Public Policy」。</p>
</blockquote>
<div class="media-embed">
  <iframe 
    src="https://open.spotify.com/embed/us/podcast/pandemic-economics/id1509074261" 
    width="100%" 
    height="152" 
    frameBorder="0" 
    allowfullscreen 
    allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" 
    loading="lazy"
    style="border-radius: 12px;"
  ></iframe>
</div>

<div class="media-embed">
  <iframe 
    allow="autoplay *; encrypted-media *; fullscreen *; clipboard-write" 
    frameborder="0" 
    height="175" 
    width="100%"
    style="border-radius: 12px; overflow: hidden;" 
    sandbox="allow-forms allow-popups allow-same-origin allow-scripts allow-storage-access-by-user-activation allow-top-navigation-by-user-activation" 
    src="https://embed.podcasts.apple.com/us/podcast/pandemic-economics/id1509074261"
    loading="lazy"
  ></iframe>
</div>

<hr>
<p>想像兩個在同一間法律事務所工作的助理律師。他們處理同樣類型的案件，面對同樣的工作要求，擁有類似的教育背景。唯一的差別是，一個是男性，一個是女性。你可能會猜測，他們使用 AI 工具的比例應該差不多吧？</p>
<p>芝加哥大學 Booth 商學院的經濟學助理教授哈默（Anders Humlum）原本也這麼想。但當他和研究團隊分析實際數據時，結果讓他們大吃一驚：女性助理律師採用 AI 工具的比例，比她們的男性同事低了超過 10 個百分點。這個落差不是發生在不同公司之間，也不是發生在不同工作類型之間，而是在同一間公司、同樣的工作崗位上。</p>
<p>這個發現揭示了 AI 革命中一個令人不安的現象：號稱能「民主化」知識和技能的新技術，其紅利可能正在以我們沒有預期的方式被分配。</p>
<h2 id="一個讓研究者震驚的數字">一個讓研究者震驚的數字</h2>
<p>哈默在芝加哥大學 Becker Friedman Institute 舉辦的論壇上分享這個發現時，坦言這是他研究中「最令人驚訝」的結果。他原本預期會看到一些採用率的差異，但沒想到差距會這麼大，也沒想到會這麼系統性。</p>
<p>這個研究的設計非常嚴謹。研究團隊不是簡單地比較所有男性和女性員工的 AI 使用率，而是特別控制了可能造成混淆的因素。他們比較的是在同一間法律事務所工作、處理同樣類型法律任務的員工。這意味著工作環境、任務性質、公司文化這些外部因素都被排除了，剩下的差異更有可能反映個人層面的因素。</p>
<p>超過 10 個百分點的落差意味著什麼？假設一間事務所有 100 名男性助理律師和 100 名女性助理律師，如果男性中有 60 人在使用 ChatGPT 或類似工具來輔助工作，女性中可能只有不到 50 人在使用。這不是微小的統計差異，而是非常顯著的行為分化。</p>
<p>更值得注意的是，這個性別落差出現在一個理論上應該很容易「跨越」的門檻。使用 ChatGPT 不需要特殊的技術背景，不需要昂貴的設備，也不需要主管的批准——你只要開一個網頁，就可以開始嘗試。如果連這麼低的採用門檻都出現如此大的性別差異，我們不禁要問：是什麼造成了這個落差？</p>
<h2 id="不只是性別問題高薪族群用得更多">不只是性別問題：高薪族群用得更多</h2>
<p>哈默的研究揭示的不只是性別落差，還有一個更廣泛的不平等模式：AI 工具的使用，與使用者在 ChatGPT 出現之前的收入水準高度相關。簡單來說，本來賺得多的人，更傾向於使用 AI 工具；本來賺得少的人，反而用得更少。</p>
<p>這個發現與很多人對 AI 的期待形成了鮮明對比。很多人（包括一些知名經濟學家）認為，語言模型有潛力「填補技能落差」（bridge skills gaps）。理論上，一個沒有法律背景的人可以用 ChatGPT 來解讀複雜的合約；一個沒學過程式設計的人可以用 AI 來寫簡單的程式碼。這應該有助於讓更多人獲得原本遙不可及的能力，從而縮小不同技能群體之間的差距。</p>
<p>但實際的採用模式顯示，事情並沒有照著這個美好的劇本發展。那些原本就具備較多技能、享有較高薪資的人，反而更積極地擁抱這些新工具。而那些理論上最能從 AI 中受益的人——技能較少、薪資較低的群體——卻沒有以同樣的速度跟上。</p>
<p>這意味著什麼？如果 AI 真的能帶來生產力提升和收入增加，而使用 AI 的又主要是本來就收入較高的人，那麼 AI 的普及可能不會縮小不平等，反而會擴大不平等。本來收入高的人會變得更有生產力、賺得更多；本來收入低的人則可能相對落後。這是一個令人擔憂的趨勢。</p>
<h2 id="為什麼會這樣可能的解釋">為什麼會這樣？可能的解釋</h2>
<p>為什麼會出現這樣的採用落差？研究者和論壇上的其他專家提出了幾種可能的解釋。</p>
<p>第一種解釋與「技術自信心」有關。研究顯示，面對新技術時，不同群體的反應往往不同。即使實際能力相當，某些群體可能對自己使用新技術的能力較沒信心，或者對嘗試新工具感到較多焦慮。這種心理因素可能導致採用率的差異。我們知道在 STEM 領域存在類似的現象——女性在這些領域的代表性偏低，部分原因與社會化過程中形成的自我認知有關。</p>
<p>第二種解釋涉及「工作時間的彈性」。在很多情況下，學習和嘗試新工具需要投入額外的時間——這些時間往往在正常工作時間之外。如果某些群體在工作之外承擔更多的家庭責任或其他義務，他們可能較難找到時間來實驗新技術。這種時間分配的不平等，可能轉化為技術採用的不平等。</p>
<p>第三種解釋與「資訊網絡」有關。人們往往從同事、朋友那裡學習新工具的使用方式。如果某些群體在職場或社交圈中較少接觸到 AI 的早期使用者，他們獲得「這個工具很有用」這類資訊的機會就會較少。網絡效應可能放大了最初的小差異，使其變成顯著的採用落差。</p>
<p>第四種解釋則與「風險態度」有關。在工作中嘗試新工具有一定的風險——如果工具出錯，可能影響工作品質；如果被認為過度依賴 AI，可能影響職業形象。不同群體對這些風險的評估可能不同，導致採用行為的差異。</p>
<p>這些解釋並不互相排斥，真實的情況可能是多種因素共同作用的結果。但不管原因是什麼，結果都是一樣的：AI 工具的採用正在沿著既有的社會斷層線發生分化。</p>
<h2 id="大學能做什麼芝大-polsky-center-的嘗試">大學能做什麼？芝大 Polsky Center 的嘗試</h2>
<p>面對這樣的不平等趨勢，有什麼可以做的？在論壇上，芝加哥大學 Polsky Center for Entrepreneurship and Innovation 的副校長兼總監麥耶卡（Samir Mayekar）分享了一些他們正在進行的嘗試。</p>
<p>Polsky Center 的一個創新做法是利用 AI 來分析學校的研究論文和發明揭露資料。他們把大量學術論文的引用數據餵給模型，讓它識別出哪些研究被大量專利和其他研究引用，可能具有商業化潛力。這個分析的一個意外發現是：有些研究者（特別是女性研究者）的論文被大量引用，但她們並沒有申請專利或創業。</p>
<p>這個發現來自西北大學的一個類似研究。研究人員發現，女性研究者擁有高被引論文卻沒有申請專利的情況比男性更常見。在識別出這些案例後，學校主動接觸這些研究者，提供專利申請的支持和創業指導。結果是？幾家新創公司因此誕生了。</p>
<p>這個案例說明，AI 本身可以成為促進公平的工具——如果我們刻意用它來識別和彌補既有的不平等。</p>
<p>Polsky Center 的另一項工作是針對小型企業的 AI 培訓。透過他們的「Polsky Exchange」計畫，中心邀請業界專家為小企業主提供 AI 應用的培訓和諮詢。麥耶卡觀察到，對很多小企業主來說，「AI」這個詞聽起來就很嚇人，他們不確定它對自己的生意意味著什麼，更不知道從何開始。提供具體的、貼近實際業務的指導，是降低採用門檻的關鍵。</p>
<p>這些做法的共同點是：它們不是被動等待 AI 的紅利自然「滴落」（trickle down）到每個人身上，而是主動識別可能被遺漏的群體，並提供有針對性的支持。</p>
<h2 id="如果不主動介入ai-紅利可能只屬於特定族群">如果不主動介入，AI 紅利可能只屬於特定族群</h2>
<p>哈默的研究傳達了一個清楚的訊息：AI 工具的普及並不會自動帶來更公平的結果。如果我們什麼都不做，讓市場和個人自行決定誰採用、誰不採用，結果很可能是既有的不平等被放大而非縮小。</p>
<p>這不是說 AI 本身是壞的，也不是說技術進步應該被阻止。問題在於技術如何被分配、被使用、被從中獲益。一個能讓更多人受益的 AI 革命，需要刻意的努力：識別採用的障礙，提供有針對性的培訓和支持，創造讓更多人願意嘗試的環境。</p>
<p>MIT 經濟學家奧托爾（David Autor）曾表達過一個願景：AI 有潛力重建中產階級的工作機會，因為它可以讓原本缺乏某些專業技能的人也能從事高價值的工作。但正如哈默的研究所顯示的，從願景到現實還有很長的路。那些「原本缺乏專業技能的人」必須先開始使用這些工具，才能從中受益。而目前的數據顯示，這個「開始使用」的步驟，本身就存在著系統性的偏差。</p>
<p>在這場 AI 革命中，最需要這些工具的人，可能恰恰是最晚採用的人。如果我們在乎公平，就不能只是旁觀這個過程自然展開。</p>

        </div>
        <div class="post_extra mb-2">
          
<div class="copy" data-before="分享故事" data-after="已複製">
  <svg class="icon">
    <use xlink:href="#copy"></use>
  </svg>
</div>
        </div>
        <div>
        
        </div>
      </div>
    </div>
    <a href=https://bnextmedia.github.io/AINEXT/ class="post_nav"><span class="post_next">Latest Posts
      <svg class="icon icon_scale">
        <use xlink:href="#double-arrow"></use>
      </svg>
    </span></a>
  </div>

    </main>
    <footer class="footer wrap pale">
  <p>&copy;&nbsp;<span class="year"></span>&nbsp;AINEXT</p>
  <p class="attribution upcase">由 <a href = 'https://bnextmedia.github.io/AINEXT/' target = '_blank' title = '領英個人檔案' rel = 'nonopener'>AINEXT</a> 設計</p>
</footer>


<script src="https://bnextmedia.github.io/AINEXT/js/index.min.0c2fb80a1ade817d7387f0de8ee061e7de6878a65a420dc61a6e0d0b3bb765c4c0394caefa7c40b16d39c7d74283b3cab364aa109f58cad99d149ec813f930c8.js"></script>

    <svg width="0" height="0" class="hidden">
  <symbol xmlns="http://www.w3.org/2000/svg" viewBox="0 0 699.428 699.428" id="copy">
    <path d="M502.714 0H240.428C194.178 0 153 42.425 153 87.429l-25.267.59c-46.228 0-84.019 41.834-84.019 86.838V612c0 45.004 41.179 87.428 87.429 87.428H459c46.249 0 87.428-42.424 87.428-87.428h21.857c46.25 0 87.429-42.424 87.429-87.428v-349.19L502.714 0zM459 655.715H131.143c-22.95 0-43.714-21.441-43.714-43.715V174.857c0-22.272 18.688-42.993 41.638-42.993l23.933-.721v393.429C153 569.576 194.178 612 240.428 612h262.286c0 22.273-20.765 43.715-43.714 43.715zm153-131.143c0 22.271-20.765 43.713-43.715 43.713H240.428c-22.95 0-43.714-21.441-43.714-43.713V87.429c0-22.272 20.764-43.714 43.714-43.714H459c-.351 50.337 0 87.975 0 87.975 0 45.419 40.872 86.882 87.428 86.882H612v306zm-65.572-349.715c-23.277 0-43.714-42.293-43.714-64.981V44.348L612 174.857h-65.572zm-43.714 131.537H306c-12.065 0-21.857 9.77-21.857 21.835 0 12.065 9.792 21.835 21.857 21.835h196.714c12.065 0 21.857-9.771 21.857-21.835 0-12.065-9.792-21.835-21.857-21.835zm0 109.176H306c-12.065 0-21.857 9.77-21.857 21.834 0 12.066 9.792 21.836 21.857 21.836h196.714c12.065 0 21.857-9.77 21.857-21.836 0-12.064-9.792-21.834-21.857-21.834z"></path>
  </symbol>
  <symbol viewBox="0 0 53 42" xmlns="http://www.w3.org/2000/svg" id="double-arrow">
    <path d="M.595 39.653a1.318 1.318 0 0 1 0-1.864L16.55 21.833a1.318 1.318 0 0 0 0-1.863L.595 4.014a1.318 1.318 0 0 1 0-1.863L2.125.62a1.318 1.318 0 0 1 1.864 0l19.35 19.349a1.318 1.318 0 0 1 0 1.863l-19.35 19.35a1.318 1.318 0 0 1-1.863 0zm29 0a1.318 1.318 0 0 1 0-1.864L45.55 21.833a1.318 1.318 0 0 0 0-1.863L29.595 4.014a1.318 1.318 0 0 1 0-1.863l1.53-1.53a1.318 1.318 0 0 1 1.864 0l19.35 19.349a1.318 1.318 0 0 1 0 1.863l-19.35 19.35a1.318 1.318 0 0 1-1.863 0z"></path>
  </symbol>
</svg>
  </body>
</html>
