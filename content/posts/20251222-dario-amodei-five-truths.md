---
title: "Anthropic CEO 說了五個圈內人才敢講的真話"
date: 2025-12-22T21:15:00+08:00
description: "Anthropic CEO Dario Amodei 在紐約時報 DealBook Summit 公開談論 AI 產業的敏感議題：有人在 YOLO 賭博式投資、消費者市場的戰爭 Anthropic 不參與、Scaling Laws 會持續有效沒有奇點、監管爭議的本質是路線之爭、工作衝擊需要三層解法。這位願意講真話的 CEO，展現了一種清醒的樂觀主義。"
tags: ["Anthropic", "Dario Amodei", "AI 監管", "AI 安全", "AI 就業衝擊"]
categories: ["AI 產業"]
source_url: "https://www.youtube.com/watch?v=FEj7wAjwQIk"
source_name: "紐約時報 DealBook Summit"
draft: false
---

> 本文整理自 Dario Amodei 於 2024 年 12 月在紐約時報 DealBook Summit 的公開訪談。
> 📺 影片連結：[YouTube](https://www.youtube.com/watch?v=FEj7wAjwQIk)

Dario Amodei 是 Anthropic 的 CEO 兼共同創辦人。在一個所有 AI 公司都在喊「我們最強」的時代，他是少數願意在公開場合講真話的人。這場將近 40 分鐘的訪談，他談了泡沫風險、產業競爭、監管爭議、國家安全、還有工作衝擊——每一個都是別人避之唯恐不及的敏感話題。

值得一聽的原因不是他特別悲觀。恰恰相反，他可能是業界最樂觀的人之一。他寫過一篇文章說 AI 可能在十年內把人類壽命延長到 150 歲。但他的樂觀建立在一個前提上：我們得先誠實面對風險。這篇文章整理了他在訪談中說的五個「真話」，每一個都值得細想。

---

## 真相一：有人在 YOLO，而且可能會出事

主持人 Andrew Ross Sorkin 開門見山問：AI 產業現在的投資規模，是不是泡沫？

Dario 的回答很有層次。他說技術面他很有信心，Scaling Laws 會持續有效，模型會繼續變強。但經濟面，他確實擔心。他用了一個內部術語：「**不確定性錐**」（cone of uncertainty）。

這個概念是這樣的：Anthropic 的營收過去三年每年成長十倍——2023 年 1 億美元，2024 年 10 億，2025 年預計落在 80 到 100 億之間。如果你「很蠢地」直接外推這個趨勢，明年就是 1000 億。但 Dario 說他自己都不信。用比較務實的方式估算，可能是 200 億，也可能是 500 億。這個範圍就是「錐」——越往未來看，可能的範圍就越大，不確定性也越高。

問題在於，建資料中心需要一到兩年。你現在就得決定要買多少運算資源，來服務兩年後的客戶。買少了，客戶來了你接不住，只能把他們推給競爭對手。買多了，營收跟不上，最糟的情況就是破產。

Dario 說 Anthropic 採取保守策略：「我們計畫的是錐的下緣。就算落在第十百分位的悲觀情境，我們也要能撐得住。」但他話鋒一轉，說有些公司不是這樣想的。

「如果你是那種天性上就喜歡 **YOLO** 的人，或者就是喜歡大數字，你可能會把風險調得很高。」

YOLO 是網路俚語，You Only Live Once，意思是「反正只活一次，賭一把」。Dario 沒有點名是誰在 YOLO，但他說得很直接：有些人做的是不負責任的賭博，而且「我非常擔心」。

主持人追問：那個人是誰？Dario 笑著說：「這個問題我不會回答。」但他補了一句：「我想大家都知道是誰。」

場上有兩家獨立的大型 AI 公司——Anthropic 和 OpenAI。Dario 說 Anthropic 計畫 2028 年損益兩平。而根據公開報導，OpenAI 預計在 2030 年達成，但在那之前會先虧損約 740 億美元。

他沒有說那個 YOLO 的人是誰。但數學會說話。

---

## 真相二：消費者市場的戰爭，我們不玩

訪談進行到一半，主持人提到矽谷最近的焦慮：Google 的新模型 Gemini 引發熱議，Sam Altman 發了內部信說「code red」，要大家趕快回去加班趕進度。

Dario 的反應出乎意料地淡定。他說：「這正是我慶幸 Anthropic 走了不同路線的時候。」

他的意思是：Google 和 OpenAI 都在打消費者市場的戰爭。Google 要守住搜尋的霸主地位，OpenAI 的核心也是 ChatGPT 這個消費者產品。兩邊都在搶「誰是一般人最常用的 AI」這個位置。

Anthropic 選擇的是企業市場。他們的客戶是公司，不是個人用戶。這意味著他們優化的方向不一樣：更注重程式碼能力、金融分析、生醫研究，而不是「聊天體驗」或「參與度」。

「那兩家在打仗，對我們來說，企業客戶是他們的次要業務。我們不用參與那場 code red，可以專心把模型做好、繼續成長。」

這不是說 Anthropic 不在乎模型品質。Dario 特別提到他們剛發布的 Claude Opus 4.5，說「幾乎所有人都認為這是目前最強的程式模型」。但他強調的是，他們不用因為消費者市場的風吹草動就進入緊急狀態。

這也連結到一個更大的問題：AI 公司的「護城河」到底是什麼？

Dario 的答案是：專業化。「如果你是為企業做模型，你會專注在不同的事情上——程式、科學、高智識活動。這跟為消費者做模型是不一樣的最佳化方向。」

他還提到一個有趣的觀察：就算是賣 API 這種看起來很沒黏性的生意，客戶其實很難換。因為下游的使用者已經習慣了某個模型的「個性」和回應方式，換模型就要重新調整所有的 prompt 和工作流程。「這其實比你想像的難很多。」

---

## 真相三：Scaling 會一直有效，沒有什麼「奇點」

主持人問了一個技術問題：要達到 AGI，光靠現在的 transformer 架構加上更多運算資源就夠了嗎？還是需要什麼根本性的新突破？

Dario 的回答很乾脆：「不，我認為 scaling 就會帶我們到那裡。」

他說他已經觀察 Scaling Laws 超過十年了。這個定律的核心是：當你增加模型參數、訓練資料、運算量，模型的表現就會以可預測的方式提升。過去十年，這個規律從來沒有失效過。

「偶爾會有一些小修改，像是 reasoning models、test-time compute 這些。但那都是微調，不是根本性的改變。」

他特別不喜歡 AGI、ASI（人工超級智慧）這些詞。「我不知道那是什麼意思。這就像問：摩爾定律什麼時候會產生一個『奇點』？沒有奇點，只有持續的指數成長。」

他描述的圖景是這樣的：模型會在每一個領域持續變強——程式、數學、科學、法律、金融。現在的模型已經可以在高中數學奧林匹亞獲勝，正在進攻大學等級的競賽，也開始能做原創的數學研究。

然後他說了一個讓我印象深刻的細節：

「最近第一次，我們內部有人跟我說：『我不再自己寫程式了。我不會打開編輯器自己寫 code。我就讓 Claude 寫初稿，我只負責編輯。』我們以前從來沒有到過這個程度。」

這不是在說未來，是在說現在，就發生在 Anthropic 內部。那個「被 AI 取代」的未來，對某些工作來說，已經是現在進行式了。

---

## 真相四：監管之爭，其實是路線之爭

訪談中最火爆的一段，是主持人直接唸出川普政府 AI 顧問 David Sacks 對 Anthropic 的批評：

「Anthropic 正在執行一套精密的監管俘獲策略，靠的是販賣恐懼。他們要為各州的監管狂熱負主要責任，這正在傷害新創生態。」

這是很重的指控。「監管俘獲」（regulatory capture）的意思是大公司利用監管來拉高門檻，把小公司擋在外面。Sacks 的言下之意是：Anthropic 假裝關心安全，其實是在用監管消滅競爭對手。

Dario 的回應有幾層。

首先，他拒絕把這變成人身攻擊：「我不認為應該針對特定個人。這是政策問題，不是哪個政府的問題。」

然後他反駁事實層面的錯誤：「我從 2016 年就開始寫 AI 安全的論文了，那時候我連公司都沒有，根本不可能有什麼監管俘獲的計畫。」

更重要的是，他指出 Anthropic 支持的法案都設計了小公司豁免條款。他特別提到加州的 SB 1047 法案：「這個法案根本不適用於營收 5 億美元以下的新創。」

SB 1047 的實際門檻是：訓練成本超過 1 億美元、或運算量超過 10^26 浮點運算的模型才需要遵守。這個門檻，全世界大概只有不到十家公司碰得到。說這會傷害新創生態，在 Dario 看來是「與現實完全不符」。

（補充說明：SB 1047 最終在 2024 年 9 月被加州州長 Gavin Newsom 否決，理由是法案只看模型規模、沒有考慮部署情境，可能造成「虛假的安全感」。但 Anthropic 對法案的支持立場，確實引發了矽谷內部的激烈爭論。）

Dario 接著點出他認為真正的分歧：

「我擔心有些人把 AI 當成以前的網路或電信來看——是的，有些問題，但市場會自己解決。我不這樣看。如果你去問真正在做 AI 研究的人，不是投資 AI 的創投、不是科技評論員，而是真正在建造這個技術的人——他們既興奮又擔憂。他們擔心國安風險、擔心模型對齊、擔心經濟衝擊。」

他用了一個比喻：「說我們要十年不監管 AI，就像說『我在開車，但我要把方向盤拆掉，因為接下來十年我都不需要轉彎』。」

這場爭論的本質，不是「監管好不好」，而是「AI 是不是一種特殊的技術」。加速派認為 AI 就是另一個網路，放著讓市場跑就好。安全派認為 AI 不一樣，它的能力成長速度和潛在影響需要不同的治理方式。

Dario 選邊站了。而且站得很明確。

---

## 真相五：工作衝擊沒有銀彈，但有三層解法

訪談的最後一段談到就業。主持人問：你說可能有一半的入門級工作會消失，那該怎麼辦？

Dario 說他提出警告不是要當末日預言家，而是因為「警告是解決問題的第一步。如果我們不警告，就會盲目地踩進地雷。」

他提出了三層解法，從短期到長期：

**第一層：企業端的選擇**

每個導入 AI 的企業都面臨一個選擇：你可以用 AI 來「提高效率」——讓機器做原本人做的事，減少人力成本。但你也可以用 AI 來「創造新價值」——讓人可以做十倍的事情，因為 AI 處理了 90% 的繁瑣工作。

Dario 說第一種一定會發生，他們不是要阻止。但如果企業能多做第二種，「創造的工作可能比消失的更多」。

**第二層：政府介入**

他說再培訓計畫不是萬靈丹，但「我們還是需要某種形式的再培訓」。企業要做，政府也要做。

更重要的是財政工具。他引用了 Anthropic 最近發布的一份報告：光是現有的 AI 模型，就可能讓生產力每年提升 1.6%，幾乎是原本的兩倍。如果模型繼續進步，可能達到 5% 甚至 10%。

「這是一塊很大的餅。如果財富集中在少數人手上，政府需要某種方式重新分配。可能是稅務政策，可能是其他工具。」

**第三層：社會重構**

這是最慢、但最根本的層次。他引用凱因斯 1930 年的文章〈我們孫輩的經濟可能性〉：凱因斯當時就預測，未來的世代可能每週只需要工作 15-20 小時。

「也許工作不再需要是人生的中心。也許人們可以在其他地方找到意義，或者工作變成是為了滿足感，而不是經濟生存。」

他強調這不是要政府由上而下地重塑社會。「社會需要自己重組。我們都需要搞清楚如何在後 AGI 時代運作。」

這三層解法從「企業可以明天就做」到「需要幾十年共識」，時間尺度不同，但他認為三個都需要。

---

## 結語：清醒的樂觀主義者

聽完整場訪談，我對 Dario Amodei 的印象是：這是一個真正相信自己在做的事情會改變世界的人，但他同時非常清醒地看到這件事可能帶來的問題。

他對技術的樂觀幾乎是激進的——他相信 Scaling Laws、相信模型會持續變強、相信 AI 可以延長人類壽命。但他對經濟、對社會、對治理的態度是謹慎的——他承認有人在 YOLO、承認工作會消失、承認需要監管。

這種組合很少見。矽谷的主流敘事通常是兩種：要嘛是「AI 會解決一切問題，不要擋路」的加速派，要嘛是「AI 會毀滅人類，趕快停下來」的末日派。Dario 兩邊都不是。

他的立場可以這樣總結：AI 的潛力是真的，風險也是真的，而且兩者都比大多數人想像的更大。我們的工作是最大化前者、最小化後者。這需要誠實面對問題，而不是假裝問題不存在。

這大概是為什麼他願意在公開場合說這些別人不敢說的話。

因為他真的相信：清醒，是抵達那個美好未來的前提。
