---
title: "o1 共同創作者的 2025 AI 預言：三個你該知道的核心趨勢"
date: 2025-12-25T10:00:00+08:00
description: "Jason Wei 是 OpenAI o1 和 Deep Research 的共同創作者，擁有超過 9 萬次學術引用。在 Stanford AI Club 的演講中，他分享了理解 2025 年 AI 發展的三個關鍵框架：智慧商品化、驗證者法則、以及智慧的鋸齒狀邊緣。"
tags: ["Jason Wei", "OpenAI", "o1", "AI 趨勢", "Stanford"]
categories: ["AI 產業"]
source_url: "https://www.youtube.com/watch?v=b6Doq2fz81U"
source_name: "Stanford AI Club"
draft: false
---

{{< youtube b6Doq2fz81U >}}

---

> 本文整理自 Stanford AI Club 2025 年的演講。

「AI 還剩幾年會取代我們的工作？」如果你問一個量化交易員，他可能會說 ChatGPT 根本做不了他的事；但如果你問一個頂尖 AI 實驗室的研究員，答案可能是兩到三年。這個巨大的認知落差，正是 Jason Wei 這場演講想解決的問題。

Jason Wei 是誰？他是 OpenAI o1 和 Deep Research 的共同創作者，在加入 OpenAI 之前是 Google Brain 的研究科學家，推廣了 Chain-of-Thought Prompting 和 Instruction Tuning 這些現在已成為業界標準的技術。他的學術引用超過 9 萬次，是當今最有影響力的 AI 研究者之一。最近他加入了 Meta 的 Superintelligence Labs。

在 Stanford AI Club 的演講中，他提出了三個理解 2025 年 AI 發展的核心框架。這不是預測未來，而是提供一套思考工具。

## 第一：智慧正在變成大宗商品

Jason Wei 把 AI 進步分成兩個階段。第一階段是「解鎖能力」——AI 原本做不到某件事，現在可以了。第二階段是「成本歸零」——一旦能力解鎖，做這件事的成本會被快速壓低。

他用 MMLU（一個常見的 AI 評測基準）來舉例。過去五年，模型在這個測試上的表現穩定提升，這是第一階段。但更有意思的是第二階段：達到同樣分數所需的成本，每年都在急遽下降。去年要花一塊美金才能達到的表現，今年可能只要幾分錢。

為什麼這個趨勢會持續？關鍵在於「自適應運算」（Adaptive Compute）。過去的深度學習有個奇怪的特性：不管問題有多簡單或複雜，模型用的運算量都一樣。問加州首府是什麼，和問一道 IMO 數學題，消耗的資源差不多。

但 o1 改變了這個遊戲規則。現在模型可以根據問題難度調整思考時間。簡單問題快速解決，困難問題花更多運算。這意味著簡單任務的成本可以被壓到極低，而困難任務則可以透過堆疊運算來解決。

另一個他強調的趨勢是「知識即時化」。他畫了一張圖，x 軸是時代（前網路、網路、聊天機器人、Agent），y 軸是取得特定資訊的時間。比如說，1983 年釜山有多少人結婚？在前網路時代，你可能得飛到韓國、去政府圖書館翻好幾天的檔案。網路時代快一點，但你可能不會韓文，還是得花不少時間。現在？OpenAI 的 Operator 可以在幾分鐘內幫你查到答案，因為它能直接操作韓國統計資料庫 KOSIS 的介面。

這帶來幾個影響。第一，過去被「知識門檻」保護的領域會被民主化，寫程式和個人健康管理是最明顯的例子。第二，公開資訊的價值會下降，私有資訊的相對價值會上升——如果你知道哪些房子沒在市場上但可以賣，這個資訊現在更值錢了。

## 第二：驗證者法則

這是 Jason Wei 自創的概念，他稱之為「Verifier's Law」。核心主張很簡單：**AI 被訓練來解決某個任務的能力，與這個任務有多容易被驗證成正比。**

他先解釋了「驗證不對稱性」這個電腦科學的老概念。有些問題，解決很難，但驗證很簡單。數獨是經典例子：填好一個困難的數獨可能要花半小時，但檢查答案對不對只要幾秒鐘。寫出能運作的 Twitter 需要數百個工程師，但驗證它能不能用只要點一點。

但反過來也有。寫一篇看起來正確的事實文章很容易，但逐一查證每個事實可能極其費時。聲稱「只吃野牛肉是最佳飲食」只要十秒，但驗證這個說法需要大規模樣本和長期追蹤。

Jason Wei 提出五個衡量「可驗證性」的指標：是否有客觀正確答案、驗證速度多快、能否同時驗證大量答案、雜訊是否夠低、是否有連續的獎勵信號（而不只是對錯二元）。

這個法則的意涵是：**任何容易驗證的可解任務，最終都會被 AI 征服。**

他舉了 DeepMind 的 AlphaEvolve 作為最佳案例。這個系統專挑符合驗證不對稱性的問題來解——比如在一個大六邊形裡塞 11 個小六邊形，求最小外框。這種問題有客觀答案、可以程式化驗證、沒有雜訊、而且有連續的優劣比較（框越小越好）。AlphaEvolve 用大量採樣和迭代改進，在這類問題上取得了超越人類的成果。

對創業者來說，這意味著一個機會：找到原本難以驗證的領域，設計出可量化的評估方式，然後讓 AI 去最佳化。測量本身就是價值。

## 第三：智慧的鋸齒狀邊緣

最後一個概念是對「AI 快速起飛」論述的反駁。有些人相信一旦 AI 達到某個臨界點，就會在短時間內遠遠超越人類。Jason Wei 不這樣看。

他認為「自我改進」不是一個二元開關，而是一個連續光譜。今年 AI 可能連程式碼都跑不起來，明年可以跑但結果很差，後年可以跑但比不上頂尖研究員，大後年可以自主運作但偶爾需要人類介入。這是漸進的，不是跳躍的。

更重要的是，他認為不同任務的進步速度差異極大。這就是「鋸齒狀邊緣」——AI 的能力圖不是一條平滑的線，而是高低起伏的鋸齒。有些任務 AI 已經做得很好（困難數學題、競賽程式設計），有些則還差得遠（說 Tlingit 語，一種只有幾百人會說的美洲原住民語言）。

他給出三個預測任務難度的因素：

**第一，是否為數位任務。** 數位任務可以快速迭代、大量平行測試，實體任務則受限於物理世界的速度。這就是為什麼 AI 下棋比 AI 做家務進步快得多。

**第二，對人類來說有多難。** 一般來說，人類覺得簡單的事 AI 也比較快學會。

**第三，資料是否豐富。** 這點很直接——有大量資料的任務進步快，資料稀缺的任務進步慢。但有一個例外：如果任務有明確的評估指標，就可以用強化學習生成合成資料，繞過資料稀缺的限制。這就是 AlphaZero 和 AlphaEvolve 的做法。

他列了一張有趣的表格預測各種任務何時會被 AI 征服：翻譯前 50 大語言（已完成）、除錯基本程式碼（2023）、競賽數學（2024）、AI 研究（2027）、化學研究（比 AI 研究晚，因為不是純數位）、製作電影（2029）、翻譯 Tlingit 語（可能永遠不會）、修水管（不確定）、理髮（很難）、傳統烏茲別克地毯編織（遙遙無期）。

最後一項他開玩笑：「帶女朋友約會讓她開心」——人類就做不到，不是數位任務，沒有資料，所以 AI 應該也不行。我們的工作還保得住。

## 這對我們意味著什麼

Jason Wei 這場演講不是在預測未來，而是提供一套思考框架。當你評估某個領域會不會被 AI 顛覆時，可以問三個問題：成本壓縮到極限後會怎樣？這個任務容易驗證嗎？它符合數位、簡單、資料豐富這三個條件嗎？

答案不會告訴你確切的時間表，但會告訴你方向。而方向，往往比時間點更重要。
