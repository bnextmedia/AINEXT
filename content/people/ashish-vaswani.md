---
# === 基本資訊 ===
title: "阿希什・瓦斯瓦尼 Ashish Vaswani"
slug: "ashish-vaswani"
name_zh: "阿希什・瓦斯瓦尼"
name_en: "Ashish Vaswani"
name_full_en: "Ashish Vaswani"

# === 照片 ===
photo: "/images/people/ashish-vaswani.jpg"
photo_alt: "Ashish Vaswani"
photo_credit: "Essential AI"
photo_source: ""

# === 基本背景 ===
nationality: "印度/美國"
birth_year: 1986
birth_place: "印度"
death_year: null
residence: "美國舊金山"

# === 現職 ===
current_position: "共同創辦人與執行長"
current_organization: "Essential AI"
current_org_slug: "essential-ai"

# === 簡介 ===
description_short: "Transformer 論文第一作者，Essential AI 創辦人"
description_long: |
  Ashish Vaswani 是劃時代論文「Attention Is All You Need」的第一作者，這篇論文提出的 Transformer 架構徹底改變了人工智慧的發展方向，成為 ChatGPT、GPT-4、Claude、Gemini 等現代大型語言模型的基礎。他先後創立了 Adept AI 和 Essential AI，致力於將 AI 技術應用於企業場景。

# === 人物分類 ===
person_type: ["科學家", "創辦人", "CEO"]
importance_level: "A"
importance_reason: "Transformer 架構第一作者，論文引用超過 17 萬次，現代生成式 AI 的技術基石"

# === AI 領域專長 ===
ai_domains: ["深度學習", "自然語言處理", "注意力機制", "Transformer"]
ai_impact_areas: ["LLM", "機器翻譯", "生成式 AI"]

# === 關鍵貢獻（白話解釋）===
key_contributions:
  - title: "Transformer 架構"
    description: "作為第一作者提出完全基於注意力機制的 Transformer 架構，取代了傳統的循環神經網路"
    impact_on_llm: "ChatGPT、GPT-4、Claude、Gemini、Llama 等所有主流 LLM 都基於 Transformer 架構"
    impact_on_other: "徹底改變自然語言處理、電腦視覺、語音辨識等多個領域"
    year: 2017
  - title: "自注意力機制（Self-Attention）"
    description: "讓模型能夠同時關注輸入序列中的所有位置，解決了長距離依賴問題"
    impact_on_llm: "使 LLM 能夠理解長文本中的上下文關係"
    impact_on_other: "大幅提升並行計算效率，讓大規模訓練成為可能"
    year: 2017

# === 代表作品 ===
representative_works:
  - title: "Attention Is All You Need"
    type: "論文"
    year: 2017
    description: "提出 Transformer 架構，被引用超過 17 萬次，是 21 世紀引用次數前十的論文"
    url: "https://arxiv.org/abs/1706.03762"

# === 獲獎紀錄 ===
awards:
  - name: "NEC C&C Prize"
    year: 2024
    issuer: "NEC C&C Foundation"
    category: "computer_science"
    significance: "表彰 Transformer 團隊對深度學習架構的開創性貢獻"
  - name: "Research.com 世界頂尖科學家"
    year: 2025
    issuer: "Research.com"
    category: "recognition"
    significance: "基於 D-index 31 和超過 12.7 萬次引用"

# === 學歷 ===
education:
  - institution: "南加州大學"
    institution_en: "University of Southern California"
    degree: "電腦科學博士"
    field: "電腦科學"
    years: "2010-2014"
    thesis: "機器翻譯與自然語言處理"
  - institution: "比爾拉理工學院"
    institution_en: "Birla Institute of Technology, Mesra"
    degree: "電腦科學與工程學士"
    field: "電腦科學"
    years: "1998-2002"

# === 職業經歷 ===
career_history:
  - organization: "Essential AI"
    organization_en: "Essential AI"
    position: "共同創辦人與執行長"
    years: "2022-現在"
    org_slug: "essential-ai"
    description: "專注企業 AI 工作流程自動化"
  - organization: "Adept AI"
    organization_en: "Adept AI"
    position: "共同創辦人"
    years: "2022"
    org_slug: "adept-ai"
    description: "AI Agent 新創公司"
  - organization: "Google Brain"
    organization_en: "Google Brain"
    position: "資深研究科學家"
    years: "2016-2021"
    org_slug: "google"
    description: "開發 Transformer 架構"
  - organization: "南加州大學資訊科學研究所"
    organization_en: "USC Information Sciences Institute"
    position: "電腦科學家"
    years: "2014-2016"
    org_slug: ""
    description: "大規模研究專案"

# === 師承與門生 ===
mentors:
  - name: "David Chiang"
    relation: "博士指導教授"
    people_slug: ""
    note: "機器翻譯專家"

notable_students: []

# === 重要論文 ===
publications:
  - title: "Attention Is All You Need"
    year: 2017
    venue: "NeurIPS"
    coauthors: ["Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan Gomez", "Łukasz Kaiser", "Illia Polosukhin"]
    citations: 173000
    significance: "提出 Transformer 架構，改變 AI 發展方向"

# === 創立或參與的組織 ===
founded_companies:
  - name: "Essential AI"
    year: 2022
    role: "共同創辦人與執行長"
    outcome: "專注企業 AI，獲得 AMD、Google、NVIDIA 投資"
    company_slug: "essential-ai"
  - name: "Adept AI"
    year: 2022
    role: "共同創辦人"
    outcome: "AI Agent 新創，後離開"
    company_slug: "adept-ai"

# === 重要言論 ===
notable_quotes:
  - quote: "Transformer 的核心洞見是，你不需要循環——注意力本身就足以捕捉序列中的所有關係。"
    context: "解釋 Transformer 設計理念"
    date: ""
    source: ""

# === 對 AI 發展的立場 ===
ai_safety_stance: "neutral"
ai_development_view: |
  Vaswani 相信 AI 應該被設計來增強人類能力，而非取代人類。他創立的 Essential AI 專注於企業場景的「人機協作」，讓 AI 處理重複性工作，讓人類專注於創造性任務。

# === 相關人物 ===
related_people:
  - slug: "noam-shazeer"
    relation: "Transformer 論文共同作者"
  - slug: "niki-parmar"
    relation: "Transformer 論文共同作者，Essential AI 共同創辦人"
  - slug: "llion-jones"
    relation: "Transformer 論文共同作者"
  - slug: "aidan-gomez"
    relation: "Transformer 論文共同作者"
  - slug: "lukasz-kaiser"
    relation: "Transformer 論文共同作者"
  - slug: "illia-polosukhin"
    relation: "Transformer 論文共同作者"
  - slug: "jakob-uszkoreit"
    relation: "Transformer 論文共同作者"

# === 相關公司 ===
related_companies:
  - slug: "essential-ai"
    relation: "創辦人與執行長"
  - slug: "google"
    relation: "前研究科學家"

# === 社群連結 ===
social:
  personal_website: ""
  twitter: ""
  linkedin: ""
  github: ""
  google_scholar: "https://scholar.google.com/citations?user=oR9sCGYAAAAJ"
  wikipedia: "https://en.wikipedia.org/wiki/Ashish_Vaswani"

# === 延伸資源 ===
resources:
  - title: "Attention Is All You Need 論文"
    url: "https://arxiv.org/abs/1706.03762"
    type: "paper"
  - title: "Essential AI 官網"
    url: "https://essential.ai/"
    type: "official"

# === 標籤 ===
tags: ["Transformer", "注意力機制", "Google Brain", "Essential AI", "NLP", "LLM"]

# === 元資料 ===
data_sources: ["Wikipedia", "Google Scholar", "LinkedIn"]
last_updated: "2026-01-26"
update_notes: "初始建檔"
draft: false
---

## 一句話認識他

**Ashish Vaswani 是「Attention Is All You Need」論文的第一作者——這篇論文提出的 Transformer 架構，是 ChatGPT、Claude、Gemini 等所有現代 AI 的技術基石。**

---

## 為什麼重要？

2017 年，一篇名為「Attention Is All You Need」的論文在 NeurIPS 會議上發表。當時沒有人預料到，這篇論文會在幾年後改變整個科技產業。

論文的核心想法其實很簡單：你不需要複雜的循環神經網路來處理文字——只要讓模型能「注意」到輸入序列中的每個位置，它就能理解上下文。這個「自注意力機制」（Self-Attention）配合並行計算的設計，讓訓練效率提升了數個數量級。

Ashish Vaswani 是這篇論文的第一作者。這篇論文被引用超過 17 萬次，是 21 世紀引用次數前十的學術論文。更重要的是，它的影響遠超學術界：

- **ChatGPT** 就是 GPT（Generative Pre-trained **Transformer**）
- **BERT** 是 Bidirectional Encoder Representations from **Transformers**
- **Claude** 的架構也基於 Transformer
- **Gemini**、**Llama**、**Mistral** 都一樣

可以說，沒有 Transformer，就沒有今天的生成式 AI 革命。

---

## 關鍵貢獻

### Transformer 架構（2017）

**問題背景**
在 Transformer 之前，處理序列資料（如文字、語音）的主流方法是循環神經網路（RNN）和 LSTM。這些方法有一個根本問題：必須按順序處理，無法並行，所以訓練很慢；而且難以捕捉長距離的依賴關係。

**Vaswani 的解決方案**
Transformer 完全捨棄了循環結構，改用「自注意力機制」。模型可以同時看到輸入序列的所有位置，計算它們之間的關聯程度，然後決定要「注意」哪些部分。

**白話解釋**
想像你在讀一個很長的句子。傳統方法是從頭讀到尾，每讀一個字就試著記住前面的內容。Transformer 則像是把整個句子展開在桌上，可以同時看到所有字，直接找出哪些字之間有關聯。

例如「那隻**貓**坐在墊子上，因為**牠**很累」——Transformer 可以直接計算出「牠」和「貓」高度相關，不需要按順序讀過整個句子。

**為什麼重要**
1. **並行計算**：可以用 GPU 大規模並行訓練，效率比 RNN 高出幾個數量級
2. **長距離依賴**：不管兩個字相隔多遠，都能直接計算關聯
3. **可擴展性**：模型越大、數據越多，效果越好——這就是後來 GPT 系列「越大越強」的基礎

---

## 人生軌跡

### 印度到美國（1986-2014）

Ashish Vaswani 出生於印度，在 Birla Institute of Technology（BIT Mesra）完成電腦科學學士學位。這所學校是印度最受尊敬的工程學院之一。

畢業後，他前往美國南加州大學（USC）攻讀電腦科學博士，師從機器翻譯專家 David Chiang。讀博期間，他在 IBM 和 Google 實習，開始接觸自然語言處理的工業應用。

2014 年博士畢業後，Vaswani 在 USC 資訊科學研究所（ISI）擔任電腦科學家，繼續從事機器翻譯研究。

### Google Brain 與 Transformer（2016-2021）

2016 年，Vaswani 加入 Google Brain 團隊。這是當時全球最頂尖的 AI 研究團隊之一，聚集了 Jeff Dean、Geoffrey Hinton 等傳奇人物。

2017 年，Vaswani 與七位同事共同發表了「Attention Is All You Need」。論文的作者順序是隨機的，但 Vaswani 作為第一作者，被認為是核心貢獻者之一。

這篇論文最初的目標是改進機器翻譯，但很快人們發現，Transformer 架構可以應用於幾乎所有序列處理任務——從文字生成到圖像辨識，從語音合成到蛋白質結構預測。

### 創業之路（2022-現在）

2022 年，Vaswani 離開 Google，與 Niki Parmar、David Luan 等人共同創立 Adept AI，專注於開發 AI Agent。但不久後他離開 Adept，與 Niki Parmar 再次合作創立 Essential AI。

Essential AI 專注於企業場景的 AI 應用，目標是自動化重複性的工作流程。公司獲得了 AMD、Google、NVIDIA 等科技巨頭的投資，募資超過 5600 萬美元。

Vaswani 目前擔任 Essential AI 的執行長，繼續推動 AI 技術的實際應用。

---

## 「Transformer 八人幫」

Vaswani 是「Attention Is All You Need」八位作者之一。這八位作者後來都離開了 Google，各自在 AI 領域有重要發展：

| 作者 | 現況 |
|------|------|
| **Ashish Vaswani** | Essential AI 執行長 |
| **Noam Shazeer** | 重返 Google，Gemini 技術負責人 |
| **Niki Parmar** | Anthropic（Claude 開發公司） |
| **Jakob Uszkoreit** | Inceptive 創辦人（AI 生物科技） |
| **Llion Jones** | Sakana AI 共同創辦人 |
| **Aidan Gomez** | Cohere 執行長 |
| **Łukasz Kaiser** | OpenAI 研究員 |
| **Illia Polosukhin** | NEAR Protocol 執行長 |

這八人的離開被稱為 Google 的「人才流失」，但也推動了整個 AI 產業的多元發展。

---

## 延伸閱讀

### 必讀論文

1. **"Attention Is All You Need"（NeurIPS 2017）**
   - Transformer 的原始論文
   - [arXiv 連結](https://arxiv.org/abs/1706.03762)

### 推薦影片

- **NVIDIA GTC 2024**：Transformer 作者與 Jensen Huang 的對談

---

## 照片來源建議

1. **Essential AI 官方照片**
   - 來源：公司新聞稿
   - 授權：需確認媒體使用許可

2. **學術會議照片**
   - 來源：NeurIPS、ICML 等會議
   - 授權：需逐一確認

---

## 相關人物

- **[Noam Shazeer](/people/noam-shazeer/)**：Transformer 共同作者，Google Gemini 技術負責人
- **[Niki Parmar](/people/niki-parmar/)**：Transformer 共同作者，現任職 Anthropic
- **[Aidan Gomez](/people/aidan-gomez/)**：Transformer 共同作者，Cohere 執行長
- **[Llion Jones](/people/llion-jones/)**：Transformer 共同作者，Sakana AI 共同創辦人
- **[Geoffrey Hinton](/people/geoffrey-hinton/)**：深度學習教父，Google Brain 的精神領袖
