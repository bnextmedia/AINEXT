---
title: "為什麼你的 AI Agent 總是不夠可靠？這個開發者訪談了 100 人後找到答案"
date: 2025-12-25T17:35:00+08:00
description: "用框架快速做出 Agent 很容易，但要突破 70-80% 的完成度卻很難。HumanLayer 創辦人 Dex Horthy 訪談超過 100 位開發者後發現：生產環境中真正可靠的 Agent，其實沒那麼 agentic。它們大多是軟體，只在關鍵節點用 LLM。這篇文章整理他的核心發現。"
tags: ["AI Agent", "12-Factor Agents", "Dex Horthy", "HumanLayer", "軟體工程"]
categories: ["AI 產業"]
source_url: "https://www.youtube.com/watch?v=8kMaTybvDUw"
source_name: "AI Engineer 大會"
draft: false
---

> 本文整理自 Dex Horthy 在 AI Engineer 大會的演講。
> 🎧 收聽連結：[YouTube](https://www.youtube.com/watch?v=8kMaTybvDUw)

「誰建過 Agent？」台下一片手海。「誰建過十個以上的 Agent？」手少了一些。「誰建過一百個 Agent？」剩下幾隻手。Dex Horthy 站在 AI Engineer 大會的講台上，看著這些手，知道他們都經歷過同樣的事。

他自己也經歷過。第一次嘗試做 DevOps Agent 時，他給了 Agent 一個 Makefile，說「你可以執行 make 指令，去把專案建起來」。結果 Agent 把順序全搞錯了。Dex 花了兩小時不斷修改 Prompt，加入越來越多細節，最後寫出了精確的執行步驟。然後他意識到：「我用 90 秒就能寫出這個 bash script。」不是每個問題都需要 Agent。

但更常見的情況是另一種困境：你用框架快速做出一個 Agent，達到 70-80% 的完成度，足以讓老闆興奮、讓團隊擴編。然後你發現，要突破這個天花板，你得鑽進七層深的呼叫堆疊，試圖理解這個 Prompt 到底是怎麼組出來的、這些工具是怎麼傳進去的。最後你可能會像 Dex 一樣，把整個框架丟掉重寫。

## 訪談 100 位開發者後的發現

Dex 是 HumanLayer 的創辦人。過去一年，他為了幫助人們建構更可靠的 Agent，訪談了超過 100 位創辦人、開發者、工程師。他發現了一個出乎意料的模式：真正在生產環境運作良好的 Agent，其實沒有那麼「agentic」。它們大多數是軟體，只是在特定節點用了 LLM。

這些團隊都在做類似的事情：他們不是從零開始用某個 Agent 框架，而是把一些小型的、模組化的概念套用到現有的程式碼中。這些概念沒有名字、沒有定義，但它們有效。Dex 決定把這些模式整理出來，寫成「12-Factor Agents」——借用十年前 Heroku 定義雲端原生應用那份經典文件的精神。

這份文件發布後，一天內登上 Hacker News 首頁，兩個月內在 GitHub 拿到四千多顆星。Dex 說這不是反框架宣言，而更像是一份願望清單：我們希望框架能滿足那些需要高可靠性、同時又想快速迭代的開發者。

## 三個關鍵洞見

第一個洞見：Tool Use 沒那麼神秘。Dex 半開玩笑地說「Tool Use is harmful」——不是說不該讓 Agent 跟外部世界互動，而是說我們不該把這件事神秘化。實際發生的事情很單純：LLM 輸出一段 JSON，你用確定性的程式碼執行它，可能把結果餵回去。就這樣。它不是什麼外星實體在跟環境互動，它就是 JSON 加程式碼。當你這樣理解，你就能用普通的 switch 語句和迴圈來處理，不需要框架的魔法。

第二個洞見：Context Engineering 是王道。LLM 是純函數——輸入 token，輸出 token。決定輸出品質的唯一因素，就是你輸入了什麼。Prompt、Memory、RAG、History，這些全都是「怎麼把對的 token 送進模型」的問題。Dex 觀察到一個常見錯誤：當 Agent 呼叫 API 失敗，開發者把錯誤訊息直接加到 Context 讓它重試。這很容易讓 Agent 陷入混亂，看到一堆錯誤訊息後失去方向。正確做法是主動管理 Context：成功後清掉錯誤訊息、摘要而非貼上整個 stack trace。你要思考的是：我想讓模型看到什麼？

第三個洞見：小 Agent 勝過大 Agent。那個「給 LLM 一個目標，讓它自己找路」的願景，在長流程中行不通。就算 Gemini 能吃兩百萬個 token，沒有人會說這樣比精心控制的 Context 更可靠。真正有效的模式是 Micro Agents：主流程還是確定性的 DAG，只在特定節點放入小型 Agent 迴圈，每個只處理 3-10 個步驟。Context 可控，職責清楚，每個 Agent 只做它擅長的事。

## 實戰案例：HumanLayer 的部署機器人

Dex 分享了他們內部的部署機器人怎麼運作。大部分 CI/CD 流程是確定性的程式碼：測試、建置、驗證。但當 GitHub PR 合併、開發環境測試通過後，流程會交給一個小型 Agent。這個 Agent 會說：「好，我來部署。我打算先部署前端。」這時候它會問人類：可以嗎？

人類可以說：「不，先部署後端。」Agent 就調整計畫，提議部署後端，獲得批准後執行。後端部署完成，它會記得還要部署前端，再次提議、獲得批准、執行。一旦全部完成，控制權就回到確定性程式碼，跑生產環境的端對端測試。如果測試失敗，會交給另一個小型的 rollback Agent 處理。

這整個流程可能涉及 100 個工具、20 個步驟，但每個 Agent 的 Context 都是可控的，職責都是清楚的。Dex 說這是他們在 Slack 頻道裡實際運作的東西，不是理論。

## Agent 就是軟體

Dex 在結尾問了一個問題：「有人寫過 switch 語句嗎？while 迴圈？」全場舉手。這就是他的重點。建構可靠的 Agent 不需要神秘的 AI 背景，需要的是軟體工程的基本功。

他引用了 NotebookLM 團隊的說法：找到模型能力的邊界——那個它不是每次都能做對的事——然後用工程手段讓它變得可靠。如果你能做到這點，你就創造了比別人更好的東西。這不是靠框架給你的，這是靠你理解系統、掌控細節、不斷迭代得來的。

LLM 是無狀態的函數。狀態是你管的。控制流程是你的，不是框架的。工具調用就是 JSON 加程式碼。當你這樣看 Agent，很多事情就簡單了。你不需要等某個框架變得夠成熟，你現在就能用軟體工程的方式，建構可靠的 Agent。
