---
title: "Scaling Law 只是現象描述：智谱 CEO 張鵬的 AGI 哲學與技術判斷"
date: 2026-01-19T11:00:00+08:00
description: "智谱 CEO 張鵬在上市前夕的深度訪談中，分享了對 Scaling Law、Transformer 架構、認知智能本質的獨到見解。他認為暴力堆算力並非通往 AGI 的唯一路徑，真正的智能需要具備舉一反三、自我糾錯的認知能力。"
tags: ["智谱", "張鵬", "Scaling Law", "AGI", "認知智能", "Transformer", "GLM", "Podcast"]
categories: ["AI 產業動態"]
source_url: "https://www.youtube.com/watch?v=9zSMTUUEfmU"
source_name: "張小珺商業訪談錄"
draft: false
---

> 本文整理自「張小珺商業訪談錄」2026 年 1 月播出的單集，聚焦智谱 CEO 張鵬對 AI 技術本質的思考。

{{< youtube 9zSMTUUEfmU >}}

{{< spotify "episode/31QevjVrP0uqRu5i9BzG3e" >}}

---

「Scaling Law 只是一個現象的描述，它並沒有一個很科學的依據。」

這句話出自智谱 CEO 張鵬，在公司登陸港交所成為「全球大模型第一股」前夕的深度訪談中。當整個產業都在談論「暴力美學」、瘋狂堆疊算力的時候，這位清華出身的技術創業者提出了不同的思考。

智谱是中國「AI 六小虎」之首，其開發的 GLM 系列大模型在國內外都有廣泛應用。但與許多競爭者不同，智谱的技術路線始終帶有濃厚的「學院派」色彩——不盲從、重原理、講究降本增效。

這場訪談揭示了張鵬對 AI 技術本質的深度思考：什麼是真正的認知智能？Scaling Law 的極限在哪裡？通往 AGI 的路徑是什麼？

## 張鈸院士的象限圖：認知智能的起點

要理解智谱的技術哲學，必須從一個人說起：**張鈸院士**。

張鈸是中國人工智能領域的奠基人，1987 年建立了中國第一個人工智能國家重點實驗室，培養了超過 90 名博士生。他是智谱的戰略顧問，也是張鵬在清華的導師。

張鵬回憶，早在 2016 年，張鈸院士就畫過一個象限圖來解釋 AI 的局限：

- **「知道自己知道」**：這是當時 AI 能處理的範圍，非常小
- **「知道自己不知道」**：認知智能的目標，機器要知道自己的能力邊界
- **「不知道自己不知道」**：更高層次的探索領域

「上一代人工智能解決的是感知問題，」張鵬解釋，「機器只是一些技能，單個的技能，它不知道『為什麼』。認知智能要讓機器『知其所以然』——理解原有的知識，綜合起來重新演繹和推理，得到新的知識。」

這個框架定義了智谱的技術追求：不只是做一個會聊天的 chatbot，而是要讓機器具備真正的認知能力。

## 感知 vs 認知：自動駕駛的啟示

張鵬用自動駕駛來說明感知智能與認知智能的區別。

傳統自動駕駛的技術架構是：感知（雷達、視覺）→ 決策系統 → 控制輸出（方向盤、油門、剎車）。這是一個閉環的自動控制系統，追求感知精度和決策速度。

「這種方案最害怕的是各種 corner case，」張鵬說，「你可以訓練一萬遍、十萬遍，路上碰到車怎麼辦、碰到紅燈怎麼辦。但你很難訓練一千遍一萬遍，說路上突然穿過去一隻兔子怎麼辦。」

問題的本質是：這套系統只能機械地執行學習到的規則，**規則以外的東西它無法泛化**。

「認知的能力是說，我通過有限的樣本學習之後，總結出來的東西能搬到一些我沒見過的情況上，能泛化，」張鵬強調，「這才是認知智能和原來感知智能最大的區別。有腦子。」

腦子的關鍵是什麼？**能夠根據記憶去推演新的情況**——舉一反三。

## 真正的認知能力：學習、推理、自我糾錯

那麼，泛化能力從何而來？張鵬認為有三個關鍵要素：

1. **學習能力**：從數據中提取知識
2. **邏輯推理能力**：將知識組合起來解決新問題
3. **自我糾錯能力**：識別錯誤並修正

他舉了一個生活化的例子：如果你會開手動擋的車，讓你去開自動擋，你很快就能學會。為什麼？

「你會去嘗試，嘗試，誒，不對，跟以前不一樣。嘗試幾次之後就知道，哦，原來是這樣。沒人告訴你怎麼開，你自己就能學會。這就是學習、反饋、試錯，然後再泛化到新的情況上去。」

## 好的數據：試錯比正確更有價值

這引出了一個反直覺的觀點：**什麼是好的訓練數據？**

張鵬引用一位數據專家的說法：「以前以為對的數據是好的數據，後來發現錯了。有很多中間出錯、然後又糾正的數據才是好數據。這種數據可能更貴，因為它含有試錯的過程。」

這與 2024 年圖靈獎得主 Richard Sutton 的觀點不謀而合。Sutton 是強化學習領域的開創者，他強調「經驗時代」的重要性——經驗包含正確的和失敗的，所有的體驗都是智能提升的必經路徑。

「真正的認知能力，或者說學習的能力，本質是什麼？」張鵬反問，「是從正確的數據、已有的規則性數據裡面學習到的機械性記憶更有用，還是試錯的經驗更有用？」

答案似乎是後者。這也解釋了為什麼現在的大模型訓練越來越強調 Post-training 階段的強化學習，而非單純的預訓練。

## Scaling Law 批判：只是現象，不是科學

2023 年，「暴力美學」是中國大模型圈的流行詞。大家相信 Scaling Law：參數量翻倍，智能水平就會指數級提升。

張鵬不買帳。

「Scaling Law 只是一個現象的描述，它並沒有一個很科學的依據，」他說，「就是說隨著參數量的增長，智能水平呈現一個指數級的爆發式增長。」

從科學的角度，發現現象只是第一步，更重要的是探究現象背後的原因。「如果我掌握了這個原因的本質，我就能利用好這個事情，而不是從簡單的表象上來說，堆參數。」

張鵬觀察到，對於智谱來說，Scaling Law 「不起作用」的時間點並不是技術瓶頸，而是**成本先受不了了**。

「非常貴啊，你知道 i3（NVIDIA GPU）年就開始漲嘛，漲得多可怕。」

面對這個困境，有兩條路：

1. **融更多的錢，講更大的故事**——OpenAI 堅決走這條路
2. **優化算法，降低成本**——智谱選擇兩條路都走，但更強調第二條

## 十四分之一的成本：GLM 的設計哲學

智谱訓練 GLM-130B（1300 億參數）的成本是多少？

**算力約 400 萬人民幣，加上人工成本約 1000 萬人民幣**。

相比之下，OpenAI 訓練 GPT-3 的成本據估計約 2000 萬美元（約 1.4 億人民幣）。智谱只用了十四分之一。

怎麼做到的？

首先是 **GLM 算法本身的設計**。GLM 融合了 BERT（雙向理解）和 GPT（單向生成）的優勢，訓練過程更穩定，量化後的精度損失更小。

其次是**工程優化**。智谱很早就實現了在消費級顯卡上運行千億模型的推理，把硬體成本從一百多萬降到二三十萬。

「這是中國人的優勢，」張鵬說，「大家會去摳細節，要效益，要收益，控成本。」

## 不迷信暴力美學：克制的參數規模

更有意思的是，智谱一直**克制地控制模型規模**。

從 2022 年到 2024 年，智谱的主力模型一直維持在千億參數級別（GLM-130B），直到 GLM-4 才擴大到兩千億。他們從未像一些競爭者那樣，上來就奔著萬億參數去。

「我還是非常克制的，」張鵬說，「這件事情並不取決於模型的參數量或規模，本質上還是看最後的效果。」

2025 年底發布的 GLM-4.7 驗證了這個思路——參數量只有三千多億，但在多項基準測試中位居國內第一。

「好並不是因為它把參數量又加了一倍。好的點在於訓練效率更高、數據利用率更高。」

## L0 到 L5：通往 AGI 的五個階梯

智谱提出了一個通往 AGI 的路線圖，分為五個階段（L0 到 L5）：

**L1：預訓練**
- 從已有數據學習世界知識
- Scaling Law：參數量、數據量、算力

**L2：對齊與推理**
- 學會正確地使用知識
- 關鍵技術：SFT（監督微調）
- Scaling Law：Test-time Compute

**L3：自學習**
- 從經驗中學習，包括試錯
- 關鍵技術：強化學習
- Scaling Law：RL Scaling

**L4：自我認知**
- 知道自己知道什麼、不知道什麼
- 回到張鈸院士的象限圖

**L5：意識**
- 類似人類的 consciousness
- 定義還不清晰

張鵬認為，當前的大模型處於 **L3 階段**，正在從 SFT 走向強化學習。這也解釋了為什麼 OpenAI 的 o1、DeepSeek 的 R1 等「推理模型」成為 2025 年的焦點——它們代表了從 L2 到 L3 的躍遷。

## Transformer 不是終極答案

智谱首席科學家唐傑教授曾公開表示：Transformer 不一定是終極答案，很可能會有更有效、更優美的算法來替代。

張鵬認同這個觀點：「現在的計算方式還不是最完美的，應該還會有更好的方式。」

他的判斷依據是：Transformer 的核心——注意力機制（Attention）——從 2012 年到現在已經有無數的「魔改」版本。

「你看這個 Attention 爆了多少東西出來，各種各樣的變種。它為什麼還有這麼多可魔改的空間？就是在於它本身可能還不是那個最完美的答案，還比較粗糙，還有很多空間可以探索。」

DeepSeek 在這方面做了很多工作，智谱也在探索下一代架構。

## DeepSeek 的開源衝擊

說到 DeepSeek，這家由量化交易巨頭幻方量化孵化的公司，在 2025 年初以開源策略震撼全球。

DeepSeek-R1 的發布直接導致英偉達股價單日暴跌 17%，市值蒸發近 6000 億美元。原因是：這個模型的能力與 OpenAI 的 o1 相當，但訓練成本據稱只有 560 萬美元，而且完全開源。

對智谱來說，DeepSeek 的開源策略是雙面刃。

「在商業化市場上，很多客戶腦子裡面就把開源和免費畫等號了，」張鵬說，「他們會問，你開源都不要錢了，你為什麼還要收我錢？」

但張鵬堅持區分開源與商業化：「商業化客戶需要的是產品、工具和服務，而不僅僅是模型本身。」

智谱自己也堅持開源。2022 年開源 GLM-130B、2023 年開源 ChatGLM-6B，都是出於「回饋社群」的理念。但開源的是研究版本，商業化走另一條路。

## AGI 是信仰，不是曲線救國

訪談中，張鵬多次提到「AGI 信仰」這個詞。

「融資其實是在尋找跟我們有同樣理想、同樣堅定的 AGI 信仰的人，」他說，「這條路還是挺漫長的，如果大家不是為了同樣的信念來做這件事，很難堅持長期一起來做。」

有些公司選擇「曲線救國」——先找到確定性的商業化路徑，賺到錢再投入 AGI 研究。張鵬不認同這個思路。

「信仰這個東西，想要堅持下去本來就是一件很難的事情。我個人不喜歡為自己繞路找理由。這個事情難且重要，那我們還是要堅定地朝這個方向努力。」

他也從技術角度解釋：「單向能力突破這件事情，並不能真正幫助 AGI 實現。上一代人工智能在機器視覺上、在特定任務上，確實比人還好了。它不解決問題。」

## 結語：智能與計算的本質聯繫

訪談接近尾聲時，主持人問了一個深刻的問題：如果 Scaling Law 不是科學描述，那這個過程更像是什麼？

張鵬的回答：「我們還是希望從科學的角度，不管是從原理還是從系統的工程實踐，去找到所謂的智能和計算之間的本質聯繫是什麼。」

這個問題沒有答案。但張鵬的態度很清楚：**不迷信現象，追問本質**。

當整個產業都在討論參數量、算力、融資規模的時候，智谱選擇了一條不那麼「性感」但可能更紮實的路：降本增效、算法創新、長期主義。

這條路能走多遠？市場會給出答案。但至少，智谱的存在提醒我們：通往 AGI 的路徑，可能不只有一條。

---

## 我的觀察

張鵬這場訪談最讓我印象深刻的，是他對「暴力美學」的冷靜批判。

過去兩年，AI 產業的敘事被「更大的模型、更多的算力、更高的融資」主導。OpenAI 融了幾百億美元，微軟投了上千億建資料中心，大家都相信「大力出奇跡」。

但張鵬提出了一個根本性的問題：**我們真的理解為什麼 Scaling 會帶來智能提升嗎？**

如果不理解，那麼當 Scaling 遇到瓶頸（不管是成本瓶頸還是技術瓶頸），我們就會束手無策。

DeepSeek 的出現某種程度上驗證了這個觀點。用十分之一甚至更低的成本，達到相近的效果——這說明「暴力」不是唯一的路徑。

當然，智谱的路線也有風險。在一個「贏家通吃」的市場，如果對手用更多資源堆出更強的模型，你的「降本增效」可能只是螳臂當車。

但換個角度看，這正是生態多樣性的價值。如果所有公司都走 OpenAI 的路線，那一旦這條路走不通，整個產業就會陷入困境。

智谱選擇了一條不同的路。不管最終結果如何，這種獨立思考的精神，本身就值得尊敬。

---

**延伸閱讀：**
- 智谱創業歷程：[從清華實驗室到全球大模型第一股：智谱 CEO 張鵬的 10 年創業路](/posts/20260119-zhipu-ipo-startup-journey/)
