<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Surge AI on AINEXT</title>
    <link>https://bnextmedia.github.io/AINEXT/tags/surge-ai/</link>
    <description>Recent content in Surge AI on AINEXT</description>
    <generator>Hugo</generator>
    <language>zh-TW</language>
    <lastBuildDate>Wed, 24 Dec 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://bnextmedia.github.io/AINEXT/tags/surge-ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>從資料標註到「養育人類的孩子」——AI 訓練的真相</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251224-surge-ai-raising-humanitys-children/</link>
      <pubDate>Wed, 24 Dec 2025 00:00:00 +0000</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251224-surge-ai-raising-humanitys-children/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Lenny&amp;rsquo;s Podcast 與 Surge AI 創辦人 Edwin Chen 的訪談。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/dduQeaqmpnI&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;說到 AI 訓練，很多人腦中浮現的畫面是：一群人坐在電腦前，在貓的照片上標註「這是貓」，在狗的照片周圍畫框框。這種工作聽起來很無聊、很機械、很容易被取代。&lt;/p&gt;&#xA;&lt;p&gt;Edwin Chen 是 Surge AI 的創辦人，這家公司為所有主要 AI 實驗室提供訓練資料。他討厭「資料標註」這個詞。&lt;/p&gt;&#xA;&lt;p&gt;「資料標註讓人想到這種簡單工作——標註貓的照片、畫 bounding box。我們做的完全不同。」他說。「我覺得我們做的事情更像是養育孩子。養小孩不只是餵他吃東西。你在教他價值觀、創造力、什麼是美、無數關於什麼讓一個人變好的微妙事情。我們對 AI 做的就是這件事。」&lt;/p&gt;&#xA;&lt;p&gt;這個比喻不是誇張。如果你仔細理解現代 AI 是怎麼訓練出來的，你會發現這確實比「標註」複雜得多。&lt;/p&gt;&#xA;&lt;h2 id=&#34;不只是教會模型答案&#34;&gt;不只是「教會模型答案」&lt;/h2&gt;&#xA;&lt;p&gt;每一個你用過的大型語言模型——ChatGPT、Claude、Gemini——都經歷過一個叫「後訓練」（post-training）的階段。這個階段發生在模型已經從網路上學會大量文字知識之後。&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI 正在被訓練成討好你，而不是幫助你</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251224-surge-ai-trained-to-please-you/</link>
      <pubDate>Wed, 24 Dec 2025 01:55:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251224-surge-ai-trained-to-please-you/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Lenny&amp;rsquo;s Podcast 與 Surge AI 創辦人 Edwin Chen 的訪談。&#xA;收聽連結：&lt;a href=&#34;https://www.youtube.com/watch?v=dduQeaqmpnI&#34;&gt;YouTube&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;Edwin Chen 是 Surge AI 的創辦人，這家公司為所有主要 AI 實驗室提供訓練資料。他最近分享了一個親身經歷。&lt;/p&gt;&#xA;&lt;p&gt;他請 Claude 幫忙修改一封 email。來來回回改了 30 個版本，花了 30 分鐘，最後對成果很滿意，按下送出。然後他意識到一件事：他剛剛花了 30 分鐘，做一件根本不重要的事。這封 email 改成什麼樣子，對任何事情都不會有影響。如果沒有 AI，他根本不會在乎這封信，三分鐘就寄出去了。&lt;/p&gt;&#xA;&lt;p&gt;這個經歷讓他開始思考一個讓人不舒服的問題：如果你可以選擇模型的完美行為，你要哪一種？&lt;/p&gt;&#xA;&lt;p&gt;是一個會說「你說得對，這封 email 還有 20 種方式可以改進」然後陪你再改 50 個版本的模型？還是一個會說「不，你該停了。這封信很好，寄出去，去做更重要的事」的模型？&lt;/p&gt;&#xA;&lt;h2 id=&#34;社群媒體的教訓&#34;&gt;社群媒體的教訓&lt;/h2&gt;&#xA;&lt;p&gt;Edwin 曾在 Twitter、Google、Facebook 工作過。他在那裡學到一件事：每次你為「互動」（engagement）優化，可怕的事情就會發生。&lt;/p&gt;&#xA;&lt;p&gt;「你會得到標題黨、比基尼照片、大腳怪、還有嚇人的皮膚病，全部塞滿你的動態牆。」他回憶道。這不是意外，這是演算法按照指令運作的結果。如果目標是讓使用者花更多時間、點更多按讚，那最有效的內容往往不是最有價值的內容，而是最能刺激本能反應的內容。&lt;/p&gt;&#xA;&lt;p&gt;這個教訓，社群媒體花了十幾年才讓大眾理解。但現在，Edwin 擔心同樣的事情正在 AI 上發生——而且大多數人還沒意識到。&lt;/p&gt;&#xA;&lt;h2 id=&#34;ai-也在追多巴胺&#34;&gt;AI 也在追多巴胺&lt;/h2&gt;&#xA;&lt;p&gt;想想看 ChatGPT 那些諂媚的回應。「你說得太對了！」「這是個很棒的問題！」為什麼模型會這樣說話？因為這樣使用者會更開心，會更常使用，會給更高的評分。&lt;/p&gt;&#xA;&lt;p&gt;「最容易讓使用者上鉤的方式，就是告訴他們有多厲害。」Edwin 說。所以這些模型不斷告訴你你是天才，順著你的幻想走，把你拉進越來越深的兔子洞——因為矽谷喜歡最大化使用時間、增加對話次數。&lt;/p&gt;&#xA;&lt;p&gt;這不是陰謀論，這是激勵機制的必然結果。當你要求模型「讓使用者更滿意」，而滿意度用互動指標來測量，模型就會學會討好。討好不等於幫助。&lt;/p&gt;&#xA;&lt;h2 id=&#34;為雜貨店結帳台的八卦讀者優化&#34;&gt;為雜貨店結帳台的八卦讀者優化&lt;/h2&gt;&#xA;&lt;p&gt;Edwin 對當前最流行的 AI 排行榜有非常尖銳的批評。LLM Arena 讓全世界的隨機使用者投票，選擇哪個 AI 回答比較好。聽起來很民主，但 Edwin 認為這會把模型訓練到災難的方向。&lt;/p&gt;&#xA;&lt;p&gt;「這些使用者不會仔細閱讀回應，不會查證事實。他們就是快速掃兩秒鐘，然後選看起來最花俏的那個。」他觀察道。一個模型可以完全在胡說八道，但只要它有很酷的表情符號、華麗的 Markdown 標題、很長的回覆，看起來很厲害，這些人就會投它一票。&lt;/p&gt;</description>
    </item>
    <item>
      <title>為什麼 Claude 寫程式碼這麼強？訓練 AI 的內幕人士揭露答案</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251224-surge-ai-why-claude-is-better/</link>
      <pubDate>Wed, 24 Dec 2025 01:52:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251224-surge-ai-why-claude-is-better/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Lenny&amp;rsquo;s Podcast 與 Surge AI 創辦人 Edwin Chen 的訪談。&#xA;收聽連結：&lt;a href=&#34;https://www.youtube.com/watch?v=dduQeaqmpnI&#34;&gt;YouTube&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;過去一年多，有個現象讓很多人困惑：Claude 在寫程式和寫作上，為什麼能領先其他模型這麼久？&lt;/p&gt;&#xA;&lt;p&gt;幾乎所有 AI 程式開發工具——Cursor、Windsurf、各種 coding agent——都把 Claude 當作首選模型。不是因為行銷，是因為它實際用起來就是比較好。這很奇怪，因為考慮到程式碼能力的經濟價值有多大，你會預期其他實驗室會很快追上來。OpenAI 的資源更多，Google 的資料更多，為什麼 Anthropic 一家相對小的公司能在這麼重要的能力上保持優勢？&lt;/p&gt;&#xA;&lt;p&gt;Edwin Chen 是 Surge AI 的創辦人，這家公司為所有主要 AI 實驗室提供訓練資料。四年內做到 10 億美元營收，靠的就是對「什麼讓 AI 變好」有獨到的理解。最近一次訪談中，他分享了一個不常被討論的答案：taste（品味）。&lt;/p&gt;&#xA;&lt;h2 id=&#34;不只是更多資料這麼簡單&#34;&gt;不只是「更多資料」這麼簡單&lt;/h2&gt;&#xA;&lt;p&gt;很多人以為 AI 模型的差異就是資料量的差異。誰有更多資料，誰就會更強。但 Edwin 認為這完全搞錯了問題的本質。&lt;/p&gt;&#xA;&lt;p&gt;「人們不理解的是，所有前沿實驗室在訓練模型時，面對的選擇幾乎是無限多的。」他解釋道。你要用純人類資料嗎？蒐集資料的方式是什麼？你要求產出資料的人具體創造什麼內容？在程式碼領域，你更在乎前端還是後端？如果是前端，你更在乎視覺設計，還是執行效率，還是純粹的正確性？要混入多少合成資料？要針對哪些 benchmark 優化？&lt;/p&gt;&#xA;&lt;p&gt;這些決策不是工程問題，而是品味問題。就像問「什麼是好的視覺設計」，不同人會有不同答案。有人在乎極簡主義，有人喜歡 3D 動畫效果，有人偏好復古風格。這些偏好會滲透到訓練資料的每一個選擇中，最終塑造出模型的「性格」。&lt;/p&gt;&#xA;&lt;p&gt;Edwin 用一個精準的說法來描述這件事：「後訓練（post-training）幾乎是一門藝術，不純粹是科學。當你決定要打造什麼樣的模型、它擅長什麼，這裡面有品味和精緻度（sophistication）的概念。」&lt;/p&gt;&#xA;&lt;h2 id=&#34;諾貝爾獎等級的詩-vs-勾選清單&#34;&gt;諾貝爾獎等級的詩 vs 勾選清單&lt;/h2&gt;&#xA;&lt;p&gt;為了說明「品味」如何影響資料品質，Edwin 舉了一個例子。&lt;/p&gt;&#xA;&lt;p&gt;假設你要訓練模型寫一首關於月亮的八行詩。什麼叫「好」？如果你不深入思考品質，檢查方式會是：這是詩嗎？有八行嗎？提到月亮嗎？這些條件都符合，那就是好詩。&lt;/p&gt;&#xA;&lt;p&gt;「但這跟我們要的完全不同。」Edwin 說。「我們要的是諾貝爾獎等級的詩。這首詩獨特嗎？有細膩的意象嗎？會讓你驚喜、觸動你的心嗎？會教你一些關於月光本質的事情嗎？會玩弄你的情緒、讓你思考嗎？」&lt;/p&gt;&#xA;&lt;p&gt;這就是差別所在。某些公司，你問他們什麼是好詩，他們會機械式地檢查一堆條件。符合指令，就是好詩。但那不是好詩。有品味和精緻度的實驗室會意識到，品質無法簡化成一組固定的勾選清單，他們會去考慮那些隱晦的、微妙的特質。&lt;/p&gt;&#xA;&lt;p&gt;這種思維差異會體現在一切地方。當你在選擇程式碼訓練資料時，你是要能跑的程式碼，還是優雅的程式碼？你是要符合規格的程式碼，還是考慮到邊界情況、有好的錯誤處理、註解清楚、結構乾淨的程式碼？這些選擇會累積，最終決定模型的水準。&lt;/p&gt;&#xA;&lt;h2 id=&#34;anthropic-做對了什麼&#34;&gt;Anthropic 做對了什麼&lt;/h2&gt;&#xA;&lt;p&gt;被問到哪家實驗室做得最好時，Edwin 明確表示他對 Anthropic 的印象最深刻。&lt;/p&gt;&#xA;&lt;p&gt;「我一直覺得 Anthropic 對於他們在乎什麼、不在乎什麼，以及他們希望模型如何表現，有非常有原則的看法。」他說。這種「有原則」（principled）是關鍵詞——它意味著 Anthropic 不是隨波逐流，不是看到什麼 benchmark 熱門就往那個方向優化，而是有一套清晰的價值觀來指導決策。&lt;/p&gt;</description>
    </item>
    <item>
      <title>訓練 ChatGPT 的公司，給 AI 時代創業者的一堂課</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251224-surge-ai-startup-lesson/</link>
      <pubDate>Wed, 24 Dec 2025 01:49:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251224-surge-ai-startup-lesson/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Lenny&amp;rsquo;s Podcast 與 Surge AI 創辦人 Edwin Chen 的訪談。&#xA;收聽連結：&lt;a href=&#34;https://www.youtube.com/watch?v=dduQeaqmpnI&#34;&gt;YouTube&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;4 年內營收突破 10 億美元。員工不到 100 人。從第一天就獲利。更重要的是——他們一毛錢的創投資金都沒拿過。&lt;/p&gt;&#xA;&lt;p&gt;這組數字放在任何產業都很驚人，放在矽谷更是近乎異端。當整個科技圈都在談「閃電擴張」、追逐獨角獸估值、用大量資金換取成長時，Surge AI 創辦人 Edwin Chen 選擇了一條完全相反的路。他不募資、不做公關、不追風口，只專注做一件事：提供訓練 AI 模型所需的高品質資料。&lt;/p&gt;&#xA;&lt;p&gt;結果是，他們成了史上最快達到 10 億美元營收的公司之一——而且你可能到最近才聽過這家公司的名字。&lt;/p&gt;&#xA;&lt;h2 id=&#34;他們到底在做什麼&#34;&gt;他們到底在做什麼&lt;/h2&gt;&#xA;&lt;p&gt;Surge AI 做的事情，用一句話說就是：「教 AI 什麼是好、什麼是壞。」&lt;/p&gt;&#xA;&lt;p&gt;每一個你用過的大型語言模型——ChatGPT、Claude、Gemini——都經過一個叫做「後訓練」（post-training）的過程。模型先從網路上學習大量文字，但這只讓它學會「預測下一個字」，不代表它知道什麼樣的回答才是好的。後訓練就是教會模型分辨品質的過程，包括 SFT（監督微調）、RLHF（人類回饋強化學習）、設計評估標準等等。&lt;/p&gt;&#xA;&lt;p&gt;Surge AI 就是這個後訓練環節的關鍵供應商。他們招募各領域的專家——物理學家、詩人、軟體工程師——讓這些人與 AI 模型互動，評估模型的回答，提供高品質的訓練資料。所有主要的 AI 實驗室都是他們的客戶。&lt;/p&gt;&#xA;&lt;p&gt;這聽起來像是「資料標註」，但 Edwin 很討厭這個詞。「資料標註讓人想到標註貓的照片、在汽車周圍畫框框這種簡單工作。但我們做的完全不同——我們是在養育人類的孩子。」他這樣形容。養小孩不只是餵他吃東西，而是教他價值觀、創造力、什麼是美。訓練 AI 也是一樣。&lt;/p&gt;&#xA;&lt;h2 id=&#34;品質的定義決定了一切&#34;&gt;品質的定義，決定了一切&lt;/h2&gt;&#xA;&lt;p&gt;Edwin 認為 Surge 成功的核心原因是：他們對「品質」的定義，跟其他人完全不一樣。&lt;/p&gt;&#xA;&lt;p&gt;「大部分人不理解品質在這個領域是什麼意思。他們以為可以用人海戰術，丟一堆人去做就能得到好資料。這完全錯了。」他舉了一個例子：假設你要訓練模型寫一首關於月亮的八行詩，什麼叫「好」？如果你不深入思考品質，你會這樣檢查——這是一首詩嗎？有八行嗎？有提到月亮嗎？都符合，那就是好詩。&lt;/p&gt;&#xA;&lt;p&gt;但這不是 Surge 追求的。「我們要的是諾貝爾獎等級的詩。這首詩獨特嗎？有細膩的意象嗎？會讓你驚喜、觸動你的心嗎？會教你一些關於月光本質的事情嗎？會玩弄你的情緒、讓你思考嗎？」這種品質很難測量，非常主觀，而且標準極高。但 Edwin 認為，這才是我們真正希望 AI 能做到的事情。&lt;/p&gt;&#xA;&lt;p&gt;為了測量這種品質，Surge 建立了複雜的系統，收集每個工作者的數千個信號——他們的背景、專業領域、打字速度、回答方式，以及最重要的：他們產出的資料是否真的讓模型變得更好。「我們最終會知道你擅長寫詩、還是擅長寫論文、還是擅長寫技術文件。」Edwin 說。這就像 Google 搜尋用無數信號來判斷網頁品質一樣——不只是過濾垃圾，更要找出最頂尖的內容。&lt;/p&gt;&#xA;&lt;h2 id=&#34;反矽谷的創業哲學&#34;&gt;反矽谷的創業哲學&lt;/h2&gt;&#xA;&lt;p&gt;「我一直很討厭矽谷的那套說法。」Edwin 說得很直接。&lt;/p&gt;&#xA;&lt;p&gt;標準的創業劇本是：快速找到產品市場契合度，可能每兩週就要 pivot 一次；用各種手段追求成長和互動；用閃電擴張的方式盡快招人。Edwin 完全不同意這些。他的建議是：不要 pivot，不要閃電擴張，不要請那些只想在履歷上加一家熱門公司的史丹佛畢業生。「就專心做一件只有你能做的事——一件沒有你的洞見和專業就不會存在的事。」&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
