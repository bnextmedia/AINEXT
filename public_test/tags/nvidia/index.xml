<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>NVIDIA on AINEXT</title>
    <link>https://bnextmedia.github.io/AINEXT/tags/nvidia/</link>
    <description>Recent content in NVIDIA on AINEXT</description>
    <generator>Hugo</generator>
    <language>zh-TW</language>
    <lastBuildDate>Tue, 13 Jan 2026 16:00:00 +0800</lastBuildDate>
    <atom:link href="https://bnextmedia.github.io/AINEXT/tags/nvidia/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>黃仁勳反駁 AI 泡沫論：「悲觀者在派對上聽起來很聰明，樂觀者才是推動人類前進的人」</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20260113-jensen-huang-no-priors-ai-bubble/</link>
      <pubDate>Tue, 13 Jan 2026 16:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20260113-jensen-huang-no-priors-ai-bubble/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 No Priors Podcast 2026 年 1 月播出的單集，主持人為創投 Conviction 創辦人 Sarah Guo 與知名天使投資人 Elad Gil。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/k-xtmISBCNE&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;iframe &#xA;    src=&#34;https://open.spotify.com/embed/episode/4kSlkESoQ8GPU6meWACSlf&#34; &#xA;    width=&#34;100%&#34; &#xA;    height=&#34;152&#34; &#xA;    frameBorder=&#34;0&#34; &#xA;    allowfullscreen &#xA;    allow=&#34;autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture&#34; &#xA;    loading=&#34;lazy&#34;&#xA;    style=&#34;border-radius: 12px;&#34;&#xA;  &gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;iframe &#xA;    allow=&#34;autoplay *; encrypted-media *; fullscreen *; clipboard-write&#34; &#xA;    frameborder=&#34;0&#34; &#xA;    height=&#34;175&#34; &#xA;    width=&#34;100%&#34;&#xA;    style=&#34;border-radius: 12px; overflow: hidden;&#34; &#xA;    sandbox=&#34;allow-forms allow-popups allow-same-origin allow-scripts allow-storage-access-by-user-activation allow-top-navigation-by-user-activation&#34; &#xA;    src=&#34;https://embed.podcasts.apple.com/ua/podcast/nvidias-jensen-huang-on-reasoning-models-robotics-and/id1668002688?i=1000744277967&#34;&#xA;    loading=&#34;lazy&#34;&#xA;  &gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;關於主持人與節目&#34;&gt;關於主持人與節目&lt;/h2&gt;&#xA;&lt;p&gt;Sarah Guo 是創投公司 Conviction 的創辦人，專注於 AI 原生新創的早期投資。她曾在 Greylock Partners 擔任合夥人，20 多歲就成為該公司史上最年輕的普通合夥人之一。她的投資組合包括 Figma、Harvey（法律 AI）、Mistral AI、Cognition AI（Devin）等明星公司，入選 2025 年 Midas Seed 榜單。&lt;/p&gt;</description>
    </item>
    <item>
      <title>AMD 的佑級野心：蘇姿丰如何用一場演講宣示挑戰 NVIDIA</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20260107-amd-yotta-ambition-ces-2026/</link>
      <pubDate>Wed, 07 Jan 2026 22:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20260107-amd-yotta-ambition-ces-2026/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 AMD 於 CES 2026（2026 年 1 月 6 日）發表的主題演講。&#xA;🎬 收看連結：&lt;a href=&#34;https://www.youtube.com/watch?v=TvBNWbFK2lY&#34;&gt;YouTube&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;一座重達 3,175 公斤的龐然大物被推上了 CES 2026 的舞台。這不是什麼概念車或機器人，而是一座 AI 運算機櫃。AMD 執行長蘇姿丰站在這座名為「Helios」的機櫃旁，用一句話定義了它的身份：「世界上最好的 AI 機櫃。」這句話是對 NVIDIA 的直接挑釁。過去幾年，NVIDIA 的 DGX 系統幾乎壟斷了 AI 資料中心的高階運算市場。但蘇姿丰顯然不打算繼續當追趕者。她用長達兩小時的主題演講，鋪陳了 AMD 的完整戰略藍圖——從雲端到邊緣、從資料中心到個人電腦、從醫療到太空，AMD 要讓 AI 無所不在。&lt;/p&gt;&#xA;&lt;p&gt;這場演講的核心訊息可以用三個字總結：Yotta scale（佑級規模）。這個單位對多數人來說很陌生，但它代表的數字令人震撼。一個 Yottaflop 是 10 的 24 次方——也就是 1 後面跟著 24 個零。相較於我們熟悉的「Peta」（拍，10 的 15 次方），Yotta 大了十億倍；相較於目前全球超級電腦的頂尖水準「Exa」（艾，10 的 18 次方），Yotta 大了一百萬倍。如果用一支 iPhone 16 的運算能力來比較，一個 Yottaflop 大約相當於一千億支 iPhone 同時全力運算。蘇姿丰預測，未來五年內，全球 AI 運算需求將達到 10 Yottaflops 以上，這是 2022 年水準的一萬倍。這個數字聽起來瘋狂，但她的論據很清楚：AI 使用者已經從一百萬人成長到十億人，而這只是開始。&lt;/p&gt;</description>
    </item>
    <item>
      <title>NVIDIA 的全棧帝國：CES 2026 揭示黃仁勳的終極野心</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20260107-nvidia-ces-2026-jensen-huang-keynote/</link>
      <pubDate>Wed, 07 Jan 2026 12:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20260107-nvidia-ces-2026-jensen-huang-keynote/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 NVIDIA 於 CES 2026（2026 年 1 月 5 日）發表的完整活動，包含開場 Panel 討論與黃仁勳主題演講。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/0NBILspM4c4&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;開場白這不只是產品發布&#34;&gt;開場白：這不只是產品發布&lt;/h2&gt;&#xA;&lt;p&gt;3,000 人擠滿拉斯維加斯 Fountain Blue 劇院，另外 3,000 人在場外透過螢幕觀看，全球數百萬人同步收看直播。這是 CES 2026 最受矚目的一場活動，但黃仁勳要展示的，遠不只是幾顆新晶片。&lt;/p&gt;&#xA;&lt;p&gt;當你看完這整場活動，你會發現一件事：&lt;strong&gt;NVIDIA 已經不是一家賣 GPU 的公司了。&lt;/strong&gt; 它正在系統性地吃下 AI 產業鏈的每一層——從最底層的晶片，到最上層的應用程式，中間經過基礎設施、模型、開發工具，全部都要。&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI 硬體突圍與美國財政危機：All-In 年終關鍵回顧</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20260106-all-in-podcast-recap-ai-fiscal-crisis/</link>
      <pubDate>Tue, 06 Jan 2026 12:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20260106-all-in-podcast-recap-ai-fiscal-crisis/</guid>
      <description>&lt;p&gt;如果說這一集的《All-In Podcast》是一部電影，那它肯定是一部充滿張力的雙線敘事片。&lt;/p&gt;&#xA;&lt;p&gt;上半場，是一部令人背脊發涼的政治驚悚片：獨立記者揭發明尼蘇達州數億美元的福利詐欺，資金疑似流向恐怖組織，而加州政府正試圖通過沒收富人資產來填補赤字黑洞。下半場，畫風一轉成為硬核科技大片：NVIDIA 與 Groq 的 200 億美元合作案，宣告了 AI 運算架構的全新時代來臨。&lt;/p&gt;&#xA;&lt;p&gt;這兩種截然不同的氛圍——政治上的腐敗與絕望，科技上的突破與希望——在同一集節目中激烈碰撞。這或許正是當前世界的縮影：舊秩序正在崩解，而新秩序正在程式碼與晶片中重生。&lt;/p&gt;&#xA;&lt;h2 id=&#34;崩壞的系統當詐欺變成工業&#34;&gt;崩壞的系統：當詐欺變成工業&lt;/h2&gt;&#xA;&lt;p&gt;故事從一位 23 歲的獨立記者 Nick Shirley 開始。他深入明尼蘇達州，揭發了一連串令人咋舌的福利詐欺案。&lt;/p&gt;&#xA;&lt;p&gt;其中最荒謬的是「Feeding Our Future」醜聞：一個名義上為了餵飽貧困兒童的計畫，被詐取了 2.5 億美元。Shirley 實地走訪那些領取鉅額補助的「托兒所」，發現大多是大門深鎖的空殼，有些甚至連招牌都拼錯字。更令人震驚的是，自閉症治療補助的申報額在短短五年間暴增了 130 倍，從 300 萬美元激增至 4 億美元。&lt;/p&gt;&#xA;&lt;p&gt;David Sacks 犀利地指出，這不是單純的管理疏失，而是民主黨建立的「贊助體系（Patronage System）」。透過放任詐欺，政府資金被輸送給特定族群（在此案中是索馬利亞移民社群），再透過政治獻金回流，形成一個完美的利益閉環。&lt;/p&gt;&#xA;&lt;p&gt;而在西岸的加州，面對 180 億美元的財政赤字，政客們提出的解方竟然是「資產沒收」。David Friedberg 分析了加州擬議中的「億萬富翁稅」，這項法案試圖對未實現的資產增值徵稅。這打破了「有收入才繳稅」的百年原則，本質上是對私有財產的掠奪。Chamath Palihapitiya 警告，這種竭澤而漁的政策將導致資本加速逃離美國，最終引發債券市場的崩盤。&lt;/p&gt;&#xA;&lt;p&gt;「如果我們認為這種規模的盜竊是可以接受的，」Chamath 語重心長地說，「那這就是美國帝國終結的開始。」&lt;/p&gt;&#xA;&lt;h2 id=&#34;科技的救贖groq-與-nvidia-的世紀聯手&#34;&gt;科技的救贖：Groq 與 NVIDIA 的世紀聯手&lt;/h2&gt;&#xA;&lt;p&gt;然而，就在對體制的絕望中，科技界傳來了令人振奮的消息。NVIDIA 宣佈與 AI 晶片新創 Groq 達成 200 億美元的戰略合作。&lt;/p&gt;&#xA;&lt;p&gt;作為 Groq 的早期投資人，Chamath 在節目中親自拆解了這場合作背後的技術邏輯。他解釋了 AI 推論（Inference）的兩個關鍵階段：&lt;strong&gt;Pre-fill（預填充）&lt;strong&gt;與&lt;/strong&gt;Decode（解碼）&lt;/strong&gt;。&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Pre-fill（閱讀）&lt;/strong&gt;：這是模型讀取你輸入的 Prompt 的過程。這需要巨大的平行運算能力，是 NVIDIA GPU 的絕對主場。&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Decode（寫作）&lt;/strong&gt;：這是模型一個字一個字生成回答的過程。這時的瓶頸不再是算力，而是記憶體頻寬。&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Chamath 用「搭電梯」來比喻：GPU 的架構就像是要不斷搭電梯上下樓搬運數據，對於需要頻繁存取的 Decode 階段來說，效率極低。而 Groq 的架構則是將記憶體（SRAM）直接做在晶片上，完全消除了外部傳輸的延遲。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Groq 攜手 NVIDIA：Chamath 親解「Pre-fill 與 Decode」的架構之爭</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20260106-groq-nvidia-prefill-decode/</link>
      <pubDate>Tue, 06 Jan 2026 12:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20260106-groq-nvidia-prefill-decode/</guid>
      <description>&lt;p&gt;這可能是近期 AI 硬體圈最令人震驚的消息之一：NVIDIA 宣佈與 AI 晶片新創 Groq 達成戰略合作。&lt;/p&gt;&#xA;&lt;p&gt;這個消息之所以反直覺，是因為 Groq 長期以來都被視為 NVIDIA 的挑戰者。Groq 創辦人 Jonathan Ross 曾是 Google TPU 的發明者，這家公司主打的 LPU（Language Processing Unit）架構，正是為了打破 GPU 在大型語言模型（LLM）推論上的壟斷而生。然而，這場原本被視為「大衛對抗歌利亞」的戰爭，卻在 2025 年底演變成了一場價值 200 億美元的聯手。&lt;/p&gt;&#xA;&lt;p&gt;為什麼 NVIDIA 執行長黃仁勳（Jensen Huang）會願意「擁抱」競爭對手？All-In Podcast 主持人、同時也是 Groq 早期投資人的 Chamath Palihapitiya，在最新一集節目中揭露了這場合作背後的技術邏輯。這不僅是一次商業上的合縱連橫，更揭示了 LLM 運算架構正在經歷一場根本性的典範轉移——從單一架構通吃，走向「Pre-fill（預填充）」與「Decode（解碼）」的分工時代。&lt;/p&gt;&#xA;&lt;h2 id=&#34;llm-的兩張面孔閱讀與寫作&#34;&gt;LLM 的兩張面孔：閱讀與寫作&lt;/h2&gt;&#xA;&lt;p&gt;要理解這次合作的意義，首先得理解大型語言模型是如何思考的。Chamath 在節目中引用了一組關鍵概念：Pre-fill（預填充）與 Decode（解碼）。這兩個術語聽起來生硬，但它們精準地描述了 AI 處理任務的兩個截然不同的階段。&lt;/p&gt;&#xA;&lt;p&gt;所謂「Pre-fill」，就是模型的「閱讀階段」。當你把一長串 Prompt（提示詞）丟給 ChatGPT 時，模型必須一次性讀取所有的文字，計算字與字之間的關聯。這個過程是高度平行化的，需要巨大的算力來同時處理龐大的矩陣運算。這正是 NVIDIA GPU 的主場——GPU 的設計初衷就是為了處理這種大規模並行任務，它能像推土機一樣，暴力且高效地碾過這些數據。隨著 Context Window（上下文視窗）越來越大，Pre-fill 的運算需求也呈指數級上升，這讓 NVIDIA 的優勢更加不可撼動。&lt;/p&gt;&#xA;&lt;p&gt;然而，當模型讀完題目，開始「寫作」時，情況就變了。這就是「Decode」階段。在這個階段，模型必須一個字、一個字（token by token）地生成答案。每生成一個字，它都必須回頭看之前生成的所有內容，以確保上下文連貫。&lt;/p&gt;&#xA;&lt;p&gt;這時，運算的瓶頸不再是「算力」，而是「記憶體頻寬」。因為每生成一個字，資料就必須在晶片的運算單元（Logic）和記憶體（HBM）之間來回搬運一次。這就像是你每寫一個字，都得從書桌跑到圖書館查一次字典，然後再跑回來寫下一個字。無論你的寫字速度（算力）有多快，你的產出速度最終會被「跑圖書館」（記憶體傳輸）的時間給卡住。這就是為什麼我們有時會覺得 AI 回答時會「卡頓」或「像打字機一樣慢」的物理原因。&lt;/p&gt;&#xA;&lt;h2 id=&#34;蓋大樓的比喻為什麼-gpu-在-decode-階段效率低&#34;&gt;蓋大樓的比喻：為什麼 GPU 在 Decode 階段效率低？&lt;/h2&gt;&#xA;&lt;p&gt;Chamath 用了一個生動的建築比喻來解釋這個瓶頸。想像你在一棟摩天大樓裡，如果你要從 A 點移動到 B 點（完成一次運算），在 GPU 的架構下，你必須先搭電梯上到 10 樓，處理完後再搭電梯回到一樓，然後走到隔壁棟，再搭電梯上去。這個「搭電梯」的過程，就是資料在 HBM（高頻寬記憶體）與運算單元之間傳輸的過程。&lt;/p&gt;</description>
    </item>
    <item>
      <title>2025 年 AI 投資全景：我們到底在第幾局？</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20260106-ai-investment-2025-early-innings/</link>
      <pubDate>Tue, 06 Jan 2026 11:30:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20260106-ai-investment-2025-early-innings/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Deepwater Asset Management 旗下《DeepTech》Podcast 2025 年 9 月播出的單集。&#xA;🎬 YouTube：&lt;a href=&#34;https://www.youtube.com/watch?v=NsQozkZmrXA&#34;&gt;收看連結&lt;/a&gt;&#xA;🎧 Spotify：&lt;a href=&#34;https://open.spotify.com/episode/54P6sV9SekO2nPjtHiiJIN&#34;&gt;收聽連結&lt;/a&gt;&#xA;🎧 Apple Podcast：&lt;a href=&#34;https://podcasts.apple.com/us/podcast/deeptech-ep5-upon-further-review-were-still-early-in-ai/id1721973292?i=1000726489600&#34;&gt;收聽連結&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;「幾個月前我說我們在第三局。上一季財報後我說第二局。現在我開始懷疑，我們可能還在第一局。」&lt;/p&gt;&#xA;&lt;p&gt;這是 Deepwater Asset Management 合夥人 Gene Munster 在 2025 年 9 月錄製《DeepTech》Podcast 時說的話。他用棒球的比喻來描述 AI 產業的發展階段：九局的比賽，我們可能才剛開始。&lt;/p&gt;&#xA;&lt;p&gt;這個判斷如果正確，意味著什麼？意味著我們看到的所有 AI 相關股價上漲、所有資本支出計畫、所有產品發布，都只是故事的開頭。真正的高潮還沒到來。&lt;/p&gt;&#xA;&lt;p&gt;但這個判斷有可能是錯的。90 年代的網路泡沫中，也有很多人說「我們還很早期」——直到一切崩盤。&lt;/p&gt;&#xA;&lt;p&gt;Gene Munster 和他的合夥人 Doug Clinton 在這集節目中，試圖回答一個關鍵問題：這一次，有什麼不一樣？&lt;/p&gt;&#xA;&lt;h2 id=&#34;從-oracle-的瘋狂一天說起&#34;&gt;從 Oracle 的瘋狂一天說起&lt;/h2&gt;&#xA;&lt;p&gt;2025 年 9 月，甲骨文（Oracle）經歷了公司史上最戲劇性的一天。股價單日上漲 35%，市值增加約 2500 億美元。這個漲幅讓 81 歲的創辦人艾里森（Larry Ellison）一度超越馬斯克，成為全球首富。&lt;/p&gt;&#xA;&lt;p&gt;觸發這波上漲的是 Oracle 公佈的 2030 年營收目標：1440 億美元。這個數字建立在一個核心假設上：AI 基礎設施的需求會持續爆發性成長，而 Oracle 已經卡到了好位置——它拿下了 OpenAI 這個超級大客戶。&lt;/p&gt;&#xA;&lt;p&gt;Gene Munster 把這一天和 2023 年 Nvidia 的「覺醒時刻」相比較。那一年，Nvidia 公布財報，營收大幅超出預期，股價一天內創造了類似的市值增長。那是整個資本市場「突然意識到 AI 是真的」的時刻。&lt;/p&gt;</description>
    </item>
    <item>
      <title>客製化晶片來了，Nvidia 的好日子要結束了嗎？</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20260106-custom-silicon-nvidia-groq/</link>
      <pubDate>Tue, 06 Jan 2026 10:30:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20260106-custom-silicon-nvidia-groq/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Deepwater Asset Management 旗下《DeepTech》Podcast 2025 年 9 月播出的單集。&#xA;🎬 YouTube：&lt;a href=&#34;https://www.youtube.com/watch?v=NsQozkZmrXA&#34;&gt;收看連結&lt;/a&gt;&#xA;🎧 Spotify：&lt;a href=&#34;https://open.spotify.com/episode/54P6sV9SekO2nPjtHiiJIN&#34;&gt;收聽連結&lt;/a&gt;&#xA;🎧 Apple Podcast：&lt;a href=&#34;https://podcasts.apple.com/us/podcast/deeptech-ep5-upon-further-review-were-still-early-in-ai/id1721973292?i=1000726489600&#34;&gt;收聽連結&lt;/a&gt;&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;p&gt;OpenAI 和晶片設計公司 Broadcom 簽下了一份價值超過 100 億美元的合約，要開發專為 OpenAI 設計的客製化 AI 晶片。幾乎在同一時間，Nvidia 宣布以 200 億美元收購 AI 推論晶片新創公司 Groq 的技術和團隊。&lt;/p&gt;&#xA;&lt;p&gt;這兩則新聞放在一起看，透露出一個重要訊號：AI 晶片市場正在發生結構性的變化。&lt;/p&gt;&#xA;&lt;p&gt;投資管理公司 Deepwater Asset Management 的合夥人 Doug Clinton 在《DeepTech》Podcast 中提出了一個大膽的判斷：AI 產業的敘事正在從「GPU 需求」轉向「客製化晶片需求」。這個轉變對 Nvidia 來說，可能是好消息，也可能是壞消息——取決於你用什麼時間尺度來看。&lt;/p&gt;&#xA;&lt;h2 id=&#34;為什麼市值超過-1000-億美元的-ai-公司都想自己做晶片&#34;&gt;為什麼市值超過 1000 億美元的 AI 公司都想自己做晶片？&lt;/h2&gt;&#xA;&lt;p&gt;Doug Clinton 在節目中提出了一個明確的判斷：任何市值超過 1000 億美元的 AI 公司，最終都必須發展自己的客製化晶片。這不是選擇題，而是生存問題。&lt;/p&gt;&#xA;&lt;p&gt;理由很直接：成本和效率。&lt;/p&gt;&#xA;&lt;p&gt;Nvidia 的 GPU 是「通用型」晶片，設計目標是能夠處理各種不同的運算任務。這種通用性是它的優勢，讓 Nvidia 可以賣給各種不同的客戶。但通用性也意味著妥協——對於任何單一特定任務，通用型晶片都不會是「最佳化」的選擇。&lt;/p&gt;&#xA;&lt;p&gt;客製化晶片（Broadcom 稱之為 XPU）則不同。它是專門為特定模型、特定用途設計的。當你知道這顆晶片只需要跑某一種模型時，你可以把所有不需要的功能都拿掉，把所有資源都集中在你需要的功能上。結果就是：更低的功耗、更高的效率、更低的單位運算成本。&lt;/p&gt;</description>
    </item>
    <item>
      <title>台積電美國廠的真實成本：誰來買單？</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251226-tsmc-us-fabs-cost-who-pays/</link>
      <pubDate>Fri, 26 Dec 2025 13:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251226-tsmc-us-fabs-cost-who-pays/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自芝加哥大學 Becker Friedman Institute 製作的《The Pie》Podcast，2025 年 5 月 13 日播出的單集。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;iframe &#xA;    src=&#34;https://open.spotify.com/embed/show/2UEsLEtKK1JHOWO4Mf9uPa&#34; &#xA;    width=&#34;100%&#34; &#xA;    height=&#34;152&#34; &#xA;    frameBorder=&#34;0&#34; &#xA;    allowfullscreen &#xA;    allow=&#34;autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture&#34; &#xA;    loading=&#34;lazy&#34;&#xA;    style=&#34;border-radius: 12px;&#34;&#xA;  &gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;iframe &#xA;    allow=&#34;autoplay *; encrypted-media *; fullscreen *; clipboard-write&#34; &#xA;    frameborder=&#34;0&#34; &#xA;    height=&#34;175&#34; &#xA;    width=&#34;100%&#34;&#xA;    style=&#34;border-radius: 12px; overflow: hidden;&#34; &#xA;    sandbox=&#34;allow-forms allow-popups allow-same-origin allow-scripts allow-storage-access-by-user-activation allow-top-navigation-by-user-activation&#34; &#xA;    src=&#34;https://embed.podcasts.apple.com/us/podcast/pandemic-economics/id1509074261&#34;&#xA;    loading=&#34;lazy&#34;&#xA;  &gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;台積電在美國設廠的成本比在台灣高，這件事早就不是秘密。但芝加哥大學經濟學教授謝長泰（Chang-Tai Hsieh）在一集 Podcast 中，把這個問題往下推了一層：這些額外成本最終會落在誰身上？答案會影響的不只是幾家公司的財報，可能還包括整個 AI 革命的發展速度。&lt;/p&gt;&#xA;&lt;h2 id=&#34;成本轉嫁的三條路&#34;&gt;成本轉嫁的三條路&lt;/h2&gt;&#xA;&lt;p&gt;謝長泰分析，如果台積電真的在美國擴大產能，而這些產能的營運成本確實比台灣高（目前的證據顯示確實如此），那麼接下來會發生三件事之一。&lt;/p&gt;&#xA;&lt;p&gt;第一種可能是台積電自己吸收成本。這意味著台積電的利潤會下降，股東得到的回報會減少。對於一家市值超過兆美元的公司來說，利潤率的任何下滑都會在財報上非常顯眼。&lt;/p&gt;&#xA;&lt;p&gt;第二種可能是台積電把成本轉嫁給客戶。它的主要客戶是誰？Apple、NVIDIA、Meta——這些全球最有價值的科技公司。如果晶片價格上漲，這些公司就必須做出選擇：是自己吸收成本、壓縮利潤，還是再往下轉嫁給自己的客戶？&lt;/p&gt;&#xA;&lt;p&gt;第三種可能是成本最終轉嫁到消費者身上。iPhone 變貴、NVIDIA 的 GPU 變貴、雲端 AI 服務的訂閱費變貴。&lt;/p&gt;&#xA;&lt;p&gt;謝長泰坦承他不知道 NVIDIA 等公司的利潤率到底有多高，也不知道它們有沒有能力吸收這些成本。但他指出，不管是哪一種情況，結果都是有人的利潤會減少。&lt;/p&gt;&#xA;&lt;h2 id=&#34;兩種世界觀的碰撞&#34;&gt;兩種世界觀的碰撞&lt;/h2&gt;&#xA;&lt;p&gt;這裡謝長泰提出了一個更深層的問題：利潤減少到底是好事還是壞事？&lt;/p&gt;&#xA;&lt;p&gt;他描述了兩種對立的世界觀。第一種是「進步派」的觀點：如果公司賺得少，那就意味著股東分得少，其他人分得多。從這個角度看，高科技公司利潤下降不是什麼壞事，反而是財富重新分配的機會。&lt;/p&gt;&#xA;&lt;p&gt;第二種觀點則認為，利潤是驅動創新的關鍵燃料。這些公司之所以能投入大量資金進行研發，正是因為它們有豐厚的利潤。如果利潤被壓縮，研發投資就會減少，下一波技術革命可能會被推遲。&lt;/p&gt;&#xA;&lt;p&gt;「哪一邊是對的？我不知道，」謝長泰說。他指出，有些公司確實是把利潤拿去分紅而不是投資，但也有很多公司如果沒有利潤，所有對未來創新的投資都會停滯。「我們現在處於哪種情況？很難說。」&lt;/p&gt;&#xA;&lt;h2 id=&#34;對-ai-產業的潛在影響&#34;&gt;對 AI 產業的潛在影響&lt;/h2&gt;&#xA;&lt;p&gt;如果把這個問題放到 AI 產業的脈絡下，影響可能更加深遠。目前，AI 革命的硬體基礎幾乎完全建立在台積電製造的先進晶片上。NVIDIA 的 GPU、各大科技公司的 AI 加速器、甚至 Apple 的自研晶片，都依賴台積電的製程技術。&lt;/p&gt;</description>
    </item>
    <item>
      <title>GPU 有 70% 時間在「等記憶體」：AI 半導體的真正瓶頸在哪？</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251226-gpu-waiting-for-memory/</link>
      <pubDate>Fri, 26 Dec 2025 10:30:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251226-gpu-waiting-for-memory/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自韓國財經節目《삼프로TV 언더스탠딩》2025 年 11 月播出的單集，來賓為 KAIST 電子及電機工程學部金正鎬教授。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/uJWZQb9rWUk&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;你以為 AI 運算的瓶頸是 GPU 不夠強？這個假設可能從根本上就錯了。&lt;/p&gt;&#xA;&lt;p&gt;KAIST 電子及電機工程學部的金正鎬（Kim Jung-ho）教授在韓國財經節目中揭示了一個反直覺的事實：目前的 AI 晶片，包括 NVIDIA 最先進的 GPU，有大約 60% 到 70% 的時間處於閒置狀態。它們不是在計算，而是在等待。等什麼？等記憶體把資料送過來。&lt;/p&gt;&#xA;&lt;p&gt;這就像一條高速公路上有一輛超級跑車，引擎馬力驚人，但前面塞車了。跑車的性能再好，也只能停在那裡空轉。在 AI 運算的世界裡，GPU 就是那輛跑車，而記憶體的頻寬就是那條塞車的公路。&lt;/p&gt;&#xA;&lt;h2 id=&#34;為什麼-gpu-會餓肚子&#34;&gt;為什麼 GPU 會「餓肚子」？&lt;/h2&gt;&#xA;&lt;p&gt;要理解這個現象，得先理解 AI 模型是怎麼運作的。當你問 ChatGPT 一個問題時，它不是一次把整個答案想好再說出來，而是一個字、一個字地「吐」出來。每吐一個字，模型都需要回去查一本巨大的「參考書」——這本參考書儲存了它學過的所有知識，技術上叫做模型參數和 KV Cache。&lt;/p&gt;</description>
    </item>
    <item>
      <title>NVIDIA 可能收購記憶體公司？KAIST 教授的驚人預測與背後邏輯</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251226-nvidia-may-acquire-memory-company/</link>
      <pubDate>Fri, 26 Dec 2025 10:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251226-nvidia-may-acquire-memory-company/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自韓國財經節目《삼프로TV 언더스탠딩》2025 年 11 月播出的單集，來賓為 KAIST 電子及電機工程學部金正鎬教授。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/uJWZQb9rWUk&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;「我的夢想是，NVIDIA 為了維持主導地位，最終會收購記憶體公司。」&lt;/p&gt;&#xA;&lt;p&gt;這句話出自 KAIST（韓國科學技術院）電子及電機工程學部的金正鎬（Kim Jung-ho）教授。他在韓國財經節目《삼프로TV 언더스탠딩》中，拋出了一個可能改變半導體產業版圖的預測：當記憶體變得比 GPU 更重要時，NVIDIA 的選擇可能不是繼續依賴外部供應商，而是直接把記憶體公司買下來。&lt;/p&gt;&#xA;&lt;p&gt;這不是空穴來風的臆測。金教授是 HBM（High Bandwidth Memory，高頻寬記憶體）技術發展的重要推手之一，早在 2010 年代就參與了這項技術的早期研究。他對半導體產業的判斷，往往比市場共識早上好幾年。&lt;/p&gt;&#xA;&lt;h2 id=&#34;為什麼-nvidia-需要擁有自己的記憶體&#34;&gt;為什麼 NVIDIA 需要擁有自己的記憶體？&lt;/h2&gt;&#xA;&lt;p&gt;要理解這個預測的邏輯，首先要理解一個反直覺的事實：在 AI 運算中，GPU 有相當大比例的時間其實是在「等待」。等什麼？等記憶體把資料送過來。金教授估計，目前的 AI 晶片有 60% 到 70% 的時間處於閒置狀態，因為記憶體的頻寬和容量跟不上 GPU 的運算速度。&lt;/p&gt;</description>
    </item>
    <item>
      <title>黃仁勳說美國「正在輸」——他到底在擔心什麼？</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251224-jensen-huang-us-losing-ai-race/</link>
      <pubDate>Wed, 24 Dec 2025 12:40:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251224-jensen-huang-us-losing-ai-race/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自黃仁勳（Jensen Huang）於 2024 年 12 月在華府的公開對談。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/jpZ0dPsnIWw&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;「中國正在贏得 AI 競賽。」&lt;/p&gt;&#xA;&lt;p&gt;這個標題前陣子傳遍了科技圈。說這話的人是黃仁勳，NVIDIA 的創辦人兼執行長，全球市值最高的科技公司掌門人。標題一出，輿論炸鍋。有人說他在唱衰美國，有人說他在為進入中國市場鋪路，也有人說他只是在講實話。&lt;/p&gt;&#xA;&lt;p&gt;在華府的這場對談中，黃仁勳自己提到了這個「很棒的標題」。他笑著說：「標題確實抓到了很多注意力。但是，免責聲明的部分、基礎論述的部分，被省略了。」&lt;/p&gt;&#xA;&lt;p&gt;所以，他到底在擔心什麼？&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;先把整張圖攤開來看&#34;&gt;先把整張圖攤開來看&lt;/h2&gt;&#xA;&lt;p&gt;黃仁勳不喜歡用「ChatGPT 對 DeepSeek」這種簡化的方式談美中 AI 競爭。他認為 AI 是一個五層的堆疊：能源、晶片、基礎設施、模型、應用。要評估誰「贏」誰「輸」，得一層一層看。&lt;/p&gt;&#xA;&lt;p&gt;當主持人問他「中國是不是真的在贏」，他沒有直接回答，而是逐層分析。這種拆解方式比任何二分法都有意義。讓我們跟著他走一遍。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;能源層美國-50-分中國-100-分還在漲&#34;&gt;能源層：美國 50 分，中國 100 分還在漲&lt;/h2&gt;&#xA;&lt;p&gt;這是黃仁勳最擔心的一層。&lt;/p&gt;&#xA;&lt;p&gt;中國的能源產能是美國的兩倍。而且中國還在快速成長，美國基本持平。這個落差讓黃仁勳很困惑：「我們的經濟規模比他們大，能源產能卻只有一半。這說不通。」&lt;/p&gt;&#xA;&lt;p&gt;為什麼能源這麼重要？因為美國現在要同時做三件事：建晶片工廠（半導體製造回流）、建超級電腦工廠、建 AI 資料中心。這三種設施都是電力怪獸。沒有能源，製造業回流就是空談，AI 基礎設施就建不起來。&lt;/p&gt;</description>
    </item>
    <item>
      <title>黃仁勳的「AI 五層蛋糕」——為什麼理解這個框架比追 ChatGPT 更重要</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251224-jensen-huang-ai-five-layers/</link>
      <pubDate>Wed, 24 Dec 2025 12:35:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251224-jensen-huang-ai-five-layers/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自黃仁勳（Jensen Huang）於 2024 年 12 月在華府的公開對談。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/jpZ0dPsnIWw&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;多數人談 AI，談的是 ChatGPT。更進階一點的，可能還會聊 Claude、Gemini、Grok。但黃仁勳在華府的這場對談中，開頭就丟出一個數字：全世界有 150 萬個 AI 模型。ChatGPT、Claude、Gemini、Grok？這四個加起來，只是 150 萬分之四。&lt;/p&gt;&#xA;&lt;p&gt;這不是在炫耀數字。黃仁勳想說的是：如果你只盯著這幾個「明星模型」看 AI 產業，你根本沒看到全貌。他用了一個簡單但有力的框架來解釋整個 AI 產業的結構——他稱之為「五層蛋糕」。理解這個框架，比追著看哪個 AI 又更新了更重要。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;第一層能源&#34;&gt;第一層：能源&lt;/h2&gt;&#xA;&lt;p&gt;蛋糕的最底層是能源。這聽起來很基礎，但黃仁勳認為這是川普政府上任後做對的第一件事。&lt;/p&gt;&#xA;&lt;p&gt;「如果沒有能源，我們怎麼建晶片廠？怎麼建電腦系統廠？怎麼建那些我們稱之為 AI 工廠的資料中心？」黃仁勳直接點出問題。美國現在同時在建三種工廠：晶片工廠、超級電腦工廠、AI 工廠。每一種都需要大量能源。但問題是，中國的能源產能是美國的兩倍，而且還在快速成長。美國？基本持平。&lt;/p&gt;&#xA;&lt;p&gt;這個數字讓人不安。美國的經濟規模比中國大，能源產能卻只有人家一半。更麻煩的是，過去幾年美國社會對能源產業的態度偏向敵視。黃仁勳認為，川普政府願意公開支持能源產業發展，是「上任後做的最重要的事情之一」。沒有能源，後面四層都是空談。&lt;/p&gt;</description>
    </item>
    <item>
      <title>開源 AI 的隱憂——為什麼黃仁勳說中國「遙遙領先」</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251224-jensen-huang-open-source-ai-concerns/</link>
      <pubDate>Wed, 24 Dec 2025 12:30:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251224-jensen-huang-open-source-ai-concerns/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自黃仁勳（Jensen Huang）於 2024 年 12 月在華府的公開對談。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/jpZ0dPsnIWw&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;提到 AI 模型，多數人想到的是 ChatGPT、Claude、Gemini 這些明星產品。它們確實代表了當前 AI 能力的最高水準。但黃仁勳在華府對談中丟出了一個讓人停下來思考的數字：全世界有 150 萬個 AI 模型。&lt;/p&gt;&#xA;&lt;p&gt;150 萬。ChatGPT、Claude、Gemini、Grok——這四個加起來，只是其中的 150 萬分之四。&lt;/p&gt;&#xA;&lt;p&gt;更重要的是，這 150 萬個模型中，絕大多數是開源的。而在開源 AI 這個領域，中國「遙遙領先」。這是黃仁勳的原話。&lt;/p&gt;&#xA;&lt;p&gt;這為什麼重要？因為開源不只是一種授權方式，它是整個 AI 產業能夠蓬勃發展的基礎。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;為什麼開源對-ai-這麼重要&#34;&gt;為什麼開源對 AI 這麼重要？&lt;/h2&gt;&#xA;&lt;p&gt;黃仁勳解釋得很直接：沒有開源，新創公司無法起步。&lt;/p&gt;</description>
    </item>
    <item>
      <title>從洗碗工到 3 兆美元——黃仁勳談「為什麼我還在拼」</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251224-jensen-huang-dishwasher-to-3-trillion/</link>
      <pubDate>Wed, 24 Dec 2025 12:25:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251224-jensen-huang-dishwasher-to-3-trillion/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自黃仁勳（Jensen Huang）於 2024 年 12 月在華府的公開對談。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/jpZ0dPsnIWw&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;「我不需要工作了。」&lt;/p&gt;&#xA;&lt;p&gt;這是黃仁勳在華府對談中說的話。NVIDIA 的市值超過 3 兆美元，是全球最有價值的科技公司之一。黃仁勳個人身價數百億美元。以任何標準來看，他早就可以退休了。&lt;/p&gt;&#xA;&lt;p&gt;但他接著說：「這是我絕對不會錯過的十年。」&lt;/p&gt;&#xA;&lt;p&gt;為什麼？&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;九歲移民從洗碗開始&#34;&gt;九歲移民，從洗碗開始&lt;/h2&gt;&#xA;&lt;p&gt;對談一開始，主持人 David Rubenstein 提到了一個共同點：他們兩個人的第一份工作，都是在餐廳洗碗。Rubenstein 是在拉什莫爾山的餐廳打工，黃仁勳則是在 Denny&amp;rsquo;s。&lt;/p&gt;&#xA;&lt;p&gt;「你比我厲害，」Rubenstein 開玩笑說，「你後來升成了服務生，然後一路升到 NVIDIA 執行長。」&lt;/p&gt;&#xA;&lt;p&gt;黃仁勳的父親是石油工程師，母親是老師。九歲那年，父母把他送到美國，幾乎是從零開始。他們沒有什麼資源，只有一個美國夢。&lt;/p&gt;&#xA;&lt;p&gt;「這是典型的美國故事，」Rubenstein 說。「我們歡迎那些只帶著能量、想像力和創造力來到這裡的人，然後他們創造出驚人的成就。」&lt;/p&gt;&#xA;&lt;p&gt;黃仁勳對此沒有多說什麼，只是簡單地說了聲「謝謝」。但在對談的後半段，他透露了更多這段經歷對他的影響。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;你很難不對這個國家產生浪漫情懷&#34;&gt;「你很難不對這個國家產生浪漫情懷」&lt;/h2&gt;&#xA;&lt;p&gt;談到美國的競爭優勢時，黃仁勳突然變得感性。&lt;/p&gt;</description>
    </item>
    <item>
      <title>華爾街頂尖投資人：我們正走向十年內的 AI 超級智慧</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251222-gavin-baker-asi-ten-years/</link>
      <pubDate>Mon, 22 Dec 2025 21:20:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251222-gavin-baker-asi-ten-years/</guid>
      <description>&lt;p&gt;&lt;strong&gt;本文整理自 Invested Podcast 訪談。&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/ugihLT9cFTE&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;「我認為十年內我們將擁有人工超級智慧——一個在每個領域都比最聰明的人類更聰明的 AI。」說這話的是 Gavin Baker，華爾街最受尊敬的科技投資人之一。他在 Fidelity 工作時，曾是 NVIDIA 市值僅 20 億美元時的最大股東；2012 年，他管理的基金成為 Tesla 的最大股東。如今他經營避險基金 Atreides Management，被 Invested Podcast 主持人 Michael Eisenberg 稱為「全球最了解半導體供應鏈的人之一」。當這樣一位見證過多次科技週期的投資人談論 AI 的未來時，他的判斷值得認真對待。&lt;/p&gt;&#xA;&lt;p&gt;但 Baker 的觀點並不是單純的樂觀。在這場於以色列特拉維夫錄製的深度對談中，他同時指出了這場 AI 競賽中最大的未知數：我們可能達到超級智慧，但它的經濟回報是多少？沒有人知道。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Reasoning 如何拯救 AI：一場你不知道的 18 個月危機</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251222-reasoning-saved-ai-scaling-laws/</link>
      <pubDate>Mon, 22 Dec 2025 21:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251222-reasoning-saved-ai-scaling-laws/</guid>
      <description>&lt;p&gt;如果不是 Reasoning 模型的出現，AI 的進展可能在 2024 年就停滯了。這個說法聽起來驚人，但背後有著嚴謹的技術邏輯——而且這個故事鮮為人知。&lt;/p&gt;&#xA;&lt;p&gt;Gavin Baker 是 Atreides 投資公司創辦人，曾任 Fidelity 科技基金經理人，長期追蹤 AI 與半導體產業。2024 年 12 月，他接受知名投資 Podcast《Invest Like the Best》主持人 Patrick O&amp;rsquo;Shaughnessy 專訪，深入剖析了 AI 產業的競爭格局、技術演進與投資邏輯。在這場近兩小時的對談中，他揭露了一個公開市場投資人普遍忽略的事實：基於預訓練規模定律的邏輯，2024 和 2025 年的 AI 進展「理論上不應該發生」。這個看似矛盾的陳述，需要從 Scaling Laws 的本質說起。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;scaling-laws我們精確測量卻不理解的神秘法則&#34;&gt;Scaling Laws：我們精確測量卻不理解的神秘法則&lt;/h2&gt;&#xA;&lt;p&gt;要理解 Reasoning 為什麼「拯救」了 AI，首先要理解什麼是 Scaling Laws（規模定律）。這個概念是當前 AI 發展的核心驅動力，但它的本質卻帶有一種令人不安的神秘性。&lt;/p&gt;&#xA;&lt;p&gt;Pre-training Scaling Laws（預訓練規模定律）並非像牛頓力學那樣的物理定律，而是一個「經驗觀察」。研究人員發現，當你增加模型的參數量、訓練資料量、以及運算量時，模型的表現會以一種可預測的方式提升。這個觀察已經被精確測量並持續驗證了很長時間，成為各大 AI 實驗室投入數十億美元建設超大規模運算叢集的理論基礎。然而，沒有人真正知道這個定律為什麼會成立。&lt;/p&gt;&#xA;&lt;p&gt;Baker 用了一個精妙的比喻來描述這種認知落差。古埃及人可以精確測量太陽的運行軌跡，精確到能夠把金字塔的東西軸完美對準春分點，巨石陣的建造者同樣展現了對太陽週期的精確掌握。但他們完全不懂軌道力學，不知道地球繞著太陽轉，不知道為什麼太陽會東升西落、為什麼會有四季變化。他們的神話中，太陽是由神駕著戰車拉過天空。當代 AI 研究者對 Scaling Laws 的理解，與古人對太陽的理解處於類似的階段：精確測量，但缺乏根本性的理解。&lt;/p&gt;&#xA;&lt;p&gt;這種認知狀態帶來了一個實際問題：既然我們不知道 Scaling Laws 為什麼會成立，我們也無法確定它什麼時候會停止成立。每一次新模型的訓練，都是對這個經驗定律的又一次驗證。這就是為什麼 2024 年底 Google 發布 Gemini 3 時，業界如此關注——它證明了預訓練規模定律在又一個數量級上依然有效。這個確認對於整個產業的信心至關重要，因為目前所有的大規模資本支出，都是基於這個定律會繼續成立的假設。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;blackwell-延遲科技史上最複雜的產品轉換&#34;&gt;Blackwell 延遲：科技史上最複雜的產品轉換&lt;/h2&gt;&#xA;&lt;p&gt;2024 年，Nvidia 的新一代晶片 Blackwell 遭遇了嚴重的產品延遲。這不是普通的供應鏈問題或良率挑戰，而是科技史上「最複雜的產品轉換」之一。理解這次延遲的嚴重性，需要先理解從 Hopper 到 Blackwell 究竟改變了什麼。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
