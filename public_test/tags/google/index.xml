<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Google on AINEXT</title>
    <link>https://bnextmedia.github.io/AINEXT/tags/google/</link>
    <description>Recent content in Google on AINEXT</description>
    <generator>Hugo</generator>
    <language>zh-TW</language>
    <lastBuildDate>Fri, 26 Dec 2025 13:00:00 +0800</lastBuildDate>
    <atom:link href="https://bnextmedia.github.io/AINEXT/tags/google/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>兩個 CEO 的 20 年情誼——從 2004 年 IPO 到 Agentic Enterprise</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251226-google-salesforce-agentic-enterprise/</link>
      <pubDate>Fri, 26 Dec 2025 13:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251226-google-salesforce-agentic-enterprise/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Dreamforce 2025 的對談。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/brQH2CCxbSE&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;Dreamforce 2025 的舞台上，Google 執行長皮查伊（Sundar Pichai）和 Salesforce 執行長貝尼奧夫（Marc Benioff）並肩而坐。兩人認識多年，私交甚篤，這場對談的氣氛輕鬆得像老朋友聚會。&lt;/p&gt;&#xA;&lt;p&gt;但在閒話家常之間，藏著一段橫跨 20 年的商業史，以及對 AI 未來的共同願景。&lt;/p&gt;&#xA;&lt;h2 id=&#34;2004-年的交會&#34;&gt;2004 年的交會&lt;/h2&gt;&#xA;&lt;p&gt;貝尼奧夫回憶，他第一次見到 Google 創辦人佩吉（Larry Page）和布林（Sergey Brin），是在 2004 年。那年，Google 和 Salesforce 都在籌備上市。&lt;/p&gt;&#xA;&lt;p&gt;當時 Benioff 正在一場活動上演講，不只談產品策略，還介紹了 Salesforce 的「1-1-1 模式」——把公司 1% 的股權、1% 的利潤、1% 的員工時間捐給公益。佩吉和布林坐在台下聽完後，走上前來對他說：「我們也要這樣做。」&lt;/p&gt;</description>
    </item>
    <item>
      <title>2025 Model Wars 年終回顧：從 GPT-5 到 Gemini 3 的瘋狂四個月</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251226-model-wars-2025-year-in-review/</link>
      <pubDate>Fri, 26 Dec 2025 12:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251226-model-wars-2025-year-in-review/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 TBPN 2025 年 12 月 18 日播出的單集。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;iframe &#xA;    src=&#34;https://open.spotify.com/embed/episode/1v3nZ2FuZ1HFivr79nWjid&#34; &#xA;    width=&#34;100%&#34; &#xA;    height=&#34;152&#34; &#xA;    frameBorder=&#34;0&#34; &#xA;    allowfullscreen &#xA;    allow=&#34;autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture&#34; &#xA;    loading=&#34;lazy&#34;&#xA;    style=&#34;border-radius: 12px;&#34;&#xA;  &gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;iframe &#xA;    allow=&#34;autoplay *; encrypted-media *; fullscreen *; clipboard-write&#34; &#xA;    frameborder=&#34;0&#34; &#xA;    height=&#34;175&#34; &#xA;    width=&#34;100%&#34;&#xA;    style=&#34;border-radius: 12px; overflow: hidden;&#34; &#xA;    sandbox=&#34;allow-forms allow-popups allow-same-origin allow-scripts allow-storage-access-by-user-activation allow-top-navigation-by-user-activation&#34; &#xA;    src=&#34;https://embed.podcasts.apple.com/rw/podcast/%24djt-goes-nuclear-openai-in-talks-at-%24750b-2025-model/id1772360235?i=1000741910856&#34;&#xA;    loading=&#34;lazy&#34;&#xA;  &gt;&lt;/iframe&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;「Gemini 3 的發布才一個月前，感覺已經像是很久以前的事了。」TBPN 主持人在 12 月中的節目上這樣感嘆。這句話精準捕捉了 2025 年下半年 AI 產業的節奏——模型發布的速度之快，讓人幾乎來不及消化。從 8 月到 12 月，各大 AI 實驗室密集推出了超過十個重要模型，每一次發布都引發新一輪的排名洗牌和敘事轉變。這是一場史無前例的模型軍備競賽，而我們正身處其中。&lt;/p&gt;&#xA;&lt;h2 id=&#34;瘋狂四個月模型發布時間軸&#34;&gt;瘋狂四個月：模型發布時間軸&lt;/h2&gt;&#xA;&lt;p&gt;讓我們先回顧這段時間發生了什麼。8 月 7 日，OpenAI 發布 GPT-5，這是繼 GPT-4 之後睽違超過一年的重大版本更新。9 月 29 日，Anthropic 發布 Claude Sonnet 4.5，緊接著隔天，OpenAI 發布了影片生成模型 Sora 2，同一天 Meta 也發布了 Ray-Bans 顯示器整合。&lt;/p&gt;&#xA;&lt;p&gt;11 月是最瘋狂的月份。11 月 3 日，OpenAI 和 Amazon 宣布價值 380 億美元的合作案。11 月 12 日，GPT-5.1 發布。11 月 17 日，Elon Musk 的 xAI 發布 Grok 4.1。11 月 18 日，Google 發布 Gemini 3——這個發布在當時引發了巨大迴響，被視為 Google 在 AI 競賽中重新站穩腳步的標誌。11 月 20 日，NanoBananaPro（一個影像生成模型）問世。11 月 24 日，Anthropic 發布 Claude Opus 4.5。&lt;/p&gt;</description>
    </item>
    <item>
      <title>量子電腦 3-5 年內將破解現有加密——Sundar Pichai 的未來預言</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251226-quantum-computing-crypto-threat/</link>
      <pubDate>Fri, 26 Dec 2025 12:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251226-quantum-computing-crypto-threat/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Dreamforce 2025 的對談。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/brQH2CCxbSE&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;「我們在 3 到 5 年內，會面臨一個必須讓加密系統適應量子運算的時刻。」&lt;/p&gt;&#xA;&lt;p&gt;這句話出自 Google 執行長皮查伊（Sundar Pichai），說的是量子電腦對現有資安體系的威脅。他在 Dreamforce 2025 的對談中，被問到未來 10 年的科技展望，給出了一系列讓人既興奮又緊張的預測。&lt;/p&gt;&#xA;&lt;h2 id=&#34;從諾貝爾獎談起&#34;&gt;從諾貝爾獎談起&lt;/h2&gt;&#xA;&lt;p&gt;Pichai 提到，就在對談前兩週，他才去了一趟 Google 位於聖塔芭芭拉的量子運算實驗室。那是一個他投入超過十年心血的團隊。週一他離開實驗室，週二早上就得知團隊的首席科學家獲得了諾貝爾物理學獎。&lt;/p&gt;&#xA;&lt;p&gt;這已經是 Google 連續第二年有員工得到諾貝爾獎。2024 年，DeepMind 的哈薩比斯（Demis Hassabis）和乘伯（John Jumper）因 AlphaFold 獲得諾貝爾化學獎。這種「從基礎研究到實際產品」的路徑，是 Google 一直在追求的模式。&lt;/p&gt;</description>
    </item>
    <item>
      <title>ChatGPT 來了，Google 在想什麼？——Sundar Pichai 親述 AI 競爭內幕</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251226-google-chatgpt-ai-competition/</link>
      <pubDate>Fri, 26 Dec 2025 11:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251226-google-chatgpt-ai-competition/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Dreamforce 2025 的對談。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/brQH2CCxbSE&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;2022 年 11 月 30 日，OpenAI 發布 ChatGPT。接下來的幾週，這個聊天機器人以史上最快速度突破一億用戶，媒體開始大量報導「Google 殺手」、「搜尋引擎末日」之類的標題。&lt;/p&gt;&#xA;&lt;p&gt;外界的敘事是：Google 這個 AI 領域的先驅，被一家舊金山的新創公司打了個措手不及。&lt;/p&gt;&#xA;&lt;p&gt;但 Google 執行長皮查伊（Sundar Pichai）在 Dreamforce 2025 的對談中，給出了一個不太一樣的版本。「當 ChatGPT 發布的時候，」他說，「跟外界的感受相反，我其實是興奮的。」&lt;/p&gt;&#xA;&lt;h2 id=&#34;那篇改變一切的論文&#34;&gt;那篇改變一切的論文&lt;/h2&gt;&#xA;&lt;p&gt;要理解 Pichai 為什麼不慌，得先回到 2017 年。&lt;/p&gt;</description>
    </item>
    <item>
      <title>從等 5 年電話到 AI 霸主——Sundar Pichai 的矽谷之路</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251226-sundar-pichai-silicon-valley-journey/</link>
      <pubDate>Fri, 26 Dec 2025 10:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251226-sundar-pichai-silicon-valley-journey/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Dreamforce 2025 的對談。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/brQH2CCxbSE&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;「我等了五年才拿到一支撥盤電話。」&lt;/p&gt;&#xA;&lt;p&gt;這句話出自 Google 執行長皮查伊（Sundar Pichai）之口，說的是他在南印度成長的日子。在那個年代，電話是政府製造的，有一長串等候名單。當電話終於送到家裡時，他們家成了社區裡第一批有電話的家庭，鄰居們會跑來借用，打給遠方的親人。一支電話，創造了一個小社區。&lt;/p&gt;&#xA;&lt;p&gt;這個畫面，後來成為 Pichai 職涯的隱喻：科技不只是工具，而是連結人與機會的橋樑。&lt;/p&gt;&#xA;&lt;h2 id=&#34;從閱讀中長出來的好奇心&#34;&gt;從閱讀中長出來的好奇心&lt;/h2&gt;&#xA;&lt;p&gt;Pichai 的母親因為經濟因素，高中之後就沒再升學。但她是個瘋狂的閱讀者，這個習慣傳給了她的兒子。Pichai 回憶，他對學習和知識的熱愛，最早是從外公和母親那裡學來的。這種對知識的渴望，後來成為他加入 Google 的核心動機——那句使命宣言「讓資訊普及、人人受益」（to make information universally accessible and useful），對他來說不是口號，而是真實的召喚。&lt;/p&gt;&#xA;&lt;p&gt;南印度的成長環境也塑造了他的價值觀。Salesforce 執行長貝尼奧夫（Marc Benioff）在對談中提到，南印度有一種母系社會的能量，女性在家庭中扮演核心角色。Pichai 沒有否認這一點，反而補充說，這種強調家庭、學習和智慧的文化，讓他從小就對「獲取知識」這件事有一種近乎本能的追求。&lt;/p&gt;&#xA;&lt;p&gt;他對科技的興趣，最早是從物理開始的。半導體讓他著迷——這種能把沙子變成數位時代基石的神奇材料。「有個地方叫矽谷，」他笑著說，「對一個對半導體有興趣的小孩來說，這大概是最好的廣告了。」&lt;/p&gt;&#xA;&lt;h2 id=&#34;stanford-的震撼教育&#34;&gt;Stanford 的震撼教育&lt;/h2&gt;&#xA;&lt;p&gt;Pichai 後來進入印度理工學院（IIT），接著拿到獎學金到 Stanford 念研究所。這是他第一次真正接觸到「美國夢」的具體樣貌。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sergey Brin 的史丹佛往事：從撬鎖、溜直排輪到創辦 Google</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251225-sergey-brin-stanford-lockpicking-story/</link>
      <pubDate>Thu, 25 Dec 2025 12:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251225-sergey-brin-stanford-lockpicking-story/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自史丹佛工程學院百年校慶活動，2025 年 12 月播出。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/0nlNX94FcUE&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;「追溯時效應該已經過了吧，我可以講這個故事了。」&lt;/p&gt;&#xA;&lt;p&gt;這是 Google 共同創辦人 Sergey Brin 在史丹佛工程學院百年校慶活動上說的話。台下是數百位學生和校友，台上還坐著史丹佛校長。接下來他講的故事，讓人很難相信這位身價千億美元的科技巨頭，當年是這麼度過他的博士生涯的。&lt;/p&gt;&#xA;&lt;h2 id=&#34;撬鎖爬鷹架入侵系統&#34;&gt;撬鎖、爬鷹架、入侵系統&lt;/h2&gt;&#xA;&lt;p&gt;Brin 1993 年進入史丹佛電腦科學博士班，起初被分配到 Margaret Jacks Hall——主校區內一棟老舊的建築，有著「吱吱作響的小房間和門」。在那裡，他學會了一項特殊技能：撬鎖。「感謝 MIT 的撬鎖指南，」他笑著說。&lt;/p&gt;&#xA;&lt;p&gt;這個技能在幾年後派上了用場。1996 年，電腦科學系搬進了全新的 Gates 大樓。這棟由比爾蓋茲資助興建的建築採用了電子門禁系統，每個人都有一張紅外線感應的電子門卡。Brin 意識到，他的撬鎖技術在這裡行不通了。&lt;/p&gt;&#xA;&lt;p&gt;但他發現了一個漏洞。&lt;/p&gt;&#xA;&lt;p&gt;當時大樓還在進行最後的裝修，外牆架著施工鷹架。而負責製作門禁卡的那台電腦，恰好放在一間有陽台的房間裡。那扇陽台門用的是傳統機械鎖，不是電子鎖。&lt;/p&gt;&#xA;&lt;p&gt;「我知道他們下週就要拆掉鷹架了，」Brin 回憶，「所以我必須行動。」&lt;/p&gt;&#xA;&lt;p&gt;他從自己辦公室的窗戶爬出去，沿著四樓的鷹架橫移，到達那個陽台，撬開機械鎖，進入房間。接著他複製了製卡電腦上的所有軟體，給自己做了一張萬能門禁卡，然後刪除痕跡。&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI 太聰明反而更會騙人？Gemini 3 Flash 的「幻覺式推理」現象</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251225-gemini-flash-hallucination-reasoning/</link>
      <pubDate>Thu, 25 Dec 2025 11:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251225-gemini-flash-hallucination-reasoning/</guid>
      <description>&lt;p&gt;Google 推出的 Gemini 3 Flash 在各項 benchmark 上表現亮眼，速度快、成本低，而且智能水準幾乎追平旗艦級的 Gemini 3 Pro。但在最近一集 Break Even Brothers Podcast 中，主持人提到了一個有趣的發現：Gemini 3 Flash 的幻覺率（hallucination rate）其實蠻高的。更奇怪的是，這並沒有影響它在 benchmark 上的優異表現。這是怎麼回事？&lt;/p&gt;&#xA;&lt;p&gt;「我看到的線上分析指出，Gemini 3 Flash 的幻覺率其實蠻高的，」主持人說明。所謂幻覺，就是模型會自己編造事實——說一些聽起來很有道理，但實際上完全是捏造的內容。這在 AI 領域一直是個大問題，也是很多人不敢完全信任 AI 輸出的主要原因。但令人意外的是，即使幻覺率高，Gemini 3 Flash 在各種測試中的最終答案正確率卻沒有受到太大影響。&lt;/p&gt;&#xA;&lt;h2 id=&#34;幻覺式推理在思考過程中瞎掰卻能自我修正&#34;&gt;「幻覺式推理」：在思考過程中瞎掰，卻能自我修正&lt;/h2&gt;&#xA;&lt;p&gt;這個現象讓人困惑。按照常理，一個會亂編東西的 AI 應該更容易給出錯誤答案才對。為什麼 Gemini 3 Flash 能夠兩者兼得？Podcast 主持人給出了一個解釋：「這個 benchmark 的分析認為，模型幾乎是用幻覺的方式『推理出』答案。」&lt;/p&gt;&#xA;&lt;p&gt;想像一下這個場景：AI 在解決一個複雜問題時，它的思考過程（chain of thought）可能會走錯方向、編造一些不存在的中間步驟或假設。但因為它整體的推理能力夠強，它能夠在後續的思考中發現這些錯誤，然後自我修正，最終還是得到正確答案。換句話說，它在推理「過程」中會胡說八道，但推理「結果」卻是對的。&lt;/p&gt;&#xA;&lt;p&gt;這讓人想到 OpenAI 的 o3 模型。當時 o3 推出時也有類似的觀察——高智能伴隨著高幻覺率。主持人回憶道：「o3 在 benchmark 上同樣展現出高智能但高幻覺的特性，這跟它深度的 chain of thought 推理有關。」這些模型在思考過程中可能會偏離軌道，但它們的推理能力強到可以「想通」這些錯誤，最後還是走回正軌。&lt;/p&gt;&#xA;&lt;p&gt;這是一個有點弔詭的現象。傳統上我們認為幻覺是 AI 的缺陷，是需要被消除的問題。但這些觀察暗示，某種程度的「創造性瞎掰」可能反而有助於推理——只要 AI 有足夠的能力在後續步驟中自我糾正。就像人類在解題時，有時候也會先嘗試一個錯誤的方向，然後意識到不對，再回頭嘗試別的方法。&lt;/p&gt;&#xA;&lt;h2 id=&#34;這對-ai-開發者和使用者意味著什麼&#34;&gt;這對 AI 開發者和使用者意味著什麼&lt;/h2&gt;&#xA;&lt;p&gt;這個發現對實際應用有什麼影響？首先，它提醒我們不要只看單一指標。幻覺率高不一定代表模型不可靠，最終答案的正確率高也不代表模型的思考過程完全正確。評估 AI 模型需要更全面的視角，而不是只看某個 benchmark 的分數。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sergey Brin 給焦慮學生的建議：別因為 AI 會寫程式就轉去念比較文學</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251225-sergey-brin-dont-quit-cs-for-ai/</link>
      <pubDate>Thu, 25 Dec 2025 11:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251225-sergey-brin-dont-quit-cs-for-ai/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自史丹佛工程學院百年校慶活動，2025 年 12 月播出。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/0nlNX94FcUE&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;「我該不該繼續念電腦科學？」&lt;/p&gt;&#xA;&lt;p&gt;這個問題來自台下一位史丹佛大一新生。在場的是 Google 共同創辦人 Sergey Brin、史丹佛校長 Jonathan Levin，以及工程學院院長 Jennifer Widom。在 AI 似乎能做越來越多事情的今天，這個問題代表了無數學生的焦慮。&lt;/p&gt;&#xA;&lt;p&gt;Brin 的回答出人意料：「不要因為 AI 會寫程式就轉去念比較文學。老實說，AI 寫比較文學可能寫得更好。」&lt;/p&gt;&#xA;&lt;h2 id=&#34;一個反直覺的論點&#34;&gt;一個反直覺的論點&lt;/h2&gt;&#xA;&lt;p&gt;這個回答乍聽之下像是在開玩笑，但 Brin 認真地解釋了他的邏輯。&lt;/p&gt;&#xA;&lt;p&gt;AI 寫程式確實已經相當不錯，但程式碼有一個特性：錯誤會被立即發現。程式要嘛能跑，要嘛不能跑；要嘛通過測試，要嘛不通過。這意味著 AI 生成的程式碼需要人類持續監督和修正。「老實說，AI 有時候還是會犯蠻顯著的錯誤，」Brin 說，「所以你總是需要監督它。」&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sergey Brin 坦承：Google 發明了 Transformer，卻沒當回事</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251225-sergey-brin-google-ai-mistake/</link>
      <pubDate>Thu, 25 Dec 2025 10:00:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251225-sergey-brin-google-ai-mistake/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自史丹佛工程學院百年校慶活動，2025 年 12 月播出。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/0nlNX94FcUE&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;「我們確實搞砸了。」&lt;/p&gt;&#xA;&lt;p&gt;這句話出自 Google 共同創辦人 Sergey Brin，場合是史丹佛工程學院的百年校慶活動。台下坐著數百位學生，台上還有史丹佛校長 Jonathan Levin。在這個本該頌揚成就的場合，Brin 卻選擇談論 Google 在 AI 發展上的重大失誤。&lt;/p&gt;&#xA;&lt;h2 id=&#34;發明革命卻沒認真對待&#34;&gt;發明革命，卻沒認真對待&lt;/h2&gt;&#xA;&lt;p&gt;Brin 指的是 2017 年 Google 發表的那篇「Attention Is All You Need」論文——Transformer 架構的誕生。這個架構後來成為 ChatGPT、Claude、Gemini 等所有現代大型語言模型的基礎。換句話說，Google 發明了 AI 革命的核心技術。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Jeff Dean 的 35 年 AI 旅程——從大學論文到 Gemini</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251223-jeff-dean-35-years-ai-journey/</link>
      <pubDate>Tue, 23 Dec 2025 00:57:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251223-jeff-dean-35-years-ai-journey/</guid>
      <description>&lt;blockquote&gt;&#xA;&lt;p&gt;本文整理自 Stanford AI Club 邀請 Jeff Dean 的演講。&lt;/p&gt;&#xA;&lt;/blockquote&gt;&#xA;&lt;div class=&#34;media-embed&#34;&gt;&#xA;  &lt;div class=&#34;video-container&#34;&gt;&#xA;    &lt;iframe &#xA;      src=&#34;https://www.youtube.com/embed/AnTw_t21ayE&#34; &#xA;      allowfullscreen &#xA;      title=&#34;YouTube Video&#34;&#xA;      loading=&#34;lazy&#34;&#xA;    &gt;&lt;/iframe&gt;&#xA;  &lt;/div&gt;&#xA;&lt;/div&gt;&#xA;&#xA;&lt;style&gt;&#xA;.media-embed {&#xA;  max-width: 100%;&#xA;  margin: 1rem 0;&#xA;}&#xA;&#xA;.video-container {&#xA;  position: relative;&#xA;  padding-bottom: 56.25%;&#xA;  height: 0;&#xA;  overflow: hidden;&#xA;}&#xA;&#xA;.video-container iframe {&#xA;  position: absolute;&#xA;  top: 0;&#xA;  left: 0;&#xA;  width: 100%;&#xA;  height: 100%;&#xA;  border: 0;&#xA;  border-radius: 12px;&#xA;}&#xA;&lt;/style&gt;&#xA;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;1990-年一個大學生以為-32-核就能改變世界&#34;&gt;1990 年，一個大學生以為 32 核就能改變世界&lt;/h2&gt;&#xA;&lt;p&gt;1990 年，Jeff Dean 在大學畢業前寫了一篇關於神經網路的論文。當時他剛接觸到這個領域，立刻被迷住了。「這是一個很棒的抽象概念，」他回憶，「我們可以用它來建構模式辨識系統，解決各種問題。」於是他決定做一個野心勃勃的畢業專題：用系上那台 32 核處理器的電腦來並行訓練神經網路。&lt;/p&gt;&#xA;&lt;p&gt;他實作了兩種現在我們稱之為「資料平行」(data parallelism) 和「模型平行」(model parallelism) 的訓練方式，研究當處理器數量增加時，訓練速度如何提升。結果呢？「我完全錯了，」Jeff Dean 笑著說，「要訓練出真正好用的神經網路，需要的不是 32 倍的運算力，而是一百萬倍。」&lt;/p&gt;&#xA;&lt;p&gt;這個「錯誤」說明了一件事：神經網路的潛力比當時任何人想像的都大，但實現這個潛力需要的運算規模，也遠超過 1990 年代的技術能提供的。Jeff Dean 畢業後去做了其他事，但他一直惦記著這個想法。&lt;/p&gt;</description>
    </item>
    <item>
      <title>四大 AI 實驗室爭霸戰：一場史無前例的戰略博弈</title>
      <link>https://bnextmedia.github.io/AINEXT/posts/20251222-four-ai-labs-competition/</link>
      <pubDate>Mon, 22 Dec 2025 21:10:00 +0800</pubDate>
      <guid>https://bnextmedia.github.io/AINEXT/posts/20251222-four-ai-labs-competition/</guid>
      <description>&lt;p&gt;地球上只有四家 AI 實驗室真正重要：OpenAI、Google（Gemini）、Anthropic、和 XAI。這不是誇張的說法，而是基於技術能力、資本規模、和競爭態勢的冷靜評估。更值得關注的是，Meta、Microsoft、Amazon 這些擁有龐大資源的科技巨頭，投入數十億美元後依然未能躋身第一梯隊。這個現象本身就是理解當前 AI 競爭格局的重要線索。&lt;/p&gt;&#xA;&lt;p&gt;Gavin Baker 是 Atreides 投資公司創辦人，曾任 Fidelity 科技基金經理人，長期追蹤 AI 與半導體產業。在 2024 年 12 月與《Invest Like the Best》主持人 Patrick O&amp;rsquo;Shaughnessy 的對談中，他以投資人的視角，深入剖析了四大實驗室的競爭動態。這場分析揭示了一個比表面更複雜的戰略棋局，其中每個玩家都清楚知道自己的位置、對手的戰術、以及最終的獎品是什麼。&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;一個令人警醒的事實前沿模型比想像中更難做&#34;&gt;一個令人警醒的事實：前沿模型比想像中更難做&lt;/h2&gt;&#xA;&lt;p&gt;在分析四大實驗室之前，首先要理解一個產業現實：打造前沿 AI 模型比任何人預期的都要困難。這不是謙虛的說法，而是有具體案例支撐的事實。&lt;/p&gt;&#xA;&lt;p&gt;2025 年初，Mark Zuckerberg 公開表示他「高度確信」Meta 在年內某個時候會擁有「最好、最強大的 AI」。這是一個大膽的預測，來自一家擁有頂尖人才、龐大資本、和海量數據的公司。結果呢？Meta 的模型可能連前一百名都排不進去。這個預測錯得不能再錯。&lt;/p&gt;&#xA;&lt;p&gt;Meta 不是唯一失敗的例子。Microsoft 收購了 Inflection AI，這家公司的創辦人包括 DeepMind 的共同創辦人，擁有頂級的 AI 人才。Microsoft 當時暗示，他們預期內部模型的能力會快速提升，將越來越多的 AI 服務建立在自己的模型上。這個預期沒有實現。Amazon 收購了 Adept AI，推出了自己的 Nova 模型系列，但這些模型的表現連前二十名都進不了。三家擁有近乎無限資源的科技巨頭，三次失敗的嘗試。&lt;/p&gt;&#xA;&lt;p&gt;這些失敗揭示了什麼？首先，讓大規模 GPU 叢集保持「連貫」運作是一項極其困難的工程挑戰。「連貫」的意思是，叢集中的每一張 GPU 都知道其他 GPU 在做什麼，它們共享記憶體、透過高速網路協同運算。當你有兩萬張、十萬張、甚至二十萬張 GPU 時，保持它們的連貫需要頂尖的系統工程能力。物理定律限制了連貫叢集的上限大約在二十萬到三十萬張的量級，但達到這個上限之前，工程挑戰已經足夠艱鉅。&lt;/p&gt;&#xA;&lt;p&gt;更微妙的是，不同公司運作 GPU 的效率差異極大。如果你的叢集只有 30% 的正常運作時間，而競爭對手達到 90%，你們根本不是在同一個量級競爭。這種效率差異不容易從外部觀察到，但它直接決定了誰能更快地完成訓練、迭代更多的實驗、累積更多的改進。許多公司過去習慣於為成本最佳化運作基礎設施，而非為效能最佳化。這種組織慣性在 AI 訓練中成為致命的劣勢。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
